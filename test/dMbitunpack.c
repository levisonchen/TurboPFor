cc -msse3 -march=corei7-avx -mtune=corei7-avx -march=native -w -E -P bitunpack.c
typedef signed char int8_t;
typedef short int int16_t;
typedef int int32_t;
typedef long int int64_t;
typedef unsigned char uint8_t;
typedef unsigned short int uint16_t;
typedef unsigned int uint32_t;
typedef unsigned long int uint64_t;
typedef signed char int_least8_t;
typedef short int int_least16_t;
typedef int int_least32_t;
typedef long int int_least64_t;
typedef unsigned char uint_least8_t;
typedef unsigned short int uint_least16_t;
typedef unsigned int uint_least32_t;
typedef unsigned long int uint_least64_t;
typedef signed char int_fast8_t;
typedef long int int_fast16_t;
typedef long int int_fast32_t;
typedef long int int_fast64_t;
typedef unsigned char uint_fast8_t;
typedef unsigned long int uint_fast16_t;
typedef unsigned long int uint_fast32_t;
typedef unsigned long int uint_fast64_t;
typedef long int intptr_t;
typedef unsigned long int uintptr_t;
typedef long int intmax_t;
typedef unsigned long int uintmax_t;
static inline int __bsr32( int x) { asm("bsr  %1,%0" : "=r" (x) : "rm" (x) ); return x; }
static inline int bsr32( int x) { int b = -1; asm("bsrl %1,%0" : "+r" (b) : "rm" (x) ); return b + 1; }
static inline int bsr64(uint64_t x) { return x?64 - __builtin_clzll(x):0; }
static inline unsigned rol32(unsigned x, int s) { asm ("roll %%cl,%0" :"=r" (x) :"0" (x),"c" (s)); return x; }
static inline unsigned ror32(unsigned x, int s) { asm ("rorl %%cl,%0" :"=r" (x) :"0" (x),"c" (s)); return x; }
static inline uint64_t rol64(uint64_t x, int s) { asm ("rolq %%cl,%0" :"=r" (x) :"0" (x),"c" (s)); return x; }
static inline uint64_t ror64(uint64_t x, int s) { asm ("rorq %%cl,%0" :"=r" (x) :"0" (x),"c" (s)); return x; }

typedef long unsigned int size_t;
typedef unsigned char __u_char;
typedef unsigned short int __u_short;
typedef unsigned int __u_int;
typedef unsigned long int __u_long;
typedef signed char __int8_t;
typedef unsigned char __uint8_t;
typedef signed short int __int16_t;
typedef unsigned short int __uint16_t;
typedef signed int __int32_t;
typedef unsigned int __uint32_t;
typedef signed long int __int64_t;
typedef unsigned long int __uint64_t;
typedef long int __quad_t;
typedef unsigned long int __u_quad_t;
typedef unsigned long int __dev_t;
typedef unsigned int __uid_t;
typedef unsigned int __gid_t;
typedef unsigned long int __ino_t;
typedef unsigned long int __ino64_t;
typedef unsigned int __mode_t;
typedef unsigned long int __nlink_t;
typedef long int __off_t;
typedef long int __off64_t;
typedef int __pid_t;
typedef struct { int __val[2]; } __fsid_t;
typedef long int __clock_t;
typedef unsigned long int __rlim_t;
typedef unsigned long int __rlim64_t;
typedef unsigned int __id_t;
typedef long int __time_t;
typedef unsigned int __useconds_t;
typedef long int __suseconds_t;
typedef int __daddr_t;
typedef int __key_t;
typedef int __clockid_t;
typedef void * __timer_t;
typedef long int __blksize_t;
typedef long int __blkcnt_t;
typedef long int __blkcnt64_t;
typedef unsigned long int __fsblkcnt_t;
typedef unsigned long int __fsblkcnt64_t;
typedef unsigned long int __fsfilcnt_t;
typedef unsigned long int __fsfilcnt64_t;
typedef long int __fsword_t;
typedef long int __ssize_t;
typedef long int __syscall_slong_t;
typedef unsigned long int __syscall_ulong_t;
typedef __off64_t __loff_t;
typedef __quad_t *__qaddr_t;
typedef char *__caddr_t;
typedef long int __intptr_t;
typedef unsigned int __socklen_t;
struct _IO_FILE;

typedef struct _IO_FILE FILE;


typedef struct _IO_FILE __FILE;
typedef struct
{
  int __count;
  union
  {
    unsigned int __wch;
    char __wchb[4];
  } __value;
} __mbstate_t;
typedef struct
{
  __off_t __pos;
  __mbstate_t __state;
} _G_fpos_t;
typedef struct
{
  __off64_t __pos;
  __mbstate_t __state;
} _G_fpos64_t;
typedef __builtin_va_list __gnuc_va_list;
struct _IO_jump_t; struct _IO_FILE;
typedef void _IO_lock_t;
struct _IO_marker {
  struct _IO_marker *_next;
  struct _IO_FILE *_sbuf;
  int _pos;
};
enum __codecvt_result
{
  __codecvt_ok,
  __codecvt_partial,
  __codecvt_error,
  __codecvt_noconv
};
struct _IO_FILE {
  int _flags;
  char* _IO_read_ptr;
  char* _IO_read_end;
  char* _IO_read_base;
  char* _IO_write_base;
  char* _IO_write_ptr;
  char* _IO_write_end;
  char* _IO_buf_base;
  char* _IO_buf_end;
  char *_IO_save_base;
  char *_IO_backup_base;
  char *_IO_save_end;
  struct _IO_marker *_markers;
  struct _IO_FILE *_chain;
  int _fileno;
  int _flags2;
  __off_t _old_offset;
  unsigned short _cur_column;
  signed char _vtable_offset;
  char _shortbuf[1];
  _IO_lock_t *_lock;
  __off64_t _offset;
  void *__pad1;
  void *__pad2;
  void *__pad3;
  void *__pad4;
  size_t __pad5;
  int _mode;
  char _unused2[15 * sizeof (int) - 4 * sizeof (void *) - sizeof (size_t)];
};
typedef struct _IO_FILE _IO_FILE;
struct _IO_FILE_plus;
extern struct _IO_FILE_plus _IO_2_1_stdin_;
extern struct _IO_FILE_plus _IO_2_1_stdout_;
extern struct _IO_FILE_plus _IO_2_1_stderr_;
typedef __ssize_t __io_read_fn (void *__cookie, char *__buf, size_t __nbytes);
typedef __ssize_t __io_write_fn (void *__cookie, const char *__buf,
     size_t __n);
typedef int __io_seek_fn (void *__cookie, __off64_t *__pos, int __w);
typedef int __io_close_fn (void *__cookie);
extern int __underflow (_IO_FILE *);
extern int __uflow (_IO_FILE *);
extern int __overflow (_IO_FILE *, int);
extern int _IO_getc (_IO_FILE *__fp);
extern int _IO_putc (int __c, _IO_FILE *__fp);
extern int _IO_feof (_IO_FILE *__fp) __attribute__ ((__nothrow__ , __leaf__));
extern int _IO_ferror (_IO_FILE *__fp) __attribute__ ((__nothrow__ , __leaf__));
extern int _IO_peekc_locked (_IO_FILE *__fp);
extern void _IO_flockfile (_IO_FILE *) __attribute__ ((__nothrow__ , __leaf__));
extern void _IO_funlockfile (_IO_FILE *) __attribute__ ((__nothrow__ , __leaf__));
extern int _IO_ftrylockfile (_IO_FILE *) __attribute__ ((__nothrow__ , __leaf__));
extern int _IO_vfscanf (_IO_FILE * __restrict, const char * __restrict,
   __gnuc_va_list, int *__restrict);
extern int _IO_vfprintf (_IO_FILE *__restrict, const char *__restrict,
    __gnuc_va_list);
extern __ssize_t _IO_padn (_IO_FILE *, int, __ssize_t);
extern size_t _IO_sgetn (_IO_FILE *, void *, size_t);
extern __off64_t _IO_seekoff (_IO_FILE *, __off64_t, int, int);
extern __off64_t _IO_seekpos (_IO_FILE *, __off64_t, int);
extern void _IO_free_backup_area (_IO_FILE *) __attribute__ ((__nothrow__ , __leaf__));
typedef __gnuc_va_list va_list;
typedef __off_t off_t;
typedef __ssize_t ssize_t;

typedef _G_fpos_t fpos_t;

extern struct _IO_FILE *stdin;
extern struct _IO_FILE *stdout;
extern struct _IO_FILE *stderr;

extern int remove (const char *__filename) __attribute__ ((__nothrow__ , __leaf__));
extern int rename (const char *__old, const char *__new) __attribute__ ((__nothrow__ , __leaf__));

extern int renameat (int __oldfd, const char *__old, int __newfd,
       const char *__new) __attribute__ ((__nothrow__ , __leaf__));

extern FILE *tmpfile (void) ;
extern char *tmpnam (char *__s) __attribute__ ((__nothrow__ , __leaf__)) ;

extern char *tmpnam_r (char *__s) __attribute__ ((__nothrow__ , __leaf__)) ;
extern char *tempnam (const char *__dir, const char *__pfx)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__malloc__)) ;

extern int fclose (FILE *__stream);
extern int fflush (FILE *__stream);

extern int fflush_unlocked (FILE *__stream);

extern FILE *fopen (const char *__restrict __filename,
      const char *__restrict __modes) ;
extern FILE *freopen (const char *__restrict __filename,
        const char *__restrict __modes,
        FILE *__restrict __stream) ;

extern FILE *fdopen (int __fd, const char *__modes) __attribute__ ((__nothrow__ , __leaf__)) ;
extern FILE *fmemopen (void *__s, size_t __len, const char *__modes)
  __attribute__ ((__nothrow__ , __leaf__)) ;
extern FILE *open_memstream (char **__bufloc, size_t *__sizeloc) __attribute__ ((__nothrow__ , __leaf__)) ;

extern void setbuf (FILE *__restrict __stream, char *__restrict __buf) __attribute__ ((__nothrow__ , __leaf__));
extern int setvbuf (FILE *__restrict __stream, char *__restrict __buf,
      int __modes, size_t __n) __attribute__ ((__nothrow__ , __leaf__));

extern void setbuffer (FILE *__restrict __stream, char *__restrict __buf,
         size_t __size) __attribute__ ((__nothrow__ , __leaf__));
extern void setlinebuf (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__));

extern int fprintf (FILE *__restrict __stream,
      const char *__restrict __format, ...);
extern int printf (const char *__restrict __format, ...);
extern int sprintf (char *__restrict __s,
      const char *__restrict __format, ...) __attribute__ ((__nothrow__));
extern int vfprintf (FILE *__restrict __s, const char *__restrict __format,
       __gnuc_va_list __arg);
extern int vprintf (const char *__restrict __format, __gnuc_va_list __arg);
extern int vsprintf (char *__restrict __s, const char *__restrict __format,
       __gnuc_va_list __arg) __attribute__ ((__nothrow__));


extern int snprintf (char *__restrict __s, size_t __maxlen,
       const char *__restrict __format, ...)
     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 3, 4)));
extern int vsnprintf (char *__restrict __s, size_t __maxlen,
        const char *__restrict __format, __gnuc_va_list __arg)
     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 3, 0)));

extern int vdprintf (int __fd, const char *__restrict __fmt,
       __gnuc_va_list __arg)
     __attribute__ ((__format__ (__printf__, 2, 0)));
extern int dprintf (int __fd, const char *__restrict __fmt, ...)
     __attribute__ ((__format__ (__printf__, 2, 3)));

extern int fscanf (FILE *__restrict __stream,
     const char *__restrict __format, ...) ;
extern int scanf (const char *__restrict __format, ...) ;
extern int sscanf (const char *__restrict __s,
     const char *__restrict __format, ...) __attribute__ ((__nothrow__ , __leaf__));
extern int fscanf (FILE *__restrict __stream, const char *__restrict __format, ...) __asm__ ("" "__isoc99_fscanf") ;
extern int scanf (const char *__restrict __format, ...) __asm__ ("" "__isoc99_scanf") ;
extern int sscanf (const char *__restrict __s, const char *__restrict __format, ...) __asm__ ("" "__isoc99_sscanf") __attribute__ ((__nothrow__ , __leaf__));


extern int vfscanf (FILE *__restrict __s, const char *__restrict __format,
      __gnuc_va_list __arg)
     __attribute__ ((__format__ (__scanf__, 2, 0))) ;
extern int vscanf (const char *__restrict __format, __gnuc_va_list __arg)
     __attribute__ ((__format__ (__scanf__, 1, 0))) ;
extern int vsscanf (const char *__restrict __s,
      const char *__restrict __format, __gnuc_va_list __arg)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__format__ (__scanf__, 2, 0)));
extern int vfscanf (FILE *__restrict __s, const char *__restrict __format, __gnuc_va_list __arg) __asm__ ("" "__isoc99_vfscanf")
     __attribute__ ((__format__ (__scanf__, 2, 0))) ;
extern int vscanf (const char *__restrict __format, __gnuc_va_list __arg) __asm__ ("" "__isoc99_vscanf")
     __attribute__ ((__format__ (__scanf__, 1, 0))) ;
extern int vsscanf (const char *__restrict __s, const char *__restrict __format, __gnuc_va_list __arg) __asm__ ("" "__isoc99_vsscanf") __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__format__ (__scanf__, 2, 0)));


extern int fgetc (FILE *__stream);
extern int getc (FILE *__stream);
extern int getchar (void);

extern int getc_unlocked (FILE *__stream);
extern int getchar_unlocked (void);
extern int fgetc_unlocked (FILE *__stream);

extern int fputc (int __c, FILE *__stream);
extern int putc (int __c, FILE *__stream);
extern int putchar (int __c);

extern int fputc_unlocked (int __c, FILE *__stream);
extern int putc_unlocked (int __c, FILE *__stream);
extern int putchar_unlocked (int __c);
extern int getw (FILE *__stream);
extern int putw (int __w, FILE *__stream);

extern char *fgets (char *__restrict __s, int __n, FILE *__restrict __stream)
     ;

extern __ssize_t __getdelim (char **__restrict __lineptr,
          size_t *__restrict __n, int __delimiter,
          FILE *__restrict __stream) ;
extern __ssize_t getdelim (char **__restrict __lineptr,
        size_t *__restrict __n, int __delimiter,
        FILE *__restrict __stream) ;
extern __ssize_t getline (char **__restrict __lineptr,
       size_t *__restrict __n,
       FILE *__restrict __stream) ;

extern int fputs (const char *__restrict __s, FILE *__restrict __stream);
extern int puts (const char *__s);
extern int ungetc (int __c, FILE *__stream);
extern size_t fread (void *__restrict __ptr, size_t __size,
       size_t __n, FILE *__restrict __stream) ;
extern size_t fwrite (const void *__restrict __ptr, size_t __size,
        size_t __n, FILE *__restrict __s);

extern size_t fread_unlocked (void *__restrict __ptr, size_t __size,
         size_t __n, FILE *__restrict __stream) ;
extern size_t fwrite_unlocked (const void *__restrict __ptr, size_t __size,
          size_t __n, FILE *__restrict __stream);

extern int fseek (FILE *__stream, long int __off, int __whence);
extern long int ftell (FILE *__stream) ;
extern void rewind (FILE *__stream);

extern int fseeko (FILE *__stream, __off_t __off, int __whence);
extern __off_t ftello (FILE *__stream) ;

extern int fgetpos (FILE *__restrict __stream, fpos_t *__restrict __pos);
extern int fsetpos (FILE *__stream, const fpos_t *__pos);


extern void clearerr (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__));
extern int feof (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int ferror (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__)) ;

extern void clearerr_unlocked (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__));
extern int feof_unlocked (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int ferror_unlocked (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__)) ;

extern void perror (const char *__s);

extern int sys_nerr;
extern const char *const sys_errlist[];
extern int fileno (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int fileno_unlocked (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__)) ;
extern FILE *popen (const char *__command, const char *__modes) ;
extern int pclose (FILE *__stream);
extern char *ctermid (char *__s) __attribute__ ((__nothrow__ , __leaf__));
extern void flockfile (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__));
extern int ftrylockfile (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__)) ;
extern void funlockfile (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__));

extern unsigned char _vtab32_[];
static inline unsigned vblen16(unsigned short x) { return ((x) < (((254 - (64/8 - 3)) - (1<<3)) - (1<<6))?1:((x) < ((((254 - (64/8 - 3)) - (1<<3)) - (1<<6)) + (1 << (8+6)))?2:((x) < (((((254 - (64/8 - 3)) - (1<<3)) - (1<<6)) + (1 << (8+6))) + (1 << (16+3))))?3:(bsr32(x)+7)/8+1)); }
static inline unsigned vblen32(unsigned x) { return ((x) < (((254 - (64/8 - 3)) - (1<<3)) - (1<<6))?1:((x) < ((((254 - (64/8 - 3)) - (1<<3)) - (1<<6)) + (1 << (8+6)))?2:((x) < (((((254 - (64/8 - 3)) - (1<<3)) - (1<<6)) + (1 << (8+6))) + (1 << (16+3))))?3:(bsr32(x)+7)/8+1)); }
static inline unsigned vblen64(uint64_t x) { return ((x) < (((254 - (64/8 - 3)) - (1<<3)) - (1<<6))?1:((x) < ((((254 - (64/8 - 3)) - (1<<3)) - (1<<6)) + (1 << (8+6)))?2:((x) < (((((254 - (64/8 - 3)) - (1<<3)) - (1<<6)) + (1 << (8+6))) + (1 << (16+3))))?3:(bsr32(x)+7)/8+1)); }
static inline unsigned vbvlen16(unsigned x) { return ((x) < (((254 - (64/8 - 3)) - (1<<3)) - (1<<6))?1:((x) < ((254 - (64/8 - 3)) - (1<<3))?2:((x) < (254 - (64/8 - 3)))?3:(x-(254 - (64/8 - 3))))); }
static inline unsigned vbvlen32(unsigned x) { return ((x) < (((254 - (64/8 - 3)) - (1<<3)) - (1<<6))?1:((x) < ((254 - (64/8 - 3)) - (1<<3))?2:((x) < (254 - (64/8 - 3)))?3:(x-(254 - (64/8 - 3))))); }
static inline unsigned vbvlen64(unsigned x) { return ((x) < (((254 - (64/8 - 3)) - (1<<3)) - (1<<6))?1:((x) < ((254 - (64/8 - 3)) - (1<<3))?2:((x) < (254 - (64/8 - 3)))?3:(x-(254 - (64/8 - 3))))); }
unsigned char *vbenc16( unsigned short *__restrict in, unsigned n, unsigned char *__restrict out);
unsigned char *vbenc32( unsigned *__restrict in, unsigned n, unsigned char *__restrict out);
unsigned char *vbenc64( uint64_t *__restrict in, unsigned n, unsigned char *__restrict out);
unsigned char *vbdec16( unsigned char *__restrict in, unsigned n, unsigned short *__restrict out);
unsigned char *vbdec32( unsigned char *__restrict in, unsigned n, unsigned *__restrict out);
unsigned char *vbdec64( unsigned char *__restrict in, unsigned n, uint64_t *__restrict out);
unsigned short vbgetx16( unsigned char *__restrict in, unsigned idx);
unsigned vbgetx32( unsigned char *__restrict in, unsigned idx);
uint64_t vbgetx64( unsigned char *__restrict in, unsigned idx);
unsigned vbgeteq16( unsigned char **__restrict in, unsigned n, unsigned idx, unsigned short key);
unsigned vbgeteq32( unsigned char **__restrict in, unsigned n, unsigned idx, unsigned key);
unsigned vbgeteq64( unsigned char **__restrict in, unsigned n, unsigned idx, uint64_t key);
unsigned char *vbdenc16( unsigned short *__restrict in, unsigned n, unsigned char *__restrict out, unsigned short start);
unsigned char *vbdenc32( unsigned *__restrict in, unsigned n, unsigned char *__restrict out, unsigned start);
unsigned char *vbdenc64( uint64_t *__restrict in, unsigned n, unsigned char *__restrict out, uint64_t start);
unsigned char *vbddec16( unsigned char *__restrict in, unsigned n, unsigned short *__restrict out, unsigned short start);
unsigned char *vbddec32( unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start);
unsigned char *vbddec64( unsigned char *__restrict in, unsigned n, uint64_t *__restrict out, uint64_t start);
unsigned short vbdgetx16( unsigned char *__restrict in, unsigned idx, unsigned short start);
unsigned vbdgetx32( unsigned char *__restrict in, unsigned idx, unsigned start);
uint64_t vbdgetx64( unsigned char *__restrict in, unsigned idx, uint64_t start);
unsigned vbdgetgeq16( unsigned char **__restrict in, unsigned n, unsigned idx, unsigned short *key, unsigned short start);
unsigned vbdgetgeq32( unsigned char **__restrict in, unsigned n, unsigned idx, unsigned *key, unsigned start);
unsigned vbdgetgeq64( unsigned char **__restrict in, unsigned n, unsigned idx, uint64_t *key, uint64_t start);
unsigned char *vbd1enc16(unsigned short *__restrict in, unsigned n, unsigned char *__restrict out, unsigned short start);
unsigned char *vbd1enc32(unsigned *__restrict in, unsigned n, unsigned char *__restrict out, unsigned start);
unsigned char *vbd1enc64(uint64_t *__restrict in, unsigned n, unsigned char *__restrict out, uint64_t start);
unsigned char *vbd1dec16(unsigned char *__restrict in, unsigned n, unsigned short *__restrict out, unsigned short start);
unsigned char *vbd1dec32(unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start);
unsigned char *vbd1dec64(unsigned char *__restrict in, unsigned n, uint64_t *__restrict out, uint64_t start);
unsigned short vbd1getx16( unsigned char *__restrict in, unsigned idx, unsigned short start);
unsigned vbd1getx32( unsigned char *__restrict in, unsigned idx, unsigned start);
uint64_t vbd1getx64( unsigned char *__restrict in, unsigned idx, uint64_t start);
unsigned vbd1getgeq16( unsigned char **__restrict in, unsigned n, unsigned idx, unsigned short *key, unsigned short start);
unsigned vbd1getgeq32( unsigned char **__restrict in, unsigned n, unsigned idx, unsigned *key, unsigned start);
unsigned vbd1getgeq64( unsigned char **__restrict in, unsigned n, unsigned idx, uint64_t *key, uint64_t start);
unsigned char *vbzenc8( unsigned char *__restrict in, unsigned n, unsigned char *__restrict out, unsigned char start);
unsigned char *vbzenc16( unsigned short *__restrict in, unsigned n, unsigned char *__restrict out, unsigned short start);
unsigned char *vbzenc32( unsigned *__restrict in, unsigned n, unsigned char *__restrict out, unsigned start);
unsigned char *vbzenc64( uint64_t *__restrict in, unsigned n, unsigned char *__restrict out, uint64_t start);
unsigned char *vbzdec8( unsigned char *__restrict in, unsigned n, unsigned char *__restrict out, unsigned char start);
unsigned char *vbzdec16( unsigned char *__restrict in, unsigned n, unsigned short *__restrict out, unsigned short start);
unsigned char *vbzdec32( unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start);
unsigned char *vbzdec64( unsigned char *__restrict in, unsigned n, uint64_t *__restrict out, uint64_t start);
unsigned char *vbddenc16( unsigned short *__restrict in, unsigned n, unsigned char *__restrict out, unsigned short start);
unsigned char *vbddenc32( unsigned *__restrict in, unsigned n, unsigned char *__restrict out, unsigned start);
unsigned char *vbddenc64( uint64_t *__restrict in, unsigned n, unsigned char *__restrict out, uint64_t start);
unsigned char *vbdddec16( unsigned char *__restrict in, unsigned n, unsigned short *__restrict out, unsigned short start);
unsigned char *vbdddec32( unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start);
unsigned char *vbdddec64( unsigned char *__restrict in, unsigned n, uint64_t *__restrict out, uint64_t start);
unsigned short vbzgetx16( unsigned char *__restrict in, unsigned idx, unsigned short start);
unsigned vbzgetx32( unsigned char *__restrict in, unsigned idx, unsigned start);
uint64_t vbzgetx64( unsigned char *__restrict in, unsigned idx, uint64_t start);
typedef long int ptrdiff_t;
typedef int wchar_t;
typedef struct {
  long long __max_align_ll __attribute__((__aligned__(__alignof__(long long))));
  long double __max_align_ld __attribute__((__aligned__(__alignof__(long double))));
} max_align_t;
size_t bitnpack8( uint8_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnpack16( uint16_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnpack32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnpack64( uint64_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnpack128v16( uint16_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnpack128v32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnpack128v64( uint64_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnpack256v32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitndpack8( uint8_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitndpack16( uint16_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitndpack32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitndpack64( uint64_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitndpack128v16( uint16_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitndpack128v32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitndpack256v32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnd1pack8( uint8_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnd1pack16( uint16_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnd1pack32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnd1pack64( uint64_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnd1pack128v16( uint16_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnd1pack128v32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnd1pack256v32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnzpack8( uint8_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnzpack16( uint16_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnzpack32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnzpack64( uint64_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnzpack128v16( uint16_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnzpack128v32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnzpack256v32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnfpack8( uint8_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnfpack16( uint16_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnfpack32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnfpack64( uint64_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnfpack128v16( uint16_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnfpack128v32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnfpack256v32( uint32_t *__restrict in, size_t n, unsigned char *__restrict out);
size_t bitnunpack8( unsigned char *__restrict in, size_t n, uint8_t *__restrict out);
size_t bitnunpack16( unsigned char *__restrict in, size_t n, uint16_t *__restrict out);
size_t bitnunpack32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
size_t bitnunpack64( unsigned char *__restrict in, size_t n, uint64_t *__restrict out);
size_t bitnunpack128v16( unsigned char *__restrict in, size_t n, uint16_t *__restrict out);
size_t bitnunpack128v32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
size_t bitnunpack128v64( unsigned char *__restrict in, size_t n, uint64_t *__restrict out);
size_t bitnunpack256v32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
size_t bitndunpack8( unsigned char *__restrict in, size_t n, uint8_t *__restrict out);
size_t bitndunpack16( unsigned char *__restrict in, size_t n, uint16_t *__restrict out);
size_t bitndunpack32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
size_t bitndunpack64( unsigned char *__restrict in, size_t n, uint64_t *__restrict out);
size_t bitndunpack128v16( unsigned char *__restrict in, size_t n, uint16_t *__restrict out);
size_t bitndunpack128v32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
size_t bitndunpack256v32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
size_t bitnd1unpack8( unsigned char *__restrict in, size_t n, uint8_t *__restrict out);
size_t bitnd1unpack16( unsigned char *__restrict in, size_t n, uint16_t *__restrict out);
size_t bitnd1unpack32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
size_t bitnd1unpack64( unsigned char *__restrict in, size_t n, uint64_t *__restrict out);
size_t bitnd1unpack128v16(unsigned char *__restrict in, size_t n, uint16_t *__restrict out);
size_t bitnd1unpack128v32(unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
size_t bitnd1unpack256v32(unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
size_t bitnzunpack8( unsigned char *__restrict in, size_t n, uint8_t *__restrict out);
size_t bitnzunpack16( unsigned char *__restrict in, size_t n, uint16_t *__restrict out);
size_t bitnzunpack32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
size_t bitnzunpack64( unsigned char *__restrict in, size_t n, uint64_t *__restrict out);
size_t bitnzunpack128v16( unsigned char *__restrict in, size_t n, uint16_t *__restrict out);
size_t bitnzunpack128v32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
size_t bitnzunpack256v32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
size_t bitnfunpack8( unsigned char *__restrict in, size_t n, uint8_t *__restrict out);
size_t bitnfunpack16( unsigned char *__restrict in, size_t n, uint16_t *__restrict out);
size_t bitnfunpack32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
size_t bitnfunpack64( unsigned char *__restrict in, size_t n, uint64_t *__restrict out);
size_t bitnfunpack128v16( unsigned char *__restrict in, size_t n, uint16_t *__restrict out);
size_t bitnfunpack128v32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
size_t bitnfunpack256v32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out);
unsigned char *bitpack8( uint8_t *__restrict in, unsigned n, const unsigned char *__restrict out , unsigned b);
unsigned char *bitpack16( uint16_t *__restrict in, unsigned n, const unsigned char *__restrict out , unsigned b);
unsigned char *bitpack32( uint32_t *__restrict in, unsigned n, const unsigned char *__restrict out , unsigned b);
unsigned char *bitpack64( uint64_t *__restrict in, unsigned n, const unsigned char *__restrict out , unsigned b);
unsigned char *bitdpack8( uint8_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint8_t start, unsigned b);
unsigned char *bitdpack16( uint16_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint16_t start, unsigned b);
unsigned char *bitdpack32( uint32_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint32_t start, unsigned b);
unsigned char *bitdpack64( uint64_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint64_t start, unsigned b);
unsigned char *bitd1pack8( uint8_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint8_t start, unsigned b);
unsigned char *bitd1pack16( uint16_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint16_t start, unsigned b);
unsigned char *bitd1pack32( uint32_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint32_t start, unsigned b);
unsigned char *bitd1pack64( uint64_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint64_t start, unsigned b);
unsigned char *bitfpack8( uint8_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint8_t start, unsigned b);
unsigned char *bitfpack16( uint16_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint16_t start, unsigned b);
unsigned char *bitfpack32( uint32_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint32_t start, unsigned b);
unsigned char *bitfpack64( uint64_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint64_t start, unsigned b);
unsigned char *bitf1pack8( uint8_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint8_t start, unsigned b);
unsigned char *bitf1pack16( uint16_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint16_t start, unsigned b);
unsigned char *bitf1pack32( uint32_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint32_t start, unsigned b);
unsigned char *bitf1pack64( uint64_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint64_t start, unsigned b);
unsigned char *bitzpack8( uint8_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint8_t start, unsigned b);
unsigned char *bitzpack16( uint16_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint16_t start, unsigned b);
unsigned char *bitzpack32( uint32_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint32_t start, unsigned b);
unsigned char *bitzpack64( uint64_t *__restrict in, unsigned n, const unsigned char *__restrict out, uint64_t start, unsigned b);
unsigned char *bitpack128v16( unsigned short *__restrict in, unsigned n, unsigned char *__restrict out , unsigned b);
unsigned char *bitdpack128v16( unsigned short *__restrict in, unsigned n, unsigned char *__restrict out, unsigned short start, unsigned b);
unsigned char *bitd1pack128v16(unsigned short *__restrict in, unsigned n, unsigned char *__restrict out, unsigned short start, unsigned b);
unsigned char *bitfpack128v16( unsigned short *__restrict in, unsigned n, unsigned char *__restrict out, unsigned short start, unsigned b);
unsigned char *bitf1pack128v16(unsigned short *__restrict in, unsigned n, unsigned char *__restrict out, unsigned short start, unsigned b);
unsigned char *bitzpack128v16( unsigned short *__restrict in, unsigned n, unsigned char *__restrict out, unsigned short start, unsigned b);
unsigned char *bitpack128v32( unsigned *__restrict in, unsigned n, unsigned char *__restrict out , unsigned b);
unsigned char *bitdpack128v32( unsigned *__restrict in, unsigned n, unsigned char *__restrict out, unsigned start, unsigned b);
unsigned char *bitd1pack128v32(unsigned *__restrict in, unsigned n, unsigned char *__restrict out, unsigned start, unsigned b);
unsigned char *bitfpack128v32( unsigned *__restrict in, unsigned n, unsigned char *__restrict out, unsigned start, unsigned b);
unsigned char *bitf1pack128v32(unsigned *__restrict in, unsigned n, unsigned char *__restrict out, unsigned start, unsigned b);
unsigned char *bitzpack128v32( unsigned *__restrict in, unsigned n, unsigned char *__restrict out, unsigned start, unsigned b);
unsigned char *bitpack128v64( uint64_t *__restrict in, unsigned n, unsigned char *__restrict out , unsigned b);
unsigned char *bitpack256v32( unsigned *__restrict in, unsigned n, unsigned char *__restrict out , unsigned b);
unsigned char *bitdpack256v32( unsigned *__restrict in, unsigned n, unsigned char *__restrict out, unsigned start, unsigned b);
unsigned char *bitd1pack256v32(unsigned *__restrict in, unsigned n, unsigned char *__restrict out, unsigned start, unsigned b);
unsigned char *bitfpack256v32( unsigned *__restrict in, unsigned n, unsigned char *__restrict out, unsigned start, unsigned b);
unsigned char *bitf1pack256v32(unsigned *__restrict in, unsigned n, unsigned char *__restrict out, unsigned start, unsigned b);
unsigned char *bitzpack256v32( unsigned *__restrict in, unsigned n, unsigned char *__restrict out, unsigned start, unsigned b);
unsigned char *bitunpack8( const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out, unsigned b);
unsigned char *bitunpack16( const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out, unsigned b);
unsigned char *bitunpack32( const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out, unsigned b);
unsigned char *bitunpack64( const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out, unsigned b);
static inline __attribute__((always_inline)) unsigned bitgetx32(const unsigned char *__restrict in, unsigned idx, unsigned b) { unsigned bidx = b*idx; return (((*(uint64_t *)((uint32_t *)in+(bidx>>5))) >> (bidx&0x1f)) & ((1ull<<(b))-1)); }
static inline __attribute__((always_inline)) unsigned _bitgetx32(const unsigned char *__restrict in, uint64_t bidx, unsigned b) { return (((*(uint64_t *)((uint32_t *)in+(bidx>>5))) >> (bidx&0x1f)) & ((1ull<<(b))-1)); }
static inline __attribute__((always_inline)) unsigned bitgetx8( const unsigned char *__restrict in, unsigned idx, unsigned b) { unsigned bidx = b*idx; return (((*(unsigned short *)((uint16_t *)in+(bidx>>4))) >> (bidx& 0xf)) & ((1u <<(b))-1)); }
static inline __attribute__((always_inline)) unsigned _bitgetx8( const unsigned char *__restrict in, unsigned bidx, unsigned b) { return (((*(unsigned short *)((uint16_t *)in+(bidx>>4))) >> (bidx& 0xf)) & ((1u <<(b))-1)); }
static inline __attribute__((always_inline)) unsigned bitgetx16(const unsigned char *__restrict in, unsigned idx, unsigned b) { unsigned bidx = b*idx; return (((*(unsigned *)((uint32_t *)in+(bidx>>4))) >> (bidx& 0xf)) & ((1u <<(b))-1)); }
static inline __attribute__((always_inline)) unsigned _bitgetx16(const unsigned char *__restrict in, unsigned bidx, unsigned b) { return (((*(unsigned *)((uint32_t *)in+(bidx>>4))) >> (bidx& 0xf)) & ((1u <<(b))-1)); }
static inline __attribute__((always_inline)) void bitsetx16(const unsigned char *__restrict in, unsigned idx, unsigned v, unsigned b) { unsigned bidx = b*idx; unsigned *p = (unsigned *) in+(bidx>>4) ; *p = ( *p & ~(((1u <<b)-1) << (bidx& 0xf)) ) | v<<(bidx& 0xf);}
static inline __attribute__((always_inline)) void bitsetx32(const unsigned char *__restrict in, unsigned idx, unsigned v, unsigned b) { unsigned bidx = b*idx; unsigned long long *p = (unsigned long long *)((unsigned *)in+(bidx>>5)); *p = ( *p & ~(((1ull<<b)-1) << (bidx&0x1f)) ) | (unsigned long long)v<<(bidx&0x1f);}
unsigned char *bitdunpack8( const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out, uint8_t start, unsigned b);
unsigned char *bitdunpack16( const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out, uint16_t start, unsigned b);
unsigned char *bitdunpack32( const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out, uint32_t start, unsigned b);
unsigned char *bitdunpack64( const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out, uint64_t start, unsigned b);
unsigned char *bitd1unpack8( const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out, uint8_t start, unsigned b);
unsigned char *bitd1unpack16(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out, uint16_t start, unsigned b);
unsigned char *bitd1unpack32(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out, uint32_t start, unsigned b);
unsigned char *bitd1unpack64(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out, uint64_t start, unsigned b);
unsigned char *bitzunpack8( const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out, uint8_t start, unsigned b);
unsigned char *bitzunpack16( const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out, uint16_t start, unsigned b);
unsigned char *bitzunpack32( const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out, uint32_t start, unsigned b);
unsigned char *bitzunpack64( const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out, uint64_t start, unsigned b);
unsigned char *bitfunpack8( const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out, uint8_t start, unsigned b);
unsigned char *bitfunpack16( const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out, uint16_t start, unsigned b);
unsigned char *bitfunpack32( const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out, uint32_t start, unsigned b);
unsigned char *bitfunpack64( const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out, uint64_t start, unsigned b);
unsigned char *bitf1unpack8( const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out, uint8_t start, unsigned b);
unsigned char *bitf1unpack16(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out, uint16_t start, unsigned b);
unsigned char *bitf1unpack32(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out, uint32_t start, unsigned b);
unsigned char *bitf1unpack64(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out, uint64_t start, unsigned b);
unsigned char *bitunpack128v16( const unsigned char *__restrict in, unsigned n, unsigned short *__restrict out, unsigned b);
unsigned char *bitzunpack128v16( const unsigned char *__restrict in, unsigned n, unsigned short *__restrict out, unsigned short start, unsigned b);
unsigned char *bitdunpack128v16( const unsigned char *__restrict in, unsigned n, unsigned short *__restrict out, unsigned short start, unsigned b);
unsigned char *bitd1unpack128v16(const unsigned char *__restrict in, unsigned n, unsigned short *__restrict out, unsigned short start, unsigned b);
unsigned char *bitfunpack128v16( const unsigned char *__restrict in, unsigned n, unsigned short *__restrict out, unsigned short start, unsigned b);
unsigned char *bitf1unpack128v16(const unsigned char *__restrict in, unsigned n, unsigned short *__restrict out, unsigned short start, unsigned b);
unsigned char *bitunpack128v32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned b);
unsigned char *bitzunpack128v32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b);
unsigned char *bitdunpack128v32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b);
unsigned char *bitd1unpack128v32(const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b);
unsigned char *bitfunpack128v32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b);
unsigned char *bitf1unpack128v32(const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b);
unsigned char *bitunpack256w32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned b);
unsigned char *bitunpack128v64( const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out, unsigned b);
unsigned char *bitunpack256v32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned b);
unsigned char *bitzunpack256v32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b);
unsigned char *bitdunpack256v32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b);
unsigned char *bitd1unpack256v32(const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b);
unsigned char *bitfunpack256v32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b);
unsigned char *bitf1unpack256v32(const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b);
unsigned char *bitunpack128h32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned b);
unsigned char *bitzunpack128h32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b);
unsigned char *bitdunpack128h32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b);
unsigned char *bitd1unpack128h32(const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b);
unsigned char *_bitunpack128v16( const unsigned char *__restrict in, unsigned n, unsigned short *__restrict out, unsigned b, unsigned short *__restrict pex, unsigned char *bb);
unsigned char *_bitdunpack128v16( const unsigned char *__restrict in, unsigned n, unsigned short *__restrict out, unsigned short start, unsigned b, unsigned short *__restrict pex, unsigned char *bb);
unsigned char *_bitd1unpack128v16(const unsigned char *__restrict in, unsigned n, unsigned short *__restrict out, unsigned short start, unsigned b, unsigned short *__restrict pex, unsigned char *bb);
unsigned char *_bitzunpack128v16( const unsigned char *__restrict in, unsigned n, unsigned short *__restrict out, unsigned short start, unsigned b, unsigned short *__restrict pex, unsigned char *bb);
unsigned char *_bitunpack128v32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned b, unsigned *__restrict pex, unsigned char *bb);
unsigned char *_bitdunpack128v32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b, unsigned *__restrict pex, unsigned char *bb);
unsigned char *_bitd1unpack128v32(const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b, unsigned *__restrict pex, unsigned char *bb);
unsigned char *_bitzunpack128v32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b, unsigned *__restrict pex, unsigned char *bb);
unsigned char *_bitunpack128h32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned b, unsigned *__restrict pex, unsigned char *bb);
unsigned char *_bitdunpack128h32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b, unsigned *__restrict pex, unsigned char *bb);
unsigned char *_bitd1unpack128h32(const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b, unsigned *__restrict pex, unsigned char *bb);
unsigned char *_bitunpack128v64( const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out, unsigned b, uint32_t *__restrict pex, unsigned char *bb);
unsigned char *_bitunpack256v32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned b, unsigned *__restrict pex, unsigned char *bb);
unsigned char *_bitdunpack256v32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b, unsigned *__restrict pex, unsigned char *bb);
unsigned char *_bitd1unpack256v32(const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b, unsigned *__restrict pex, unsigned char *bb);
unsigned char *_bitzunpack256v32( const unsigned char *__restrict in, unsigned n, unsigned *__restrict out, unsigned start, unsigned b, unsigned *__restrict pex, unsigned char *bb);
static inline unsigned char zigzagenc8( char x) { return x << 1 ^ x >> 7; }
static inline char zigzagdec8( unsigned char x) { return x >> 1 ^ -(x & 1); }
static inline unsigned short zigzagenc16(short x) { return x << 1 ^ x >> 15; }
static inline short zigzagdec16(unsigned short x) { return x >> 1 ^ -(x & 1); }
static inline unsigned zigzagenc31(int x) { x = (x << 2 | ((x>>30)& 2)) ^ x >> 31; return x; }
static inline unsigned zigzagdec31(unsigned x) { return (x >> 2 | (x& 2)<<30 ) ^ -(x & 1); }
static inline unsigned long long zigzagenc63(long long x) { x = (x << 2 | ((x>>62)& 2)) ^ x >> 63; return x; }
static inline long long zigzagdec63(unsigned long long x) { return (x >> 2 | (x& 2)<<62 ) ^ -(x & 1); }
static inline unsigned zigzagenc32(int x) { return x << 1 ^ x >> 31; }
static inline int zigzagdec32(unsigned x) { return x >> 1 ^ -(x & 1); }
static inline uint64_t zigzagenc64(int64_t x) { return x << 1 ^ x >> 63; }
static inline int64_t zigzagdec64(uint64_t x) { return x >> 1 ^ -(x & 1); }
typedef int __m64 __attribute__ ((__vector_size__ (8), __may_alias__));
typedef int __v2si __attribute__ ((__vector_size__ (8)));
typedef short __v4hi __attribute__ ((__vector_size__ (8)));
typedef char __v8qi __attribute__ ((__vector_size__ (8)));
typedef long long __v1di __attribute__ ((__vector_size__ (8)));
typedef float __v2sf __attribute__ ((__vector_size__ (8)));
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_empty (void)
{
  __builtin_ia32_emms ();
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_empty (void)
{
  _mm_empty ();
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi32_si64 (int __i)
{
  return (__m64) __builtin_ia32_vec_init_v2si (__i, 0);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_from_int (int __i)
{
  return _mm_cvtsi32_si64 (__i);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_from_int64 (long long __i)
{
  return (__m64) __i;
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64_m64 (long long __i)
{
  return (__m64) __i;
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64x_si64 (long long __i)
{
  return (__m64) __i;
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_pi64x (long long __i)
{
  return (__m64) __i;
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64_si32 (__m64 __i)
{
  return __builtin_ia32_vec_ext_v2si ((__v2si)__i, 0);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_to_int (__m64 __i)
{
  return _mm_cvtsi64_si32 (__i);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_to_int64 (__m64 __i)
{
  return (long long)__i;
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtm64_si64 (__m64 __i)
{
  return (long long)__i;
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64_si64x (__m64 __i)
{
  return (long long)__i;
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_packs_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_packsswb ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_packsswb (__m64 __m1, __m64 __m2)
{
  return _mm_packs_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_packs_pi32 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_packssdw ((__v2si)__m1, (__v2si)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_packssdw (__m64 __m1, __m64 __m2)
{
  return _mm_packs_pi32 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_packs_pu16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_packuswb ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_packuswb (__m64 __m1, __m64 __m2)
{
  return _mm_packs_pu16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_punpckhbw ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_punpckhbw (__m64 __m1, __m64 __m2)
{
  return _mm_unpackhi_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_punpckhwd ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_punpckhwd (__m64 __m1, __m64 __m2)
{
  return _mm_unpackhi_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_pi32 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_punpckhdq ((__v2si)__m1, (__v2si)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_punpckhdq (__m64 __m1, __m64 __m2)
{
  return _mm_unpackhi_pi32 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_punpcklbw ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_punpcklbw (__m64 __m1, __m64 __m2)
{
  return _mm_unpacklo_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_punpcklwd ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_punpcklwd (__m64 __m1, __m64 __m2)
{
  return _mm_unpacklo_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_pi32 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_punpckldq ((__v2si)__m1, (__v2si)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_punpckldq (__m64 __m1, __m64 __m2)
{
  return _mm_unpacklo_pi32 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_paddb (__m64 __m1, __m64 __m2)
{
  return _mm_add_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_paddw (__m64 __m1, __m64 __m2)
{
  return _mm_add_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_pi32 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddd ((__v2si)__m1, (__v2si)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_paddd (__m64 __m1, __m64 __m2)
{
  return _mm_add_pi32 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_si64 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddq ((__v1di)__m1, (__v1di)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddsb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_paddsb (__m64 __m1, __m64 __m2)
{
  return _mm_adds_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddsw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_paddsw (__m64 __m1, __m64 __m2)
{
  return _mm_adds_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_pu8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddusb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_paddusb (__m64 __m1, __m64 __m2)
{
  return _mm_adds_pu8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_pu16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddusw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_paddusw (__m64 __m1, __m64 __m2)
{
  return _mm_adds_pu16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psubb (__m64 __m1, __m64 __m2)
{
  return _mm_sub_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psubw (__m64 __m1, __m64 __m2)
{
  return _mm_sub_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_pi32 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubd ((__v2si)__m1, (__v2si)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psubd (__m64 __m1, __m64 __m2)
{
  return _mm_sub_pi32 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_si64 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubq ((__v1di)__m1, (__v1di)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubsb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psubsb (__m64 __m1, __m64 __m2)
{
  return _mm_subs_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubsw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psubsw (__m64 __m1, __m64 __m2)
{
  return _mm_subs_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_pu8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubusb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psubusb (__m64 __m1, __m64 __m2)
{
  return _mm_subs_pu8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_pu16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubusw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psubusw (__m64 __m1, __m64 __m2)
{
  return _mm_subs_pu16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_madd_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pmaddwd ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmaddwd (__m64 __m1, __m64 __m2)
{
  return _mm_madd_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mulhi_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pmulhw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmulhw (__m64 __m1, __m64 __m2)
{
  return _mm_mulhi_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mullo_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pmullw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmullw (__m64 __m1, __m64 __m2)
{
  return _mm_mullo_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sll_pi16 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_psllw ((__v4hi)__m, (__v4hi)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psllw (__m64 __m, __m64 __count)
{
  return _mm_sll_pi16 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_slli_pi16 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_psllwi ((__v4hi)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psllwi (__m64 __m, int __count)
{
  return _mm_slli_pi16 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sll_pi32 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_pslld ((__v2si)__m, (__v2si)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pslld (__m64 __m, __m64 __count)
{
  return _mm_sll_pi32 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_slli_pi32 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_pslldi ((__v2si)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pslldi (__m64 __m, int __count)
{
  return _mm_slli_pi32 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sll_si64 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_psllq ((__v1di)__m, (__v1di)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psllq (__m64 __m, __m64 __count)
{
  return _mm_sll_si64 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_slli_si64 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_psllqi ((__v1di)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psllqi (__m64 __m, int __count)
{
  return _mm_slli_si64 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sra_pi16 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_psraw ((__v4hi)__m, (__v4hi)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psraw (__m64 __m, __m64 __count)
{
  return _mm_sra_pi16 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srai_pi16 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_psrawi ((__v4hi)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrawi (__m64 __m, int __count)
{
  return _mm_srai_pi16 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sra_pi32 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_psrad ((__v2si)__m, (__v2si)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrad (__m64 __m, __m64 __count)
{
  return _mm_sra_pi32 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srai_pi32 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_psradi ((__v2si)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psradi (__m64 __m, int __count)
{
  return _mm_srai_pi32 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srl_pi16 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_psrlw ((__v4hi)__m, (__v4hi)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrlw (__m64 __m, __m64 __count)
{
  return _mm_srl_pi16 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srli_pi16 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_psrlwi ((__v4hi)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrlwi (__m64 __m, int __count)
{
  return _mm_srli_pi16 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srl_pi32 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_psrld ((__v2si)__m, (__v2si)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrld (__m64 __m, __m64 __count)
{
  return _mm_srl_pi32 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srli_pi32 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_psrldi ((__v2si)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrldi (__m64 __m, int __count)
{
  return _mm_srli_pi32 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srl_si64 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_psrlq ((__v1di)__m, (__v1di)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrlq (__m64 __m, __m64 __count)
{
  return _mm_srl_si64 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srli_si64 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_psrlqi ((__v1di)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrlqi (__m64 __m, int __count)
{
  return _mm_srli_si64 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_and_si64 (__m64 __m1, __m64 __m2)
{
  return __builtin_ia32_pand (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pand (__m64 __m1, __m64 __m2)
{
  return _mm_and_si64 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_andnot_si64 (__m64 __m1, __m64 __m2)
{
  return __builtin_ia32_pandn (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pandn (__m64 __m1, __m64 __m2)
{
  return _mm_andnot_si64 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_or_si64 (__m64 __m1, __m64 __m2)
{
  return __builtin_ia32_por (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_por (__m64 __m1, __m64 __m2)
{
  return _mm_or_si64 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_xor_si64 (__m64 __m1, __m64 __m2)
{
  return __builtin_ia32_pxor (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pxor (__m64 __m1, __m64 __m2)
{
  return _mm_xor_si64 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pcmpeqb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pcmpeqb (__m64 __m1, __m64 __m2)
{
  return _mm_cmpeq_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pcmpgtb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pcmpgtb (__m64 __m1, __m64 __m2)
{
  return _mm_cmpgt_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pcmpeqw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pcmpeqw (__m64 __m1, __m64 __m2)
{
  return _mm_cmpeq_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pcmpgtw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pcmpgtw (__m64 __m1, __m64 __m2)
{
  return _mm_cmpgt_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_pi32 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pcmpeqd ((__v2si)__m1, (__v2si)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pcmpeqd (__m64 __m1, __m64 __m2)
{
  return _mm_cmpeq_pi32 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_pi32 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pcmpgtd ((__v2si)__m1, (__v2si)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pcmpgtd (__m64 __m1, __m64 __m2)
{
  return _mm_cmpgt_pi32 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setzero_si64 (void)
{
  return (__m64)0LL;
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_pi32 (int __i1, int __i0)
{
  return (__m64) __builtin_ia32_vec_init_v2si (__i0, __i1);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_pi16 (short __w3, short __w2, short __w1, short __w0)
{
  return (__m64) __builtin_ia32_vec_init_v4hi (__w0, __w1, __w2, __w3);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_pi8 (char __b7, char __b6, char __b5, char __b4,
      char __b3, char __b2, char __b1, char __b0)
{
  return (__m64) __builtin_ia32_vec_init_v8qi (__b0, __b1, __b2, __b3,
            __b4, __b5, __b6, __b7);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_pi32 (int __i0, int __i1)
{
  return _mm_set_pi32 (__i1, __i0);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_pi16 (short __w0, short __w1, short __w2, short __w3)
{
  return _mm_set_pi16 (__w3, __w2, __w1, __w0);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_pi8 (char __b0, char __b1, char __b2, char __b3,
       char __b4, char __b5, char __b6, char __b7)
{
  return _mm_set_pi8 (__b7, __b6, __b5, __b4, __b3, __b2, __b1, __b0);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_pi32 (int __i)
{
  return _mm_set_pi32 (__i, __i);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_pi16 (short __w)
{
  return _mm_set_pi16 (__w, __w, __w, __w);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_pi8 (char __b)
{
  return _mm_set_pi8 (__b, __b, __b, __b, __b, __b, __b, __b);
}

typedef enum
{
  P_ALL,
  P_PID,
  P_PGID
} idtype_t;
static __inline unsigned int
__bswap_32 (unsigned int __bsx)
{
  return __builtin_bswap32 (__bsx);
}
static __inline __uint64_t
__bswap_64 (__uint64_t __bsx)
{
  return __builtin_bswap64 (__bsx);
}
union wait
  {
    int w_status;
    struct
      {
 unsigned int __w_termsig:7;
 unsigned int __w_coredump:1;
 unsigned int __w_retcode:8;
 unsigned int:16;
      } __wait_terminated;
    struct
      {
 unsigned int __w_stopval:8;
 unsigned int __w_stopsig:8;
 unsigned int:16;
      } __wait_stopped;
  };
typedef union
  {
    union wait *__uptr;
    int *__iptr;
  } __WAIT_STATUS __attribute__ ((__transparent_union__));

typedef struct
  {
    int quot;
    int rem;
  } div_t;
typedef struct
  {
    long int quot;
    long int rem;
  } ldiv_t;


__extension__ typedef struct
  {
    long long int quot;
    long long int rem;
  } lldiv_t;

extern size_t __ctype_get_mb_cur_max (void) __attribute__ ((__nothrow__ , __leaf__)) ;

extern double atof (const char *__nptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;
extern int atoi (const char *__nptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;
extern long int atol (const char *__nptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;


__extension__ extern long long int atoll (const char *__nptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;


extern double strtod (const char *__restrict __nptr,
        char **__restrict __endptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));


extern float strtof (const char *__restrict __nptr,
       char **__restrict __endptr) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern long double strtold (const char *__restrict __nptr,
       char **__restrict __endptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));


extern long int strtol (const char *__restrict __nptr,
   char **__restrict __endptr, int __base)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern unsigned long int strtoul (const char *__restrict __nptr,
      char **__restrict __endptr, int __base)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));

__extension__
extern long long int strtoq (const char *__restrict __nptr,
        char **__restrict __endptr, int __base)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
__extension__
extern unsigned long long int strtouq (const char *__restrict __nptr,
           char **__restrict __endptr, int __base)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));

__extension__
extern long long int strtoll (const char *__restrict __nptr,
         char **__restrict __endptr, int __base)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
__extension__
extern unsigned long long int strtoull (const char *__restrict __nptr,
     char **__restrict __endptr, int __base)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));

extern char *l64a (long int __n) __attribute__ ((__nothrow__ , __leaf__)) ;
extern long int a64l (const char *__s)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;

typedef __u_char u_char;
typedef __u_short u_short;
typedef __u_int u_int;
typedef __u_long u_long;
typedef __quad_t quad_t;
typedef __u_quad_t u_quad_t;
typedef __fsid_t fsid_t;
typedef __loff_t loff_t;
typedef __ino_t ino_t;
typedef __dev_t dev_t;
typedef __gid_t gid_t;
typedef __mode_t mode_t;
typedef __nlink_t nlink_t;
typedef __uid_t uid_t;
typedef __pid_t pid_t;
typedef __id_t id_t;
typedef __daddr_t daddr_t;
typedef __caddr_t caddr_t;
typedef __key_t key_t;

typedef __clock_t clock_t;



typedef __time_t time_t;


typedef __clockid_t clockid_t;
typedef __timer_t timer_t;
typedef unsigned long int ulong;
typedef unsigned short int ushort;
typedef unsigned int uint;
typedef unsigned int u_int8_t __attribute__ ((__mode__ (__QI__)));
typedef unsigned int u_int16_t __attribute__ ((__mode__ (__HI__)));
typedef unsigned int u_int32_t __attribute__ ((__mode__ (__SI__)));
typedef unsigned int u_int64_t __attribute__ ((__mode__ (__DI__)));
typedef int register_t __attribute__ ((__mode__ (__word__)));
typedef int __sig_atomic_t;
typedef struct
  {
    unsigned long int __val[(1024 / (8 * sizeof (unsigned long int)))];
  } __sigset_t;
typedef __sigset_t sigset_t;
struct timespec
  {
    __time_t tv_sec;
    __syscall_slong_t tv_nsec;
  };
struct timeval
  {
    __time_t tv_sec;
    __suseconds_t tv_usec;
  };
typedef __suseconds_t suseconds_t;
typedef long int __fd_mask;
typedef struct
  {
    __fd_mask __fds_bits[1024 / (8 * (int) sizeof (__fd_mask))];
  } fd_set;
typedef __fd_mask fd_mask;

extern int select (int __nfds, fd_set *__restrict __readfds,
     fd_set *__restrict __writefds,
     fd_set *__restrict __exceptfds,
     struct timeval *__restrict __timeout);
extern int pselect (int __nfds, fd_set *__restrict __readfds,
      fd_set *__restrict __writefds,
      fd_set *__restrict __exceptfds,
      const struct timespec *__restrict __timeout,
      const __sigset_t *__restrict __sigmask);


__extension__
extern unsigned int gnu_dev_major (unsigned long long int __dev)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
__extension__
extern unsigned int gnu_dev_minor (unsigned long long int __dev)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
__extension__
extern unsigned long long int gnu_dev_makedev (unsigned int __major,
            unsigned int __minor)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));

typedef __blksize_t blksize_t;
typedef __blkcnt_t blkcnt_t;
typedef __fsblkcnt_t fsblkcnt_t;
typedef __fsfilcnt_t fsfilcnt_t;
typedef unsigned long int pthread_t;
union pthread_attr_t
{
  char __size[56];
  long int __align;
};
typedef union pthread_attr_t pthread_attr_t;
typedef struct __pthread_internal_list
{
  struct __pthread_internal_list *__prev;
  struct __pthread_internal_list *__next;
} __pthread_list_t;
typedef union
{
  struct __pthread_mutex_s
  {
    int __lock;
    unsigned int __count;
    int __owner;
    unsigned int __nusers;
    int __kind;
    short __spins;
    short __elision;
    __pthread_list_t __list;
  } __data;
  char __size[40];
  long int __align;
} pthread_mutex_t;
typedef union
{
  char __size[4];
  int __align;
} pthread_mutexattr_t;
typedef union
{
  struct
  {
    int __lock;
    unsigned int __futex;
    __extension__ unsigned long long int __total_seq;
    __extension__ unsigned long long int __wakeup_seq;
    __extension__ unsigned long long int __woken_seq;
    void *__mutex;
    unsigned int __nwaiters;
    unsigned int __broadcast_seq;
  } __data;
  char __size[48];
  __extension__ long long int __align;
} pthread_cond_t;
typedef union
{
  char __size[4];
  int __align;
} pthread_condattr_t;
typedef unsigned int pthread_key_t;
typedef int pthread_once_t;
typedef union
{
  struct
  {
    int __lock;
    unsigned int __nr_readers;
    unsigned int __readers_wakeup;
    unsigned int __writer_wakeup;
    unsigned int __nr_readers_queued;
    unsigned int __nr_writers_queued;
    int __writer;
    int __shared;
    signed char __rwelision;
    unsigned char __pad1[7];
    unsigned long int __pad2;
    unsigned int __flags;
  } __data;
  char __size[56];
  long int __align;
} pthread_rwlock_t;
typedef union
{
  char __size[8];
  long int __align;
} pthread_rwlockattr_t;
typedef volatile int pthread_spinlock_t;
typedef union
{
  char __size[32];
  long int __align;
} pthread_barrier_t;
typedef union
{
  char __size[4];
  int __align;
} pthread_barrierattr_t;

extern long int random (void) __attribute__ ((__nothrow__ , __leaf__));
extern void srandom (unsigned int __seed) __attribute__ ((__nothrow__ , __leaf__));
extern char *initstate (unsigned int __seed, char *__statebuf,
   size_t __statelen) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern char *setstate (char *__statebuf) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
struct random_data
  {
    int32_t *fptr;
    int32_t *rptr;
    int32_t *state;
    int rand_type;
    int rand_deg;
    int rand_sep;
    int32_t *end_ptr;
  };
extern int random_r (struct random_data *__restrict __buf,
       int32_t *__restrict __result) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int srandom_r (unsigned int __seed, struct random_data *__buf)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int initstate_r (unsigned int __seed, char *__restrict __statebuf,
   size_t __statelen,
   struct random_data *__restrict __buf)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2, 4)));
extern int setstate_r (char *__restrict __statebuf,
         struct random_data *__restrict __buf)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));

extern int rand (void) __attribute__ ((__nothrow__ , __leaf__));
extern void srand (unsigned int __seed) __attribute__ ((__nothrow__ , __leaf__));

extern int rand_r (unsigned int *__seed) __attribute__ ((__nothrow__ , __leaf__));
extern double drand48 (void) __attribute__ ((__nothrow__ , __leaf__));
extern double erand48 (unsigned short int __xsubi[3]) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern long int lrand48 (void) __attribute__ ((__nothrow__ , __leaf__));
extern long int nrand48 (unsigned short int __xsubi[3])
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern long int mrand48 (void) __attribute__ ((__nothrow__ , __leaf__));
extern long int jrand48 (unsigned short int __xsubi[3])
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern void srand48 (long int __seedval) __attribute__ ((__nothrow__ , __leaf__));
extern unsigned short int *seed48 (unsigned short int __seed16v[3])
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern void lcong48 (unsigned short int __param[7]) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
struct drand48_data
  {
    unsigned short int __x[3];
    unsigned short int __old_x[3];
    unsigned short int __c;
    unsigned short int __init;
    __extension__ unsigned long long int __a;
  };
extern int drand48_r (struct drand48_data *__restrict __buffer,
        double *__restrict __result) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int erand48_r (unsigned short int __xsubi[3],
        struct drand48_data *__restrict __buffer,
        double *__restrict __result) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int lrand48_r (struct drand48_data *__restrict __buffer,
        long int *__restrict __result)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int nrand48_r (unsigned short int __xsubi[3],
        struct drand48_data *__restrict __buffer,
        long int *__restrict __result)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int mrand48_r (struct drand48_data *__restrict __buffer,
        long int *__restrict __result)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int jrand48_r (unsigned short int __xsubi[3],
        struct drand48_data *__restrict __buffer,
        long int *__restrict __result)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int srand48_r (long int __seedval, struct drand48_data *__buffer)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int seed48_r (unsigned short int __seed16v[3],
       struct drand48_data *__buffer) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int lcong48_r (unsigned short int __param[7],
        struct drand48_data *__buffer)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));

extern void *malloc (size_t __size) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__malloc__)) ;
extern void *calloc (size_t __nmemb, size_t __size)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__malloc__)) ;


extern void *realloc (void *__ptr, size_t __size)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__warn_unused_result__));
extern void free (void *__ptr) __attribute__ ((__nothrow__ , __leaf__));

extern void cfree (void *__ptr) __attribute__ ((__nothrow__ , __leaf__));

extern void *alloca (size_t __size) __attribute__ ((__nothrow__ , __leaf__));

extern void *valloc (size_t __size) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__malloc__)) ;
extern int posix_memalign (void **__memptr, size_t __alignment, size_t __size)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;
extern void *aligned_alloc (size_t __alignment, size_t __size)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__malloc__)) __attribute__ ((__alloc_size__ (2))) ;

extern void abort (void) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__noreturn__));
extern int atexit (void (*__func) (void)) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int at_quick_exit (void (*__func) (void)) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));

extern int on_exit (void (*__func) (int __status, void *__arg), void *__arg)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));

extern void exit (int __status) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__noreturn__));
extern void quick_exit (int __status) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__noreturn__));


extern void _Exit (int __status) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__noreturn__));


extern char *getenv (const char *__name) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;

extern int putenv (char *__string) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int setenv (const char *__name, const char *__value, int __replace)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int unsetenv (const char *__name) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int clearenv (void) __attribute__ ((__nothrow__ , __leaf__));
extern char *mktemp (char *__template) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int mkstemp (char *__template) __attribute__ ((__nonnull__ (1))) ;
extern int mkstemps (char *__template, int __suffixlen) __attribute__ ((__nonnull__ (1))) ;
extern char *mkdtemp (char *__template) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;

extern int system (const char *__command) ;

extern char *realpath (const char *__restrict __name,
         char *__restrict __resolved) __attribute__ ((__nothrow__ , __leaf__)) ;
typedef int (*__compar_fn_t) (const void *, const void *);

extern void *bsearch (const void *__key, const void *__base,
        size_t __nmemb, size_t __size, __compar_fn_t __compar)
     __attribute__ ((__nonnull__ (1, 2, 5))) ;
extern void qsort (void *__base, size_t __nmemb, size_t __size,
     __compar_fn_t __compar) __attribute__ ((__nonnull__ (1, 4)));
extern int abs (int __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)) ;
extern long int labs (long int __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)) ;

__extension__ extern long long int llabs (long long int __x)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)) ;

extern div_t div (int __numer, int __denom)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)) ;
extern ldiv_t ldiv (long int __numer, long int __denom)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)) ;


__extension__ extern lldiv_t lldiv (long long int __numer,
        long long int __denom)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)) ;

extern char *ecvt (double __value, int __ndigit, int *__restrict __decpt,
     int *__restrict __sign) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4))) ;
extern char *fcvt (double __value, int __ndigit, int *__restrict __decpt,
     int *__restrict __sign) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4))) ;
extern char *gcvt (double __value, int __ndigit, char *__buf)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3))) ;
extern char *qecvt (long double __value, int __ndigit,
      int *__restrict __decpt, int *__restrict __sign)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4))) ;
extern char *qfcvt (long double __value, int __ndigit,
      int *__restrict __decpt, int *__restrict __sign)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4))) ;
extern char *qgcvt (long double __value, int __ndigit, char *__buf)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3))) ;
extern int ecvt_r (double __value, int __ndigit, int *__restrict __decpt,
     int *__restrict __sign, char *__restrict __buf,
     size_t __len) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4, 5)));
extern int fcvt_r (double __value, int __ndigit, int *__restrict __decpt,
     int *__restrict __sign, char *__restrict __buf,
     size_t __len) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4, 5)));
extern int qecvt_r (long double __value, int __ndigit,
      int *__restrict __decpt, int *__restrict __sign,
      char *__restrict __buf, size_t __len)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4, 5)));
extern int qfcvt_r (long double __value, int __ndigit,
      int *__restrict __decpt, int *__restrict __sign,
      char *__restrict __buf, size_t __len)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4, 5)));

extern int mblen (const char *__s, size_t __n) __attribute__ ((__nothrow__ , __leaf__));
extern int mbtowc (wchar_t *__restrict __pwc,
     const char *__restrict __s, size_t __n) __attribute__ ((__nothrow__ , __leaf__));
extern int wctomb (char *__s, wchar_t __wchar) __attribute__ ((__nothrow__ , __leaf__));
extern size_t mbstowcs (wchar_t *__restrict __pwcs,
   const char *__restrict __s, size_t __n) __attribute__ ((__nothrow__ , __leaf__));
extern size_t wcstombs (char *__restrict __s,
   const wchar_t *__restrict __pwcs, size_t __n)
     __attribute__ ((__nothrow__ , __leaf__));

extern int rpmatch (const char *__response) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;
extern int getsubopt (char **__restrict __optionp,
        char *const *__restrict __tokens,
        char **__restrict __valuep)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2, 3))) ;
extern int getloadavg (double __loadavg[], int __nelem)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));

extern int posix_memalign (void **, size_t, size_t);
static __inline void *
_mm_malloc (size_t size, size_t alignment)
{
  void *ptr;
  if (alignment == 1)
    return malloc (size);
  if (alignment == 2 || (sizeof (void *) == 8 && alignment == 4))
    alignment = sizeof (void *);
  if (posix_memalign (&ptr, alignment, size) == 0)
    return ptr;
  else
    return ((void *)0);
}
static __inline void
_mm_free (void * ptr)
{
  free (ptr);
}
enum _mm_hint
{
  _MM_HINT_ET0 = 7,
  _MM_HINT_ET1 = 6,
  _MM_HINT_T0 = 3,
  _MM_HINT_T1 = 2,
  _MM_HINT_T2 = 1,
  _MM_HINT_NTA = 0
};
typedef float __m128 __attribute__ ((__vector_size__ (16), __may_alias__));
typedef float __v4sf __attribute__ ((__vector_size__ (16)));
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_undefined_ps (void)
{
  __m128 __Y = __Y;
  return __Y;
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setzero_ps (void)
{
  return __extension__ (__m128){ 0.0f, 0.0f, 0.0f, 0.0f };
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_addss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_subss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mul_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_mulss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_div_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_divss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sqrt_ss (__m128 __A)
{
  return (__m128) __builtin_ia32_sqrtss ((__v4sf)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_rcp_ss (__m128 __A)
{
  return (__m128) __builtin_ia32_rcpss ((__v4sf)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_rsqrt_ss (__m128 __A)
{
  return (__m128) __builtin_ia32_rsqrtss ((__v4sf)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_minss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_maxss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_ps (__m128 __A, __m128 __B)
{
  return (__m128) ((__v4sf)__A + (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_ps (__m128 __A, __m128 __B)
{
  return (__m128) ((__v4sf)__A - (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mul_ps (__m128 __A, __m128 __B)
{
  return (__m128) ((__v4sf)__A * (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_div_ps (__m128 __A, __m128 __B)
{
  return (__m128) ((__v4sf)__A / (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sqrt_ps (__m128 __A)
{
  return (__m128) __builtin_ia32_sqrtps ((__v4sf)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_rcp_ps (__m128 __A)
{
  return (__m128) __builtin_ia32_rcpps ((__v4sf)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_rsqrt_ps (__m128 __A)
{
  return (__m128) __builtin_ia32_rsqrtps ((__v4sf)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_minps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_maxps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_and_ps (__m128 __A, __m128 __B)
{
  return __builtin_ia32_andps (__A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_andnot_ps (__m128 __A, __m128 __B)
{
  return __builtin_ia32_andnps (__A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_or_ps (__m128 __A, __m128 __B)
{
  return __builtin_ia32_orps (__A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_xor_ps (__m128 __A, __m128 __B)
{
  return __builtin_ia32_xorps (__A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpeqss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpltss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpless ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movss ((__v4sf) __A,
     (__v4sf)
     __builtin_ia32_cmpltss ((__v4sf) __B,
        (__v4sf)
        __A));
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movss ((__v4sf) __A,
     (__v4sf)
     __builtin_ia32_cmpless ((__v4sf) __B,
        (__v4sf)
        __A));
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpneqss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnlt_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpnltss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnle_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpnless ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpngt_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movss ((__v4sf) __A,
     (__v4sf)
     __builtin_ia32_cmpnltss ((__v4sf) __B,
         (__v4sf)
         __A));
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnge_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movss ((__v4sf) __A,
     (__v4sf)
     __builtin_ia32_cmpnless ((__v4sf) __B,
         (__v4sf)
         __A));
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpord_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpordss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpunord_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpunordss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpeqps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpltps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpleps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpgtps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpgeps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpneqps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnlt_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpnltps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnle_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpnleps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpngt_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpngtps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnge_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpngeps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpord_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpordps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpunord_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpunordps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comieq_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_comieq ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comilt_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_comilt ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comile_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_comile ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comigt_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_comigt ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comige_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_comige ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comineq_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_comineq ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomieq_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_ucomieq ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomilt_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_ucomilt ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomile_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_ucomile ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomigt_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_ucomigt ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomige_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_ucomige ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomineq_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_ucomineq ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_si32 (__m128 __A)
{
  return __builtin_ia32_cvtss2si ((__v4sf) __A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvt_ss2si (__m128 __A)
{
  return _mm_cvtss_si32 (__A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_si64 (__m128 __A)
{
  return __builtin_ia32_cvtss2si64 ((__v4sf) __A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_si64x (__m128 __A)
{
  return __builtin_ia32_cvtss2si64 ((__v4sf) __A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_pi32 (__m128 __A)
{
  return (__m64) __builtin_ia32_cvtps2pi ((__v4sf) __A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvt_ps2pi (__m128 __A)
{
  return _mm_cvtps_pi32 (__A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttss_si32 (__m128 __A)
{
  return __builtin_ia32_cvttss2si ((__v4sf) __A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtt_ss2si (__m128 __A)
{
  return _mm_cvttss_si32 (__A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttss_si64 (__m128 __A)
{
  return __builtin_ia32_cvttss2si64 ((__v4sf) __A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttss_si64x (__m128 __A)
{
  return __builtin_ia32_cvttss2si64 ((__v4sf) __A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttps_pi32 (__m128 __A)
{
  return (__m64) __builtin_ia32_cvttps2pi ((__v4sf) __A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtt_ps2pi (__m128 __A)
{
  return _mm_cvttps_pi32 (__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi32_ss (__m128 __A, int __B)
{
  return (__m128) __builtin_ia32_cvtsi2ss ((__v4sf) __A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvt_si2ss (__m128 __A, int __B)
{
  return _mm_cvtsi32_ss (__A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64_ss (__m128 __A, long long __B)
{
  return (__m128) __builtin_ia32_cvtsi642ss ((__v4sf) __A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64x_ss (__m128 __A, long long __B)
{
  return (__m128) __builtin_ia32_cvtsi642ss ((__v4sf) __A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpi32_ps (__m128 __A, __m64 __B)
{
  return (__m128) __builtin_ia32_cvtpi2ps ((__v4sf) __A, (__v2si)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvt_pi2ps (__m128 __A, __m64 __B)
{
  return _mm_cvtpi32_ps (__A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpi16_ps (__m64 __A)
{
  __v4hi __sign;
  __v2si __hisi, __losi;
  __v4sf __zero, __ra, __rb;
  __sign = __builtin_ia32_pcmpgtw ((__v4hi)0LL, (__v4hi)__A);
  __losi = (__v2si) __builtin_ia32_punpcklwd ((__v4hi)__A, __sign);
  __hisi = (__v2si) __builtin_ia32_punpckhwd ((__v4hi)__A, __sign);
  __zero = (__v4sf) _mm_setzero_ps ();
  __ra = __builtin_ia32_cvtpi2ps (__zero, __losi);
  __rb = __builtin_ia32_cvtpi2ps (__ra, __hisi);
  return (__m128) __builtin_ia32_movlhps (__ra, __rb);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpu16_ps (__m64 __A)
{
  __v2si __hisi, __losi;
  __v4sf __zero, __ra, __rb;
  __losi = (__v2si) __builtin_ia32_punpcklwd ((__v4hi)__A, (__v4hi)0LL);
  __hisi = (__v2si) __builtin_ia32_punpckhwd ((__v4hi)__A, (__v4hi)0LL);
  __zero = (__v4sf) _mm_setzero_ps ();
  __ra = __builtin_ia32_cvtpi2ps (__zero, __losi);
  __rb = __builtin_ia32_cvtpi2ps (__ra, __hisi);
  return (__m128) __builtin_ia32_movlhps (__ra, __rb);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpi8_ps (__m64 __A)
{
  __v8qi __sign;
  __sign = __builtin_ia32_pcmpgtb ((__v8qi)0LL, (__v8qi)__A);
  __A = (__m64) __builtin_ia32_punpcklbw ((__v8qi)__A, __sign);
  return _mm_cvtpi16_ps(__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpu8_ps(__m64 __A)
{
  __A = (__m64) __builtin_ia32_punpcklbw ((__v8qi)__A, (__v8qi)0LL);
  return _mm_cvtpu16_ps(__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpi32x2_ps(__m64 __A, __m64 __B)
{
  __v4sf __zero = (__v4sf) _mm_setzero_ps ();
  __v4sf __sfa = __builtin_ia32_cvtpi2ps (__zero, (__v2si)__A);
  __v4sf __sfb = __builtin_ia32_cvtpi2ps (__sfa, (__v2si)__B);
  return (__m128) __builtin_ia32_movlhps (__sfa, __sfb);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_pi16(__m128 __A)
{
  __v4sf __hisf = (__v4sf)__A;
  __v4sf __losf = __builtin_ia32_movhlps (__hisf, __hisf);
  __v2si __hisi = __builtin_ia32_cvtps2pi (__hisf);
  __v2si __losi = __builtin_ia32_cvtps2pi (__losf);
  return (__m64) __builtin_ia32_packssdw (__hisi, __losi);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_pi8(__m128 __A)
{
  __v4hi __tmp = (__v4hi) _mm_cvtps_pi16 (__A);
  return (__m64) __builtin_ia32_packsswb (__tmp, (__v4hi)0LL);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_unpckhps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_unpcklps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadh_pi (__m128 __A, __m64 const *__P)
{
  return (__m128) __builtin_ia32_loadhps ((__v4sf)__A, (const __v2sf *)__P);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeh_pi (__m64 *__P, __m128 __A)
{
  __builtin_ia32_storehps ((__v2sf *)__P, (__v4sf)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movehl_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movhlps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movelh_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movlhps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadl_pi (__m128 __A, __m64 const *__P)
{
  return (__m128) __builtin_ia32_loadlps ((__v4sf)__A, (const __v2sf *)__P);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storel_pi (__m64 *__P, __m128 __A)
{
  __builtin_ia32_storelps ((__v2sf *)__P, (__v4sf)__A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movemask_ps (__m128 __A)
{
  return __builtin_ia32_movmskps ((__v4sf)__A);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_getcsr (void)
{
  return __builtin_ia32_stmxcsr ();
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_GET_EXCEPTION_STATE (void)
{
  return _mm_getcsr() & 0x003f;
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_GET_EXCEPTION_MASK (void)
{
  return _mm_getcsr() & 0x1f80;
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_GET_ROUNDING_MODE (void)
{
  return _mm_getcsr() & 0x6000;
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_GET_FLUSH_ZERO_MODE (void)
{
  return _mm_getcsr() & 0x8000;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setcsr (unsigned int __I)
{
  __builtin_ia32_ldmxcsr (__I);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_SET_EXCEPTION_STATE(unsigned int __mask)
{
  _mm_setcsr((_mm_getcsr() & ~0x003f) | __mask);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_SET_EXCEPTION_MASK (unsigned int __mask)
{
  _mm_setcsr((_mm_getcsr() & ~0x1f80) | __mask);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_SET_ROUNDING_MODE (unsigned int __mode)
{
  _mm_setcsr((_mm_getcsr() & ~0x6000) | __mode);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_SET_FLUSH_ZERO_MODE (unsigned int __mode)
{
  _mm_setcsr((_mm_getcsr() & ~0x8000) | __mode);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_ss (float __F)
{
  return __extension__ (__m128)(__v4sf){ __F, 0.0f, 0.0f, 0.0f };
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_ps (float __F)
{
  return __extension__ (__m128)(__v4sf){ __F, __F, __F, __F };
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_ps1 (float __F)
{
  return _mm_set1_ps (__F);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_ss (float const *__P)
{
  return _mm_set_ss (*__P);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load1_ps (float const *__P)
{
  return _mm_set1_ps (*__P);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_ps1 (float const *__P)
{
  return _mm_load1_ps (__P);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_ps (float const *__P)
{
  return (__m128) *(__v4sf *)__P;
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadu_ps (float const *__P)
{
  return (__m128) __builtin_ia32_loadups (__P);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadr_ps (float const *__P)
{
  __v4sf __tmp = *(__v4sf *)__P;
  return (__m128) __builtin_ia32_shufps (__tmp, __tmp, (((0) << 6) | ((1) << 4) | ((2) << 2) | (3)));
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_ps (const float __Z, const float __Y, const float __X, const float __W)
{
  return __extension__ (__m128)(__v4sf){ __W, __X, __Y, __Z };
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_ps (float __Z, float __Y, float __X, float __W)
{
  return __extension__ (__m128)(__v4sf){ __Z, __Y, __X, __W };
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_ss (float *__P, __m128 __A)
{
  *__P = ((__v4sf)__A)[0];
}
extern __inline float __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_f32 (__m128 __A)
{
  return ((__v4sf)__A)[0];
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_ps (float *__P, __m128 __A)
{
  *(__v4sf *)__P = (__v4sf)__A;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeu_ps (float *__P, __m128 __A)
{
  __builtin_ia32_storeups (__P, (__v4sf)__A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store1_ps (float *__P, __m128 __A)
{
  __v4sf __va = (__v4sf)__A;
  __v4sf __tmp = __builtin_ia32_shufps (__va, __va, (((0) << 6) | ((0) << 4) | ((0) << 2) | (0)));
  _mm_storeu_ps (__P, __tmp);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_ps1 (float *__P, __m128 __A)
{
  _mm_store1_ps (__P, __A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storer_ps (float *__P, __m128 __A)
{
  __v4sf __va = (__v4sf)__A;
  __v4sf __tmp = __builtin_ia32_shufps (__va, __va, (((0) << 6) | ((1) << 4) | ((2) << 2) | (3)));
  _mm_store_ps (__P, __tmp);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_move_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_pi16 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_pmaxsw ((__v4hi)__A, (__v4hi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmaxsw (__m64 __A, __m64 __B)
{
  return _mm_max_pi16 (__A, __B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_pu8 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_pmaxub ((__v8qi)__A, (__v8qi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmaxub (__m64 __A, __m64 __B)
{
  return _mm_max_pu8 (__A, __B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_pi16 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_pminsw ((__v4hi)__A, (__v4hi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pminsw (__m64 __A, __m64 __B)
{
  return _mm_min_pi16 (__A, __B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_pu8 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_pminub ((__v8qi)__A, (__v8qi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pminub (__m64 __A, __m64 __B)
{
  return _mm_min_pu8 (__A, __B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movemask_pi8 (__m64 __A)
{
  return __builtin_ia32_pmovmskb ((__v8qi)__A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmovmskb (__m64 __A)
{
  return _mm_movemask_pi8 (__A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mulhi_pu16 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_pmulhuw ((__v4hi)__A, (__v4hi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmulhuw (__m64 __A, __m64 __B)
{
  return _mm_mulhi_pu16 (__A, __B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskmove_si64 (__m64 __A, __m64 __N, char *__P)
{
  __builtin_ia32_maskmovq ((__v8qi)__A, (__v8qi)__N, __P);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_maskmovq (__m64 __A, __m64 __N, char *__P)
{
  _mm_maskmove_si64 (__A, __N, __P);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_avg_pu8 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_pavgb ((__v8qi)__A, (__v8qi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pavgb (__m64 __A, __m64 __B)
{
  return _mm_avg_pu8 (__A, __B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_avg_pu16 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_pavgw ((__v4hi)__A, (__v4hi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pavgw (__m64 __A, __m64 __B)
{
  return _mm_avg_pu16 (__A, __B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sad_pu8 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_psadbw ((__v8qi)__A, (__v8qi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psadbw (__m64 __A, __m64 __B)
{
  return _mm_sad_pu8 (__A, __B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_pi (__m64 *__P, __m64 __A)
{
  __builtin_ia32_movntq ((unsigned long long *)__P, (unsigned long long)__A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_ps (float *__P, __m128 __A)
{
  __builtin_ia32_movntps (__P, (__v4sf)__A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sfence (void)
{
  __builtin_ia32_sfence ();
}
typedef double __v2df __attribute__ ((__vector_size__ (16)));
typedef long long __v2di __attribute__ ((__vector_size__ (16)));
typedef unsigned long long __v2du __attribute__ ((__vector_size__ (16)));
typedef int __v4si __attribute__ ((__vector_size__ (16)));
typedef unsigned int __v4su __attribute__ ((__vector_size__ (16)));
typedef short __v8hi __attribute__ ((__vector_size__ (16)));
typedef unsigned short __v8hu __attribute__ ((__vector_size__ (16)));
typedef char __v16qi __attribute__ ((__vector_size__ (16)));
typedef unsigned char __v16qu __attribute__ ((__vector_size__ (16)));
typedef long long __m128i __attribute__ ((__vector_size__ (16), __may_alias__));
typedef double __m128d __attribute__ ((__vector_size__ (16), __may_alias__));
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_sd (double __F)
{
  return __extension__ (__m128d){ __F, 0.0 };
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_pd (double __F)
{
  return __extension__ (__m128d){ __F, __F };
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_pd1 (double __F)
{
  return _mm_set1_pd (__F);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_pd (double __W, double __X)
{
  return __extension__ (__m128d){ __X, __W };
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_pd (double __W, double __X)
{
  return __extension__ (__m128d){ __W, __X };
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_undefined_pd (void)
{
  __m128d __Y = __Y;
  return __Y;
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setzero_pd (void)
{
  return __extension__ (__m128d){ 0.0, 0.0 };
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_move_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_movsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_pd (double const *__P)
{
  return *(__m128d *)__P;
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadu_pd (double const *__P)
{
  return __builtin_ia32_loadupd (__P);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load1_pd (double const *__P)
{
  return _mm_set1_pd (*__P);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_sd (double const *__P)
{
  return _mm_set_sd (*__P);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_pd1 (double const *__P)
{
  return _mm_load1_pd (__P);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadr_pd (double const *__P)
{
  __m128d __tmp = _mm_load_pd (__P);
  return __builtin_ia32_shufpd (__tmp, __tmp, (((0) << 1) | (1)));
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_pd (double *__P, __m128d __A)
{
  *(__m128d *)__P = __A;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeu_pd (double *__P, __m128d __A)
{
  __builtin_ia32_storeupd (__P, __A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_sd (double *__P, __m128d __A)
{
  *__P = ((__v2df)__A)[0];
}
extern __inline double __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_f64 (__m128d __A)
{
  return ((__v2df)__A)[0];
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storel_pd (double *__P, __m128d __A)
{
  _mm_store_sd (__P, __A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeh_pd (double *__P, __m128d __A)
{
  *__P = ((__v2df)__A)[1];
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store1_pd (double *__P, __m128d __A)
{
  _mm_store_pd (__P, __builtin_ia32_shufpd (__A, __A, (((0) << 1) | (0))));
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_pd1 (double *__P, __m128d __A)
{
  _mm_store1_pd (__P, __A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storer_pd (double *__P, __m128d __A)
{
  _mm_store_pd (__P, __builtin_ia32_shufpd (__A, __A, (((0) << 1) | (1))));
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi128_si32 (__m128i __A)
{
  return __builtin_ia32_vec_ext_v4si ((__v4si)__A, 0);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi128_si64 (__m128i __A)
{
  return ((__v2di)__A)[0];
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi128_si64x (__m128i __A)
{
  return ((__v2di)__A)[0];
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_pd (__m128d __A, __m128d __B)
{
  return (__m128d) ((__v2df)__A + (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_addsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_pd (__m128d __A, __m128d __B)
{
  return (__m128d) ((__v2df)__A - (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_subsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mul_pd (__m128d __A, __m128d __B)
{
  return (__m128d) ((__v2df)__A * (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mul_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_mulsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_div_pd (__m128d __A, __m128d __B)
{
  return (__m128d) ((__v2df)__A / (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_div_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_divsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sqrt_pd (__m128d __A)
{
  return (__m128d)__builtin_ia32_sqrtpd ((__v2df)__A);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sqrt_sd (__m128d __A, __m128d __B)
{
  __v2df __tmp = __builtin_ia32_movsd ((__v2df)__A, (__v2df)__B);
  return (__m128d)__builtin_ia32_sqrtsd ((__v2df)__tmp);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_minpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_minsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_maxpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_maxsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_and_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_andpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_andnot_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_andnpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_or_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_orpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_xor_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_xorpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpeqpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpltpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmplepd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpgtpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpgepd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpneqpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnlt_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpnltpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnle_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpnlepd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpngt_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpngtpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnge_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpngepd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpord_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpordpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpunord_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpunordpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpeqsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpltsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmplesd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,
      (__v2df)
      __builtin_ia32_cmpltsd ((__v2df) __B,
         (__v2df)
         __A));
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,
      (__v2df)
      __builtin_ia32_cmplesd ((__v2df) __B,
         (__v2df)
         __A));
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpneqsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnlt_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpnltsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnle_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpnlesd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpngt_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,
      (__v2df)
      __builtin_ia32_cmpnltsd ((__v2df) __B,
          (__v2df)
          __A));
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnge_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,
      (__v2df)
      __builtin_ia32_cmpnlesd ((__v2df) __B,
          (__v2df)
          __A));
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpord_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpordsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpunord_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpunordsd ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comieq_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_comisdeq ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comilt_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_comisdlt ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comile_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_comisdle ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comigt_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_comisdgt ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comige_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_comisdge ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comineq_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_comisdneq ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomieq_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_ucomisdeq ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomilt_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_ucomisdlt ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomile_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_ucomisdle ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomigt_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_ucomisdgt ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomige_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_ucomisdge ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomineq_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_ucomisdneq ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_epi64x (long long __q1, long long __q0)
{
  return __extension__ (__m128i)(__v2di){ __q0, __q1 };
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_epi64 (__m64 __q1, __m64 __q0)
{
  return _mm_set_epi64x ((long long)__q1, (long long)__q0);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_epi32 (int __q3, int __q2, int __q1, int __q0)
{
  return __extension__ (__m128i)(__v4si){ __q0, __q1, __q2, __q3 };
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_epi16 (short __q7, short __q6, short __q5, short __q4,
        short __q3, short __q2, short __q1, short __q0)
{
  return __extension__ (__m128i)(__v8hi){
    __q0, __q1, __q2, __q3, __q4, __q5, __q6, __q7 };
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_epi8 (char __q15, char __q14, char __q13, char __q12,
       char __q11, char __q10, char __q09, char __q08,
       char __q07, char __q06, char __q05, char __q04,
       char __q03, char __q02, char __q01, char __q00)
{
  return __extension__ (__m128i)(__v16qi){
    __q00, __q01, __q02, __q03, __q04, __q05, __q06, __q07,
    __q08, __q09, __q10, __q11, __q12, __q13, __q14, __q15
  };
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_epi64x (long long __A)
{
  return _mm_set_epi64x (__A, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_epi64 (__m64 __A)
{
  return _mm_set_epi64 (__A, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_epi32 (int __A)
{
  return _mm_set_epi32 (__A, __A, __A, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_epi16 (short __A)
{
  return _mm_set_epi16 (__A, __A, __A, __A, __A, __A, __A, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_epi8 (char __A)
{
  return _mm_set_epi8 (__A, __A, __A, __A, __A, __A, __A, __A,
         __A, __A, __A, __A, __A, __A, __A, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_epi64 (__m64 __q0, __m64 __q1)
{
  return _mm_set_epi64 (__q1, __q0);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_epi32 (int __q0, int __q1, int __q2, int __q3)
{
  return _mm_set_epi32 (__q3, __q2, __q1, __q0);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_epi16 (short __q0, short __q1, short __q2, short __q3,
         short __q4, short __q5, short __q6, short __q7)
{
  return _mm_set_epi16 (__q7, __q6, __q5, __q4, __q3, __q2, __q1, __q0);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_epi8 (char __q00, char __q01, char __q02, char __q03,
        char __q04, char __q05, char __q06, char __q07,
        char __q08, char __q09, char __q10, char __q11,
        char __q12, char __q13, char __q14, char __q15)
{
  return _mm_set_epi8 (__q15, __q14, __q13, __q12, __q11, __q10, __q09, __q08,
         __q07, __q06, __q05, __q04, __q03, __q02, __q01, __q00);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_si128 (__m128i const *__P)
{
  return *__P;
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadu_si128 (__m128i const *__P)
{
  return (__m128i) __builtin_ia32_loaddqu ((char const *)__P);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadl_epi64 (__m128i const *__P)
{
  return _mm_set_epi64 ((__m64)0LL, *(__m64 *)__P);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_si128 (__m128i *__P, __m128i __B)
{
  *__P = __B;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeu_si128 (__m128i *__P, __m128i __B)
{
  __builtin_ia32_storedqu ((char *)__P, (__v16qi)__B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storel_epi64 (__m128i *__P, __m128i __B)
{
  *(long long *)__P = ((__v2di)__B)[0];
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movepi64_pi64 (__m128i __B)
{
  return (__m64) ((__v2di)__B)[0];
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movpi64_epi64 (__m64 __A)
{
  return _mm_set_epi64 ((__m64)0LL, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_move_epi64 (__m128i __A)
{
  return (__m128i)__builtin_ia32_movq128 ((__v2di) __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_undefined_si128 (void)
{
  __m128i __Y = __Y;
  return __Y;
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setzero_si128 (void)
{
  return __extension__ (__m128i)(__v4si){ 0, 0, 0, 0 };
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi32_pd (__m128i __A)
{
  return (__m128d)__builtin_ia32_cvtdq2pd ((__v4si) __A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi32_ps (__m128i __A)
{
  return (__m128)__builtin_ia32_cvtdq2ps ((__v4si) __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpd_epi32 (__m128d __A)
{
  return (__m128i)__builtin_ia32_cvtpd2dq ((__v2df) __A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpd_pi32 (__m128d __A)
{
  return (__m64)__builtin_ia32_cvtpd2pi ((__v2df) __A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpd_ps (__m128d __A)
{
  return (__m128)__builtin_ia32_cvtpd2ps ((__v2df) __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttpd_epi32 (__m128d __A)
{
  return (__m128i)__builtin_ia32_cvttpd2dq ((__v2df) __A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttpd_pi32 (__m128d __A)
{
  return (__m64)__builtin_ia32_cvttpd2pi ((__v2df) __A);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpi32_pd (__m64 __A)
{
  return (__m128d)__builtin_ia32_cvtpi2pd ((__v2si) __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_epi32 (__m128 __A)
{
  return (__m128i)__builtin_ia32_cvtps2dq ((__v4sf) __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttps_epi32 (__m128 __A)
{
  return (__m128i)__builtin_ia32_cvttps2dq ((__v4sf) __A);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_pd (__m128 __A)
{
  return (__m128d)__builtin_ia32_cvtps2pd ((__v4sf) __A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_si32 (__m128d __A)
{
  return __builtin_ia32_cvtsd2si ((__v2df) __A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_si64 (__m128d __A)
{
  return __builtin_ia32_cvtsd2si64 ((__v2df) __A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_si64x (__m128d __A)
{
  return __builtin_ia32_cvtsd2si64 ((__v2df) __A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttsd_si32 (__m128d __A)
{
  return __builtin_ia32_cvttsd2si ((__v2df) __A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttsd_si64 (__m128d __A)
{
  return __builtin_ia32_cvttsd2si64 ((__v2df) __A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttsd_si64x (__m128d __A)
{
  return __builtin_ia32_cvttsd2si64 ((__v2df) __A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_ss (__m128 __A, __m128d __B)
{
  return (__m128)__builtin_ia32_cvtsd2ss ((__v4sf) __A, (__v2df) __B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi32_sd (__m128d __A, int __B)
{
  return (__m128d)__builtin_ia32_cvtsi2sd ((__v2df) __A, __B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64_sd (__m128d __A, long long __B)
{
  return (__m128d)__builtin_ia32_cvtsi642sd ((__v2df) __A, __B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64x_sd (__m128d __A, long long __B)
{
  return (__m128d)__builtin_ia32_cvtsi642sd ((__v2df) __A, __B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_sd (__m128d __A, __m128 __B)
{
  return (__m128d)__builtin_ia32_cvtss2sd ((__v2df) __A, (__v4sf)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_unpckhpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_unpcklpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadh_pd (__m128d __A, double const *__B)
{
  return (__m128d)__builtin_ia32_loadhpd ((__v2df)__A, __B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadl_pd (__m128d __A, double const *__B)
{
  return (__m128d)__builtin_ia32_loadlpd ((__v2df)__A, __B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movemask_pd (__m128d __A)
{
  return __builtin_ia32_movmskpd ((__v2df)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_packs_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_packsswb128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_packs_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_packssdw128 ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_packus_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_packuswb128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpckhbw128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpckhwd128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpckhdq128 ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpckhqdq128 ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpcklbw128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpcklwd128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpckldq128 ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpcklqdq128 ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v16qu)__A + (__v16qu)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v8hu)__A + (__v8hu)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v4su)__A + (__v4su)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v2du)__A + (__v2du)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_paddsb128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_paddsw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_epu8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_paddusb128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_epu16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_paddusw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v16qu)__A - (__v16qu)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v8hu)__A - (__v8hu)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v4su)__A - (__v4su)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v2du)__A - (__v2du)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psubsb128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psubsw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_epu8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psubusb128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_epu16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psubusw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_madd_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pmaddwd128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mulhi_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pmulhw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mullo_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v8hu)__A * (__v8hu)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mul_su32 (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pmuludq ((__v2si)__A, (__v2si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mul_epu32 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pmuludq128 ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_slli_epi16 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_psllwi128 ((__v8hi)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_slli_epi32 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_pslldi128 ((__v4si)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_slli_epi64 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_psllqi128 ((__v2di)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srai_epi16 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_psrawi128 ((__v8hi)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srai_epi32 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_psradi128 ((__v4si)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srli_epi16 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_psrlwi128 ((__v8hi)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srli_epi32 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_psrldi128 ((__v4si)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srli_epi64 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_psrlqi128 ((__v2di)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sll_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psllw128((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sll_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pslld128((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sll_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psllq128((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sra_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psraw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sra_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psrad128 ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srl_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psrlw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srl_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psrld128 ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srl_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psrlq128 ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_and_si128 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v2du)__A & (__v2du)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_andnot_si128 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pandn128 ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_or_si128 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v2du)__A | (__v2du)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_xor_si128 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v2du)__A ^ (__v2du)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v16qi)__A == (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v8hi)__A == (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v4si)__A == (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v16qi)__A < (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v8hi)__A < (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v4si)__A < (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v16qi)__A > (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v8hi)__A > (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v4si)__A > (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pmaxsw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epu8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pmaxub128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pminsw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epu8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pminub128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movemask_epi8 (__m128i __A)
{
  return __builtin_ia32_pmovmskb128 ((__v16qi)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mulhi_epu16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pmulhuw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskmoveu_si128 (__m128i __A, __m128i __B, char *__C)
{
  __builtin_ia32_maskmovdqu ((__v16qi)__A, (__v16qi)__B, __C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_avg_epu8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pavgb128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_avg_epu16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pavgw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sad_epu8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psadbw128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_si32 (int *__A, int __B)
{
  __builtin_ia32_movnti (__A, __B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_si64 (long long int *__A, long long int __B)
{
  __builtin_ia32_movnti64 (__A, __B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_si128 (__m128i *__A, __m128i __B)
{
  __builtin_ia32_movntdq ((__v2di *)__A, (__v2di)__B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_pd (double *__A, __m128d __B)
{
  __builtin_ia32_movntpd (__A, (__v2df)__B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_clflush (void const *__A)
{
  __builtin_ia32_clflush (__A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_lfence (void)
{
  __builtin_ia32_lfence ();
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mfence (void)
{
  __builtin_ia32_mfence ();
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi32_si128 (int __A)
{
  return _mm_set_epi32 (0, 0, 0, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64_si128 (long long __A)
{
  return _mm_set_epi64x (0, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64x_si128 (long long __A)
{
  return _mm_set_epi64x (0, __A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_castpd_ps(__m128d __A)
{
  return (__m128) __A;
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_castpd_si128(__m128d __A)
{
  return (__m128i) __A;
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_castps_pd(__m128 __A)
{
  return (__m128d) __A;
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_castps_si128(__m128 __A)
{
  return (__m128i) __A;
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_castsi128_ps(__m128i __A)
{
  return (__m128) __A;
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_castsi128_pd(__m128i __A)
{
  return (__m128d) __A;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_pause (void)
{
  __builtin_ia32_pause ();
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_addsub_ps (__m128 __X, __m128 __Y)
{
  return (__m128) __builtin_ia32_addsubps ((__v4sf)__X, (__v4sf)__Y);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadd_ps (__m128 __X, __m128 __Y)
{
  return (__m128) __builtin_ia32_haddps ((__v4sf)__X, (__v4sf)__Y);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsub_ps (__m128 __X, __m128 __Y)
{
  return (__m128) __builtin_ia32_hsubps ((__v4sf)__X, (__v4sf)__Y);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movehdup_ps (__m128 __X)
{
  return (__m128) __builtin_ia32_movshdup ((__v4sf)__X);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_moveldup_ps (__m128 __X)
{
  return (__m128) __builtin_ia32_movsldup ((__v4sf)__X);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_addsub_pd (__m128d __X, __m128d __Y)
{
  return (__m128d) __builtin_ia32_addsubpd ((__v2df)__X, (__v2df)__Y);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadd_pd (__m128d __X, __m128d __Y)
{
  return (__m128d) __builtin_ia32_haddpd ((__v2df)__X, (__v2df)__Y);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsub_pd (__m128d __X, __m128d __Y)
{
  return (__m128d) __builtin_ia32_hsubpd ((__v2df)__X, (__v2df)__Y);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loaddup_pd (double const *__P)
{
  return _mm_load1_pd (__P);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movedup_pd (__m128d __X)
{
  return ((__m128d)__builtin_ia32_shufpd ((__v2df)(__m128d)(__X), (__v2df)(__m128d)(__X), (int)((((0) << 1) | (0)))));
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_lddqu_si128 (__m128i const *__P)
{
  return (__m128i) __builtin_ia32_lddqu ((char const *)__P);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_monitor (void const * __P, unsigned int __E, unsigned int __H)
{
  __builtin_ia32_monitor (__P, __E, __H);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mwait (unsigned int __E, unsigned int __H)
{
  __builtin_ia32_mwait (__E, __H);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadd_epi16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_phaddw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadd_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_phaddd128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadds_epi16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_phaddsw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadd_pi16 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_phaddw ((__v4hi)__X, (__v4hi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadd_pi32 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_phaddd ((__v2si)__X, (__v2si)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadds_pi16 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_phaddsw ((__v4hi)__X, (__v4hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsub_epi16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_phsubw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsub_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_phsubd128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsubs_epi16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_phsubsw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsub_pi16 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_phsubw ((__v4hi)__X, (__v4hi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsub_pi32 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_phsubd ((__v2si)__X, (__v2si)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsubs_pi16 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_phsubsw ((__v4hi)__X, (__v4hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maddubs_epi16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmaddubsw128 ((__v16qi)__X, (__v16qi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maddubs_pi16 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_pmaddubsw ((__v8qi)__X, (__v8qi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mulhrs_epi16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmulhrsw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mulhrs_pi16 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_pmulhrsw ((__v4hi)__X, (__v4hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_shuffle_epi8 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pshufb128 ((__v16qi)__X, (__v16qi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_shuffle_pi8 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_pshufb ((__v8qi)__X, (__v8qi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sign_epi8 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psignb128 ((__v16qi)__X, (__v16qi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sign_epi16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psignw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sign_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psignd128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sign_pi8 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_psignb ((__v8qi)__X, (__v8qi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sign_pi16 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_psignw ((__v4hi)__X, (__v4hi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sign_pi32 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_psignd ((__v2si)__X, (__v2si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_abs_epi8 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pabsb128 ((__v16qi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_abs_epi16 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pabsw128 ((__v8hi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_abs_epi32 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pabsd128 ((__v4si)__X);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_abs_pi8 (__m64 __X)
{
  return (__m64) __builtin_ia32_pabsb ((__v8qi)__X);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_abs_pi16 (__m64 __X)
{
  return (__m64) __builtin_ia32_pabsw ((__v4hi)__X);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_abs_pi32 (__m64 __X)
{
  return (__m64) __builtin_ia32_pabsd ((__v2si)__X);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testz_si128 (__m128i __M, __m128i __V)
{
  return __builtin_ia32_ptestz128 ((__v2di)__M, (__v2di)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testc_si128 (__m128i __M, __m128i __V)
{
  return __builtin_ia32_ptestc128 ((__v2di)__M, (__v2di)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testnzc_si128 (__m128i __M, __m128i __V)
{
  return __builtin_ia32_ptestnzc128 ((__v2di)__M, (__v2di)__V);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_blendv_epi8 (__m128i __X, __m128i __Y, __m128i __M)
{
  return (__m128i) __builtin_ia32_pblendvb128 ((__v16qi)__X,
            (__v16qi)__Y,
            (__v16qi)__M);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_blendv_ps (__m128 __X, __m128 __Y, __m128 __M)
{
  return (__m128) __builtin_ia32_blendvps ((__v4sf)__X,
        (__v4sf)__Y,
        (__v4sf)__M);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_blendv_pd (__m128d __X, __m128d __Y, __m128d __M)
{
  return (__m128d) __builtin_ia32_blendvpd ((__v2df)__X,
         (__v2df)__Y,
         (__v2df)__M);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi64 (__m128i __X, __m128i __Y)
{
  return (__m128i) ((__v2di)__X == (__v2di)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epi8 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pminsb128 ((__v16qi)__X, (__v16qi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epi8 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmaxsb128 ((__v16qi)__X, (__v16qi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epu16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pminuw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epu16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmaxuw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pminsd128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmaxsd128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epu32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pminud128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epu32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmaxud128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mullo_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) ((__v4su)__X * (__v4su)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mul_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmuldq128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_minpos_epu16 (__m128i __X)
{
  return (__m128i) __builtin_ia32_phminposuw128 ((__v8hi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi8_epi32 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxbd128 ((__v16qi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi16_epi32 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxwd128 ((__v8hi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi8_epi64 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxbq128 ((__v16qi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi32_epi64 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxdq128 ((__v4si)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi16_epi64 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxwq128 ((__v8hi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi8_epi16 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxbw128 ((__v16qi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu8_epi32 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxbd128 ((__v16qi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu16_epi32 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxwd128 ((__v8hi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu8_epi64 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxbq128 ((__v16qi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu32_epi64 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxdq128 ((__v4si)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu16_epi64 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxwq128 ((__v8hi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu8_epi16 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxbw128 ((__v16qi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_packus_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_packusdw128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_load_si128 (__m128i *__X)
{
  return (__m128i) __builtin_ia32_movntdqa ((__v2di *) __X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi64 (__m128i __X, __m128i __Y)
{
  return (__m128i) ((__v2di)__X > (__v2di)__Y);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_popcnt_u32 (unsigned int __X)
{
  return __builtin_popcount (__X);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_popcnt_u64 (unsigned long long __X)
{
  return __builtin_popcountll (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_crc32_u8 (unsigned int __C, unsigned char __V)
{
  return __builtin_ia32_crc32qi (__C, __V);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_crc32_u16 (unsigned int __C, unsigned short __V)
{
  return __builtin_ia32_crc32hi (__C, __V);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_crc32_u32 (unsigned int __C, unsigned int __V)
{
  return __builtin_ia32_crc32si (__C, __V);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_crc32_u64 (unsigned long long __C, unsigned long long __V)
{
  return __builtin_ia32_crc32di (__C, __V);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesdec_si128 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_aesdec128 ((__v2di)__X, (__v2di)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesdeclast_si128 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_aesdeclast128 ((__v2di)__X,
       (__v2di)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesenc_si128 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_aesenc128 ((__v2di)__X, (__v2di)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesenclast_si128 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_aesenclast128 ((__v2di)__X, (__v2di)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesimc_si128 (__m128i __X)
{
  return (__m128i) __builtin_ia32_aesimc128 ((__v2di)__X);
}
typedef double __v4df __attribute__ ((__vector_size__ (32)));
typedef float __v8sf __attribute__ ((__vector_size__ (32)));
typedef long long __v4di __attribute__ ((__vector_size__ (32)));
typedef unsigned long long __v4du __attribute__ ((__vector_size__ (32)));
typedef int __v8si __attribute__ ((__vector_size__ (32)));
typedef unsigned int __v8su __attribute__ ((__vector_size__ (32)));
typedef short __v16hi __attribute__ ((__vector_size__ (32)));
typedef unsigned short __v16hu __attribute__ ((__vector_size__ (32)));
typedef char __v32qi __attribute__ ((__vector_size__ (32)));
typedef unsigned char __v32qu __attribute__ ((__vector_size__ (32)));
typedef float __m256 __attribute__ ((__vector_size__ (32),
         __may_alias__));
typedef long long __m256i __attribute__ ((__vector_size__ (32),
       __may_alias__));
typedef double __m256d __attribute__ ((__vector_size__ (32),
           __may_alias__));
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_add_pd (__m256d __A, __m256d __B)
{
  return (__m256d) ((__v4df)__A + (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_add_ps (__m256 __A, __m256 __B)
{
  return (__m256) ((__v8sf)__A + (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_addsub_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_addsubpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_addsub_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_addsubps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_and_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_andpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_and_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_andps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_andnot_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_andnpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_andnot_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_andnps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_blendv_pd (__m256d __X, __m256d __Y, __m256d __M)
{
  return (__m256d) __builtin_ia32_blendvpd256 ((__v4df)__X,
            (__v4df)__Y,
            (__v4df)__M);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_blendv_ps (__m256 __X, __m256 __Y, __m256 __M)
{
  return (__m256) __builtin_ia32_blendvps256 ((__v8sf)__X,
           (__v8sf)__Y,
           (__v8sf)__M);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_div_pd (__m256d __A, __m256d __B)
{
  return (__m256d) ((__v4df)__A / (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_div_ps (__m256 __A, __m256 __B)
{
  return (__m256) ((__v8sf)__A / (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hadd_pd (__m256d __X, __m256d __Y)
{
  return (__m256d) __builtin_ia32_haddpd256 ((__v4df)__X, (__v4df)__Y);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hadd_ps (__m256 __X, __m256 __Y)
{
  return (__m256) __builtin_ia32_haddps256 ((__v8sf)__X, (__v8sf)__Y);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hsub_pd (__m256d __X, __m256d __Y)
{
  return (__m256d) __builtin_ia32_hsubpd256 ((__v4df)__X, (__v4df)__Y);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hsub_ps (__m256 __X, __m256 __Y)
{
  return (__m256) __builtin_ia32_hsubps256 ((__v8sf)__X, (__v8sf)__Y);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_maxpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_maxps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_minpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_minps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mul_pd (__m256d __A, __m256d __B)
{
  return (__m256d) ((__v4df)__A * (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mul_ps (__m256 __A, __m256 __B)
{
  return (__m256) ((__v8sf)__A * (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_or_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_orpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_or_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_orps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sub_pd (__m256d __A, __m256d __B)
{
  return (__m256d) ((__v4df)__A - (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sub_ps (__m256 __A, __m256 __B)
{
  return (__m256) ((__v8sf)__A - (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_xor_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_xorpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_xor_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_xorps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi32_pd (__m128i __A)
{
  return (__m256d)__builtin_ia32_cvtdq2pd256 ((__v4si) __A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi32_ps (__m256i __A)
{
  return (__m256)__builtin_ia32_cvtdq2ps256 ((__v8si) __A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtpd_ps (__m256d __A)
{
  return (__m128)__builtin_ia32_cvtpd2ps256 ((__v4df) __A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtps_epi32 (__m256 __A)
{
  return (__m256i)__builtin_ia32_cvtps2dq256 ((__v8sf) __A);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtps_pd (__m128 __A)
{
  return (__m256d)__builtin_ia32_cvtps2pd256 ((__v4sf) __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttpd_epi32 (__m256d __A)
{
  return (__m128i)__builtin_ia32_cvttpd2dq256 ((__v4df) __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtpd_epi32 (__m256d __A)
{
  return (__m128i)__builtin_ia32_cvtpd2dq256 ((__v4df) __A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttps_epi32 (__m256 __A)
{
  return (__m256i)__builtin_ia32_cvttps2dq256 ((__v8sf) __A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_zeroall (void)
{
  __builtin_ia32_vzeroall ();
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_zeroupper (void)
{
  __builtin_ia32_vzeroupper ();
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutevar_pd (__m128d __A, __m128i __C)
{
  return (__m128d) __builtin_ia32_vpermilvarpd ((__v2df)__A,
      (__v2di)__C);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutevar_pd (__m256d __A, __m256i __C)
{
  return (__m256d) __builtin_ia32_vpermilvarpd256 ((__v4df)__A,
         (__v4di)__C);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutevar_ps (__m128 __A, __m128i __C)
{
  return (__m128) __builtin_ia32_vpermilvarps ((__v4sf)__A,
            (__v4si)__C);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutevar_ps (__m256 __A, __m256i __C)
{
  return (__m256) __builtin_ia32_vpermilvarps256 ((__v8sf)__A,
        (__v8si)__C);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcast_ss (float const *__X)
{
  return (__m128) __builtin_ia32_vbroadcastss (__X);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_sd (double const *__X)
{
  return (__m256d) __builtin_ia32_vbroadcastsd256 (__X);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_ss (float const *__X)
{
  return (__m256) __builtin_ia32_vbroadcastss256 (__X);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_pd (__m128d const *__X)
{
  return (__m256d) __builtin_ia32_vbroadcastf128_pd256 (__X);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_ps (__m128 const *__X)
{
  return (__m256) __builtin_ia32_vbroadcastf128_ps256 (__X);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_load_pd (double const *__P)
{
  return *(__m256d *)__P;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_store_pd (double *__P, __m256d __A)
{
  *(__m256d *)__P = __A;
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_load_ps (float const *__P)
{
  return *(__m256 *)__P;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_store_ps (float *__P, __m256 __A)
{
  *(__m256 *)__P = __A;
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_loadu_pd (double const *__P)
{
  return (__m256d) __builtin_ia32_loadupd256 (__P);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_storeu_pd (double *__P, __m256d __A)
{
  __builtin_ia32_storeupd256 (__P, (__v4df)__A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_loadu_ps (float const *__P)
{
  return (__m256) __builtin_ia32_loadups256 (__P);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_storeu_ps (float *__P, __m256 __A)
{
  __builtin_ia32_storeups256 (__P, (__v8sf)__A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_load_si256 (__m256i const *__P)
{
  return *__P;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_store_si256 (__m256i *__P, __m256i __A)
{
  *__P = __A;
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_loadu_si256 (__m256i const *__P)
{
  return (__m256i) __builtin_ia32_loaddqu256 ((char const *)__P);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_storeu_si256 (__m256i *__P, __m256i __A)
{
  __builtin_ia32_storedqu256 ((char *)__P, (__v32qi)__A);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskload_pd (double const *__P, __m128i __M)
{
  return (__m128d) __builtin_ia32_maskloadpd ((const __v2df *)__P,
           (__v2di)__M);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskstore_pd (double *__P, __m128i __M, __m128d __A)
{
  __builtin_ia32_maskstorepd ((__v2df *)__P, (__v2di)__M, (__v2df)__A);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskload_pd (double const *__P, __m256i __M)
{
  return (__m256d) __builtin_ia32_maskloadpd256 ((const __v4df *)__P,
       (__v4di)__M);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskstore_pd (double *__P, __m256i __M, __m256d __A)
{
  __builtin_ia32_maskstorepd256 ((__v4df *)__P, (__v4di)__M, (__v4df)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskload_ps (float const *__P, __m128i __M)
{
  return (__m128) __builtin_ia32_maskloadps ((const __v4sf *)__P,
          (__v4si)__M);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskstore_ps (float *__P, __m128i __M, __m128 __A)
{
  __builtin_ia32_maskstoreps ((__v4sf *)__P, (__v4si)__M, (__v4sf)__A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskload_ps (float const *__P, __m256i __M)
{
  return (__m256) __builtin_ia32_maskloadps256 ((const __v8sf *)__P,
      (__v8si)__M);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskstore_ps (float *__P, __m256i __M, __m256 __A)
{
  __builtin_ia32_maskstoreps256 ((__v8sf *)__P, (__v8si)__M, (__v8sf)__A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movehdup_ps (__m256 __X)
{
  return (__m256) __builtin_ia32_movshdup256 ((__v8sf)__X);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_moveldup_ps (__m256 __X)
{
  return (__m256) __builtin_ia32_movsldup256 ((__v8sf)__X);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movedup_pd (__m256d __X)
{
  return (__m256d) __builtin_ia32_movddup256 ((__v4df)__X);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_lddqu_si256 (__m256i const *__P)
{
  return (__m256i) __builtin_ia32_lddqu256 ((char const *)__P);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_stream_si256 (__m256i *__A, __m256i __B)
{
  __builtin_ia32_movntdq256 ((__v4di *)__A, (__v4di)__B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_stream_pd (double *__A, __m256d __B)
{
  __builtin_ia32_movntpd256 (__A, (__v4df)__B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_stream_ps (float *__P, __m256 __A)
{
  __builtin_ia32_movntps256 (__P, (__v8sf)__A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rcp_ps (__m256 __A)
{
  return (__m256) __builtin_ia32_rcpps256 ((__v8sf)__A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rsqrt_ps (__m256 __A)
{
  return (__m256) __builtin_ia32_rsqrtps256 ((__v8sf)__A);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sqrt_pd (__m256d __A)
{
  return (__m256d) __builtin_ia32_sqrtpd256 ((__v4df)__A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sqrt_ps (__m256 __A)
{
  return (__m256) __builtin_ia32_sqrtps256 ((__v8sf)__A);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpackhi_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_unpckhpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpacklo_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_unpcklpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpackhi_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_unpckhps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpacklo_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_unpcklps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testz_pd (__m128d __M, __m128d __V)
{
  return __builtin_ia32_vtestzpd ((__v2df)__M, (__v2df)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testc_pd (__m128d __M, __m128d __V)
{
  return __builtin_ia32_vtestcpd ((__v2df)__M, (__v2df)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testnzc_pd (__m128d __M, __m128d __V)
{
  return __builtin_ia32_vtestnzcpd ((__v2df)__M, (__v2df)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testz_ps (__m128 __M, __m128 __V)
{
  return __builtin_ia32_vtestzps ((__v4sf)__M, (__v4sf)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testc_ps (__m128 __M, __m128 __V)
{
  return __builtin_ia32_vtestcps ((__v4sf)__M, (__v4sf)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testnzc_ps (__m128 __M, __m128 __V)
{
  return __builtin_ia32_vtestnzcps ((__v4sf)__M, (__v4sf)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testz_pd (__m256d __M, __m256d __V)
{
  return __builtin_ia32_vtestzpd256 ((__v4df)__M, (__v4df)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testc_pd (__m256d __M, __m256d __V)
{
  return __builtin_ia32_vtestcpd256 ((__v4df)__M, (__v4df)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testnzc_pd (__m256d __M, __m256d __V)
{
  return __builtin_ia32_vtestnzcpd256 ((__v4df)__M, (__v4df)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testz_ps (__m256 __M, __m256 __V)
{
  return __builtin_ia32_vtestzps256 ((__v8sf)__M, (__v8sf)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testc_ps (__m256 __M, __m256 __V)
{
  return __builtin_ia32_vtestcps256 ((__v8sf)__M, (__v8sf)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testnzc_ps (__m256 __M, __m256 __V)
{
  return __builtin_ia32_vtestnzcps256 ((__v8sf)__M, (__v8sf)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testz_si256 (__m256i __M, __m256i __V)
{
  return __builtin_ia32_ptestz256 ((__v4di)__M, (__v4di)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testc_si256 (__m256i __M, __m256i __V)
{
  return __builtin_ia32_ptestc256 ((__v4di)__M, (__v4di)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testnzc_si256 (__m256i __M, __m256i __V)
{
  return __builtin_ia32_ptestnzc256 ((__v4di)__M, (__v4di)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movemask_pd (__m256d __A)
{
  return __builtin_ia32_movmskpd256 ((__v4df)__A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movemask_ps (__m256 __A)
{
  return __builtin_ia32_movmskps256 ((__v8sf)__A);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_undefined_pd (void)
{
  __m256d __Y = __Y;
  return __Y;
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_undefined_ps (void)
{
  __m256 __Y = __Y;
  return __Y;
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_undefined_si256 (void)
{
  __m256i __Y = __Y;
  return __Y;
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setzero_pd (void)
{
  return __extension__ (__m256d){ 0.0, 0.0, 0.0, 0.0 };
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setzero_ps (void)
{
  return __extension__ (__m256){ 0.0, 0.0, 0.0, 0.0,
     0.0, 0.0, 0.0, 0.0 };
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setzero_si256 (void)
{
  return __extension__ (__m256i)(__v4di){ 0, 0, 0, 0 };
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_pd (double __A, double __B, double __C, double __D)
{
  return __extension__ (__m256d){ __D, __C, __B, __A };
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_ps (float __A, float __B, float __C, float __D,
        float __E, float __F, float __G, float __H)
{
  return __extension__ (__m256){ __H, __G, __F, __E,
     __D, __C, __B, __A };
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_epi32 (int __A, int __B, int __C, int __D,
    int __E, int __F, int __G, int __H)
{
  return __extension__ (__m256i)(__v8si){ __H, __G, __F, __E,
       __D, __C, __B, __A };
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_epi16 (short __q15, short __q14, short __q13, short __q12,
    short __q11, short __q10, short __q09, short __q08,
    short __q07, short __q06, short __q05, short __q04,
    short __q03, short __q02, short __q01, short __q00)
{
  return __extension__ (__m256i)(__v16hi){
    __q00, __q01, __q02, __q03, __q04, __q05, __q06, __q07,
    __q08, __q09, __q10, __q11, __q12, __q13, __q14, __q15
  };
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_epi8 (char __q31, char __q30, char __q29, char __q28,
    char __q27, char __q26, char __q25, char __q24,
    char __q23, char __q22, char __q21, char __q20,
    char __q19, char __q18, char __q17, char __q16,
    char __q15, char __q14, char __q13, char __q12,
    char __q11, char __q10, char __q09, char __q08,
    char __q07, char __q06, char __q05, char __q04,
    char __q03, char __q02, char __q01, char __q00)
{
  return __extension__ (__m256i)(__v32qi){
    __q00, __q01, __q02, __q03, __q04, __q05, __q06, __q07,
    __q08, __q09, __q10, __q11, __q12, __q13, __q14, __q15,
    __q16, __q17, __q18, __q19, __q20, __q21, __q22, __q23,
    __q24, __q25, __q26, __q27, __q28, __q29, __q30, __q31
  };
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_epi64x (long long __A, long long __B, long long __C,
     long long __D)
{
  return __extension__ (__m256i)(__v4di){ __D, __C, __B, __A };
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set1_pd (double __A)
{
  return __extension__ (__m256d){ __A, __A, __A, __A };
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set1_ps (float __A)
{
  return __extension__ (__m256){ __A, __A, __A, __A,
     __A, __A, __A, __A };
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set1_epi32 (int __A)
{
  return __extension__ (__m256i)(__v8si){ __A, __A, __A, __A,
       __A, __A, __A, __A };
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set1_epi16 (short __A)
{
  return _mm256_set_epi16 (__A, __A, __A, __A, __A, __A, __A, __A,
      __A, __A, __A, __A, __A, __A, __A, __A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set1_epi8 (char __A)
{
  return _mm256_set_epi8 (__A, __A, __A, __A, __A, __A, __A, __A,
     __A, __A, __A, __A, __A, __A, __A, __A,
     __A, __A, __A, __A, __A, __A, __A, __A,
     __A, __A, __A, __A, __A, __A, __A, __A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set1_epi64x (long long __A)
{
  return __extension__ (__m256i)(__v4di){ __A, __A, __A, __A };
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_pd (double __A, double __B, double __C, double __D)
{
  return _mm256_set_pd (__D, __C, __B, __A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_ps (float __A, float __B, float __C, float __D,
  float __E, float __F, float __G, float __H)
{
  return _mm256_set_ps (__H, __G, __F, __E, __D, __C, __B, __A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_epi32 (int __A, int __B, int __C, int __D,
     int __E, int __F, int __G, int __H)
{
  return _mm256_set_epi32 (__H, __G, __F, __E, __D, __C, __B, __A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_epi16 (short __q15, short __q14, short __q13, short __q12,
     short __q11, short __q10, short __q09, short __q08,
     short __q07, short __q06, short __q05, short __q04,
     short __q03, short __q02, short __q01, short __q00)
{
  return _mm256_set_epi16 (__q00, __q01, __q02, __q03,
      __q04, __q05, __q06, __q07,
      __q08, __q09, __q10, __q11,
      __q12, __q13, __q14, __q15);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_epi8 (char __q31, char __q30, char __q29, char __q28,
     char __q27, char __q26, char __q25, char __q24,
     char __q23, char __q22, char __q21, char __q20,
     char __q19, char __q18, char __q17, char __q16,
     char __q15, char __q14, char __q13, char __q12,
     char __q11, char __q10, char __q09, char __q08,
     char __q07, char __q06, char __q05, char __q04,
     char __q03, char __q02, char __q01, char __q00)
{
  return _mm256_set_epi8 (__q00, __q01, __q02, __q03,
     __q04, __q05, __q06, __q07,
     __q08, __q09, __q10, __q11,
     __q12, __q13, __q14, __q15,
     __q16, __q17, __q18, __q19,
     __q20, __q21, __q22, __q23,
     __q24, __q25, __q26, __q27,
     __q28, __q29, __q30, __q31);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_epi64x (long long __A, long long __B, long long __C,
      long long __D)
{
  return _mm256_set_epi64x (__D, __C, __B, __A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castpd_ps (__m256d __A)
{
  return (__m256) __A;
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castpd_si256 (__m256d __A)
{
  return (__m256i) __A;
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castps_pd (__m256 __A)
{
  return (__m256d) __A;
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castps_si256(__m256 __A)
{
  return (__m256i) __A;
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castsi256_ps (__m256i __A)
{
  return (__m256) __A;
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castsi256_pd (__m256i __A)
{
  return (__m256d) __A;
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castpd256_pd128 (__m256d __A)
{
  return (__m128d) __builtin_ia32_pd_pd256 ((__v4df)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castps256_ps128 (__m256 __A)
{
  return (__m128) __builtin_ia32_ps_ps256 ((__v8sf)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castsi256_si128 (__m256i __A)
{
  return (__m128i) __builtin_ia32_si_si256 ((__v8si)__A);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castpd128_pd256 (__m128d __A)
{
  return (__m256d) __builtin_ia32_pd256_pd ((__v2df)__A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castps128_ps256 (__m128 __A)
{
  return (__m256) __builtin_ia32_ps256_ps ((__v4sf)__A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castsi128_si256 (__m128i __A)
{
  return (__m256i) __builtin_ia32_si256_si ((__v4si)__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_abs_epi8 (__m256i __A)
{
  return (__m256i)__builtin_ia32_pabsb256 ((__v32qi)__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_abs_epi16 (__m256i __A)
{
  return (__m256i)__builtin_ia32_pabsw256 ((__v16hi)__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_abs_epi32 (__m256i __A)
{
  return (__m256i)__builtin_ia32_pabsd256 ((__v8si)__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_packs_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_packssdw256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_packs_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_packsswb256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_packus_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_packusdw256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_packus_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_packuswb256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_add_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v32qu)__A + (__v32qu)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_add_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v16hu)__A + (__v16hu)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_add_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v8su)__A + (__v8su)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_add_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4du)__A + (__v4du)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_adds_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_paddsb256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_adds_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_paddsw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_adds_epu8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_paddusb256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_adds_epu16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_paddusw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_and_si256 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4du)__A & (__v4du)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_andnot_si256 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_andnotsi256 ((__v4di)__A, (__v4di)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_avg_epu8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pavgb256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_avg_epu16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pavgw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_blendv_epi8 (__m256i __X, __m256i __Y, __m256i __M)
{
  return (__m256i) __builtin_ia32_pblendvb256 ((__v32qi)__X,
            (__v32qi)__Y,
            (__v32qi)__M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v32qi)__A == (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v16hi)__A == (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v8si)__A == (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4di)__A == (__v4di)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v32qi)__A > (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v16hi)__A > (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v8si)__A > (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4di)__A > (__v4di)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hadd_epi16 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_phaddw256 ((__v16hi)__X,
          (__v16hi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hadd_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_phaddd256 ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hadds_epi16 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_phaddsw256 ((__v16hi)__X,
           (__v16hi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hsub_epi16 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_phsubw256 ((__v16hi)__X,
          (__v16hi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hsub_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_phsubd256 ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hsubs_epi16 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_phsubsw256 ((__v16hi)__X,
           (__v16hi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maddubs_epi16 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmaddubsw256 ((__v32qi)__X,
      (__v32qi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_madd_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmaddwd256 ((__v16hi)__A,
          (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmaxsb256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmaxsw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmaxsd256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epu8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmaxub256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epu16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmaxuw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epu32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmaxud256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pminsb256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pminsw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pminsd256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epu8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pminub256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epu16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pminuw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epu32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pminud256 ((__v8si)__A, (__v8si)__B);
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movemask_epi8 (__m256i __A)
{
  return __builtin_ia32_pmovmskb256 ((__v32qi)__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi8_epi16 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxbw256 ((__v16qi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi8_epi32 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxbd256 ((__v16qi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi8_epi64 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxbq256 ((__v16qi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi16_epi32 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxwd256 ((__v8hi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi16_epi64 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxwq256 ((__v8hi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi32_epi64 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxdq256 ((__v4si)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu8_epi16 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxbw256 ((__v16qi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu8_epi32 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxbd256 ((__v16qi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu8_epi64 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxbq256 ((__v16qi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu16_epi32 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxwd256 ((__v8hi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu16_epi64 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxwq256 ((__v8hi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu32_epi64 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxdq256 ((__v4si)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mul_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmuldq256 ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mulhrs_epi16 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmulhrsw256 ((__v16hi)__X,
            (__v16hi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mulhi_epu16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmulhuw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mulhi_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmulhw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mullo_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v16hu)__A * (__v16hu)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mullo_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v8su)__A * (__v8su)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mul_epu32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmuludq256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_or_si256 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4du)__A | (__v4du)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sad_epu8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_psadbw256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_shuffle_epi8 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pshufb256 ((__v32qi)__X,
          (__v32qi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sign_epi8 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psignb256 ((__v32qi)__X, (__v32qi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sign_epi16 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psignw256 ((__v16hi)__X, (__v16hi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sign_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psignd256 ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_slli_epi16 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_psllwi256 ((__v16hi)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sll_epi16 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_psllw256((__v16hi)__A, (__v8hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_slli_epi32 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_pslldi256 ((__v8si)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sll_epi32 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_pslld256((__v8si)__A, (__v4si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_slli_epi64 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_psllqi256 ((__v4di)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sll_epi64 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_psllq256((__v4di)__A, (__v2di)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srai_epi16 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_psrawi256 ((__v16hi)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sra_epi16 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_psraw256 ((__v16hi)__A, (__v8hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srai_epi32 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_psradi256 ((__v8si)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sra_epi32 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_psrad256 ((__v8si)__A, (__v4si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srli_epi16 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_psrlwi256 ((__v16hi)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srl_epi16 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_psrlw256((__v16hi)__A, (__v8hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srli_epi32 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_psrldi256 ((__v8si)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srl_epi32 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_psrld256((__v8si)__A, (__v4si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srli_epi64 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_psrlqi256 ((__v4di)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srl_epi64 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_psrlq256((__v4di)__A, (__v2di)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sub_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v32qu)__A - (__v32qu)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sub_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v16hu)__A - (__v16hu)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sub_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v8su)__A - (__v8su)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sub_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4du)__A - (__v4du)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_subs_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_psubsb256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_subs_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_psubsw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_subs_epu8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_psubusb256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_subs_epu16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_psubusw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpackhi_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpckhbw256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpackhi_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpckhwd256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpackhi_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpckhdq256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpackhi_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpckhqdq256 ((__v4di)__A, (__v4di)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpacklo_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpcklbw256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpacklo_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpcklwd256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpacklo_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpckldq256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpacklo_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpcklqdq256 ((__v4di)__A, (__v4di)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_xor_si256 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4du)__A ^ (__v4du)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_stream_load_si256 (__m256i const *__X)
{
  return (__m256i) __builtin_ia32_movntdqa256 ((__v4di *) __X);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcastss_ps (__m128 __X)
{
  return (__m128) __builtin_ia32_vbroadcastss_ps ((__v4sf)__X);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastss_ps (__m128 __X)
{
  return (__m256) __builtin_ia32_vbroadcastss_ps256 ((__v4sf)__X);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastsd_pd (__m128d __X)
{
  return (__m256d) __builtin_ia32_vbroadcastsd_pd256 ((__v2df)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastsi128_si256 (__m128i __X)
{
  return (__m256i) __builtin_ia32_vbroadcastsi256 ((__v2di)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastb_epi8 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pbroadcastb256 ((__v16qi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastw_epi16 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pbroadcastw256 ((__v8hi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastd_epi32 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pbroadcastd256 ((__v4si)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastq_epi64 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pbroadcastq256 ((__v2di)__X);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcastb_epi8 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pbroadcastb128 ((__v16qi)__X);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcastw_epi16 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pbroadcastw128 ((__v8hi)__X);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcastd_epi32 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pbroadcastd128 ((__v4si)__X);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcastq_epi64 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pbroadcastq128 ((__v2di)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutevar8x32_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_permvarsi256 ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutevar8x32_ps (__m256 __X, __m256i __Y)
{
  return (__m256) __builtin_ia32_permvarsf256 ((__v8sf)__X, (__v8si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskload_epi32 (int const *__X, __m256i __M )
{
  return (__m256i) __builtin_ia32_maskloadd256 ((const __v8si *)__X,
      (__v8si)__M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskload_epi64 (long long const *__X, __m256i __M )
{
  return (__m256i) __builtin_ia32_maskloadq256 ((const __v4di *)__X,
      (__v4di)__M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskload_epi32 (int const *__X, __m128i __M )
{
  return (__m128i) __builtin_ia32_maskloadd ((const __v4si *)__X,
          (__v4si)__M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskload_epi64 (long long const *__X, __m128i __M )
{
  return (__m128i) __builtin_ia32_maskloadq ((const __v2di *)__X,
          (__v2di)__M);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskstore_epi32 (int *__X, __m256i __M, __m256i __Y )
{
  __builtin_ia32_maskstored256 ((__v8si *)__X, (__v8si)__M, (__v8si)__Y);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskstore_epi64 (long long *__X, __m256i __M, __m256i __Y )
{
  __builtin_ia32_maskstoreq256 ((__v4di *)__X, (__v4di)__M, (__v4di)__Y);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskstore_epi32 (int *__X, __m128i __M, __m128i __Y )
{
  __builtin_ia32_maskstored ((__v4si *)__X, (__v4si)__M, (__v4si)__Y);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskstore_epi64 (long long *__X, __m128i __M, __m128i __Y )
{
  __builtin_ia32_maskstoreq (( __v2di *)__X, (__v2di)__M, (__v2di)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sllv_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psllv8si ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sllv_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psllv4si ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sllv_epi64 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psllv4di ((__v4di)__X, (__v4di)__Y);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sllv_epi64 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psllv2di ((__v2di)__X, (__v2di)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srav_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrav8si ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_srav_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrav4si ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srlv_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrlv8si ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_srlv_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrlv4si ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srlv_epi64 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrlv4di ((__v4di)__X, (__v4di)__Y);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_srlv_epi64 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrlv2di ((__v2di)__X, (__v2di)__Y);
}
#pragma GCC push_options
#pragma GCC target("avx512f")
typedef double __v8df __attribute__ ((__vector_size__ (64)));
typedef float __v16sf __attribute__ ((__vector_size__ (64)));
typedef long long __v8di __attribute__ ((__vector_size__ (64)));
typedef unsigned long long __v8du __attribute__ ((__vector_size__ (64)));
typedef int __v16si __attribute__ ((__vector_size__ (64)));
typedef unsigned int __v16su __attribute__ ((__vector_size__ (64)));
typedef short __v32hi __attribute__ ((__vector_size__ (64)));
typedef unsigned short __v32hu __attribute__ ((__vector_size__ (64)));
typedef char __v64qi __attribute__ ((__vector_size__ (64)));
typedef unsigned char __v64qu __attribute__ ((__vector_size__ (64)));
typedef float __m512 __attribute__ ((__vector_size__ (64), __may_alias__));
typedef long long __m512i __attribute__ ((__vector_size__ (64), __may_alias__));
typedef double __m512d __attribute__ ((__vector_size__ (64), __may_alias__));
typedef unsigned char __mmask8;
typedef unsigned short __mmask16;
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set_epi64 (long long __A, long long __B, long long __C,
    long long __D, long long __E, long long __F,
    long long __G, long long __H)
{
  return __extension__ (__m512i) (__v8di)
  { __H, __G, __F, __E, __D, __C, __B, __A };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set_epi32 (int __A, int __B, int __C, int __D,
    int __E, int __F, int __G, int __H,
    int __I, int __J, int __K, int __L,
    int __M, int __N, int __O, int __P)
{
  return __extension__ (__m512i)(__v16si)
  { __P, __O, __N, __M, __L, __K, __J, __I,
    __H, __G, __F, __E, __D, __C, __B, __A };
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set_pd (double __A, double __B, double __C, double __D,
        double __E, double __F, double __G, double __H)
{
  return __extension__ (__m512d)
  { __H, __G, __F, __E, __D, __C, __B, __A };
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set_ps (float __A, float __B, float __C, float __D,
        float __E, float __F, float __G, float __H,
        float __I, float __J, float __K, float __L,
        float __M, float __N, float __O, float __P)
{
  return __extension__ (__m512)
  { __P, __O, __N, __M, __L, __K, __J, __I,
    __H, __G, __F, __E, __D, __C, __B, __A };
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_undefined_ps (void)
{
  __m512 __Y = __Y;
  return __Y;
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_undefined_pd (void)
{
  __m512d __Y = __Y;
  return __Y;
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_undefined_si512 (void)
{
  __m512i __Y = __Y;
  return __Y;
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set1_epi8 (char __A)
{
  return __extension__ (__m512i)(__v64qi)
  { __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set1_epi16 (short __A)
{
  return __extension__ (__m512i)(__v32hi)
  { __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A };
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set1_pd (double __A)
{
  return (__m512d) __builtin_ia32_broadcastsd512 (__extension__
        (__v2df) { __A, },
        (__v8df)
        _mm512_undefined_pd (),
        (__mmask8) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set1_ps (float __A)
{
  return (__m512) __builtin_ia32_broadcastss512 (__extension__
       (__v4sf) { __A, },
       (__v16sf)
       _mm512_undefined_ps (),
       (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set4_epi32 (int __A, int __B, int __C, int __D)
{
  return __extension__ (__m512i)(__v16si)
  { __D, __C, __B, __A, __D, __C, __B, __A,
    __D, __C, __B, __A, __D, __C, __B, __A };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set4_epi64 (long long __A, long long __B, long long __C,
     long long __D)
{
  return __extension__ (__m512i) (__v8di)
  { __D, __C, __B, __A, __D, __C, __B, __A };
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set4_pd (double __A, double __B, double __C, double __D)
{
  return __extension__ (__m512d)
  { __D, __C, __B, __A, __D, __C, __B, __A };
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set4_ps (float __A, float __B, float __C, float __D)
{
  return __extension__ (__m512)
  { __D, __C, __B, __A, __D, __C, __B, __A,
    __D, __C, __B, __A, __D, __C, __B, __A };
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_setzero_ps (void)
{
  return __extension__ (__m512){ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 };
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_setzero_pd (void)
{
  return __extension__ (__m512d) { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_setzero_epi32 (void)
{
  return __extension__ (__m512i)(__v8di){ 0, 0, 0, 0, 0, 0, 0, 0 };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_setzero_si512 (void)
{
  return __extension__ (__m512i)(__v8di){ 0, 0, 0, 0, 0, 0, 0, 0 };
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mov_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_movapd512_mask ((__v8df) __A,
        (__v8df) __W,
        (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mov_pd (__mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_movapd512_mask ((__v8df) __A,
        (__v8df)
        _mm512_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mov_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_movaps512_mask ((__v16sf) __A,
       (__v16sf) __W,
       (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mov_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_movaps512_mask ((__v16sf) __A,
       (__v16sf)
       _mm512_setzero_ps (),
       (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_load_pd (void const *__P)
{
  return *(__m512d *) __P;
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_load_pd (__m512d __W, __mmask8 __U, void const *__P)
{
  return (__m512d) __builtin_ia32_loadapd512_mask ((const __v8df *) __P,
         (__v8df) __W,
         (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_load_pd (__mmask8 __U, void const *__P)
{
  return (__m512d) __builtin_ia32_loadapd512_mask ((const __v8df *) __P,
         (__v8df)
         _mm512_setzero_pd (),
         (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_store_pd (void *__P, __m512d __A)
{
  *(__m512d *) __P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_store_pd (void *__P, __mmask8 __U, __m512d __A)
{
  __builtin_ia32_storeapd512_mask ((__v8df *) __P, (__v8df) __A,
       (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_load_ps (void const *__P)
{
  return *(__m512 *) __P;
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_load_ps (__m512 __W, __mmask16 __U, void const *__P)
{
  return (__m512) __builtin_ia32_loadaps512_mask ((const __v16sf *) __P,
        (__v16sf) __W,
        (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_load_ps (__mmask16 __U, void const *__P)
{
  return (__m512) __builtin_ia32_loadaps512_mask ((const __v16sf *) __P,
        (__v16sf)
        _mm512_setzero_ps (),
        (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_store_ps (void *__P, __m512 __A)
{
  *(__m512 *) __P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_store_ps (void *__P, __mmask16 __U, __m512 __A)
{
  __builtin_ia32_storeaps512_mask ((__v16sf *) __P, (__v16sf) __A,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mov_epi64 (__m512i __W, __mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdqa64_512_mask ((__v8di) __A,
           (__v8di) __W,
           (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mov_epi64 (__mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdqa64_512_mask ((__v8di) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_load_epi64 (void const *__P)
{
  return *(__m512i *) __P;
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_load_epi64 (__m512i __W, __mmask8 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_movdqa64load512_mask ((const __v8di *) __P,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_load_epi64 (__mmask8 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_movdqa64load512_mask ((const __v8di *) __P,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_store_epi64 (void *__P, __m512i __A)
{
  *(__m512i *) __P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_store_epi64 (void *__P, __mmask8 __U, __m512i __A)
{
  __builtin_ia32_movdqa64store512_mask ((__v8di *) __P, (__v8di) __A,
     (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mov_epi32 (__m512i __W, __mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdqa32_512_mask ((__v16si) __A,
           (__v16si) __W,
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mov_epi32 (__mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdqa32_512_mask ((__v16si) __A,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_load_si512 (void const *__P)
{
  return *(__m512i *) __P;
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_load_epi32 (void const *__P)
{
  return *(__m512i *) __P;
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_load_epi32 (__m512i __W, __mmask16 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_movdqa32load512_mask ((const __v16si *) __P,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_load_epi32 (__mmask16 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_movdqa32load512_mask ((const __v16si *) __P,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_store_si512 (void *__P, __m512i __A)
{
  *(__m512i *) __P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_store_epi32 (void *__P, __m512i __A)
{
  *(__m512i *) __P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_store_epi32 (void *__P, __mmask16 __U, __m512i __A)
{
  __builtin_ia32_movdqa32store512_mask ((__v16si *) __P, (__v16si) __A,
     (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mullo_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A * (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mullo_epi32 (__mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulld512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mullo_epi32 (__m512i __W, __mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulld512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sllv_epi32 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psllv16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si)
        _mm512_undefined_si512 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sllv_epi32 (__m512i __W, __mmask16 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psllv16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sllv_epi32 (__mmask16 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psllv16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si)
        _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srav_epi32 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrav16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si)
        _mm512_undefined_si512 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srav_epi32 (__m512i __W, __mmask16 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrav16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srav_epi32 (__mmask16 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrav16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si)
        _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srlv_epi32 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrlv16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si)
        _mm512_undefined_si512 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srlv_epi32 (__m512i __W, __mmask16 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrlv16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srlv_epi32 (__mmask16 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrlv16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si)
        _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_add_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v8du) __A + (__v8du) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_add_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_add_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sub_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v8du) __A - (__v8du) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sub_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sub_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sllv_epi64 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psllv8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di)
       _mm512_undefined_pd (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sllv_epi64 (__m512i __W, __mmask8 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psllv8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sllv_epi64 (__mmask8 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psllv8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srav_epi64 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrav8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di)
       _mm512_undefined_si512 (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srav_epi64 (__m512i __W, __mmask8 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrav8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srav_epi64 (__mmask8 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrav8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srlv_epi64 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrlv8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di)
       _mm512_undefined_si512 (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srlv_epi64 (__m512i __W, __mmask8 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrlv8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srlv_epi64 (__mmask8 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrlv8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_add_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A + (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_add_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddd512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_add_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddd512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mul_epi32 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmuldq512_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v8di)
        _mm512_undefined_si512 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mul_epi32 (__m512i __W, __mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmuldq512_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v8di) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mul_epi32 (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmuldq512_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v8di)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sub_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A - (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sub_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubd512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sub_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubd512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mul_epu32 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmuludq512_mask ((__v16si) __X,
         (__v16si) __Y,
         (__v8di)
         _mm512_undefined_si512 (),
         (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mul_epu32 (__m512i __W, __mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmuludq512_mask ((__v16si) __X,
         (__v16si) __Y,
         (__v8di) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mul_epu32 (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmuludq512_mask ((__v16si) __X,
         (__v16si) __Y,
         (__v8di)
         _mm512_setzero_si512 (),
         __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sll_epi64 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psllq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di)
       _mm512_undefined_si512 (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sll_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psllq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sll_epi64 (__mmask8 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psllq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srl_epi64 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrlq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di)
       _mm512_undefined_si512 (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srl_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrlq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srl_epi64 (__mmask8 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrlq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sra_epi64 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psraq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di)
       _mm512_undefined_si512 (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sra_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psraq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sra_epi64 (__mmask8 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psraq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sll_epi32 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_pslld512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si)
       _mm512_undefined_si512 (),
       (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sll_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_pslld512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sll_epi32 (__mmask16 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_pslld512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srl_epi32 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrld512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si)
       _mm512_undefined_si512 (),
       (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srl_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrld512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srl_epi32 (__mmask16 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrld512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sra_epi32 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrad512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si)
       _mm512_undefined_si512 (),
       (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sra_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrad512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sra_epi32 (__mmask16 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrad512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rcp14_pd (__m512d __A)
{
  return (__m512d) __builtin_ia32_rcp14pd512_mask ((__v8df) __A,
         (__v8df)
         _mm512_undefined_pd (),
         (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rcp14_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_rcp14pd512_mask ((__v8df) __A,
         (__v8df) __W,
         (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rcp14_pd (__mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_rcp14pd512_mask ((__v8df) __A,
         (__v8df)
         _mm512_setzero_pd (),
         (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rcp14_ps (__m512 __A)
{
  return (__m512) __builtin_ia32_rcp14ps512_mask ((__v16sf) __A,
        (__v16sf)
        _mm512_undefined_ps (),
        (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rcp14_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_rcp14ps512_mask ((__v16sf) __A,
        (__v16sf) __W,
        (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rcp14_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_rcp14ps512_mask ((__v16sf) __A,
        (__v16sf)
        _mm512_setzero_ps (),
        (__mmask16) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rcp14_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_rcp14sd ((__v2df) __B,
        (__v2df) __A);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rcp14_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_rcp14ss ((__v4sf) __B,
       (__v4sf) __A);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rsqrt14_pd (__m512d __A)
{
  return (__m512d) __builtin_ia32_rsqrt14pd512_mask ((__v8df) __A,
           (__v8df)
           _mm512_undefined_pd (),
           (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rsqrt14_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_rsqrt14pd512_mask ((__v8df) __A,
           (__v8df) __W,
           (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rsqrt14_pd (__mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_rsqrt14pd512_mask ((__v8df) __A,
           (__v8df)
           _mm512_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rsqrt14_ps (__m512 __A)
{
  return (__m512) __builtin_ia32_rsqrt14ps512_mask ((__v16sf) __A,
          (__v16sf)
          _mm512_undefined_ps (),
          (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rsqrt14_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_rsqrt14ps512_mask ((__v16sf) __A,
          (__v16sf) __W,
          (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rsqrt14_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_rsqrt14ps512_mask ((__v16sf) __A,
          (__v16sf)
          _mm512_setzero_ps (),
          (__mmask16) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rsqrt14_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_rsqrt14sd ((__v2df) __B,
          (__v2df) __A);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rsqrt14_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_rsqrt14ss ((__v4sf) __B,
         (__v4sf) __A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi8_epi32 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbd512_mask ((__v16qi) __A,
          (__v16si)
          _mm512_undefined_si512 (),
          (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi8_epi32 (__m512i __W, __mmask16 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbd512_mask ((__v16qi) __A,
          (__v16si) __W,
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi8_epi32 (__mmask16 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbd512_mask ((__v16qi) __A,
          (__v16si)
          _mm512_setzero_si512 (),
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi8_epi64 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbq512_mask ((__v16qi) __A,
          (__v8di)
          _mm512_undefined_si512 (),
          (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi8_epi64 (__m512i __W, __mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbq512_mask ((__v16qi) __A,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi8_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbq512_mask ((__v16qi) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi16_epi32 (__m256i __A)
{
  return (__m512i) __builtin_ia32_pmovsxwd512_mask ((__v16hi) __A,
          (__v16si)
          _mm512_undefined_si512 (),
          (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi16_epi32 (__m512i __W, __mmask16 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovsxwd512_mask ((__v16hi) __A,
          (__v16si) __W,
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi16_epi32 (__mmask16 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovsxwd512_mask ((__v16hi) __A,
          (__v16si)
          _mm512_setzero_si512 (),
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi16_epi64 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxwq512_mask ((__v8hi) __A,
          (__v8di)
          _mm512_undefined_si512 (),
          (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi16_epi64 (__m512i __W, __mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxwq512_mask ((__v8hi) __A,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi16_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxwq512_mask ((__v8hi) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi32_epi64 (__m256i __X)
{
  return (__m512i) __builtin_ia32_pmovsxdq512_mask ((__v8si) __X,
          (__v8di)
          _mm512_undefined_si512 (),
          (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi32_epi64 (__m512i __W, __mmask8 __U, __m256i __X)
{
  return (__m512i) __builtin_ia32_pmovsxdq512_mask ((__v8si) __X,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi32_epi64 (__mmask8 __U, __m256i __X)
{
  return (__m512i) __builtin_ia32_pmovsxdq512_mask ((__v8si) __X,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu8_epi32 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbd512_mask ((__v16qi) __A,
          (__v16si)
          _mm512_undefined_si512 (),
          (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu8_epi32 (__m512i __W, __mmask16 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbd512_mask ((__v16qi) __A,
          (__v16si) __W,
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu8_epi32 (__mmask16 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbd512_mask ((__v16qi) __A,
          (__v16si)
          _mm512_setzero_si512 (),
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu8_epi64 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbq512_mask ((__v16qi) __A,
          (__v8di)
          _mm512_undefined_si512 (),
          (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu8_epi64 (__m512i __W, __mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbq512_mask ((__v16qi) __A,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu8_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbq512_mask ((__v16qi) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu16_epi32 (__m256i __A)
{
  return (__m512i) __builtin_ia32_pmovzxwd512_mask ((__v16hi) __A,
          (__v16si)
          _mm512_undefined_si512 (),
          (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu16_epi32 (__m512i __W, __mmask16 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovzxwd512_mask ((__v16hi) __A,
          (__v16si) __W,
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu16_epi32 (__mmask16 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovzxwd512_mask ((__v16hi) __A,
          (__v16si)
          _mm512_setzero_si512 (),
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu16_epi64 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxwq512_mask ((__v8hi) __A,
          (__v8di)
          _mm512_undefined_si512 (),
          (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu16_epi64 (__m512i __W, __mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxwq512_mask ((__v8hi) __A,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu16_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxwq512_mask ((__v8hi) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu32_epi64 (__m256i __X)
{
  return (__m512i) __builtin_ia32_pmovzxdq512_mask ((__v8si) __X,
          (__v8di)
          _mm512_undefined_si512 (),
          (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu32_epi64 (__m512i __W, __mmask8 __U, __m256i __X)
{
  return (__m512i) __builtin_ia32_pmovzxdq512_mask ((__v8si) __X,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu32_epi64 (__mmask8 __U, __m256i __X)
{
  return (__m512i) __builtin_ia32_pmovzxdq512_mask ((__v8si) __X,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_abs_epi64 (__m512i __A)
{
  return (__m512i) __builtin_ia32_pabsq512_mask ((__v8di) __A,
       (__v8di)
       _mm512_undefined_si512 (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_abs_epi64 (__m512i __W, __mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsq512_mask ((__v8di) __A,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_abs_epi64 (__mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsq512_mask ((__v8di) __A,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_abs_epi32 (__m512i __A)
{
  return (__m512i) __builtin_ia32_pabsd512_mask ((__v16si) __A,
       (__v16si)
       _mm512_undefined_si512 (),
       (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_abs_epi32 (__m512i __W, __mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsd512_mask ((__v16si) __A,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_abs_epi32 (__mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsd512_mask ((__v16si) __A,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastss_ps (__m128 __A)
{
  return (__m512) __builtin_ia32_broadcastss512 ((__v4sf) __A,
       (__v16sf)
       _mm512_undefined_ps (),
       (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcastss_ps (__m512 __O, __mmask16 __M, __m128 __A)
{
  return (__m512) __builtin_ia32_broadcastss512 ((__v4sf) __A,
       (__v16sf) __O, __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcastss_ps (__mmask16 __M, __m128 __A)
{
  return (__m512) __builtin_ia32_broadcastss512 ((__v4sf) __A,
       (__v16sf)
       _mm512_setzero_ps (),
       __M);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastsd_pd (__m128d __A)
{
  return (__m512d) __builtin_ia32_broadcastsd512 ((__v2df) __A,
        (__v8df)
        _mm512_undefined_pd (),
        (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcastsd_pd (__m512d __O, __mmask8 __M, __m128d __A)
{
  return (__m512d) __builtin_ia32_broadcastsd512 ((__v2df) __A,
        (__v8df) __O, __M);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcastsd_pd (__mmask8 __M, __m128d __A)
{
  return (__m512d) __builtin_ia32_broadcastsd512 ((__v2df) __A,
        (__v8df)
        _mm512_setzero_pd (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastd_epi32 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastd512 ((__v4si) __A,
        (__v16si)
        _mm512_undefined_si512 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcastd_epi32 (__m512i __O, __mmask16 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastd512 ((__v4si) __A,
        (__v16si) __O, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcastd_epi32 (__mmask16 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastd512 ((__v4si) __A,
        (__v16si)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set1_epi32 (int __A)
{
  return (__m512i) __builtin_ia32_pbroadcastd512_gpr_mask (__A,
          (__v16si)
          _mm512_undefined_si512 (),
          (__mmask16)(-1));
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_set1_epi32 (__m512i __O, __mmask16 __M, int __A)
{
  return (__m512i) __builtin_ia32_pbroadcastd512_gpr_mask (__A, (__v16si) __O,
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_set1_epi32 (__mmask16 __M, int __A)
{
  return (__m512i)
  __builtin_ia32_pbroadcastd512_gpr_mask (__A,
       (__v16si) _mm512_setzero_si512 (),
       __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastq_epi64 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastq512 ((__v2di) __A,
        (__v8di)
        _mm512_undefined_si512 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcastq_epi64 (__m512i __O, __mmask8 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastq512 ((__v2di) __A,
        (__v8di) __O, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcastq_epi64 (__mmask8 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastq512 ((__v2di) __A,
        (__v8di)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set1_epi64 (long long __A)
{
  return (__m512i) __builtin_ia32_pbroadcastq512_gpr_mask (__A,
          (__v8di)
          _mm512_undefined_si512 (),
          (__mmask8)(-1));
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_set1_epi64 (__m512i __O, __mmask8 __M, long long __A)
{
  return (__m512i) __builtin_ia32_pbroadcastq512_gpr_mask (__A, (__v8di) __O,
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_set1_epi64 (__mmask8 __M, long long __A)
{
  return (__m512i)
  __builtin_ia32_pbroadcastq512_gpr_mask (__A,
       (__v8di) _mm512_setzero_si512 (),
       __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_f32x4 (__m128 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x4_512 ((__v4sf) __A,
           (__v16sf)
           _mm512_undefined_ps (),
           (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_f32x4 (__m512 __O, __mmask16 __M, __m128 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x4_512 ((__v4sf) __A,
           (__v16sf) __O,
           __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_f32x4 (__mmask16 __M, __m128 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x4_512 ((__v4sf) __A,
           (__v16sf)
           _mm512_setzero_ps (),
           __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_i32x4 (__m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x4_512 ((__v4si) __A,
            (__v16si)
            _mm512_undefined_si512 (),
            (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_i32x4 (__m512i __O, __mmask16 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x4_512 ((__v4si) __A,
            (__v16si) __O,
            __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_i32x4 (__mmask16 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x4_512 ((__v4si) __A,
            (__v16si)
            _mm512_setzero_si512 (),
            __M);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_f64x4 (__m256d __A)
{
  return (__m512d) __builtin_ia32_broadcastf64x4_512 ((__v4df) __A,
            (__v8df)
            _mm512_undefined_pd (),
            (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_f64x4 (__m512d __O, __mmask8 __M, __m256d __A)
{
  return (__m512d) __builtin_ia32_broadcastf64x4_512 ((__v4df) __A,
            (__v8df) __O,
            __M);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_f64x4 (__mmask8 __M, __m256d __A)
{
  return (__m512d) __builtin_ia32_broadcastf64x4_512 ((__v4df) __A,
            (__v8df)
            _mm512_setzero_pd (),
            __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_i64x4 (__m256i __A)
{
  return (__m512i) __builtin_ia32_broadcasti64x4_512 ((__v4di) __A,
            (__v8di)
            _mm512_undefined_si512 (),
            (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_i64x4 (__m512i __O, __mmask8 __M, __m256i __A)
{
  return (__m512i) __builtin_ia32_broadcasti64x4_512 ((__v4di) __A,
            (__v8di) __O,
            __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_i64x4 (__mmask8 __M, __m256i __A)
{
  return (__m512i) __builtin_ia32_broadcasti64x4_512 ((__v4di) __A,
            (__v8di)
            _mm512_setzero_si512 (),
            __M);
}
typedef enum
{
  _MM_PERM_AAAA = 0x00, _MM_PERM_AAAB = 0x01, _MM_PERM_AAAC = 0x02,
  _MM_PERM_AAAD = 0x03, _MM_PERM_AABA = 0x04, _MM_PERM_AABB = 0x05,
  _MM_PERM_AABC = 0x06, _MM_PERM_AABD = 0x07, _MM_PERM_AACA = 0x08,
  _MM_PERM_AACB = 0x09, _MM_PERM_AACC = 0x0A, _MM_PERM_AACD = 0x0B,
  _MM_PERM_AADA = 0x0C, _MM_PERM_AADB = 0x0D, _MM_PERM_AADC = 0x0E,
  _MM_PERM_AADD = 0x0F, _MM_PERM_ABAA = 0x10, _MM_PERM_ABAB = 0x11,
  _MM_PERM_ABAC = 0x12, _MM_PERM_ABAD = 0x13, _MM_PERM_ABBA = 0x14,
  _MM_PERM_ABBB = 0x15, _MM_PERM_ABBC = 0x16, _MM_PERM_ABBD = 0x17,
  _MM_PERM_ABCA = 0x18, _MM_PERM_ABCB = 0x19, _MM_PERM_ABCC = 0x1A,
  _MM_PERM_ABCD = 0x1B, _MM_PERM_ABDA = 0x1C, _MM_PERM_ABDB = 0x1D,
  _MM_PERM_ABDC = 0x1E, _MM_PERM_ABDD = 0x1F, _MM_PERM_ACAA = 0x20,
  _MM_PERM_ACAB = 0x21, _MM_PERM_ACAC = 0x22, _MM_PERM_ACAD = 0x23,
  _MM_PERM_ACBA = 0x24, _MM_PERM_ACBB = 0x25, _MM_PERM_ACBC = 0x26,
  _MM_PERM_ACBD = 0x27, _MM_PERM_ACCA = 0x28, _MM_PERM_ACCB = 0x29,
  _MM_PERM_ACCC = 0x2A, _MM_PERM_ACCD = 0x2B, _MM_PERM_ACDA = 0x2C,
  _MM_PERM_ACDB = 0x2D, _MM_PERM_ACDC = 0x2E, _MM_PERM_ACDD = 0x2F,
  _MM_PERM_ADAA = 0x30, _MM_PERM_ADAB = 0x31, _MM_PERM_ADAC = 0x32,
  _MM_PERM_ADAD = 0x33, _MM_PERM_ADBA = 0x34, _MM_PERM_ADBB = 0x35,
  _MM_PERM_ADBC = 0x36, _MM_PERM_ADBD = 0x37, _MM_PERM_ADCA = 0x38,
  _MM_PERM_ADCB = 0x39, _MM_PERM_ADCC = 0x3A, _MM_PERM_ADCD = 0x3B,
  _MM_PERM_ADDA = 0x3C, _MM_PERM_ADDB = 0x3D, _MM_PERM_ADDC = 0x3E,
  _MM_PERM_ADDD = 0x3F, _MM_PERM_BAAA = 0x40, _MM_PERM_BAAB = 0x41,
  _MM_PERM_BAAC = 0x42, _MM_PERM_BAAD = 0x43, _MM_PERM_BABA = 0x44,
  _MM_PERM_BABB = 0x45, _MM_PERM_BABC = 0x46, _MM_PERM_BABD = 0x47,
  _MM_PERM_BACA = 0x48, _MM_PERM_BACB = 0x49, _MM_PERM_BACC = 0x4A,
  _MM_PERM_BACD = 0x4B, _MM_PERM_BADA = 0x4C, _MM_PERM_BADB = 0x4D,
  _MM_PERM_BADC = 0x4E, _MM_PERM_BADD = 0x4F, _MM_PERM_BBAA = 0x50,
  _MM_PERM_BBAB = 0x51, _MM_PERM_BBAC = 0x52, _MM_PERM_BBAD = 0x53,
  _MM_PERM_BBBA = 0x54, _MM_PERM_BBBB = 0x55, _MM_PERM_BBBC = 0x56,
  _MM_PERM_BBBD = 0x57, _MM_PERM_BBCA = 0x58, _MM_PERM_BBCB = 0x59,
  _MM_PERM_BBCC = 0x5A, _MM_PERM_BBCD = 0x5B, _MM_PERM_BBDA = 0x5C,
  _MM_PERM_BBDB = 0x5D, _MM_PERM_BBDC = 0x5E, _MM_PERM_BBDD = 0x5F,
  _MM_PERM_BCAA = 0x60, _MM_PERM_BCAB = 0x61, _MM_PERM_BCAC = 0x62,
  _MM_PERM_BCAD = 0x63, _MM_PERM_BCBA = 0x64, _MM_PERM_BCBB = 0x65,
  _MM_PERM_BCBC = 0x66, _MM_PERM_BCBD = 0x67, _MM_PERM_BCCA = 0x68,
  _MM_PERM_BCCB = 0x69, _MM_PERM_BCCC = 0x6A, _MM_PERM_BCCD = 0x6B,
  _MM_PERM_BCDA = 0x6C, _MM_PERM_BCDB = 0x6D, _MM_PERM_BCDC = 0x6E,
  _MM_PERM_BCDD = 0x6F, _MM_PERM_BDAA = 0x70, _MM_PERM_BDAB = 0x71,
  _MM_PERM_BDAC = 0x72, _MM_PERM_BDAD = 0x73, _MM_PERM_BDBA = 0x74,
  _MM_PERM_BDBB = 0x75, _MM_PERM_BDBC = 0x76, _MM_PERM_BDBD = 0x77,
  _MM_PERM_BDCA = 0x78, _MM_PERM_BDCB = 0x79, _MM_PERM_BDCC = 0x7A,
  _MM_PERM_BDCD = 0x7B, _MM_PERM_BDDA = 0x7C, _MM_PERM_BDDB = 0x7D,
  _MM_PERM_BDDC = 0x7E, _MM_PERM_BDDD = 0x7F, _MM_PERM_CAAA = 0x80,
  _MM_PERM_CAAB = 0x81, _MM_PERM_CAAC = 0x82, _MM_PERM_CAAD = 0x83,
  _MM_PERM_CABA = 0x84, _MM_PERM_CABB = 0x85, _MM_PERM_CABC = 0x86,
  _MM_PERM_CABD = 0x87, _MM_PERM_CACA = 0x88, _MM_PERM_CACB = 0x89,
  _MM_PERM_CACC = 0x8A, _MM_PERM_CACD = 0x8B, _MM_PERM_CADA = 0x8C,
  _MM_PERM_CADB = 0x8D, _MM_PERM_CADC = 0x8E, _MM_PERM_CADD = 0x8F,
  _MM_PERM_CBAA = 0x90, _MM_PERM_CBAB = 0x91, _MM_PERM_CBAC = 0x92,
  _MM_PERM_CBAD = 0x93, _MM_PERM_CBBA = 0x94, _MM_PERM_CBBB = 0x95,
  _MM_PERM_CBBC = 0x96, _MM_PERM_CBBD = 0x97, _MM_PERM_CBCA = 0x98,
  _MM_PERM_CBCB = 0x99, _MM_PERM_CBCC = 0x9A, _MM_PERM_CBCD = 0x9B,
  _MM_PERM_CBDA = 0x9C, _MM_PERM_CBDB = 0x9D, _MM_PERM_CBDC = 0x9E,
  _MM_PERM_CBDD = 0x9F, _MM_PERM_CCAA = 0xA0, _MM_PERM_CCAB = 0xA1,
  _MM_PERM_CCAC = 0xA2, _MM_PERM_CCAD = 0xA3, _MM_PERM_CCBA = 0xA4,
  _MM_PERM_CCBB = 0xA5, _MM_PERM_CCBC = 0xA6, _MM_PERM_CCBD = 0xA7,
  _MM_PERM_CCCA = 0xA8, _MM_PERM_CCCB = 0xA9, _MM_PERM_CCCC = 0xAA,
  _MM_PERM_CCCD = 0xAB, _MM_PERM_CCDA = 0xAC, _MM_PERM_CCDB = 0xAD,
  _MM_PERM_CCDC = 0xAE, _MM_PERM_CCDD = 0xAF, _MM_PERM_CDAA = 0xB0,
  _MM_PERM_CDAB = 0xB1, _MM_PERM_CDAC = 0xB2, _MM_PERM_CDAD = 0xB3,
  _MM_PERM_CDBA = 0xB4, _MM_PERM_CDBB = 0xB5, _MM_PERM_CDBC = 0xB6,
  _MM_PERM_CDBD = 0xB7, _MM_PERM_CDCA = 0xB8, _MM_PERM_CDCB = 0xB9,
  _MM_PERM_CDCC = 0xBA, _MM_PERM_CDCD = 0xBB, _MM_PERM_CDDA = 0xBC,
  _MM_PERM_CDDB = 0xBD, _MM_PERM_CDDC = 0xBE, _MM_PERM_CDDD = 0xBF,
  _MM_PERM_DAAA = 0xC0, _MM_PERM_DAAB = 0xC1, _MM_PERM_DAAC = 0xC2,
  _MM_PERM_DAAD = 0xC3, _MM_PERM_DABA = 0xC4, _MM_PERM_DABB = 0xC5,
  _MM_PERM_DABC = 0xC6, _MM_PERM_DABD = 0xC7, _MM_PERM_DACA = 0xC8,
  _MM_PERM_DACB = 0xC9, _MM_PERM_DACC = 0xCA, _MM_PERM_DACD = 0xCB,
  _MM_PERM_DADA = 0xCC, _MM_PERM_DADB = 0xCD, _MM_PERM_DADC = 0xCE,
  _MM_PERM_DADD = 0xCF, _MM_PERM_DBAA = 0xD0, _MM_PERM_DBAB = 0xD1,
  _MM_PERM_DBAC = 0xD2, _MM_PERM_DBAD = 0xD3, _MM_PERM_DBBA = 0xD4,
  _MM_PERM_DBBB = 0xD5, _MM_PERM_DBBC = 0xD6, _MM_PERM_DBBD = 0xD7,
  _MM_PERM_DBCA = 0xD8, _MM_PERM_DBCB = 0xD9, _MM_PERM_DBCC = 0xDA,
  _MM_PERM_DBCD = 0xDB, _MM_PERM_DBDA = 0xDC, _MM_PERM_DBDB = 0xDD,
  _MM_PERM_DBDC = 0xDE, _MM_PERM_DBDD = 0xDF, _MM_PERM_DCAA = 0xE0,
  _MM_PERM_DCAB = 0xE1, _MM_PERM_DCAC = 0xE2, _MM_PERM_DCAD = 0xE3,
  _MM_PERM_DCBA = 0xE4, _MM_PERM_DCBB = 0xE5, _MM_PERM_DCBC = 0xE6,
  _MM_PERM_DCBD = 0xE7, _MM_PERM_DCCA = 0xE8, _MM_PERM_DCCB = 0xE9,
  _MM_PERM_DCCC = 0xEA, _MM_PERM_DCCD = 0xEB, _MM_PERM_DCDA = 0xEC,
  _MM_PERM_DCDB = 0xED, _MM_PERM_DCDC = 0xEE, _MM_PERM_DCDD = 0xEF,
  _MM_PERM_DDAA = 0xF0, _MM_PERM_DDAB = 0xF1, _MM_PERM_DDAC = 0xF2,
  _MM_PERM_DDAD = 0xF3, _MM_PERM_DDBA = 0xF4, _MM_PERM_DDBB = 0xF5,
  _MM_PERM_DDBC = 0xF6, _MM_PERM_DDBD = 0xF7, _MM_PERM_DDCA = 0xF8,
  _MM_PERM_DDCB = 0xF9, _MM_PERM_DDCC = 0xFA, _MM_PERM_DDCD = 0xFB,
  _MM_PERM_DDDA = 0xFC, _MM_PERM_DDDB = 0xFD, _MM_PERM_DDDC = 0xFE,
  _MM_PERM_DDDD = 0xFF
} _MM_PERM_ENUM;
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rolv_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prolvd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_si512 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rolv_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prolvd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rolv_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prolvd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rorv_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prorvd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_si512 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rorv_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prorvd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rorv_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prorvd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rolv_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prolvq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_undefined_si512 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rolv_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prolvq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W,
        (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rolv_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prolvq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_si512 (),
        (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rorv_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prorvq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_undefined_si512 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rorv_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prorvq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W,
        (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rorv_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prorvq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_si512 (),
        (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtu32_sd (__m128d __A, unsigned __B)
{
  return (__m128d) __builtin_ia32_cvtusi2sd32 ((__v2df) __A, __B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi32_epi8 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovdb512_mask ((__v16si) __A,
        (__v16qi)
        _mm_undefined_si128 (),
        (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi32_storeu_epi8 (void * __P, __mmask16 __M, __m512i __A)
{
  __builtin_ia32_pmovdb512mem_mask ((__v16qi *) __P, (__v16si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi32_epi8 (__m128i __O, __mmask16 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovdb512_mask ((__v16si) __A,
        (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi32_epi8 (__mmask16 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovdb512_mask ((__v16si) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtsepi32_epi8 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb512_mask ((__v16si) __A,
         (__v16qi)
         _mm_undefined_si128 (),
         (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi32_storeu_epi8 (void * __P, __mmask16 __M, __m512i __A)
{
  __builtin_ia32_pmovsdb512mem_mask ((__v16qi *) __P, (__v16si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi32_epi8 (__m128i __O, __mmask16 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb512_mask ((__v16si) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtsepi32_epi8 (__mmask16 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb512_mask ((__v16si) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtusepi32_epi8 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb512_mask ((__v16si) __A,
          (__v16qi)
          _mm_undefined_si128 (),
          (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi32_storeu_epi8 (void * __P, __mmask16 __M, __m512i __A)
{
  __builtin_ia32_pmovusdb512mem_mask ((__v16qi *) __P, (__v16si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi32_epi8 (__m128i __O, __mmask16 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb512_mask ((__v16si) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtusepi32_epi8 (__mmask16 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb512_mask ((__v16si) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi32_epi16 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovdw512_mask ((__v16si) __A,
        (__v16hi)
        _mm256_undefined_si256 (),
        (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi32_storeu_epi16 (void * __P, __mmask16 __M, __m512i __A)
{
  __builtin_ia32_pmovdw512mem_mask ((__v16hi *) __P, (__v16si) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi32_epi16 (__m256i __O, __mmask16 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovdw512_mask ((__v16si) __A,
        (__v16hi) __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi32_epi16 (__mmask16 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovdw512_mask ((__v16si) __A,
        (__v16hi)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtsepi32_epi16 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovsdw512_mask ((__v16si) __A,
         (__v16hi)
         _mm256_undefined_si256 (),
         (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi32_storeu_epi16 (void *__P, __mmask16 __M, __m512i __A)
{
  __builtin_ia32_pmovsdw512mem_mask ((__v16hi*) __P, (__v16si) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi32_epi16 (__m256i __O, __mmask16 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovsdw512_mask ((__v16si) __A,
         (__v16hi) __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtsepi32_epi16 (__mmask16 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovsdw512_mask ((__v16si) __A,
         (__v16hi)
         _mm256_setzero_si256 (),
         __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtusepi32_epi16 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovusdw512_mask ((__v16si) __A,
          (__v16hi)
          _mm256_undefined_si256 (),
          (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi32_storeu_epi16 (void *__P, __mmask16 __M, __m512i __A)
{
  __builtin_ia32_pmovusdw512mem_mask ((__v16hi*) __P, (__v16si) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi32_epi16 (__m256i __O, __mmask16 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovusdw512_mask ((__v16si) __A,
          (__v16hi) __O,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtusepi32_epi16 (__mmask16 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovusdw512_mask ((__v16si) __A,
          (__v16hi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi64_epi32 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovqd512_mask ((__v8di) __A,
        (__v8si)
        _mm256_undefined_si256 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_storeu_epi32 (void* __P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovqd512mem_mask ((__v8si *) __P, (__v8di) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_epi32 (__m256i __O, __mmask8 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovqd512_mask ((__v8di) __A,
        (__v8si) __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi64_epi32 (__mmask8 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovqd512_mask ((__v8di) __A,
        (__v8si)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtsepi64_epi32 (__m512i __A)
{
  __v8si __O;
  return (__m256i) __builtin_ia32_pmovsqd512_mask ((__v8di) __A,
         (__v8si)
         _mm256_undefined_si256 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi64_storeu_epi32 (void *__P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovsqd512mem_mask ((__v8si *) __P, (__v8di) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi64_epi32 (__m256i __O, __mmask8 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovsqd512_mask ((__v8di) __A,
         (__v8si) __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtsepi64_epi32 (__mmask8 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovsqd512_mask ((__v8di) __A,
         (__v8si)
         _mm256_setzero_si256 (),
         __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtusepi64_epi32 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovusqd512_mask ((__v8di) __A,
          (__v8si)
          _mm256_undefined_si256 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi64_storeu_epi32 (void* __P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovusqd512mem_mask ((__v8si*) __P, (__v8di) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi64_epi32 (__m256i __O, __mmask8 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovusqd512_mask ((__v8di) __A,
          (__v8si) __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtusepi64_epi32 (__mmask8 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovusqd512_mask ((__v8di) __A,
          (__v8si)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi64_epi16 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovqw512_mask ((__v8di) __A,
        (__v8hi)
        _mm_undefined_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_storeu_epi16 (void *__P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovqw512mem_mask ((__v8hi *) __P, (__v8di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_epi16 (__m128i __O, __mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovqw512_mask ((__v8di) __A,
        (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi64_epi16 (__mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovqw512_mask ((__v8di) __A,
        (__v8hi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtsepi64_epi16 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw512_mask ((__v8di) __A,
         (__v8hi)
         _mm_undefined_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi64_storeu_epi16 (void * __P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovsqw512mem_mask ((__v8hi *) __P, (__v8di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi64_epi16 (__m128i __O, __mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw512_mask ((__v8di) __A,
         (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtsepi64_epi16 (__mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw512_mask ((__v8di) __A,
         (__v8hi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtusepi64_epi16 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw512_mask ((__v8di) __A,
          (__v8hi)
          _mm_undefined_si128 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi64_storeu_epi16 (void *__P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovusqw512mem_mask ((__v8hi*) __P, (__v8di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi64_epi16 (__m128i __O, __mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw512_mask ((__v8di) __A,
          (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtusepi64_epi16 (__mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw512_mask ((__v8di) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi64_epi8 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovqb512_mask ((__v8di) __A,
        (__v16qi)
        _mm_undefined_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_storeu_epi8 (void * __P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovqb512mem_mask ((__v16qi *) __P, (__v8di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_epi8 (__m128i __O, __mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovqb512_mask ((__v8di) __A,
        (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi64_epi8 (__mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovqb512_mask ((__v8di) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtsepi64_epi8 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb512_mask ((__v8di) __A,
         (__v16qi)
         _mm_undefined_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi64_storeu_epi8 (void * __P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovsqb512mem_mask ((__v16qi *) __P, (__v8di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi64_epi8 (__m128i __O, __mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb512_mask ((__v8di) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtsepi64_epi8 (__mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb512_mask ((__v8di) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtusepi64_epi8 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb512_mask ((__v8di) __A,
          (__v16qi)
          _mm_undefined_si128 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi64_storeu_epi8 (void * __P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovusqb512mem_mask ((__v16qi *) __P, (__v8di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi64_epi8 (__m128i __O, __mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb512_mask ((__v8di) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtusepi64_epi8 (__mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb512_mask ((__v8di) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi32_pd (__m256i __A)
{
  return (__m512d) __builtin_ia32_cvtdq2pd512_mask ((__v8si) __A,
          (__v8df)
          _mm512_undefined_pd (),
          (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi32_pd (__m512d __W, __mmask8 __U, __m256i __A)
{
  return (__m512d) __builtin_ia32_cvtdq2pd512_mask ((__v8si) __A,
          (__v8df) __W,
          (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi32_pd (__mmask8 __U, __m256i __A)
{
  return (__m512d) __builtin_ia32_cvtdq2pd512_mask ((__v8si) __A,
          (__v8df)
          _mm512_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu32_pd (__m256i __A)
{
  return (__m512d) __builtin_ia32_cvtudq2pd512_mask ((__v8si) __A,
           (__v8df)
           _mm512_undefined_pd (),
           (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu32_pd (__m512d __W, __mmask8 __U, __m256i __A)
{
  return (__m512d) __builtin_ia32_cvtudq2pd512_mask ((__v8si) __A,
           (__v8df) __W,
           (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu32_pd (__mmask8 __U, __m256i __A)
{
  return (__m512d) __builtin_ia32_cvtudq2pd512_mask ((__v8si) __A,
           (__v8df)
           _mm512_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_loadu_pd (void const *__P)
{
  return (__m512d) __builtin_ia32_loadupd512_mask ((const __v8df *) __P,
         (__v8df)
         _mm512_undefined_pd (),
         (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_loadu_pd (__m512d __W, __mmask8 __U, void const *__P)
{
  return (__m512d) __builtin_ia32_loadupd512_mask ((const __v8df *) __P,
         (__v8df) __W,
         (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_loadu_pd (__mmask8 __U, void const *__P)
{
  return (__m512d) __builtin_ia32_loadupd512_mask ((const __v8df *) __P,
         (__v8df)
         _mm512_setzero_pd (),
         (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_storeu_pd (void *__P, __m512d __A)
{
  __builtin_ia32_storeupd512_mask ((__v8df *) __P, (__v8df) __A,
       (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_storeu_pd (void *__P, __mmask8 __U, __m512d __A)
{
  __builtin_ia32_storeupd512_mask ((__v8df *) __P, (__v8df) __A,
       (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_loadu_ps (void const *__P)
{
  return (__m512) __builtin_ia32_loadups512_mask ((const __v16sf *) __P,
        (__v16sf)
        _mm512_undefined_ps (),
        (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_loadu_ps (__m512 __W, __mmask16 __U, void const *__P)
{
  return (__m512) __builtin_ia32_loadups512_mask ((const __v16sf *) __P,
        (__v16sf) __W,
        (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_loadu_ps (__mmask16 __U, void const *__P)
{
  return (__m512) __builtin_ia32_loadups512_mask ((const __v16sf *) __P,
        (__v16sf)
        _mm512_setzero_ps (),
        (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_storeu_ps (void *__P, __m512 __A)
{
  __builtin_ia32_storeups512_mask ((__v16sf *) __P, (__v16sf) __A,
       (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_storeu_ps (void *__P, __mmask16 __U, __m512 __A)
{
  __builtin_ia32_storeups512_mask ((__v16sf *) __P, (__v16sf) __A,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_loadu_epi64 (__m512i __W, __mmask8 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddqudi512_mask ((const __v8di *) __P,
           (__v8di) __W,
           (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_loadu_epi64 (__mmask8 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddqudi512_mask ((const __v8di *) __P,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_storeu_epi64 (void *__P, __mmask8 __U, __m512i __A)
{
  __builtin_ia32_storedqudi512_mask ((__v8di *) __P, (__v8di) __A,
         (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_loadu_si512 (void const *__P)
{
  return (__m512i) __builtin_ia32_loaddqusi512_mask ((const __v16si *) __P,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_loadu_epi32 (__m512i __W, __mmask16 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddqusi512_mask ((const __v16si *) __P,
           (__v16si) __W,
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_loadu_epi32 (__mmask16 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddqusi512_mask ((const __v16si *) __P,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_storeu_si512 (void *__P, __m512i __A)
{
  __builtin_ia32_storedqusi512_mask ((__v16si *) __P, (__v16si) __A,
         (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_storeu_epi32 (void *__P, __mmask16 __U, __m512i __A)
{
  __builtin_ia32_storedqusi512_mask ((__v16si *) __P, (__v16si) __A,
         (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutevar_pd (__m512d __A, __m512i __C)
{
  return (__m512d) __builtin_ia32_vpermilvarpd512_mask ((__v8df) __A,
       (__v8di) __C,
       (__v8df)
       _mm512_undefined_pd (),
       (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutevar_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512i __C)
{
  return (__m512d) __builtin_ia32_vpermilvarpd512_mask ((__v8df) __A,
       (__v8di) __C,
       (__v8df) __W,
       (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutevar_pd (__mmask8 __U, __m512d __A, __m512i __C)
{
  return (__m512d) __builtin_ia32_vpermilvarpd512_mask ((__v8df) __A,
       (__v8di) __C,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutevar_ps (__m512 __A, __m512i __C)
{
  return (__m512) __builtin_ia32_vpermilvarps512_mask ((__v16sf) __A,
             (__v16si) __C,
             (__v16sf)
             _mm512_undefined_ps (),
             (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutevar_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512i __C)
{
  return (__m512) __builtin_ia32_vpermilvarps512_mask ((__v16sf) __A,
             (__v16si) __C,
             (__v16sf) __W,
             (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutevar_ps (__mmask16 __U, __m512 __A, __m512i __C)
{
  return (__m512) __builtin_ia32_vpermilvarps512_mask ((__v16sf) __A,
             (__v16si) __C,
             (__v16sf)
             _mm512_setzero_ps (),
             (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutex2var_epi64 (__m512i __A, __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varq512_mask ((__v8di) __I
                       ,
             (__v8di) __A,
             (__v8di) __B,
             (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutex2var_epi64 (__m512i __A, __mmask8 __U, __m512i __I,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varq512_mask ((__v8di) __I
                       ,
             (__v8di) __A,
             (__v8di) __B,
             (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask2_permutex2var_epi64 (__m512i __A, __m512i __I,
     __mmask8 __U, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermi2varq512_mask ((__v8di) __A,
             (__v8di) __I
                       ,
             (__v8di) __B,
             (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutex2var_epi64 (__mmask8 __U, __m512i __A,
     __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varq512_maskz ((__v8di) __I
                 ,
       (__v8di) __A,
       (__v8di) __B,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutex2var_epi32 (__m512i __A, __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2vard512_mask ((__v16si) __I
                       ,
             (__v16si) __A,
             (__v16si) __B,
             (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutex2var_epi32 (__m512i __A, __mmask16 __U,
    __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2vard512_mask ((__v16si) __I
                       ,
             (__v16si) __A,
             (__v16si) __B,
             (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask2_permutex2var_epi32 (__m512i __A, __m512i __I,
     __mmask16 __U, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermi2vard512_mask ((__v16si) __A,
             (__v16si) __I
                       ,
             (__v16si) __B,
             (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutex2var_epi32 (__mmask16 __U, __m512i __A,
     __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2vard512_maskz ((__v16si) __I
                 ,
       (__v16si) __A,
       (__v16si) __B,
       (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutex2var_pd (__m512d __A, __m512i __I, __m512d __B)
{
  return (__m512d) __builtin_ia32_vpermt2varpd512_mask ((__v8di) __I
                 ,
       (__v8df) __A,
       (__v8df) __B,
       (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutex2var_pd (__m512d __A, __mmask8 __U, __m512i __I,
        __m512d __B)
{
  return (__m512d) __builtin_ia32_vpermt2varpd512_mask ((__v8di) __I
                 ,
       (__v8df) __A,
       (__v8df) __B,
       (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask2_permutex2var_pd (__m512d __A, __m512i __I, __mmask8 __U,
         __m512d __B)
{
  return (__m512d) __builtin_ia32_vpermi2varpd512_mask ((__v8df) __A,
       (__v8di) __I
                 ,
       (__v8df) __B,
       (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutex2var_pd (__mmask8 __U, __m512d __A, __m512i __I,
         __m512d __B)
{
  return (__m512d) __builtin_ia32_vpermt2varpd512_maskz ((__v8di) __I
                  ,
        (__v8df) __A,
        (__v8df) __B,
        (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutex2var_ps (__m512 __A, __m512i __I, __m512 __B)
{
  return (__m512) __builtin_ia32_vpermt2varps512_mask ((__v16si) __I
                       ,
             (__v16sf) __A,
             (__v16sf) __B,
             (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutex2var_ps (__m512 __A, __mmask16 __U, __m512i __I, __m512 __B)
{
  return (__m512) __builtin_ia32_vpermt2varps512_mask ((__v16si) __I
                       ,
             (__v16sf) __A,
             (__v16sf) __B,
             (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask2_permutex2var_ps (__m512 __A, __m512i __I, __mmask16 __U,
         __m512 __B)
{
  return (__m512) __builtin_ia32_vpermi2varps512_mask ((__v16sf) __A,
             (__v16si) __I
                       ,
             (__v16sf) __B,
             (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutex2var_ps (__mmask16 __U, __m512 __A, __m512i __I,
         __m512 __B)
{
  return (__m512) __builtin_ia32_vpermt2varps512_maskz ((__v16si) __I
                 ,
       (__v16sf) __A,
       (__v16sf) __B,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutexvar_epi64 (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_permvardi512_mask ((__v8di) __Y,
           (__v8di) __X,
           (__v8di)
           _mm512_setzero_si512 (),
           __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutexvar_epi64 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_permvardi512_mask ((__v8di) __Y,
           (__v8di) __X,
           (__v8di)
           _mm512_undefined_si512 (),
           (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutexvar_epi64 (__m512i __W, __mmask8 __M, __m512i __X,
          __m512i __Y)
{
  return (__m512i) __builtin_ia32_permvardi512_mask ((__v8di) __Y,
           (__v8di) __X,
           (__v8di) __W,
           __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutexvar_epi32 (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_permvarsi512_mask ((__v16si) __Y,
           (__v16si) __X,
           (__v16si)
           _mm512_setzero_si512 (),
           __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutexvar_epi32 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_permvarsi512_mask ((__v16si) __Y,
           (__v16si) __X,
           (__v16si)
           _mm512_undefined_si512 (),
           (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutexvar_epi32 (__m512i __W, __mmask16 __M, __m512i __X,
          __m512i __Y)
{
  return (__m512i) __builtin_ia32_permvarsi512_mask ((__v16si) __Y,
           (__v16si) __X,
           (__v16si) __W,
           __M);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutexvar_pd (__m512i __X, __m512d __Y)
{
  return (__m512d) __builtin_ia32_permvardf512_mask ((__v8df) __Y,
           (__v8di) __X,
           (__v8df)
           _mm512_undefined_pd (),
           (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutexvar_pd (__m512d __W, __mmask8 __U, __m512i __X, __m512d __Y)
{
  return (__m512d) __builtin_ia32_permvardf512_mask ((__v8df) __Y,
           (__v8di) __X,
           (__v8df) __W,
           (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutexvar_pd (__mmask8 __U, __m512i __X, __m512d __Y)
{
  return (__m512d) __builtin_ia32_permvardf512_mask ((__v8df) __Y,
           (__v8di) __X,
           (__v8df)
           _mm512_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutexvar_ps (__m512i __X, __m512 __Y)
{
  return (__m512) __builtin_ia32_permvarsf512_mask ((__v16sf) __Y,
          (__v16si) __X,
          (__v16sf)
          _mm512_undefined_ps (),
          (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutexvar_ps (__m512 __W, __mmask16 __U, __m512i __X, __m512 __Y)
{
  return (__m512) __builtin_ia32_permvarsf512_mask ((__v16sf) __Y,
          (__v16si) __X,
          (__v16sf) __W,
          (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutexvar_ps (__mmask16 __U, __m512i __X, __m512 __Y)
{
  return (__m512) __builtin_ia32_permvarsf512_mask ((__v16sf) __Y,
          (__v16si) __X,
          (__v16sf)
          _mm512_setzero_ps (),
          (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movehdup_ps (__m512 __A)
{
  return (__m512) __builtin_ia32_movshdup512_mask ((__v16sf) __A,
         (__v16sf)
         _mm512_undefined_ps (),
         (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_movehdup_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_movshdup512_mask ((__v16sf) __A,
         (__v16sf) __W,
         (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_movehdup_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_movshdup512_mask ((__v16sf) __A,
         (__v16sf)
         _mm512_setzero_ps (),
         (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_moveldup_ps (__m512 __A)
{
  return (__m512) __builtin_ia32_movsldup512_mask ((__v16sf) __A,
         (__v16sf)
         _mm512_undefined_ps (),
         (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_moveldup_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_movsldup512_mask ((__v16sf) __A,
         (__v16sf) __W,
         (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_moveldup_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_movsldup512_mask ((__v16sf) __A,
         (__v16sf)
         _mm512_setzero_ps (),
         (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_or_si512 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A | (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_or_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A | (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_or_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pord512_mask ((__v16si) __A,
      (__v16si) __B,
      (__v16si) __W,
      (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_or_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pord512_mask ((__v16si) __A,
      (__v16si) __B,
      (__v16si)
      _mm512_setzero_si512 (),
      (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_or_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v8du) __A | (__v8du) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_or_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_porq512_mask ((__v8di) __A,
      (__v8di) __B,
      (__v8di) __W,
      (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_or_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_porq512_mask ((__v8di) __A,
      (__v8di) __B,
      (__v8di)
      _mm512_setzero_si512 (),
      (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_xor_si512 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A ^ (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_xor_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A ^ (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_xor_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pxord512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_xor_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pxord512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_xor_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v8du) __A ^ (__v8du) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_xor_epi64 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pxorq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_xor_epi64 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pxorq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_and_si512 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A & (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_and_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A & (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_and_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandd512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_and_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandd512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_and_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v8du) __A & (__v8du) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_and_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di) __W, __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_and_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di)
       _mm512_setzero_pd (),
       __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_andnot_si512 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandnd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_si512 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_andnot_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandnd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_si512 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_andnot_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandnd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_andnot_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandnd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_andnot_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandnq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_undefined_si512 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_andnot_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandnq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W, __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_andnot_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandnq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_pd (),
        __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_test_epi32_mask (__m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ptestmd512 ((__v16si) __A,
      (__v16si) __B,
      (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_test_epi32_mask (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ptestmd512 ((__v16si) __A,
      (__v16si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_test_epi64_mask (__m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ptestmq512 ((__v8di) __A,
            (__v8di) __B,
            (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_test_epi64_mask (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ptestmq512 ((__v8di) __A, (__v8di) __B, __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_testn_epi32_mask (__m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ptestnmd512 ((__v16si) __A,
       (__v16si) __B,
       (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_testn_epi32_mask (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ptestnmd512 ((__v16si) __A,
       (__v16si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_testn_epi64_mask (__m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmq512 ((__v8di) __A,
      (__v8di) __B,
      (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_testn_epi64_mask (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmq512 ((__v8di) __A,
      (__v8di) __B, __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpackhi_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhdq512_mask ((__v16si) __A,
           (__v16si) __B,
           (__v16si)
           _mm512_undefined_si512 (),
           (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpackhi_epi32 (__m512i __W, __mmask16 __U, __m512i __A,
       __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhdq512_mask ((__v16si) __A,
           (__v16si) __B,
           (__v16si) __W,
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpackhi_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhdq512_mask ((__v16si) __A,
           (__v16si) __B,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpackhi_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhqdq512_mask ((__v8di) __A,
            (__v8di) __B,
            (__v8di)
            _mm512_undefined_si512 (),
            (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpackhi_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhqdq512_mask ((__v8di) __A,
            (__v8di) __B,
            (__v8di) __W,
            (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpackhi_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhqdq512_mask ((__v8di) __A,
            (__v8di) __B,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpacklo_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckldq512_mask ((__v16si) __A,
           (__v16si) __B,
           (__v16si)
           _mm512_undefined_si512 (),
           (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpacklo_epi32 (__m512i __W, __mmask16 __U, __m512i __A,
       __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckldq512_mask ((__v16si) __A,
           (__v16si) __B,
           (__v16si) __W,
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpacklo_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckldq512_mask ((__v16si) __A,
           (__v16si) __B,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpacklo_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklqdq512_mask ((__v8di) __A,
            (__v8di) __B,
            (__v8di)
            _mm512_undefined_si512 (),
            (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpacklo_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklqdq512_mask ((__v8di) __A,
            (__v8di) __B,
            (__v8di) __W,
            (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpacklo_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklqdq512_mask ((__v8di) __A,
            (__v8di) __B,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movedup_pd (__m512d __A)
{
  return (__m512d) __builtin_ia32_movddup512_mask ((__v8df) __A,
         (__v8df)
         _mm512_undefined_pd (),
         (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_movedup_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_movddup512_mask ((__v8df) __A,
         (__v8df) __W,
         (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_movedup_pd (__mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_movddup512_mask ((__v8df) __A,
         (__v8df)
         _mm512_setzero_pd (),
         (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpacklo_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_unpcklpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df)
          _mm512_undefined_pd (),
          (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpacklo_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_unpcklpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df) __W,
          (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpacklo_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_unpcklpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df)
          _mm512_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpackhi_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_unpckhpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df)
          _mm512_undefined_pd (),
          (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpackhi_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_unpckhpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df) __W,
          (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpackhi_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_unpckhpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df)
          _mm512_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpackhi_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_unpckhps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf)
         _mm512_undefined_ps (),
         (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpackhi_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_unpckhps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf) __W,
         (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpackhi_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_unpckhps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf)
         _mm512_setzero_ps (),
         (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_stream_si512 (__m512i * __P, __m512i __A)
{
  __builtin_ia32_movntdq512 ((__v8di *) __P, (__v8di) __A);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_stream_ps (float *__P, __m512 __A)
{
  __builtin_ia32_movntps512 (__P, (__v16sf) __A);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_stream_pd (double *__P, __m512d __A)
{
  __builtin_ia32_movntpd512 (__P, (__v8df) __A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_stream_load_si512 (void *__P)
{
  return __builtin_ia32_movntdqa512 ((__v8di *)__P);
}
typedef enum
{
  _MM_MANT_NORM_1_2,
  _MM_MANT_NORM_p5_2,
  _MM_MANT_NORM_p5_1,
  _MM_MANT_NORM_p75_1p5
} _MM_MANTISSA_NORM_ENUM;
typedef enum
{
  _MM_MANT_SIGN_src,
  _MM_MANT_SIGN_zero,
  _MM_MANT_SIGN_nan
} _MM_MANTISSA_SIGN_ENUM;
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_floor_ps (__m512 __A)
{
  return (__m512) __builtin_ia32_rndscaleps_mask ((__v16sf) __A,
        (0x01 | 0x00),
        (__v16sf) __A, -1,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_floor_pd (__m512d __A)
{
  return (__m512d) __builtin_ia32_rndscalepd_mask ((__v8df) __A,
         (0x01 | 0x00),
         (__v8df) __A, -1,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_ceil_ps (__m512 __A)
{
  return (__m512) __builtin_ia32_rndscaleps_mask ((__v16sf) __A,
        (0x02 | 0x00),
        (__v16sf) __A, -1,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_ceil_pd (__m512d __A)
{
  return (__m512d) __builtin_ia32_rndscalepd_mask ((__v8df) __A,
         (0x02 | 0x00),
         (__v8df) __A, -1,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_floor_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_rndscaleps_mask ((__v16sf) __A,
        (0x01 | 0x00),
        (__v16sf) __W, __U,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_floor_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_rndscalepd_mask ((__v8df) __A,
         (0x01 | 0x00),
         (__v8df) __W, __U,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_ceil_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_rndscaleps_mask ((__v16sf) __A,
        (0x02 | 0x00),
        (__v16sf) __W, __U,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_ceil_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_rndscalepd_mask ((__v8df) __A,
         (0x02 | 0x00),
         (__v8df) __W, __U,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epi32_mask (__m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_pcmpeqd512_mask ((__v16si) __A,
           (__v16si) __B,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epi32_mask (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_pcmpeqd512_mask ((__v16si) __A,
           (__v16si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epi64_mask (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqq512_mask ((__v8di) __A,
          (__v8di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epi64_mask (__m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqq512_mask ((__v8di) __A,
          (__v8di) __B,
          (__mmask8) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epi32_mask (__m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_pcmpgtd512_mask ((__v16si) __A,
           (__v16si) __B,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epi32_mask (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_pcmpgtd512_mask ((__v16si) __A,
           (__v16si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epi64_mask (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtq512_mask ((__v8di) __A,
          (__v8di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epi64_mask (__m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtq512_mask ((__v8di) __A,
          (__v8di) __B,
          (__mmask8) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epi32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 5,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epi32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 5,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epu32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 5,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epu32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 5,
          (__mmask16) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epi64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 5,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epi64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 5,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epu64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 5,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epu64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 5,
          (__mmask8) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epi32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 2,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epi32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 2,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epu32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 2,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epu32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 2,
          (__mmask16) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epi64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 2,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epi64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 2,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epu64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 2,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epu64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 2,
          (__mmask8) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epi32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 1,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epi32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 1,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epu32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 1,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epu32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 1,
          (__mmask16) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epi64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 1,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epi64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 1,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epu64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 1,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epu64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 1,
          (__mmask8) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epi32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 4,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epi32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 4,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epu32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 4,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epu32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 4,
          (__mmask16) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epi64_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 4,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epi64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 4,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epu64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 4,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epu64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 4,
          (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compress_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_compressdf512_mask ((__v8df) __A,
            (__v8df) __W,
            (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_compress_pd (__mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_compressdf512_mask ((__v8df) __A,
            (__v8df)
            _mm512_setzero_pd (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compressstoreu_pd (void *__P, __mmask8 __U, __m512d __A)
{
  __builtin_ia32_compressstoredf512_mask ((__v8df *) __P, (__v8df) __A,
       (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compress_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_compresssf512_mask ((__v16sf) __A,
           (__v16sf) __W,
           (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_compress_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_compresssf512_mask ((__v16sf) __A,
           (__v16sf)
           _mm512_setzero_ps (),
           (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compressstoreu_ps (void *__P, __mmask16 __U, __m512 __A)
{
  __builtin_ia32_compressstoresf512_mask ((__v16sf *) __P, (__v16sf) __A,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compress_epi64 (__m512i __W, __mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_compressdi512_mask ((__v8di) __A,
            (__v8di) __W,
            (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_compress_epi64 (__mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_compressdi512_mask ((__v8di) __A,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compressstoreu_epi64 (void *__P, __mmask8 __U, __m512i __A)
{
  __builtin_ia32_compressstoredi512_mask ((__v8di *) __P, (__v8di) __A,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compress_epi32 (__m512i __W, __mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_compresssi512_mask ((__v16si) __A,
            (__v16si) __W,
            (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_compress_epi32 (__mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_compresssi512_mask ((__v16si) __A,
            (__v16si)
            _mm512_setzero_si512 (),
            (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compressstoreu_epi32 (void *__P, __mmask16 __U, __m512i __A)
{
  __builtin_ia32_compressstoresi512_mask ((__v16si *) __P, (__v16si) __A,
       (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expand_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_expanddf512_mask ((__v8df) __A,
          (__v8df) __W,
          (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expand_pd (__mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_expanddf512_maskz ((__v8df) __A,
           (__v8df)
           _mm512_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expandloadu_pd (__m512d __W, __mmask8 __U, void const *__P)
{
  return (__m512d) __builtin_ia32_expandloaddf512_mask ((const __v8df *) __P,
       (__v8df) __W,
       (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expandloadu_pd (__mmask8 __U, void const *__P)
{
  return (__m512d) __builtin_ia32_expandloaddf512_maskz ((const __v8df *) __P,
        (__v8df)
        _mm512_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expand_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_expandsf512_mask ((__v16sf) __A,
         (__v16sf) __W,
         (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expand_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_expandsf512_maskz ((__v16sf) __A,
          (__v16sf)
          _mm512_setzero_ps (),
          (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expandloadu_ps (__m512 __W, __mmask16 __U, void const *__P)
{
  return (__m512) __builtin_ia32_expandloadsf512_mask ((const __v16sf *) __P,
             (__v16sf) __W,
             (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expandloadu_ps (__mmask16 __U, void const *__P)
{
  return (__m512) __builtin_ia32_expandloadsf512_maskz ((const __v16sf *) __P,
       (__v16sf)
       _mm512_setzero_ps (),
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expand_epi64 (__m512i __W, __mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_expanddi512_mask ((__v8di) __A,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expand_epi64 (__mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_expanddi512_maskz ((__v8di) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expandloadu_epi64 (__m512i __W, __mmask8 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_expandloaddi512_mask ((const __v8di *) __P,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expandloadu_epi64 (__mmask8 __U, void const *__P)
{
  return (__m512i)
  __builtin_ia32_expandloaddi512_maskz ((const __v8di *) __P,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expand_epi32 (__m512i __W, __mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_expandsi512_mask ((__v16si) __A,
          (__v16si) __W,
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expand_epi32 (__mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_expandsi512_maskz ((__v16si) __A,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expandloadu_epi32 (__m512i __W, __mmask16 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_expandloadsi512_mask ((const __v16si *) __P,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expandloadu_epi32 (__mmask16 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_expandloadsi512_maskz ((const __v16si *) __P,
        (__v16si)
        _mm512_setzero_si512
        (), (__mmask16) __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kand (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kandhi ((__mmask16) __A, (__mmask16) __B);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kandn (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kandnhi ((__mmask16) __A, (__mmask16) __B);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kor (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_korhi ((__mmask16) __A, (__mmask16) __B);
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kortestz (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kortestzhi ((__mmask16) __A,
      (__mmask16) __B);
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kortestc (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kortestchi ((__mmask16) __A,
      (__mmask16) __B);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kxnor (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kxnorhi ((__mmask16) __A, (__mmask16) __B);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kxor (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kxorhi ((__mmask16) __A, (__mmask16) __B);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_knot (__mmask16 __A)
{
  return (__mmask16) __builtin_ia32_knothi ((__mmask16) __A);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kunpackb (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kunpckhi ((__mmask16) __A, (__mmask16) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_undefined_si512 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epi64 (__mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epi64 (__m512i __W, __mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_undefined_si512 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epi64 (__m512i __W, __mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epi64 (__mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epu64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxuq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_undefined_si512 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epu64 (__mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxuq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epu64 (__m512i __W, __mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxuq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epu64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminuq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_undefined_si512 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epu64 (__m512i __W, __mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminuq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epu64 (__mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminuq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_si512 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epi32 (__mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epi32 (__m512i __W, __mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_si512 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epi32 (__mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epi32 (__m512i __W, __mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epu32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxud512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_si512 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epu32 (__mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxud512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epu32 (__m512i __W, __mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxud512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epu32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminud512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_si512 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epu32 (__mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminud512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epu32 (__m512i __W, __mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminud512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W, __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpacklo_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_unpcklps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf)
         _mm512_undefined_ps (),
         (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpacklo_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_unpcklps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf) __W,
         (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpacklo_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_unpcklps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf)
         _mm512_setzero_ps (),
         (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_blend_pd (__mmask8 __U, __m512d __A, __m512d __W)
{
  return (__m512d) __builtin_ia32_blendmpd_512_mask ((__v8df) __A,
           (__v8df) __W,
           (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_blend_ps (__mmask16 __U, __m512 __A, __m512 __W)
{
  return (__m512) __builtin_ia32_blendmps_512_mask ((__v16sf) __A,
          (__v16sf) __W,
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_blend_epi64 (__mmask8 __U, __m512i __A, __m512i __W)
{
  return (__m512i) __builtin_ia32_blendmq_512_mask ((__v8di) __A,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_blend_epi32 (__mmask16 __U, __m512i __A, __m512i __W)
{
  return (__m512i) __builtin_ia32_blendmd_512_mask ((__v16si) __A,
          (__v16si) __W,
          (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sqrt_pd (__m512d __A)
{
  return (__m512d) __builtin_ia32_sqrtpd512_mask ((__v8df) __A,
        (__v8df)
        _mm512_undefined_pd (),
        (__mmask8) -1,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sqrt_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_sqrtpd512_mask ((__v8df) __A,
        (__v8df) __W,
        (__mmask8) __U,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sqrt_pd (__mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_sqrtpd512_mask ((__v8df) __A,
        (__v8df)
        _mm512_setzero_pd (),
        (__mmask8) __U,
        0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sqrt_ps (__m512 __A)
{
  return (__m512) __builtin_ia32_sqrtps512_mask ((__v16sf) __A,
       (__v16sf)
       _mm512_undefined_ps (),
       (__mmask16) -1,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sqrt_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_sqrtps512_mask ((__v16sf) __A,
       (__v16sf) __W,
       (__mmask16) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sqrt_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_sqrtps512_mask ((__v16sf) __A,
       (__v16sf)
       _mm512_setzero_ps (),
       (__mmask16) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_add_pd (__m512d __A, __m512d __B)
{
  return (__m512d) ((__v8df)__A + (__v8df)__B);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_add_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_addpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __W,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_add_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_addpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_add_ps (__m512 __A, __m512 __B)
{
  return (__m512) ((__v16sf)__A + (__v16sf)__B);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_add_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_addps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_add_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_addps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U,
      0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sub_pd (__m512d __A, __m512d __B)
{
  return (__m512d) ((__v8df)__A - (__v8df)__B);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sub_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_subpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __W,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sub_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_subpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sub_ps (__m512 __A, __m512 __B)
{
  return (__m512) ((__v16sf)__A - (__v16sf)__B);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sub_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_subps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sub_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_subps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U,
      0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mul_pd (__m512d __A, __m512d __B)
{
  return (__m512d) ((__v8df)__A * (__v8df)__B);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mul_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_mulpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __W,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mul_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_mulpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mul_ps (__m512 __A, __m512 __B)
{
  return (__m512) ((__v16sf)__A * (__v16sf)__B);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mul_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_mulps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mul_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_mulps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U,
      0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_div_pd (__m512d __M, __m512d __V)
{
  return (__m512d) ((__v8df)__M / (__v8df)__V);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_div_pd (__m512d __W, __mmask8 __U, __m512d __M, __m512d __V)
{
  return (__m512d) __builtin_ia32_divpd512_mask ((__v8df) __M,
       (__v8df) __V,
       (__v8df) __W,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_div_pd (__mmask8 __U, __m512d __M, __m512d __V)
{
  return (__m512d) __builtin_ia32_divpd512_mask ((__v8df) __M,
       (__v8df) __V,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_div_ps (__m512 __A, __m512 __B)
{
  return (__m512) ((__v16sf)__A / (__v16sf)__B);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_div_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_divps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_div_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_divps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U,
      0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_maxpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_undefined_pd (),
       (__mmask8) -1,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_maxpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __W,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_maxpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_maxps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_undefined_ps (),
      (__mmask16) -1,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_maxps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_maxps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U,
      0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_minpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_undefined_pd (),
       (__mmask8) -1,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_minpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __W,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_minpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_minps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_undefined_ps (),
      (__mmask16) -1,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_minps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_minps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U,
      0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_scalef_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_scalefpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df)
          _mm512_undefined_pd (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_scalef_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_scalefpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df) __W,
          (__mmask8) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_scalef_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_scalefpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df)
          _mm512_setzero_pd (),
          (__mmask8) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_scalef_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_scalefps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf)
         _mm512_undefined_ps (),
         (__mmask16) -1,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_scalef_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_scalefps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf) __W,
         (__mmask16) __U,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_scalef_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_scalefps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf)
         _mm512_setzero_ps (),
         (__mmask16) __U,
         0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_scalef_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_scalefsd_round ((__v2df) __A,
        (__v2df) __B,
        0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_scalef_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_scalefss_round ((__v4sf) __A,
       (__v4sf) __B,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmadd_pd (__m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df) __C,
          (__mmask8) -1,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmadd_pd (__m512d __A, __mmask8 __U, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df) __C,
          (__mmask8) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmadd_pd (__m512d __A, __m512d __B, __m512d __C, __mmask8 __U)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_mask3 ((__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmadd_pd (__mmask8 __U, __m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_maskz ((__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmadd_ps (__m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf) __C,
         (__mmask16) -1,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmadd_ps (__m512 __A, __mmask16 __U, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf) __C,
         (__mmask16) __U,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmadd_ps (__m512 __A, __m512 __B, __m512 __C, __mmask16 __U)
{
  return (__m512) __builtin_ia32_vfmaddps512_mask3 ((__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmadd_ps (__mmask16 __U, __m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddps512_maskz ((__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmsub_pd (__m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_mask ((__v8df) __A,
          (__v8df) __B,
          -(__v8df) __C,
          (__mmask8) -1,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmsub_pd (__m512d __A, __mmask8 __U, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_mask ((__v8df) __A,
          (__v8df) __B,
          -(__v8df) __C,
          (__mmask8) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmsub_pd (__m512d __A, __m512d __B, __m512d __C, __mmask8 __U)
{
  return (__m512d) __builtin_ia32_vfmsubpd512_mask3 ((__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmsub_pd (__mmask8 __U, __m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_maskz ((__v8df) __A,
           (__v8df) __B,
           -(__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmsub_ps (__m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         -(__v16sf) __C,
         (__mmask16) -1,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmsub_ps (__m512 __A, __mmask16 __U, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         -(__v16sf) __C,
         (__mmask16) __U,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmsub_ps (__m512 __A, __m512 __B, __m512 __C, __mmask16 __U)
{
  return (__m512) __builtin_ia32_vfmsubps512_mask3 ((__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmsub_ps (__mmask16 __U, __m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddps512_maskz ((__v16sf) __A,
          (__v16sf) __B,
          -(__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmaddsub_pd (__m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddsubpd512_mask ((__v8df) __A,
             (__v8df) __B,
             (__v8df) __C,
             (__mmask8) -1,
             0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmaddsub_pd (__m512d __A, __mmask8 __U, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddsubpd512_mask ((__v8df) __A,
             (__v8df) __B,
             (__v8df) __C,
             (__mmask8) __U,
             0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmaddsub_pd (__m512d __A, __m512d __B, __m512d __C, __mmask8 __U)
{
  return (__m512d) __builtin_ia32_vfmaddsubpd512_mask3 ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __C,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmaddsub_pd (__mmask8 __U, __m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddsubpd512_maskz ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __C,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmaddsub_ps (__m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddsubps512_mask ((__v16sf) __A,
            (__v16sf) __B,
            (__v16sf) __C,
            (__mmask16) -1,
            0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmaddsub_ps (__m512 __A, __mmask16 __U, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddsubps512_mask ((__v16sf) __A,
            (__v16sf) __B,
            (__v16sf) __C,
            (__mmask16) __U,
            0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmaddsub_ps (__m512 __A, __m512 __B, __m512 __C, __mmask16 __U)
{
  return (__m512) __builtin_ia32_vfmaddsubps512_mask3 ((__v16sf) __A,
             (__v16sf) __B,
             (__v16sf) __C,
             (__mmask16) __U,
             0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmaddsub_ps (__mmask16 __U, __m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddsubps512_maskz ((__v16sf) __A,
             (__v16sf) __B,
             (__v16sf) __C,
             (__mmask16) __U,
             0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmsubadd_pd (__m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddsubpd512_mask ((__v8df) __A,
             (__v8df) __B,
             -(__v8df) __C,
             (__mmask8) -1,
             0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmsubadd_pd (__m512d __A, __mmask8 __U, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddsubpd512_mask ((__v8df) __A,
             (__v8df) __B,
             -(__v8df) __C,
             (__mmask8) __U,
             0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmsubadd_pd (__m512d __A, __m512d __B, __m512d __C, __mmask8 __U)
{
  return (__m512d) __builtin_ia32_vfmsubaddpd512_mask3 ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __C,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmsubadd_pd (__mmask8 __U, __m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddsubpd512_maskz ((__v8df) __A,
       (__v8df) __B,
       -(__v8df) __C,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmsubadd_ps (__m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddsubps512_mask ((__v16sf) __A,
            (__v16sf) __B,
            -(__v16sf) __C,
            (__mmask16) -1,
            0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmsubadd_ps (__m512 __A, __mmask16 __U, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddsubps512_mask ((__v16sf) __A,
            (__v16sf) __B,
            -(__v16sf) __C,
            (__mmask16) __U,
            0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmsubadd_ps (__m512 __A, __m512 __B, __m512 __C, __mmask16 __U)
{
  return (__m512) __builtin_ia32_vfmsubaddps512_mask3 ((__v16sf) __A,
             (__v16sf) __B,
             (__v16sf) __C,
             (__mmask16) __U,
             0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmsubadd_ps (__mmask16 __U, __m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddsubps512_maskz ((__v16sf) __A,
             (__v16sf) __B,
             -(__v16sf) __C,
             (__mmask16) __U,
             0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fnmadd_pd (__m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_mask (-(__v8df) __A,
          (__v8df) __B,
          (__v8df) __C,
          (__mmask8) -1,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fnmadd_pd (__m512d __A, __mmask8 __U, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfnmaddpd512_mask ((__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fnmadd_pd (__m512d __A, __m512d __B, __m512d __C, __mmask8 __U)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_mask3 (-(__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fnmadd_pd (__mmask8 __U, __m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_maskz (-(__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fnmadd_ps (__m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddps512_mask (-(__v16sf) __A,
         (__v16sf) __B,
         (__v16sf) __C,
         (__mmask16) -1,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fnmadd_ps (__m512 __A, __mmask16 __U, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfnmaddps512_mask ((__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fnmadd_ps (__m512 __A, __m512 __B, __m512 __C, __mmask16 __U)
{
  return (__m512) __builtin_ia32_vfmaddps512_mask3 (-(__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fnmadd_ps (__mmask16 __U, __m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddps512_maskz (-(__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fnmsub_pd (__m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_mask (-(__v8df) __A,
          (__v8df) __B,
          -(__v8df) __C,
          (__mmask8) -1,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fnmsub_pd (__m512d __A, __mmask8 __U, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfnmsubpd512_mask ((__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fnmsub_pd (__m512d __A, __m512d __B, __m512d __C, __mmask8 __U)
{
  return (__m512d) __builtin_ia32_vfnmsubpd512_mask3 ((__v8df) __A,
            (__v8df) __B,
            (__v8df) __C,
            (__mmask8) __U,
            0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fnmsub_pd (__mmask8 __U, __m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_maskz (-(__v8df) __A,
           (__v8df) __B,
           -(__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fnmsub_ps (__m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddps512_mask (-(__v16sf) __A,
         (__v16sf) __B,
         -(__v16sf) __C,
         (__mmask16) -1,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fnmsub_ps (__m512 __A, __mmask16 __U, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfnmsubps512_mask ((__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fnmsub_ps (__m512 __A, __m512 __B, __m512 __C, __mmask16 __U)
{
  return (__m512) __builtin_ia32_vfnmsubps512_mask3 ((__v16sf) __A,
           (__v16sf) __B,
           (__v16sf) __C,
           (__mmask16) __U,
           0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fnmsub_ps (__mmask16 __U, __m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddps512_maskz (-(__v16sf) __A,
          (__v16sf) __B,
          -(__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttpd_epi32 (__m512d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2dq512_mask ((__v8df) __A,
           (__v8si)
           _mm256_undefined_si256 (),
           (__mmask8) -1,
           0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttpd_epi32 (__m256i __W, __mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2dq512_mask ((__v8df) __A,
           (__v8si) __W,
           (__mmask8) __U,
           0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttpd_epi32 (__mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2dq512_mask ((__v8df) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U,
           0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttpd_epu32 (__m512d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2udq512_mask ((__v8df) __A,
            (__v8si)
            _mm256_undefined_si256 (),
            (__mmask8) -1,
            0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttpd_epu32 (__m256i __W, __mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2udq512_mask ((__v8df) __A,
            (__v8si) __W,
            (__mmask8) __U,
            0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttpd_epu32 (__mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2udq512_mask ((__v8df) __A,
            (__v8si)
            _mm256_setzero_si256 (),
            (__mmask8) __U,
            0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtpd_epi32 (__m512d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2dq512_mask ((__v8df) __A,
          (__v8si)
          _mm256_undefined_si256 (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtpd_epi32 (__m256i __W, __mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2dq512_mask ((__v8df) __A,
          (__v8si) __W,
          (__mmask8) __U,
          0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtpd_epi32 (__mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2dq512_mask ((__v8df) __A,
          (__v8si)
          _mm256_setzero_si256 (),
          (__mmask8) __U,
          0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtpd_epu32 (__m512d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2udq512_mask ((__v8df) __A,
           (__v8si)
           _mm256_undefined_si256 (),
           (__mmask8) -1,
           0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtpd_epu32 (__m256i __W, __mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2udq512_mask ((__v8df) __A,
           (__v8si) __W,
           (__mmask8) __U,
           0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtpd_epu32 (__mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2udq512_mask ((__v8df) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttps_epi32 (__m512 __A)
{
  return (__m512i) __builtin_ia32_cvttps2dq512_mask ((__v16sf) __A,
           (__v16si)
           _mm512_undefined_si512 (),
           (__mmask16) -1,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttps_epi32 (__m512i __W, __mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvttps2dq512_mask ((__v16sf) __A,
           (__v16si) __W,
           (__mmask16) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttps_epi32 (__mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvttps2dq512_mask ((__v16sf) __A,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttps_epu32 (__m512 __A)
{
  return (__m512i) __builtin_ia32_cvttps2udq512_mask ((__v16sf) __A,
            (__v16si)
            _mm512_undefined_si512 (),
            (__mmask16) -1,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttps_epu32 (__m512i __W, __mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvttps2udq512_mask ((__v16sf) __A,
            (__v16si) __W,
            (__mmask16) __U,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttps_epu32 (__mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvttps2udq512_mask ((__v16sf) __A,
            (__v16si)
            _mm512_setzero_si512 (),
            (__mmask16) __U,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtps_epi32 (__m512 __A)
{
  return (__m512i) __builtin_ia32_cvtps2dq512_mask ((__v16sf) __A,
          (__v16si)
          _mm512_undefined_si512 (),
          (__mmask16) -1,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtps_epi32 (__m512i __W, __mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvtps2dq512_mask ((__v16sf) __A,
          (__v16si) __W,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtps_epi32 (__mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvtps2dq512_mask ((__v16sf) __A,
          (__v16si)
          _mm512_setzero_si512 (),
          (__mmask16) __U,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtps_epu32 (__m512 __A)
{
  return (__m512i) __builtin_ia32_cvtps2udq512_mask ((__v16sf) __A,
           (__v16si)
           _mm512_undefined_si512 (),
           (__mmask16) -1,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtps_epu32 (__m512i __W, __mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvtps2udq512_mask ((__v16sf) __A,
           (__v16si) __W,
           (__mmask16) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtps_epu32 (__mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvtps2udq512_mask ((__v16sf) __A,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) __U,
           0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtu64_ss (__m128 __A, unsigned long long __B)
{
  return (__m128) __builtin_ia32_cvtusi2ss64 ((__v4sf) __A, __B,
           0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtu64_sd (__m128d __A, unsigned long long __B)
{
  return (__m128d) __builtin_ia32_cvtusi2sd64 ((__v2df) __A, __B,
            0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtu32_ss (__m128 __A, unsigned __B)
{
  return (__m128) __builtin_ia32_cvtusi2ss32 ((__v4sf) __A, __B,
           0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi32_ps (__m512i __A)
{
  return (__m512) __builtin_ia32_cvtdq2ps512_mask ((__v16si) __A,
         (__v16sf)
         _mm512_undefined_ps (),
         (__mmask16) -1,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi32_ps (__m512 __W, __mmask16 __U, __m512i __A)
{
  return (__m512) __builtin_ia32_cvtdq2ps512_mask ((__v16si) __A,
         (__v16sf) __W,
         (__mmask16) __U,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi32_ps (__mmask16 __U, __m512i __A)
{
  return (__m512) __builtin_ia32_cvtdq2ps512_mask ((__v16si) __A,
         (__v16sf)
         _mm512_setzero_ps (),
         (__mmask16) __U,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu32_ps (__m512i __A)
{
  return (__m512) __builtin_ia32_cvtudq2ps512_mask ((__v16si) __A,
          (__v16sf)
          _mm512_undefined_ps (),
          (__mmask16) -1,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu32_ps (__m512 __W, __mmask16 __U, __m512i __A)
{
  return (__m512) __builtin_ia32_cvtudq2ps512_mask ((__v16si) __A,
          (__v16sf) __W,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu32_ps (__mmask16 __U, __m512i __A)
{
  return (__m512) __builtin_ia32_cvtudq2ps512_mask ((__v16si) __A,
          (__v16sf)
          _mm512_setzero_ps (),
          (__mmask16) __U,
          0x04);
}
extern __inline unsigned long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_u64 (__m128 __A)
{
  return (unsigned long long) __builtin_ia32_vcvtss2usi64 ((__v4sf)
          __A,
          0x04);
}
extern __inline unsigned long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttss_u64 (__m128 __A)
{
  return (unsigned long long) __builtin_ia32_vcvttss2usi64 ((__v4sf)
           __A,
           0x04);
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttss_i64 (__m128 __A)
{
  return (long long) __builtin_ia32_vcvttss2si64 ((__v4sf) __A,
        0x04);
}
extern __inline unsigned
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_u32 (__m128 __A)
{
  return (unsigned) __builtin_ia32_vcvtss2usi32 ((__v4sf) __A,
       0x04);
}
extern __inline unsigned
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttss_u32 (__m128 __A)
{
  return (unsigned) __builtin_ia32_vcvttss2usi32 ((__v4sf) __A,
        0x04);
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttss_i32 (__m128 __A)
{
  return (int) __builtin_ia32_vcvttss2si32 ((__v4sf) __A,
         0x04);
}
extern __inline unsigned long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_u64 (__m128d __A)
{
  return (unsigned long long) __builtin_ia32_vcvtsd2usi64 ((__v2df)
          __A,
          0x04);
}
extern __inline unsigned long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttsd_u64 (__m128d __A)
{
  return (unsigned long long) __builtin_ia32_vcvttsd2usi64 ((__v2df)
           __A,
           0x04);
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttsd_i64 (__m128d __A)
{
  return (long long) __builtin_ia32_vcvttsd2si64 ((__v2df) __A,
        0x04);
}
extern __inline unsigned
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_u32 (__m128d __A)
{
  return (unsigned) __builtin_ia32_vcvtsd2usi32 ((__v2df) __A,
       0x04);
}
extern __inline unsigned
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttsd_u32 (__m128d __A)
{
  return (unsigned) __builtin_ia32_vcvttsd2usi32 ((__v2df) __A,
        0x04);
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttsd_i32 (__m128d __A)
{
  return (int) __builtin_ia32_vcvttsd2si32 ((__v2df) __A,
         0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtps_pd (__m256 __A)
{
  return (__m512d) __builtin_ia32_cvtps2pd512_mask ((__v8sf) __A,
          (__v8df)
          _mm512_undefined_pd (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtps_pd (__m512d __W, __mmask8 __U, __m256 __A)
{
  return (__m512d) __builtin_ia32_cvtps2pd512_mask ((__v8sf) __A,
          (__v8df) __W,
          (__mmask8) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtps_pd (__mmask8 __U, __m256 __A)
{
  return (__m512d) __builtin_ia32_cvtps2pd512_mask ((__v8sf) __A,
          (__v8df)
          _mm512_setzero_pd (),
          (__mmask8) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtph_ps (__m256i __A)
{
  return (__m512) __builtin_ia32_vcvtph2ps512_mask ((__v16hi) __A,
          (__v16sf)
          _mm512_undefined_ps (),
          (__mmask16) -1,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtph_ps (__m512 __W, __mmask16 __U, __m256i __A)
{
  return (__m512) __builtin_ia32_vcvtph2ps512_mask ((__v16hi) __A,
          (__v16sf) __W,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtph_ps (__mmask16 __U, __m256i __A)
{
  return (__m512) __builtin_ia32_vcvtph2ps512_mask ((__v16hi) __A,
          (__v16sf)
          _mm512_setzero_ps (),
          (__mmask16) __U,
          0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtpd_ps (__m512d __A)
{
  return (__m256) __builtin_ia32_cvtpd2ps512_mask ((__v8df) __A,
         (__v8sf)
         _mm256_undefined_ps (),
         (__mmask8) -1,
         0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtpd_ps (__m256 __W, __mmask8 __U, __m512d __A)
{
  return (__m256) __builtin_ia32_cvtpd2ps512_mask ((__v8df) __A,
         (__v8sf) __W,
         (__mmask8) __U,
         0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtpd_ps (__mmask8 __U, __m512d __A)
{
  return (__m256) __builtin_ia32_cvtpd2ps512_mask ((__v8df) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kmov (__mmask16 __A)
{
  return __builtin_ia32_kmov16 (__A);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castpd_ps (__m512d __A)
{
  return (__m512) (__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castpd_si512 (__m512d __A)
{
  return (__m512i) (__A);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castps_pd (__m512 __A)
{
  return (__m512d) (__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castps_si512 (__m512 __A)
{
  return (__m512i) (__A);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castsi512_ps (__m512i __A)
{
  return (__m512) (__A);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castsi512_pd (__m512i __A)
{
  return (__m512d) (__A);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castpd512_pd128 (__m512d __A)
{
  return (__m128d)((__m128) __builtin_ia32_extractf32x4_mask ((__v16sf)(__m512) ((__m512)__A), (int) (0), (__v4sf)(__m128)_mm_undefined_ps(), (__mmask8)-1));
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castps512_ps128 (__m512 __A)
{
  return ((__m128) __builtin_ia32_extractf32x4_mask ((__v16sf)(__m512) (__A), (int) (0), (__v4sf)(__m128)_mm_undefined_ps(), (__mmask8)-1));
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castsi512_si128 (__m512i __A)
{
  return (__m128i)((__m128i) __builtin_ia32_extracti32x4_mask ((__v16si)(__m512i) ((__m512i)__A), (int) (0), (__v4si)(__m128i)_mm_undefined_si128 (), (__mmask8)-1));
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castpd512_pd256 (__m512d __A)
{
  return ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1));
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castps512_ps256 (__m512 __A)
{
  return (__m256)((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d)__A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1));
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castsi512_si256 (__m512i __A)
{
  return (__m256i)((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d)__A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1));
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castpd128_pd512 (__m128d __A)
{
  return (__m512d) __builtin_ia32_pd512_pd((__m128d)__A);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castps128_ps512 (__m128 __A)
{
  return (__m512) __builtin_ia32_ps512_ps((__m128)__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castsi128_si512 (__m128i __A)
{
  return (__m512i) __builtin_ia32_si512_si((__v4si)__A);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castpd256_pd512 (__m256d __A)
{
  return __builtin_ia32_pd512_256pd (__A);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castps256_ps512 (__m256 __A)
{
  return __builtin_ia32_ps512_256ps (__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castsi256_si512 (__m256i __A)
{
  return (__m512i)__builtin_ia32_si512_256si ((__v8si)__A);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epu32_mask (__m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __A,
           (__v16si) __B, 0,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epu32_mask (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __A,
           (__v16si) __B, 0, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epu64_mask (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __A,
          (__v8di) __B, 0, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epu64_mask (__m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __A,
          (__v8di) __B, 0,
          (__mmask8) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epu32_mask (__m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __A,
           (__v16si) __B, 6,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epu32_mask (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __A,
           (__v16si) __B, 6, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epu64_mask (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __A,
          (__v8di) __B, 6, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epu64_mask (__m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __A,
          (__v8di) __B, 6,
          (__mmask8) -1);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512er")
typedef double __v8df __attribute__ ((__vector_size__ (64)));
typedef float __v16sf __attribute__ ((__vector_size__ (64)));
typedef float __m512 __attribute__ ((__vector_size__ (64), __may_alias__));
typedef double __m512d __attribute__ ((__vector_size__ (64), __may_alias__));
typedef unsigned char __mmask8;
typedef unsigned short __mmask16;
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512pf")
typedef long long __v8di __attribute__ ((__vector_size__ (64)));
typedef int __v16si __attribute__ ((__vector_size__ (64)));
typedef long long __m512i __attribute__ ((__vector_size__ (64), __may_alias__));
typedef unsigned char __mmask8;
typedef unsigned short __mmask16;
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512cd")
typedef long long __v8di __attribute__ ((__vector_size__ (64)));
typedef int __v16si __attribute__ ((__vector_size__ (64)));
typedef long long __m512i __attribute__ ((__vector_size__ (64), __may_alias__));
typedef double __m512d __attribute__ ((__vector_size__ (64), __may_alias__));
typedef unsigned char __mmask8;
typedef unsigned short __mmask16;
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_conflict_epi32 (__m512i __A)
{
  return (__m512i)
  __builtin_ia32_vpconflictsi_512_mask ((__v16si) __A,
            (__v16si) _mm512_setzero_si512 (),
            (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_conflict_epi32 (__m512i __W, __mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vpconflictsi_512_mask ((__v16si) __A,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_conflict_epi32 (__mmask16 __U, __m512i __A)
{
  return (__m512i)
  __builtin_ia32_vpconflictsi_512_mask ((__v16si) __A,
            (__v16si) _mm512_setzero_si512 (),
            (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_conflict_epi64 (__m512i __A)
{
  return (__m512i)
  __builtin_ia32_vpconflictdi_512_mask ((__v8di) __A,
            (__v8di) _mm512_setzero_si512 (),
            (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_conflict_epi64 (__m512i __W, __mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vpconflictdi_512_mask ((__v8di) __A,
        (__v8di) __W,
        (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_conflict_epi64 (__mmask8 __U, __m512i __A)
{
  return (__m512i)
  __builtin_ia32_vpconflictdi_512_mask ((__v8di) __A,
            (__v8di) _mm512_setzero_si512 (),
            (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_lzcnt_epi64 (__m512i __A)
{
  return (__m512i)
  __builtin_ia32_vplzcntq_512_mask ((__v8di) __A,
        (__v8di) _mm512_setzero_si512 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_lzcnt_epi64 (__m512i __W, __mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vplzcntq_512_mask ((__v8di) __A,
           (__v8di) __W,
           (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_lzcnt_epi64 (__mmask8 __U, __m512i __A)
{
  return (__m512i)
  __builtin_ia32_vplzcntq_512_mask ((__v8di) __A,
        (__v8di) _mm512_setzero_si512 (),
        (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_lzcnt_epi32 (__m512i __A)
{
  return (__m512i)
  __builtin_ia32_vplzcntd_512_mask ((__v16si) __A,
        (__v16si) _mm512_setzero_si512 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_lzcnt_epi32 (__m512i __W, __mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vplzcntd_512_mask ((__v16si) __A,
           (__v16si) __W,
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_lzcnt_epi32 (__mmask16 __U, __m512i __A)
{
  return (__m512i)
  __builtin_ia32_vplzcntd_512_mask ((__v16si) __A,
        (__v16si) _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastmb_epi64 (__mmask8 __A)
{
  return (__m512i) __builtin_ia32_broadcastmb512 (__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastmw_epi32 (__mmask16 __A)
{
  return (__m512i) __builtin_ia32_broadcastmw512 (__A);
}
#pragma GCC pop_options
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_setzero_di (void)
{
  return __extension__ (__m128i)(__v2di){ 0LL, 0LL};
}
#pragma GCC push_options
#pragma GCC target("avx512vl")
typedef unsigned int __mmask32;
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mov_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_movapd256_mask ((__v4df) __A,
        (__v4df) __W,
        (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mov_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_movapd256_mask ((__v4df) __A,
        (__v4df)
        _mm256_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mov_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_movapd128_mask ((__v2df) __A,
        (__v2df) __W,
        (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mov_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_movapd128_mask ((__v2df) __A,
        (__v2df)
        _mm_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_load_pd (__m256d __W, __mmask8 __U, void const *__P)
{
  return (__m256d) __builtin_ia32_loadapd256_mask ((__v4df *) __P,
         (__v4df) __W,
         (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_load_pd (__mmask8 __U, void const *__P)
{
  return (__m256d) __builtin_ia32_loadapd256_mask ((__v4df *) __P,
         (__v4df)
         _mm256_setzero_pd (),
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_load_pd (__m128d __W, __mmask8 __U, void const *__P)
{
  return (__m128d) __builtin_ia32_loadapd128_mask ((__v2df *) __P,
         (__v2df) __W,
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_load_pd (__mmask8 __U, void const *__P)
{
  return (__m128d) __builtin_ia32_loadapd128_mask ((__v2df *) __P,
         (__v2df)
         _mm_setzero_pd (),
         (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_store_pd (void *__P, __mmask8 __U, __m256d __A)
{
  __builtin_ia32_storeapd256_mask ((__v4df *) __P,
       (__v4df) __A,
       (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_store_pd (void *__P, __mmask8 __U, __m128d __A)
{
  __builtin_ia32_storeapd128_mask ((__v2df *) __P,
       (__v2df) __A,
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mov_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_movaps256_mask ((__v8sf) __A,
       (__v8sf) __W,
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mov_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_movaps256_mask ((__v8sf) __A,
       (__v8sf)
       _mm256_setzero_ps (),
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mov_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_movaps128_mask ((__v4sf) __A,
       (__v4sf) __W,
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mov_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_movaps128_mask ((__v4sf) __A,
       (__v4sf)
       _mm_setzero_ps (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_load_ps (__m256 __W, __mmask8 __U, void const *__P)
{
  return (__m256) __builtin_ia32_loadaps256_mask ((__v8sf *) __P,
        (__v8sf) __W,
        (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_load_ps (__mmask8 __U, void const *__P)
{
  return (__m256) __builtin_ia32_loadaps256_mask ((__v8sf *) __P,
        (__v8sf)
        _mm256_setzero_ps (),
        (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_load_ps (__m128 __W, __mmask8 __U, void const *__P)
{
  return (__m128) __builtin_ia32_loadaps128_mask ((__v4sf *) __P,
        (__v4sf) __W,
        (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_load_ps (__mmask8 __U, void const *__P)
{
  return (__m128) __builtin_ia32_loadaps128_mask ((__v4sf *) __P,
        (__v4sf)
        _mm_setzero_ps (),
        (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_store_ps (void *__P, __mmask8 __U, __m256 __A)
{
  __builtin_ia32_storeaps256_mask ((__v8sf *) __P,
       (__v8sf) __A,
       (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_store_ps (void *__P, __mmask8 __U, __m128 __A)
{
  __builtin_ia32_storeaps128_mask ((__v4sf *) __P,
       (__v4sf) __A,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mov_epi64 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdqa64_256_mask ((__v4di) __A,
           (__v4di) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mov_epi64 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdqa64_256_mask ((__v4di) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mov_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdqa64_128_mask ((__v2di) __A,
           (__v2di) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mov_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdqa64_128_mask ((__v2di) __A,
           (__v2di)
           _mm_setzero_di (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_load_epi64 (__m256i __W, __mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_movdqa64load256_mask ((__v4di *) __P,
       (__v4di) __W,
       (__mmask8)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_load_epi64 (__mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_movdqa64load256_mask ((__v4di *) __P,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_load_epi64 (__m128i __W, __mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_movdqa64load128_mask ((__v2di *) __P,
       (__v2di) __W,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_load_epi64 (__mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_movdqa64load128_mask ((__v2di *) __P,
       (__v2di)
       _mm_setzero_di (),
       (__mmask8)
       __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_store_epi64 (void *__P, __mmask8 __U, __m256i __A)
{
  __builtin_ia32_movdqa64store256_mask ((__v4di *) __P,
     (__v4di) __A,
     (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_store_epi64 (void *__P, __mmask8 __U, __m128i __A)
{
  __builtin_ia32_movdqa64store128_mask ((__v2di *) __P,
     (__v2di) __A,
     (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mov_epi32 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdqa32_256_mask ((__v8si) __A,
           (__v8si) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mov_epi32 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdqa32_256_mask ((__v8si) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mov_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdqa32_128_mask ((__v4si) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mov_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdqa32_128_mask ((__v4si) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_load_epi32 (__m256i __W, __mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_movdqa32load256_mask ((__v8si *) __P,
       (__v8si) __W,
       (__mmask8)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_load_epi32 (__mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_movdqa32load256_mask ((__v8si *) __P,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_load_epi32 (__m128i __W, __mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_movdqa32load128_mask ((__v4si *) __P,
       (__v4si) __W,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_load_epi32 (__mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_movdqa32load128_mask ((__v4si *) __P,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8)
       __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_store_epi32 (void *__P, __mmask8 __U, __m256i __A)
{
  __builtin_ia32_movdqa32store256_mask ((__v8si *) __P,
     (__v8si) __A,
     (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_store_epi32 (void *__P, __mmask8 __U, __m128i __A)
{
  __builtin_ia32_movdqa32store128_mask ((__v4si *) __P,
     (__v4si) __A,
     (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_setzero_hi (void)
{
  return __extension__ (__m128i) (__v8hi)
  {
  0, 0, 0, 0, 0, 0, 0, 0};
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_add_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_addpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __W,
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_add_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_addpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df)
       _mm_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_add_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_addpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_add_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_addpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_add_ps (__m128 __W, __mmask16 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_addps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf) __W,
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_add_ps (__mmask16 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_addps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf)
      _mm_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_add_ps (__m256 __W, __mmask16 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_addps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_add_ps (__mmask16 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_addps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sub_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_subpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __W,
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sub_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_subpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df)
       _mm_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sub_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_subpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sub_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_subpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sub_ps (__m128 __W, __mmask16 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_subps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf) __W,
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sub_ps (__mmask16 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_subps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf)
      _mm_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sub_ps (__m256 __W, __mmask16 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_subps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sub_ps (__mmask16 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_subps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_store_epi64 (void *__P, __m256i __A)
{
  *(__m256i *) __P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_epi64 (void *__P, __m128i __A)
{
  *(__m128i *) __P = __A;
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_loadu_pd (__m256d __W, __mmask8 __U, void const *__P)
{
  return (__m256d) __builtin_ia32_loadupd256_mask ((__v4df *) __P,
         (__v4df) __W,
         (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_loadu_pd (__mmask8 __U, void const *__P)
{
  return (__m256d) __builtin_ia32_loadupd256_mask ((__v4df *) __P,
         (__v4df)
         _mm256_setzero_pd (),
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_loadu_pd (__m128d __W, __mmask8 __U, void const *__P)
{
  return (__m128d) __builtin_ia32_loadupd128_mask ((__v2df *) __P,
         (__v2df) __W,
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_loadu_pd (__mmask8 __U, void const *__P)
{
  return (__m128d) __builtin_ia32_loadupd128_mask ((__v2df *) __P,
         (__v2df)
         _mm_setzero_pd (),
         (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_storeu_pd (void *__P, __mmask8 __U, __m256d __A)
{
  __builtin_ia32_storeupd256_mask ((__v4df *) __P,
       (__v4df) __A,
       (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_storeu_pd (void *__P, __mmask8 __U, __m128d __A)
{
  __builtin_ia32_storeupd128_mask ((__v2df *) __P,
       (__v2df) __A,
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_loadu_ps (__m256 __W, __mmask8 __U, void const *__P)
{
  return (__m256) __builtin_ia32_loadups256_mask ((__v8sf *) __P,
        (__v8sf) __W,
        (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_loadu_ps (__mmask8 __U, void const *__P)
{
  return (__m256) __builtin_ia32_loadups256_mask ((__v8sf *) __P,
        (__v8sf)
        _mm256_setzero_ps (),
        (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_loadu_ps (__m128 __W, __mmask8 __U, void const *__P)
{
  return (__m128) __builtin_ia32_loadups128_mask ((__v4sf *) __P,
        (__v4sf) __W,
        (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_loadu_ps (__mmask8 __U, void const *__P)
{
  return (__m128) __builtin_ia32_loadups128_mask ((__v4sf *) __P,
        (__v4sf)
        _mm_setzero_ps (),
        (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_storeu_ps (void *__P, __mmask8 __U, __m256 __A)
{
  __builtin_ia32_storeups256_mask ((__v8sf *) __P,
       (__v8sf) __A,
       (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_storeu_ps (void *__P, __mmask8 __U, __m128 __A)
{
  __builtin_ia32_storeups128_mask ((__v4sf *) __P,
       (__v4sf) __A,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_loadu_epi64 (__m256i __W, __mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddqudi256_mask ((__v4di *) __P,
           (__v4di) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_loadu_epi64 (__mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddqudi256_mask ((__v4di *) __P,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_loadu_epi64 (__m128i __W, __mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddqudi128_mask ((__v2di *) __P,
           (__v2di) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_loadu_epi64 (__mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddqudi128_mask ((__v2di *) __P,
           (__v2di)
           _mm_setzero_di (),
           (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_storeu_epi64 (void *__P, __mmask8 __U, __m256i __A)
{
  __builtin_ia32_storedqudi256_mask ((__v4di *) __P,
         (__v4di) __A,
         (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_storeu_epi64 (void *__P, __mmask8 __U, __m128i __A)
{
  __builtin_ia32_storedqudi128_mask ((__v2di *) __P,
         (__v2di) __A,
         (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_loadu_epi32 (__m256i __W, __mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddqusi256_mask ((__v8si *) __P,
           (__v8si) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_loadu_epi32 (__mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddqusi256_mask ((__v8si *) __P,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_loadu_epi32 (__m128i __W, __mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddqusi128_mask ((__v4si *) __P,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_loadu_epi32 (__mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddqusi128_mask ((__v4si *) __P,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_storeu_epi32 (void *__P, __mmask8 __U, __m256i __A)
{
  __builtin_ia32_storedqusi256_mask ((__v8si *) __P,
         (__v8si) __A,
         (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_storeu_epi32 (void *__P, __mmask8 __U, __m128i __A)
{
  __builtin_ia32_storedqusi128_mask ((__v4si *) __P,
         (__v4si) __A,
         (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_abs_epi32 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsd256_mask ((__v8si) __A,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_abs_epi32 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsd256_mask ((__v8si) __A,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_abs_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsd128_mask ((__v4si) __A,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_abs_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsd128_mask ((__v4si) __A,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_abs_epi64 (__m256i __A)
{
  return (__m256i) __builtin_ia32_pabsq256_mask ((__v4di) __A,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_abs_epi64 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsq256_mask ((__v4di) __A,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_abs_epi64 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsq256_mask ((__v4di) __A,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_abs_epi64 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pabsq128_mask ((__v2di) __A,
       (__v2di)
       _mm_setzero_di (),
       (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_abs_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsq128_mask ((__v2di) __A,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_abs_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsq128_mask ((__v2di) __A,
       (__v2di)
       _mm_setzero_di (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtpd_epu32 (__m256d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2udq256_mask ((__v4df) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtpd_epu32 (__m128i __W, __mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2udq256_mask ((__v4df) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtpd_epu32 (__mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2udq256_mask ((__v4df) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpd_epu32 (__m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2udq128_mask ((__v2df) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtpd_epu32 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2udq128_mask ((__v2df) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtpd_epu32 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2udq128_mask ((__v2df) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttps_epi32 (__m256i __W, __mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvttps2dq256_mask ((__v8sf) __A,
           (__v8si) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttps_epi32 (__mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvttps2dq256_mask ((__v8sf) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttps_epi32 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2dq128_mask ((__v4sf) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttps_epi32 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2dq128_mask ((__v4sf) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttps_epu32 (__m256 __A)
{
  return (__m256i) __builtin_ia32_cvttps2udq256_mask ((__v8sf) __A,
            (__v8si)
            _mm256_setzero_si256 (),
            (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttps_epu32 (__m256i __W, __mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvttps2udq256_mask ((__v8sf) __A,
            (__v8si) __W,
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttps_epu32 (__mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvttps2udq256_mask ((__v8sf) __A,
            (__v8si)
            _mm256_setzero_si256 (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttps_epu32 (__m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2udq128_mask ((__v4sf) __A,
            (__v4si)
            _mm_setzero_si128 (),
            (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttps_epu32 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2udq128_mask ((__v4sf) __A,
            (__v4si) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttps_epu32 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2udq128_mask ((__v4sf) __A,
            (__v4si)
            _mm_setzero_si128 (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttpd_epi32 (__m128i __W, __mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2dq256_mask ((__v4df) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttpd_epi32 (__mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2dq256_mask ((__v4df) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttpd_epi32 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2dq128_mask ((__v2df) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttpd_epi32 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2dq128_mask ((__v2df) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttpd_epu32 (__m256d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2udq256_mask ((__v4df) __A,
            (__v4si)
            _mm_setzero_si128 (),
            (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttpd_epu32 (__m128i __W, __mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2udq256_mask ((__v4df) __A,
            (__v4si) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttpd_epu32 (__mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2udq256_mask ((__v4df) __A,
            (__v4si)
            _mm_setzero_si128 (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttpd_epu32 (__m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2udq128_mask ((__v2df) __A,
            (__v4si)
            _mm_setzero_si128 (),
            (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttpd_epu32 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2udq128_mask ((__v2df) __A,
            (__v4si) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttpd_epu32 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2udq128_mask ((__v2df) __A,
            (__v4si)
            _mm_setzero_si128 (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtpd_epi32 (__m128i __W, __mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2dq256_mask ((__v4df) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtpd_epi32 (__mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2dq256_mask ((__v4df) __A,
          (__v4si)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtpd_epi32 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2dq128_mask ((__v2df) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtpd_epi32 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2dq128_mask ((__v2df) __A,
          (__v4si)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi32_pd (__m256d __W, __mmask8 __U, __m128i __A)
{
  return (__m256d) __builtin_ia32_cvtdq2pd256_mask ((__v4si) __A,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi32_pd (__mmask8 __U, __m128i __A)
{
  return (__m256d) __builtin_ia32_cvtdq2pd256_mask ((__v4si) __A,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi32_pd (__m128d __W, __mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtdq2pd128_mask ((__v4si) __A,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi32_pd (__mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtdq2pd128_mask ((__v4si) __A,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu32_pd (__m128i __A)
{
  return (__m256d) __builtin_ia32_cvtudq2pd256_mask ((__v4si) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu32_pd (__m256d __W, __mmask8 __U, __m128i __A)
{
  return (__m256d) __builtin_ia32_cvtudq2pd256_mask ((__v4si) __A,
           (__v4df) __W,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu32_pd (__mmask8 __U, __m128i __A)
{
  return (__m256d) __builtin_ia32_cvtudq2pd256_mask ((__v4si) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu32_pd (__m128i __A)
{
  return (__m128d) __builtin_ia32_cvtudq2pd128_mask ((__v4si) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu32_pd (__m128d __W, __mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtudq2pd128_mask ((__v4si) __A,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu32_pd (__mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtudq2pd128_mask ((__v4si) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi32_ps (__m256 __W, __mmask8 __U, __m256i __A)
{
  return (__m256) __builtin_ia32_cvtdq2ps256_mask ((__v8si) __A,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi32_ps (__mmask16 __U, __m256i __A)
{
  return (__m256) __builtin_ia32_cvtdq2ps256_mask ((__v8si) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi32_ps (__m128 __W, __mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtdq2ps128_mask ((__v4si) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi32_ps (__mmask16 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtdq2ps128_mask ((__v4si) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu32_ps (__m256i __A)
{
  return (__m256) __builtin_ia32_cvtudq2ps256_mask ((__v8si) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu32_ps (__m256 __W, __mmask8 __U, __m256i __A)
{
  return (__m256) __builtin_ia32_cvtudq2ps256_mask ((__v8si) __A,
          (__v8sf) __W,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu32_ps (__mmask8 __U, __m256i __A)
{
  return (__m256) __builtin_ia32_cvtudq2ps256_mask ((__v8si) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu32_ps (__m128i __A)
{
  return (__m128) __builtin_ia32_cvtudq2ps128_mask ((__v4si) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu32_ps (__m128 __W, __mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtudq2ps128_mask ((__v4si) __A,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu32_ps (__mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtudq2ps128_mask ((__v4si) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtps_pd (__m256d __W, __mmask8 __U, __m128 __A)
{
  return (__m256d) __builtin_ia32_cvtps2pd256_mask ((__v4sf) __A,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtps_pd (__mmask8 __U, __m128 __A)
{
  return (__m256d) __builtin_ia32_cvtps2pd256_mask ((__v4sf) __A,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtps_pd (__m128d __W, __mmask8 __U, __m128 __A)
{
  return (__m128d) __builtin_ia32_cvtps2pd128_mask ((__v4sf) __A,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtps_pd (__mmask8 __U, __m128 __A)
{
  return (__m128d) __builtin_ia32_cvtps2pd128_mask ((__v4sf) __A,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi32_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovdb128_mask ((__v4si) __A,
        (__v16qi)_mm_undefined_si128(),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi32_storeu_epi8 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovdb128mem_mask ((__v16qi *) __P, (__v4si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi32_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovdb128_mask ((__v4si) __A,
        (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi32_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovdb128_mask ((__v4si) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi32_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovdb256_mask ((__v8si) __A,
        (__v16qi)_mm_undefined_si128(),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi32_epi8 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovdb256_mask ((__v8si) __A,
        (__v16qi) __O, __M);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi32_storeu_epi8 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovdb256mem_mask ((__v16qi *) __P, (__v8si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi32_epi8 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovdb256_mask ((__v8si) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsepi32_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb128_mask ((__v4si) __A,
         (__v16qi)_mm_undefined_si128(),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi32_storeu_epi8 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovsdb128mem_mask ((__v16qi *) __P, (__v4si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi32_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb128_mask ((__v4si) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtsepi32_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb128_mask ((__v4si) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtsepi32_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb256_mask ((__v8si) __A,
         (__v16qi)_mm_undefined_si128(),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi32_storeu_epi8 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovsdb256mem_mask ((__v16qi *) __P, (__v8si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi32_epi8 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb256_mask ((__v8si) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtsepi32_epi8 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb256_mask ((__v8si) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtusepi32_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb128_mask ((__v4si) __A,
          (__v16qi)_mm_undefined_si128(),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi32_storeu_epi8 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovusdb128mem_mask ((__v16qi *) __P, (__v4si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi32_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb128_mask ((__v4si) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtusepi32_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb128_mask ((__v4si) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtusepi32_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb256_mask ((__v8si) __A,
          (__v16qi)_mm_undefined_si128(),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi32_storeu_epi8 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovusdb256mem_mask ((__v16qi*) __P, (__v8si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi32_epi8 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb256_mask ((__v8si) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtusepi32_epi8 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb256_mask ((__v8si) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi32_epi16 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovdw128_mask ((__v4si) __A,
        (__v8hi) _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi32_storeu_epi16 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovdw128mem_mask ((__v8hi *) __P, (__v4si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi32_epi16 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovdw128_mask ((__v4si) __A,
        (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi32_epi16 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovdw128_mask ((__v4si) __A,
        (__v8hi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi32_epi16 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovdw256_mask ((__v8si) __A,
        (__v8hi)_mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi32_storeu_epi16 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovdw256mem_mask ((__v8hi *) __P, (__v8si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi32_epi16 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovdw256_mask ((__v8si) __A,
        (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi32_epi16 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovdw256_mask ((__v8si) __A,
        (__v8hi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsepi32_epi16 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsdw128_mask ((__v4si) __A,
         (__v8hi)_mm_setzero_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi32_storeu_epi16 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovsdw128mem_mask ((__v8hi *) __P, (__v4si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi32_epi16 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsdw128_mask ((__v4si) __A,
         (__v8hi)__O,
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtsepi32_epi16 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsdw128_mask ((__v4si) __A,
         (__v8hi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtsepi32_epi16 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsdw256_mask ((__v8si) __A,
         (__v8hi)_mm_undefined_si128(),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi32_storeu_epi16 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovsdw256mem_mask ((__v8hi *) __P, (__v8si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi32_epi16 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsdw256_mask ((__v8si) __A,
         (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtsepi32_epi16 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsdw256_mask ((__v8si) __A,
         (__v8hi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtusepi32_epi16 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusdw128_mask ((__v4si) __A,
          (__v8hi)_mm_undefined_si128(),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi32_storeu_epi16 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovusdw128mem_mask ((__v8hi *) __P, (__v4si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi32_epi16 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusdw128_mask ((__v4si) __A,
          (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtusepi32_epi16 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusdw128_mask ((__v4si) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtusepi32_epi16 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusdw256_mask ((__v8si) __A,
          (__v8hi)_mm_undefined_si128(),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi32_storeu_epi16 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovusdw256mem_mask ((__v8hi *) __P, (__v8si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi32_epi16 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusdw256_mask ((__v8si) __A,
          (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtusepi32_epi16 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusdw256_mask ((__v8si) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi64_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqb128_mask ((__v2di) __A,
        (__v16qi)_mm_undefined_si128(),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_storeu_epi8 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovqb128mem_mask ((__v16qi *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqb128_mask ((__v2di) __A,
        (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi64_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqb128_mask ((__v2di) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi64_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqb256_mask ((__v4di) __A,
        (__v16qi)_mm_undefined_si128(),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_storeu_epi8 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovqb256mem_mask ((__v16qi *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_epi8 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqb256_mask ((__v4di) __A,
        (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi64_epi8 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqb256_mask ((__v4di) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsepi64_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb128_mask ((__v2di) __A,
         (__v16qi)_mm_undefined_si128(),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi64_storeu_epi8 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovsqb128mem_mask ((__v16qi *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi64_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb128_mask ((__v2di) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtsepi64_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb128_mask ((__v2di) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtsepi64_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb256_mask ((__v4di) __A,
         (__v16qi)_mm_undefined_si128(),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi64_storeu_epi8 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovsqb256mem_mask ((__v16qi *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi64_epi8 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb256_mask ((__v4di) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtsepi64_epi8 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb256_mask ((__v4di) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtusepi64_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb128_mask ((__v2di) __A,
          (__v16qi)_mm_undefined_si128(),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi64_storeu_epi8 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovusqb128mem_mask ((__v16qi *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi64_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb128_mask ((__v2di) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtusepi64_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb128_mask ((__v2di) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtusepi64_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb256_mask ((__v4di) __A,
          (__v16qi)_mm_undefined_si128(),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi64_storeu_epi8 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovusqb256mem_mask ((__v16qi *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi64_epi8 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb256_mask ((__v4di) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtusepi64_epi8 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb256_mask ((__v4di) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi64_epi16 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqw128_mask ((__v2di) __A,
        (__v8hi)_mm_undefined_si128(),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_storeu_epi16 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovqw128mem_mask ((__v8hi *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_epi16 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqw128_mask ((__v2di) __A,
        (__v8hi)__O,
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi64_epi16 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqw128_mask ((__v2di) __A,
        (__v8hi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi64_epi16 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqw256_mask ((__v4di) __A,
        (__v8hi)_mm_undefined_si128(),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_storeu_epi16 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovqw256mem_mask ((__v8hi *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_epi16 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqw256_mask ((__v4di) __A,
        (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi64_epi16 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqw256_mask ((__v4di) __A,
        (__v8hi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsepi64_epi16 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw128_mask ((__v2di) __A,
         (__v8hi)_mm_undefined_si128(),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi64_storeu_epi16 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovsqw128mem_mask ((__v8hi *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi64_epi16 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw128_mask ((__v2di) __A,
         (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtsepi64_epi16 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw128_mask ((__v2di) __A,
         (__v8hi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtsepi64_epi16 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw256_mask ((__v4di) __A,
         (__v8hi)_mm_undefined_si128(),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi64_storeu_epi16 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovsqw256mem_mask ((__v8hi *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi64_epi16 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw256_mask ((__v4di) __A,
         (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtsepi64_epi16 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw256_mask ((__v4di) __A,
         (__v8hi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtusepi64_epi16 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw128_mask ((__v2di) __A,
          (__v8hi)_mm_undefined_si128(),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi64_storeu_epi16 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovusqw128mem_mask ((__v8hi *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi64_epi16 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw128_mask ((__v2di) __A,
          (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtusepi64_epi16 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw128_mask ((__v2di) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtusepi64_epi16 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw256_mask ((__v4di) __A,
          (__v8hi)_mm_undefined_si128(),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi64_storeu_epi16 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovusqw256mem_mask ((__v8hi *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi64_epi16 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw256_mask ((__v4di) __A,
          (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtusepi64_epi16 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw256_mask ((__v4di) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi64_epi32 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqd128_mask ((__v2di) __A,
        (__v4si)_mm_undefined_si128(),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_storeu_epi32 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovqd128mem_mask ((__v4si *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_epi32 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqd128_mask ((__v2di) __A,
        (__v4si) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi64_epi32 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqd128_mask ((__v2di) __A,
        (__v4si)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi64_epi32 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqd256_mask ((__v4di) __A,
        (__v4si)_mm_undefined_si128(),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_storeu_epi32 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovqd256mem_mask ((__v4si *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_epi32 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqd256_mask ((__v4di) __A,
        (__v4si) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi64_epi32 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqd256_mask ((__v4di) __A,
        (__v4si)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsepi64_epi32 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqd128_mask ((__v2di) __A,
         (__v4si)_mm_undefined_si128(),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi64_storeu_epi32 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovsqd128mem_mask ((__v4si *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi64_epi32 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqd128_mask ((__v2di) __A,
         (__v4si) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtsepi64_epi32 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqd128_mask ((__v2di) __A,
         (__v4si)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtsepi64_epi32 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqd256_mask ((__v4di) __A,
         (__v4si)_mm_undefined_si128(),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi64_storeu_epi32 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovsqd256mem_mask ((__v4si *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi64_epi32 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqd256_mask ((__v4di) __A,
         (__v4si)__O,
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtsepi64_epi32 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqd256_mask ((__v4di) __A,
         (__v4si)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtusepi64_epi32 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqd128_mask ((__v2di) __A,
          (__v4si)_mm_undefined_si128(),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi64_storeu_epi32 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovusqd128mem_mask ((__v4si *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi64_epi32 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqd128_mask ((__v2di) __A,
          (__v4si) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtusepi64_epi32 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqd128_mask ((__v2di) __A,
          (__v4si)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtusepi64_epi32 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqd256_mask ((__v4di) __A,
          (__v4si)_mm_undefined_si128(),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi64_storeu_epi32 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovusqd256mem_mask ((__v4si *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi64_epi32 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqd256_mask ((__v4di) __A,
          (__v4si) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtusepi64_epi32 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqd256_mask ((__v4di) __A,
          (__v4si)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcastss_ps (__m256 __O, __mmask8 __M, __m128 __A)
{
  return (__m256) __builtin_ia32_broadcastss256_mask ((__v4sf) __A,
            (__v8sf) __O,
            __M);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcastss_ps (__mmask8 __M, __m128 __A)
{
  return (__m256) __builtin_ia32_broadcastss256_mask ((__v4sf) __A,
            (__v8sf)
            _mm256_setzero_ps (),
            __M);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_broadcastss_ps (__m128 __O, __mmask8 __M, __m128 __A)
{
  return (__m128) __builtin_ia32_broadcastss128_mask ((__v4sf) __A,
            (__v4sf) __O,
            __M);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_broadcastss_ps (__mmask8 __M, __m128 __A)
{
  return (__m128) __builtin_ia32_broadcastss128_mask ((__v4sf) __A,
            (__v4sf)
            _mm_setzero_ps (),
            __M);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcastsd_pd (__m256d __O, __mmask8 __M, __m128d __A)
{
  return (__m256d) __builtin_ia32_broadcastsd256_mask ((__v2df) __A,
             (__v4df) __O,
             __M);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcastsd_pd (__mmask8 __M, __m128d __A)
{
  return (__m256d) __builtin_ia32_broadcastsd256_mask ((__v2df) __A,
             (__v4df)
             _mm256_setzero_pd (),
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcastd_epi32 (__m256i __O, __mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastd256_mask ((__v4si) __A,
             (__v8si) __O,
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcastd_epi32 (__mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastd256_mask ((__v4si) __A,
             (__v8si)
             _mm256_setzero_si256 (),
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_set1_epi32 (__m256i __O, __mmask8 __M, int __A)
{
  return (__m256i) __builtin_ia32_pbroadcastd256_gpr_mask (__A, (__v8si) __O,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_set1_epi32 (__mmask8 __M, int __A)
{
  return (__m256i) __builtin_ia32_pbroadcastd256_gpr_mask (__A,
          (__v8si)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_broadcastd_epi32 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastd128_mask ((__v4si) __A,
             (__v4si) __O,
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_broadcastd_epi32 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastd128_mask ((__v4si) __A,
             (__v4si)
             _mm_setzero_si128 (),
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_set1_epi32 (__m128i __O, __mmask8 __M, int __A)
{
  return (__m128i) __builtin_ia32_pbroadcastd128_gpr_mask (__A, (__v4si) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_set1_epi32 (__mmask8 __M, int __A)
{
  return (__m128i) __builtin_ia32_pbroadcastd128_gpr_mask (__A,
          (__v4si)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcastq_epi64 (__m256i __O, __mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastq256_mask ((__v2di) __A,
             (__v4di) __O,
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcastq_epi64 (__mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastq256_mask ((__v2di) __A,
             (__v4di)
             _mm256_setzero_si256 (),
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_set1_epi64 (__m256i __O, __mmask8 __M, long long __A)
{
  return (__m256i) __builtin_ia32_pbroadcastq256_gpr_mask (__A, (__v4di) __O,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_set1_epi64 (__mmask8 __M, long long __A)
{
  return (__m256i) __builtin_ia32_pbroadcastq256_gpr_mask (__A,
          (__v4di)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_broadcastq_epi64 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastq128_mask ((__v2di) __A,
             (__v2di) __O,
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_broadcastq_epi64 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastq128_mask ((__v2di) __A,
             (__v2di)
             _mm_setzero_si128 (),
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_set1_epi64 (__m128i __O, __mmask8 __M, long long __A)
{
  return (__m128i) __builtin_ia32_pbroadcastq128_gpr_mask (__A, (__v2di) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_set1_epi64 (__mmask8 __M, long long __A)
{
  return (__m128i) __builtin_ia32_pbroadcastq128_gpr_mask (__A,
          (__v2di)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_f32x4 (__m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x4_256_mask ((__v4sf) __A,
                (__v8sf)_mm256_undefined_pd (),
         (__mmask8) -
         1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcast_f32x4 (__m256 __O, __mmask8 __M, __m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x4_256_mask ((__v4sf) __A,
         (__v8sf) __O,
         __M);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcast_f32x4 (__mmask8 __M, __m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x4_256_mask ((__v4sf) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_i32x4 (__m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x4_256_mask ((__v4si)
          __A,
                 (__v8si)_mm256_undefined_si256 (),
          (__mmask8) -
          1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcast_i32x4 (__m256i __O, __mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x4_256_mask ((__v4si)
          __A,
          (__v8si)
          __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcast_i32x4 (__mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x4_256_mask ((__v4si)
          __A,
          (__v8si)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi8_epi32 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxbd256_mask ((__v16qi) __A,
          (__v8si) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi8_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxbd256_mask ((__v16qi) __A,
          (__v8si)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi8_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxbd128_mask ((__v16qi) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi8_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxbd128_mask ((__v16qi) __A,
          (__v4si)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi8_epi64 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxbq256_mask ((__v16qi) __A,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi8_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxbq256_mask ((__v16qi) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi8_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxbq128_mask ((__v16qi) __A,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi8_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxbq128_mask ((__v16qi) __A,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi16_epi32 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxwd256_mask ((__v8hi) __A,
          (__v8si) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi16_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxwd256_mask ((__v8hi) __A,
          (__v8si)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi16_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxwd128_mask ((__v8hi) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi16_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxwd128_mask ((__v8hi) __A,
          (__v4si)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi16_epi64 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxwq256_mask ((__v8hi) __A,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi16_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxwq256_mask ((__v8hi) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi16_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxwq128_mask ((__v8hi) __A,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi16_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxwq128_mask ((__v8hi) __A,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi32_epi64 (__m256i __W, __mmask8 __U, __m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxdq256_mask ((__v4si) __X,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi32_epi64 (__mmask8 __U, __m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxdq256_mask ((__v4si) __X,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi32_epi64 (__m128i __W, __mmask8 __U, __m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxdq128_mask ((__v4si) __X,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi32_epi64 (__mmask8 __U, __m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxdq128_mask ((__v4si) __X,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu8_epi32 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxbd256_mask ((__v16qi) __A,
          (__v8si) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu8_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxbd256_mask ((__v16qi) __A,
          (__v8si)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu8_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxbd128_mask ((__v16qi) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu8_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxbd128_mask ((__v16qi) __A,
          (__v4si)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu8_epi64 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxbq256_mask ((__v16qi) __A,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu8_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxbq256_mask ((__v16qi) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu8_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxbq128_mask ((__v16qi) __A,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu8_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxbq128_mask ((__v16qi) __A,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu16_epi32 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxwd256_mask ((__v8hi) __A,
          (__v8si) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu16_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxwd256_mask ((__v8hi) __A,
          (__v8si)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu16_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxwd128_mask ((__v8hi) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu16_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxwd128_mask ((__v8hi) __A,
          (__v4si)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu16_epi64 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxwq256_mask ((__v8hi) __A,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu16_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxwq256_mask ((__v8hi) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu16_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxwq128_mask ((__v8hi) __A,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu16_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxwq128_mask ((__v8hi) __A,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu32_epi64 (__m256i __W, __mmask8 __U, __m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxdq256_mask ((__v4si) __X,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu32_epi64 (__mmask8 __U, __m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxdq256_mask ((__v4si) __X,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu32_epi64 (__m128i __W, __mmask8 __U, __m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxdq128_mask ((__v4si) __X,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu32_epi64 (__mmask8 __U, __m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxdq128_mask ((__v4si) __X,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rcp14_pd (__m256d __A)
{
  return (__m256d) __builtin_ia32_rcp14pd256_mask ((__v4df) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rcp14_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_rcp14pd256_mask ((__v4df) __A,
           (__v4df) __W,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rcp14_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_rcp14pd256_mask ((__v4df) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rcp14_pd (__m128d __A)
{
  return (__m128d) __builtin_ia32_rcp14pd128_mask ((__v2df) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rcp14_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_rcp14pd128_mask ((__v2df) __A,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rcp14_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_rcp14pd128_mask ((__v2df) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rcp14_ps (__m256 __A)
{
  return (__m256) __builtin_ia32_rcp14ps256_mask ((__v8sf) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rcp14_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_rcp14ps256_mask ((__v8sf) __A,
          (__v8sf) __W,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rcp14_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_rcp14ps256_mask ((__v8sf) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rcp14_ps (__m128 __A)
{
  return (__m128) __builtin_ia32_rcp14ps128_mask ((__v4sf) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rcp14_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_rcp14ps128_mask ((__v4sf) __A,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rcp14_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_rcp14ps128_mask ((__v4sf) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rsqrt14_pd (__m256d __A)
{
  return (__m256d) __builtin_ia32_rsqrt14pd256_mask ((__v4df) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rsqrt14_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_rsqrt14pd256_mask ((__v4df) __A,
           (__v4df) __W,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rsqrt14_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_rsqrt14pd256_mask ((__v4df) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rsqrt14_pd (__m128d __A)
{
  return (__m128d) __builtin_ia32_rsqrt14pd128_mask ((__v2df) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rsqrt14_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_rsqrt14pd128_mask ((__v2df) __A,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rsqrt14_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_rsqrt14pd128_mask ((__v2df) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rsqrt14_ps (__m256 __A)
{
  return (__m256) __builtin_ia32_rsqrt14ps256_mask ((__v8sf) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rsqrt14_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_rsqrt14ps256_mask ((__v8sf) __A,
          (__v8sf) __W,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rsqrt14_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_rsqrt14ps256_mask ((__v8sf) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rsqrt14_ps (__m128 __A)
{
  return (__m128) __builtin_ia32_rsqrt14ps128_mask ((__v4sf) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rsqrt14_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_rsqrt14ps128_mask ((__v4sf) __A,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rsqrt14_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_rsqrt14ps128_mask ((__v4sf) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sqrt_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_sqrtpd256_mask ((__v4df) __A,
        (__v4df) __W,
        (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sqrt_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_sqrtpd256_mask ((__v4df) __A,
        (__v4df)
        _mm256_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sqrt_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_sqrtpd128_mask ((__v2df) __A,
        (__v2df) __W,
        (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sqrt_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_sqrtpd128_mask ((__v2df) __A,
        (__v2df)
        _mm_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sqrt_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_sqrtps256_mask ((__v8sf) __A,
       (__v8sf) __W,
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sqrt_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_sqrtps256_mask ((__v8sf) __A,
       (__v8sf)
       _mm256_setzero_ps (),
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sqrt_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_sqrtps128_mask ((__v4sf) __A,
       (__v4sf) __W,
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sqrt_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_sqrtps128_mask ((__v4sf) __A,
       (__v4sf)
       _mm_setzero_ps (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_add_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_paddd256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_add_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddd256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_add_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_paddq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_add_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sub_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_psubd256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sub_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubd256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sub_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_psubq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sub_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_add_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_paddd128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_add_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddd128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_add_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_paddq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_add_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sub_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psubd128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sub_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubd128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sub_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psubq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sub_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_getexp_ps (__m256 __A)
{
  return (__m256) __builtin_ia32_getexpps256_mask ((__v8sf) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) -1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_getexp_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_getexpps256_mask ((__v8sf) __A,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_getexp_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_getexpps256_mask ((__v8sf) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_getexp_pd (__m256d __A)
{
  return (__m256d) __builtin_ia32_getexppd256_mask ((__v4df) __A,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_getexp_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_getexppd256_mask ((__v4df) __A,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_getexp_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_getexppd256_mask ((__v4df) __A,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_getexp_ps (__m128 __A)
{
  return (__m128) __builtin_ia32_getexpps128_mask ((__v4sf) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_getexp_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_getexpps128_mask ((__v4sf) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_getexp_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_getexpps128_mask ((__v4sf) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_getexp_pd (__m128d __A)
{
  return (__m128d) __builtin_ia32_getexppd128_mask ((__v2df) __A,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_getexp_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_getexppd128_mask ((__v2df) __A,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_getexp_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_getexppd128_mask ((__v2df) __A,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srl_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psrld256_mask ((__v8si) __A,
       (__v4si) __B,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srl_epi32 (__mmask8 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psrld256_mask ((__v8si) __A,
       (__v4si) __B,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srl_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psrld128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srl_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrld128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srl_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psrlq256_mask ((__v4di) __A,
       (__v2di) __B,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srl_epi64 (__mmask8 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psrlq256_mask ((__v4di) __A,
       (__v2di) __B,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srl_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psrlq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srl_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrlq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_di (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_and_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pandd256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_and_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pandd256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_scalef_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_scalefpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_scalef_pd (__m256d __W, __mmask8 __U, __m256d __A,
         __m256d __B)
{
  return (__m256d) __builtin_ia32_scalefpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_scalef_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_scalefpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_scalef_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_scalefps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) -1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_scalef_ps (__m256 __W, __mmask8 __U, __m256 __A,
         __m256 __B)
{
  return (__m256) __builtin_ia32_scalefps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_scalef_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_scalefps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_scalef_pd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_scalefpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_scalef_pd (__m128d __W, __mmask8 __U, __m128d __A,
      __m128d __B)
{
  return (__m128d) __builtin_ia32_scalefpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_scalef_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_scalefpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_scalef_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_scalefps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_scalef_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_scalefps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_scalef_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_scalefps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmadd_pd (__m256d __A, __mmask8 __U, __m256d __B,
        __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df) __C,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmadd_pd (__m256d __A, __m256d __B, __m256d __C,
         __mmask8 __U)
{
  return (__m256d) __builtin_ia32_vfmaddpd256_mask3 ((__v4df) __A,
           (__v4df) __B,
           (__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmadd_pd (__mmask8 __U, __m256d __A, __m256d __B,
         __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddpd256_maskz ((__v4df) __A,
           (__v4df) __B,
           (__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmadd_pd (__m128d __A, __mmask8 __U, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df) __C,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmadd_pd (__m128d __A, __m128d __B, __m128d __C,
      __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfmaddpd128_mask3 ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmadd_pd (__mmask8 __U, __m128d __A, __m128d __B,
      __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddpd128_maskz ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmadd_ps (__m256 __A, __mmask8 __U, __m256 __B, __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf) __C,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmadd_ps (__m256 __A, __m256 __B, __m256 __C,
         __mmask8 __U)
{
  return (__m256) __builtin_ia32_vfmaddps256_mask3 ((__v8sf) __A,
          (__v8sf) __B,
          (__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmadd_ps (__mmask8 __U, __m256 __A, __m256 __B,
         __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddps256_maskz ((__v8sf) __A,
          (__v8sf) __B,
          (__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmadd_ps (__m128 __A, __mmask8 __U, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf) __C,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmadd_ps (__m128 __A, __m128 __B, __m128 __C, __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfmaddps128_mask3 ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmadd_ps (__mmask8 __U, __m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddps128_maskz ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmsub_pd (__m256d __A, __mmask8 __U, __m256d __B,
        __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddpd256_mask ((__v4df) __A,
          (__v4df) __B,
          -(__v4df) __C,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmsub_pd (__m256d __A, __m256d __B, __m256d __C,
         __mmask8 __U)
{
  return (__m256d) __builtin_ia32_vfmsubpd256_mask3 ((__v4df) __A,
           (__v4df) __B,
           (__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmsub_pd (__mmask8 __U, __m256d __A, __m256d __B,
         __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddpd256_maskz ((__v4df) __A,
           (__v4df) __B,
           -(__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmsub_pd (__m128d __A, __mmask8 __U, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddpd128_mask ((__v2df) __A,
          (__v2df) __B,
          -(__v2df) __C,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmsub_pd (__m128d __A, __m128d __B, __m128d __C,
      __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfmsubpd128_mask3 ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmsub_pd (__mmask8 __U, __m128d __A, __m128d __B,
      __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddpd128_maskz ((__v2df) __A,
           (__v2df) __B,
           -(__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmsub_ps (__m256 __A, __mmask8 __U, __m256 __B, __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         -(__v8sf) __C,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmsub_ps (__m256 __A, __m256 __B, __m256 __C,
         __mmask8 __U)
{
  return (__m256) __builtin_ia32_vfmsubps256_mask3 ((__v8sf) __A,
          (__v8sf) __B,
          (__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmsub_ps (__mmask8 __U, __m256 __A, __m256 __B,
         __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddps256_maskz ((__v8sf) __A,
          (__v8sf) __B,
          -(__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmsub_ps (__m128 __A, __mmask8 __U, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         -(__v4sf) __C,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmsub_ps (__m128 __A, __m128 __B, __m128 __C, __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfmsubps128_mask3 ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmsub_ps (__mmask8 __U, __m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddps128_maskz ((__v4sf) __A,
          (__v4sf) __B,
          -(__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmaddsub_pd (__m256d __A, __mmask8 __U, __m256d __B,
    __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddsubpd256_mask ((__v4df) __A,
             (__v4df) __B,
             (__v4df) __C,
             (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmaddsub_pd (__m256d __A, __m256d __B, __m256d __C,
     __mmask8 __U)
{
  return (__m256d) __builtin_ia32_vfmaddsubpd256_mask3 ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __C,
       (__mmask8)
       __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmaddsub_pd (__mmask8 __U, __m256d __A, __m256d __B,
     __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddsubpd256_maskz ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __C,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmaddsub_pd (__m128d __A, __mmask8 __U, __m128d __B,
        __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsubpd128_mask ((__v2df) __A,
             (__v2df) __B,
             (__v2df) __C,
             (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmaddsub_pd (__m128d __A, __m128d __B, __m128d __C,
         __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfmaddsubpd128_mask3 ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __C,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmaddsub_pd (__mmask8 __U, __m128d __A, __m128d __B,
         __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsubpd128_maskz ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __C,
       (__mmask8)
       __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmaddsub_ps (__m256 __A, __mmask8 __U, __m256 __B,
    __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddsubps256_mask ((__v8sf) __A,
            (__v8sf) __B,
            (__v8sf) __C,
            (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmaddsub_ps (__m256 __A, __m256 __B, __m256 __C,
     __mmask8 __U)
{
  return (__m256) __builtin_ia32_vfmaddsubps256_mask3 ((__v8sf) __A,
             (__v8sf) __B,
             (__v8sf) __C,
             (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmaddsub_ps (__mmask8 __U, __m256 __A, __m256 __B,
     __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddsubps256_maskz ((__v8sf) __A,
             (__v8sf) __B,
             (__v8sf) __C,
             (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmaddsub_ps (__m128 __A, __mmask8 __U, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddsubps128_mask ((__v4sf) __A,
            (__v4sf) __B,
            (__v4sf) __C,
            (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmaddsub_ps (__m128 __A, __m128 __B, __m128 __C,
         __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfmaddsubps128_mask3 ((__v4sf) __A,
             (__v4sf) __B,
             (__v4sf) __C,
             (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmaddsub_ps (__mmask8 __U, __m128 __A, __m128 __B,
         __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddsubps128_maskz ((__v4sf) __A,
             (__v4sf) __B,
             (__v4sf) __C,
             (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmsubadd_pd (__m256d __A, __mmask8 __U, __m256d __B,
    __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddsubpd256_mask ((__v4df) __A,
             (__v4df) __B,
             -(__v4df) __C,
             (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmsubadd_pd (__m256d __A, __m256d __B, __m256d __C,
     __mmask8 __U)
{
  return (__m256d) __builtin_ia32_vfmsubaddpd256_mask3 ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __C,
       (__mmask8)
       __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmsubadd_pd (__mmask8 __U, __m256d __A, __m256d __B,
     __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddsubpd256_maskz ((__v4df) __A,
       (__v4df) __B,
       -(__v4df) __C,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmsubadd_pd (__m128d __A, __mmask8 __U, __m128d __B,
        __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsubpd128_mask ((__v2df) __A,
             (__v2df) __B,
             -(__v2df) __C,
             (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmsubadd_pd (__m128d __A, __m128d __B, __m128d __C,
         __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfmsubaddpd128_mask3 ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __C,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmsubadd_pd (__mmask8 __U, __m128d __A, __m128d __B,
         __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsubpd128_maskz ((__v2df) __A,
       (__v2df) __B,
       -(__v2df) __C,
       (__mmask8)
       __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmsubadd_ps (__m256 __A, __mmask8 __U, __m256 __B,
    __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddsubps256_mask ((__v8sf) __A,
            (__v8sf) __B,
            -(__v8sf) __C,
            (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmsubadd_ps (__m256 __A, __m256 __B, __m256 __C,
     __mmask8 __U)
{
  return (__m256) __builtin_ia32_vfmsubaddps256_mask3 ((__v8sf) __A,
             (__v8sf) __B,
             (__v8sf) __C,
             (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmsubadd_ps (__mmask8 __U, __m256 __A, __m256 __B,
     __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddsubps256_maskz ((__v8sf) __A,
             (__v8sf) __B,
             -(__v8sf) __C,
             (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmsubadd_ps (__m128 __A, __mmask8 __U, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddsubps128_mask ((__v4sf) __A,
            (__v4sf) __B,
            -(__v4sf) __C,
            (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmsubadd_ps (__m128 __A, __m128 __B, __m128 __C,
         __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfmsubaddps128_mask3 ((__v4sf) __A,
             (__v4sf) __B,
             (__v4sf) __C,
             (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmsubadd_ps (__mmask8 __U, __m128 __A, __m128 __B,
         __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddsubps128_maskz ((__v4sf) __A,
             (__v4sf) __B,
             -(__v4sf) __C,
             (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fnmadd_pd (__m256d __A, __mmask8 __U, __m256d __B,
         __m256d __C)
{
  return (__m256d) __builtin_ia32_vfnmaddpd256_mask ((__v4df) __A,
           (__v4df) __B,
           (__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fnmadd_pd (__m256d __A, __m256d __B, __m256d __C,
   __mmask8 __U)
{
  return (__m256d) __builtin_ia32_vfmaddpd256_mask3 (-(__v4df) __A,
           (__v4df) __B,
           (__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fnmadd_pd (__mmask8 __U, __m256d __A, __m256d __B,
   __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddpd256_maskz (-(__v4df) __A,
           (__v4df) __B,
           (__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fnmadd_pd (__m128d __A, __mmask8 __U, __m128d __B,
      __m128d __C)
{
  return (__m128d) __builtin_ia32_vfnmaddpd128_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fnmadd_pd (__m128d __A, __m128d __B, __m128d __C,
       __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfmaddpd128_mask3 (-(__v2df) __A,
           (__v2df) __B,
           (__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fnmadd_pd (__mmask8 __U, __m128d __A, __m128d __B,
       __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddpd128_maskz (-(__v2df) __A,
           (__v2df) __B,
           (__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fnmadd_ps (__m256 __A, __mmask8 __U, __m256 __B,
         __m256 __C)
{
  return (__m256) __builtin_ia32_vfnmaddps256_mask ((__v8sf) __A,
          (__v8sf) __B,
          (__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fnmadd_ps (__m256 __A, __m256 __B, __m256 __C,
   __mmask8 __U)
{
  return (__m256) __builtin_ia32_vfmaddps256_mask3 (-(__v8sf) __A,
          (__v8sf) __B,
          (__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fnmadd_ps (__mmask8 __U, __m256 __A, __m256 __B,
   __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddps256_maskz (-(__v8sf) __A,
          (__v8sf) __B,
          (__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fnmadd_ps (__m128 __A, __mmask8 __U, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfnmaddps128_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fnmadd_ps (__m128 __A, __m128 __B, __m128 __C, __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfmaddps128_mask3 (-(__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fnmadd_ps (__mmask8 __U, __m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddps128_maskz (-(__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fnmsub_pd (__m256d __A, __mmask8 __U, __m256d __B,
         __m256d __C)
{
  return (__m256d) __builtin_ia32_vfnmsubpd256_mask ((__v4df) __A,
           (__v4df) __B,
           (__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fnmsub_pd (__m256d __A, __m256d __B, __m256d __C,
   __mmask8 __U)
{
  return (__m256d) __builtin_ia32_vfnmsubpd256_mask3 ((__v4df) __A,
            (__v4df) __B,
            (__v4df) __C,
            (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fnmsub_pd (__mmask8 __U, __m256d __A, __m256d __B,
   __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddpd256_maskz (-(__v4df) __A,
           (__v4df) __B,
           -(__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fnmsub_pd (__m128d __A, __mmask8 __U, __m128d __B,
      __m128d __C)
{
  return (__m128d) __builtin_ia32_vfnmsubpd128_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fnmsub_pd (__m128d __A, __m128d __B, __m128d __C,
       __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfnmsubpd128_mask3 ((__v2df) __A,
            (__v2df) __B,
            (__v2df) __C,
            (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fnmsub_pd (__mmask8 __U, __m128d __A, __m128d __B,
       __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddpd128_maskz (-(__v2df) __A,
           (__v2df) __B,
           -(__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fnmsub_ps (__m256 __A, __mmask8 __U, __m256 __B,
         __m256 __C)
{
  return (__m256) __builtin_ia32_vfnmsubps256_mask ((__v8sf) __A,
          (__v8sf) __B,
          (__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fnmsub_ps (__m256 __A, __m256 __B, __m256 __C,
   __mmask8 __U)
{
  return (__m256) __builtin_ia32_vfnmsubps256_mask3 ((__v8sf) __A,
           (__v8sf) __B,
           (__v8sf) __C,
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fnmsub_ps (__mmask8 __U, __m256 __A, __m256 __B,
   __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddps256_maskz (-(__v8sf) __A,
          (__v8sf) __B,
          -(__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fnmsub_ps (__m128 __A, __mmask8 __U, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfnmsubps128_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fnmsub_ps (__m128 __A, __m128 __B, __m128 __C, __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfnmsubps128_mask3 ((__v4sf) __A,
           (__v4sf) __B,
           (__v4sf) __C,
           (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fnmsub_ps (__mmask8 __U, __m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddps128_maskz (-(__v4sf) __A,
          (__v4sf) __B,
          -(__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_and_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pandd128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_and_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pandd128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_andnot_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
     __m256i __B)
{
  return (__m256i) __builtin_ia32_pandnd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W,
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_andnot_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pandnd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_andnot_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_pandnd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_andnot_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pandnd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_or_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_pord256_mask ((__v8si) __A,
      (__v8si) __B,
      (__v8si) __W,
      (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_or_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pord256_mask ((__v8si) __A,
      (__v8si) __B,
      (__v8si)
      _mm256_setzero_si256 (),
      (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_or_epi32 (__m128i __W, __mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pord128_mask ((__v4si) __A,
      (__v4si) __B,
      (__v4si) __W,
      (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_or_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pord128_mask ((__v4si) __A,
      (__v4si) __B,
      (__v4si)
      _mm_setzero_si128 (),
      (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_xor_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pxord256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_xor_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pxord256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_xor_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pxord128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_xor_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pxord128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtpd_ps (__m128 __W, __mmask8 __U, __m128d __A)
{
  return (__m128) __builtin_ia32_cvtpd2ps_mask ((__v2df) __A,
      (__v4sf) __W,
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtpd_ps (__mmask8 __U, __m128d __A)
{
  return (__m128) __builtin_ia32_cvtpd2ps_mask ((__v2df) __A,
      (__v4sf)
      _mm_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtpd_ps (__m128 __W, __mmask8 __U, __m256d __A)
{
  return (__m128) __builtin_ia32_cvtpd2ps256_mask ((__v4df) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtpd_ps (__mmask8 __U, __m256d __A)
{
  return (__m128) __builtin_ia32_cvtpd2ps256_mask ((__v4df) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtps_epi32 (__m256i __W, __mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvtps2dq256_mask ((__v8sf) __A,
          (__v8si) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtps_epi32 (__mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvtps2dq256_mask ((__v8sf) __A,
          (__v8si)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtps_epi32 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2dq128_mask ((__v4sf) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtps_epi32 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2dq128_mask ((__v4sf) __A,
          (__v4si)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtps_epu32 (__m256 __A)
{
  return (__m256i) __builtin_ia32_cvtps2udq256_mask ((__v8sf) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtps_epu32 (__m256i __W, __mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvtps2udq256_mask ((__v8sf) __A,
           (__v8si) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtps_epu32 (__mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvtps2udq256_mask ((__v8sf) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_epu32 (__m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2udq128_mask ((__v4sf) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtps_epu32 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2udq128_mask ((__v4sf) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtps_epu32 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2udq128_mask ((__v4sf) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_movedup_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_movddup256_mask ((__v4df) __A,
         (__v4df) __W,
         (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_movedup_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_movddup256_mask ((__v4df) __A,
         (__v4df)
         _mm256_setzero_pd (),
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_movedup_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_movddup128_mask ((__v2df) __A,
         (__v2df) __W,
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_movedup_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_movddup128_mask ((__v2df) __A,
         (__v2df)
         _mm_setzero_pd (),
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_movehdup_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_movshdup256_mask ((__v8sf) __A,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_movehdup_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_movshdup256_mask ((__v8sf) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_movehdup_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_movshdup128_mask ((__v4sf) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_movehdup_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_movshdup128_mask ((__v4sf) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_moveldup_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_movsldup256_mask ((__v8sf) __A,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_moveldup_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_movsldup256_mask ((__v8sf) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_moveldup_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_movsldup128_mask ((__v4sf) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_moveldup_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_movsldup128_mask ((__v4sf) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpackhi_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
    __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhdq128_mask ((__v4si) __A,
           (__v4si) __B,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpackhi_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhdq128_mask ((__v4si) __A,
           (__v4si) __B,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpackhi_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
       __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhdq256_mask ((__v8si) __A,
           (__v8si) __B,
           (__v8si) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpackhi_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhdq256_mask ((__v8si) __A,
           (__v8si) __B,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpackhi_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
    __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhqdq128_mask ((__v2di) __A,
            (__v2di) __B,
            (__v2di) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpackhi_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhqdq128_mask ((__v2di) __A,
            (__v2di) __B,
            (__v2di)
            _mm_setzero_di (),
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpackhi_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
       __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhqdq256_mask ((__v4di) __A,
            (__v4di) __B,
            (__v4di) __W,
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpackhi_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhqdq256_mask ((__v4di) __A,
            (__v4di) __B,
            (__v4di)
            _mm256_setzero_si256 (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpacklo_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
    __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckldq128_mask ((__v4si) __A,
           (__v4si) __B,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpacklo_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckldq128_mask ((__v4si) __A,
           (__v4si) __B,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpacklo_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
       __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckldq256_mask ((__v8si) __A,
           (__v8si) __B,
           (__v8si) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpacklo_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckldq256_mask ((__v8si) __A,
           (__v8si) __B,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpacklo_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
    __m128i __B)
{
  return (__m128i) __builtin_ia32_punpcklqdq128_mask ((__v2di) __A,
            (__v2di) __B,
            (__v2di) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpacklo_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpcklqdq128_mask ((__v2di) __A,
            (__v2di) __B,
            (__v2di)
            _mm_setzero_di (),
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpacklo_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
       __m256i __B)
{
  return (__m256i) __builtin_ia32_punpcklqdq256_mask ((__v4di) __A,
            (__v4di) __B,
            (__v4di) __W,
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpacklo_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpcklqdq256_mask ((__v4di) __A,
            (__v4di) __B,
            (__v4di)
            _mm256_setzero_si256 (),
            (__mmask8) __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epu32_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __A,
         (__v4si) __B, 0,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi32_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqd128_mask ((__v4si) __A,
          (__v4si) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epu32_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __A,
         (__v4si) __B, 0, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epi32_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqd128_mask ((__v4si) __A,
          (__v4si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epu32_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __A,
         (__v8si) __B, 0,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi32_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqd256_mask ((__v8si) __A,
          (__v8si) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epu32_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __A,
         (__v8si) __B, 0, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epi32_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqd256_mask ((__v8si) __A,
          (__v8si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epu64_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __A,
         (__v2di) __B, 0,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi64_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqq128_mask ((__v2di) __A,
          (__v2di) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epu64_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __A,
         (__v2di) __B, 0, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epi64_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqq128_mask ((__v2di) __A,
          (__v2di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epu64_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __A,
         (__v4di) __B, 0,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi64_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqq256_mask ((__v4di) __A,
          (__v4di) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epu64_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __A,
         (__v4di) __B, 0, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epi64_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqq256_mask ((__v4di) __A,
          (__v4di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epu32_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __A,
         (__v4si) __B, 6,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi32_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtd128_mask ((__v4si) __A,
          (__v4si) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epu32_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __A,
         (__v4si) __B, 6, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epi32_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtd128_mask ((__v4si) __A,
          (__v4si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epu32_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __A,
         (__v8si) __B, 6,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi32_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtd256_mask ((__v8si) __A,
          (__v8si) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epu32_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __A,
         (__v8si) __B, 6, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epi32_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtd256_mask ((__v8si) __A,
          (__v8si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epu64_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __A,
         (__v2di) __B, 6,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi64_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtq128_mask ((__v2di) __A,
          (__v2di) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epu64_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __A,
         (__v2di) __B, 6, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epi64_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtq128_mask ((__v2di) __A,
          (__v2di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epu64_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __A,
         (__v4di) __B, 6,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi64_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtq256_mask ((__v4di) __A,
          (__v4di) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epu64_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __A,
         (__v4di) __B, 6, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epi64_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtq256_mask ((__v4di) __A,
          (__v4di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_test_epi32_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestmd128 ((__v4si) __A,
            (__v4si) __B,
            (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_test_epi32_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestmd128 ((__v4si) __A,
            (__v4si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_test_epi32_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestmd256 ((__v8si) __A,
            (__v8si) __B,
            (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_test_epi32_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestmd256 ((__v8si) __A,
            (__v8si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_test_epi64_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestmq128 ((__v2di) __A,
            (__v2di) __B,
            (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_test_epi64_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestmq128 ((__v2di) __A,
            (__v2di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_test_epi64_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestmq256 ((__v4di) __A,
            (__v4di) __B,
            (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_test_epi64_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestmq256 ((__v4di) __A,
            (__v4di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_testn_epi32_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmd128 ((__v4si) __A,
      (__v4si) __B,
      (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_testn_epi32_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmd128 ((__v4si) __A,
      (__v4si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testn_epi32_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmd256 ((__v8si) __A,
      (__v8si) __B,
      (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_testn_epi32_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmd256 ((__v8si) __A,
      (__v8si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_testn_epi64_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmq128 ((__v2di) __A,
      (__v2di) __B,
      (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_testn_epi64_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmq128 ((__v2di) __A,
      (__v2di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testn_epi64_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmq256 ((__v4di) __A,
      (__v4di) __B,
      (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_testn_epi64_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmq256 ((__v4di) __A,
      (__v4di) __B, __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compress_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_compressdf256_mask ((__v4df) __A,
            (__v4df) __W,
            (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_compress_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_compressdf256_mask ((__v4df) __A,
            (__v4df)
            _mm256_setzero_pd (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compressstoreu_pd (void *__P, __mmask8 __U, __m256d __A)
{
  __builtin_ia32_compressstoredf256_mask ((__v4df *) __P,
       (__v4df) __A,
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compress_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_compressdf128_mask ((__v2df) __A,
            (__v2df) __W,
            (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_compress_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_compressdf128_mask ((__v2df) __A,
            (__v2df)
            _mm_setzero_pd (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compressstoreu_pd (void *__P, __mmask8 __U, __m128d __A)
{
  __builtin_ia32_compressstoredf128_mask ((__v2df *) __P,
       (__v2df) __A,
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compress_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_compresssf256_mask ((__v8sf) __A,
           (__v8sf) __W,
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_compress_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_compresssf256_mask ((__v8sf) __A,
           (__v8sf)
           _mm256_setzero_ps (),
           (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compressstoreu_ps (void *__P, __mmask8 __U, __m256 __A)
{
  __builtin_ia32_compressstoresf256_mask ((__v8sf *) __P,
       (__v8sf) __A,
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compress_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_compresssf128_mask ((__v4sf) __A,
           (__v4sf) __W,
           (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_compress_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_compresssf128_mask ((__v4sf) __A,
           (__v4sf)
           _mm_setzero_ps (),
           (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compressstoreu_ps (void *__P, __mmask8 __U, __m128 __A)
{
  __builtin_ia32_compressstoresf128_mask ((__v4sf *) __P,
       (__v4sf) __A,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compress_epi64 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_compressdi256_mask ((__v4di) __A,
            (__v4di) __W,
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_compress_epi64 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_compressdi256_mask ((__v4di) __A,
            (__v4di)
            _mm256_setzero_si256 (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compressstoreu_epi64 (void *__P, __mmask8 __U, __m256i __A)
{
  __builtin_ia32_compressstoredi256_mask ((__v4di *) __P,
       (__v4di) __A,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compress_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_compressdi128_mask ((__v2di) __A,
            (__v2di) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_compress_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_compressdi128_mask ((__v2di) __A,
            (__v2di)
            _mm_setzero_di (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compressstoreu_epi64 (void *__P, __mmask8 __U, __m128i __A)
{
  __builtin_ia32_compressstoredi128_mask ((__v2di *) __P,
       (__v2di) __A,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compress_epi32 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_compresssi256_mask ((__v8si) __A,
            (__v8si) __W,
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_compress_epi32 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_compresssi256_mask ((__v8si) __A,
            (__v8si)
            _mm256_setzero_si256 (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compressstoreu_epi32 (void *__P, __mmask8 __U, __m256i __A)
{
  __builtin_ia32_compressstoresi256_mask ((__v8si *) __P,
       (__v8si) __A,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compress_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_compresssi128_mask ((__v4si) __A,
            (__v4si) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_compress_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_compresssi128_mask ((__v4si) __A,
            (__v4si)
            _mm_setzero_si128 (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compressstoreu_epi32 (void *__P, __mmask8 __U, __m128i __A)
{
  __builtin_ia32_compressstoresi128_mask ((__v4si *) __P,
       (__v4si) __A,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expand_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_expanddf256_mask ((__v4df) __A,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expand_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_expanddf256_maskz ((__v4df) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expandloadu_pd (__m256d __W, __mmask8 __U, void const *__P)
{
  return (__m256d) __builtin_ia32_expandloaddf256_mask ((__v4df *) __P,
       (__v4df) __W,
       (__mmask8)
       __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expandloadu_pd (__mmask8 __U, void const *__P)
{
  return (__m256d) __builtin_ia32_expandloaddf256_maskz ((__v4df *) __P,
        (__v4df)
        _mm256_setzero_pd (),
        (__mmask8)
        __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expand_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_expanddf128_mask ((__v2df) __A,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expand_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_expanddf128_maskz ((__v2df) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expandloadu_pd (__m128d __W, __mmask8 __U, void const *__P)
{
  return (__m128d) __builtin_ia32_expandloaddf128_mask ((__v2df *) __P,
       (__v2df) __W,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expandloadu_pd (__mmask8 __U, void const *__P)
{
  return (__m128d) __builtin_ia32_expandloaddf128_maskz ((__v2df *) __P,
        (__v2df)
        _mm_setzero_pd (),
        (__mmask8)
        __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expand_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_expandsf256_mask ((__v8sf) __A,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expand_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_expandsf256_maskz ((__v8sf) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expandloadu_ps (__m256 __W, __mmask8 __U, void const *__P)
{
  return (__m256) __builtin_ia32_expandloadsf256_mask ((__v8sf *) __P,
             (__v8sf) __W,
             (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expandloadu_ps (__mmask8 __U, void const *__P)
{
  return (__m256) __builtin_ia32_expandloadsf256_maskz ((__v8sf *) __P,
       (__v8sf)
       _mm256_setzero_ps (),
       (__mmask8)
       __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expand_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_expandsf128_mask ((__v4sf) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expand_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_expandsf128_maskz ((__v4sf) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expandloadu_ps (__m128 __W, __mmask8 __U, void const *__P)
{
  return (__m128) __builtin_ia32_expandloadsf128_mask ((__v4sf *) __P,
             (__v4sf) __W,
             (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expandloadu_ps (__mmask8 __U, void const *__P)
{
  return (__m128) __builtin_ia32_expandloadsf128_maskz ((__v4sf *) __P,
       (__v4sf)
       _mm_setzero_ps (),
       (__mmask8)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expand_epi64 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_expanddi256_mask ((__v4di) __A,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expand_epi64 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_expanddi256_maskz ((__v4di) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expandloadu_epi64 (__m256i __W, __mmask8 __U,
          void const *__P)
{
  return (__m256i) __builtin_ia32_expandloaddi256_mask ((__v4di *) __P,
       (__v4di) __W,
       (__mmask8)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expandloadu_epi64 (__mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_expandloaddi256_maskz ((__v4di *) __P,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expand_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_expanddi128_mask ((__v2di) __A,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expand_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_expanddi128_maskz ((__v2di) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expandloadu_epi64 (__m128i __W, __mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_expandloaddi128_mask ((__v2di *) __P,
       (__v2di) __W,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expandloadu_epi64 (__mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_expandloaddi128_maskz ((__v2di *) __P,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8)
        __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expand_epi32 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_expandsi256_mask ((__v8si) __A,
          (__v8si) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expand_epi32 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_expandsi256_maskz ((__v8si) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expandloadu_epi32 (__m256i __W, __mmask8 __U,
          void const *__P)
{
  return (__m256i) __builtin_ia32_expandloadsi256_mask ((__v8si *) __P,
       (__v8si) __W,
       (__mmask8)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expandloadu_epi32 (__mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_expandloadsi256_maskz ((__v8si *) __P,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expand_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_expandsi128_mask ((__v4si) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expand_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_expandsi128_maskz ((__v4si) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expandloadu_epi32 (__m128i __W, __mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_expandloadsi128_mask ((__v4si *) __P,
       (__v4si) __W,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expandloadu_epi32 (__mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_expandloadsi128_maskz ((__v4si *) __P,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8)
        __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutex2var_pd (__m256d __A, __m256i __I, __m256d __B)
{
  return (__m256d) __builtin_ia32_vpermt2varpd256_mask ((__v4di) __I
                 ,
       (__v4df) __A,
       (__v4df) __B,
       (__mmask8) -
       1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutex2var_pd (__m256d __A, __mmask8 __U, __m256i __I,
        __m256d __B)
{
  return (__m256d) __builtin_ia32_vpermt2varpd256_mask ((__v4di) __I
                 ,
       (__v4df) __A,
       (__v4df) __B,
       (__mmask8)
       __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask2_permutex2var_pd (__m256d __A, __m256i __I, __mmask8 __U,
         __m256d __B)
{
  return (__m256d) __builtin_ia32_vpermi2varpd256_mask ((__v4df) __A,
       (__v4di) __I
                 ,
       (__v4df) __B,
       (__mmask8)
       __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutex2var_pd (__mmask8 __U, __m256d __A, __m256i __I,
         __m256d __B)
{
  return (__m256d) __builtin_ia32_vpermt2varpd256_maskz ((__v4di) __I
                  ,
        (__v4df) __A,
        (__v4df) __B,
        (__mmask8)
        __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutex2var_ps (__m256 __A, __m256i __I, __m256 __B)
{
  return (__m256) __builtin_ia32_vpermt2varps256_mask ((__v8si) __I
                       ,
             (__v8sf) __A,
             (__v8sf) __B,
             (__mmask8) -1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutex2var_ps (__m256 __A, __mmask8 __U, __m256i __I,
        __m256 __B)
{
  return (__m256) __builtin_ia32_vpermt2varps256_mask ((__v8si) __I
                       ,
             (__v8sf) __A,
             (__v8sf) __B,
             (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask2_permutex2var_ps (__m256 __A, __m256i __I, __mmask8 __U,
         __m256 __B)
{
  return (__m256) __builtin_ia32_vpermi2varps256_mask ((__v8sf) __A,
             (__v8si) __I
                       ,
             (__v8sf) __B,
             (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutex2var_ps (__mmask8 __U, __m256 __A, __m256i __I,
         __m256 __B)
{
  return (__m256) __builtin_ia32_vpermt2varps256_maskz ((__v8si) __I
                 ,
       (__v8sf) __A,
       (__v8sf) __B,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutex2var_epi64 (__m128i __A, __m128i __I, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varq128_mask ((__v2di) __I
                       ,
             (__v2di) __A,
             (__v2di) __B,
             (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutex2var_epi64 (__m128i __A, __mmask8 __U, __m128i __I,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varq128_mask ((__v2di) __I
                       ,
             (__v2di) __A,
             (__v2di) __B,
             (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask2_permutex2var_epi64 (__m128i __A, __m128i __I, __mmask8 __U,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermi2varq128_mask ((__v2di) __A,
             (__v2di) __I
                       ,
             (__v2di) __B,
             (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutex2var_epi64 (__mmask8 __U, __m128i __A, __m128i __I,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varq128_maskz ((__v2di) __I
                 ,
       (__v2di) __A,
       (__v2di) __B,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutex2var_epi32 (__m128i __A, __m128i __I, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2vard128_mask ((__v4si) __I
                       ,
             (__v4si) __A,
             (__v4si) __B,
             (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutex2var_epi32 (__m128i __A, __mmask8 __U, __m128i __I,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2vard128_mask ((__v4si) __I
                       ,
             (__v4si) __A,
             (__v4si) __B,
             (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask2_permutex2var_epi32 (__m128i __A, __m128i __I, __mmask8 __U,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermi2vard128_mask ((__v4si) __A,
             (__v4si) __I
                       ,
             (__v4si) __B,
             (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutex2var_epi32 (__mmask8 __U, __m128i __A, __m128i __I,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2vard128_maskz ((__v4si) __I
                 ,
       (__v4si) __A,
       (__v4si) __B,
       (__mmask8)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutex2var_epi64 (__m256i __A, __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varq256_mask ((__v4di) __I
                       ,
             (__v4di) __A,
             (__v4di) __B,
             (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutex2var_epi64 (__m256i __A, __mmask8 __U, __m256i __I,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varq256_mask ((__v4di) __I
                       ,
             (__v4di) __A,
             (__v4di) __B,
             (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask2_permutex2var_epi64 (__m256i __A, __m256i __I,
     __mmask8 __U, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermi2varq256_mask ((__v4di) __A,
             (__v4di) __I
                       ,
             (__v4di) __B,
             (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutex2var_epi64 (__mmask8 __U, __m256i __A,
     __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varq256_maskz ((__v4di) __I
                 ,
       (__v4di) __A,
       (__v4di) __B,
       (__mmask8)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutex2var_epi32 (__m256i __A, __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2vard256_mask ((__v8si) __I
                       ,
             (__v8si) __A,
             (__v8si) __B,
             (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutex2var_epi32 (__m256i __A, __mmask8 __U, __m256i __I,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2vard256_mask ((__v8si) __I
                       ,
             (__v8si) __A,
             (__v8si) __B,
             (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask2_permutex2var_epi32 (__m256i __A, __m256i __I,
     __mmask8 __U, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermi2vard256_mask ((__v8si) __A,
             (__v8si) __I
                       ,
             (__v8si) __B,
             (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutex2var_epi32 (__mmask8 __U, __m256i __A,
     __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2vard256_maskz ((__v8si) __I
                 ,
       (__v8si) __A,
       (__v8si) __B,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutex2var_pd (__m128d __A, __m128i __I, __m128d __B)
{
  return (__m128d) __builtin_ia32_vpermt2varpd128_mask ((__v2di) __I
                 ,
       (__v2df) __A,
       (__v2df) __B,
       (__mmask8) -
       1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutex2var_pd (__m128d __A, __mmask8 __U, __m128i __I,
     __m128d __B)
{
  return (__m128d) __builtin_ia32_vpermt2varpd128_mask ((__v2di) __I
                 ,
       (__v2df) __A,
       (__v2df) __B,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask2_permutex2var_pd (__m128d __A, __m128i __I, __mmask8 __U,
      __m128d __B)
{
  return (__m128d) __builtin_ia32_vpermi2varpd128_mask ((__v2df) __A,
       (__v2di) __I
                 ,
       (__v2df) __B,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutex2var_pd (__mmask8 __U, __m128d __A, __m128i __I,
      __m128d __B)
{
  return (__m128d) __builtin_ia32_vpermt2varpd128_maskz ((__v2di) __I
                  ,
        (__v2df) __A,
        (__v2df) __B,
        (__mmask8)
        __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutex2var_ps (__m128 __A, __m128i __I, __m128 __B)
{
  return (__m128) __builtin_ia32_vpermt2varps128_mask ((__v4si) __I
                       ,
             (__v4sf) __A,
             (__v4sf) __B,
             (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutex2var_ps (__m128 __A, __mmask8 __U, __m128i __I,
     __m128 __B)
{
  return (__m128) __builtin_ia32_vpermt2varps128_mask ((__v4si) __I
                       ,
             (__v4sf) __A,
             (__v4sf) __B,
             (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask2_permutex2var_ps (__m128 __A, __m128i __I, __mmask8 __U,
      __m128 __B)
{
  return (__m128) __builtin_ia32_vpermi2varps128_mask ((__v4sf) __A,
             (__v4si) __I
                       ,
             (__v4sf) __B,
             (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutex2var_ps (__mmask8 __U, __m128 __A, __m128i __I,
      __m128 __B)
{
  return (__m128) __builtin_ia32_vpermt2varps128_maskz ((__v4si) __I
                 ,
       (__v4sf) __A,
       (__v4sf) __B,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_srav_epi64 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psravq128_mask ((__v2di) __X,
        (__v2di) __Y,
        (__v2di)
        _mm_setzero_di (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srav_epi64 (__m128i __W, __mmask8 __U, __m128i __X,
       __m128i __Y)
{
  return (__m128i) __builtin_ia32_psravq128_mask ((__v2di) __X,
        (__v2di) __Y,
        (__v2di) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srav_epi64 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psravq128_mask ((__v2di) __X,
        (__v2di) __Y,
        (__v2di)
        _mm_setzero_di (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sllv_epi32 (__m256i __W, __mmask8 __U, __m256i __X,
   __m256i __Y)
{
  return (__m256i) __builtin_ia32_psllv8si_mask ((__v8si) __X,
       (__v8si) __Y,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sllv_epi32 (__mmask8 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psllv8si_mask ((__v8si) __X,
       (__v8si) __Y,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sllv_epi32 (__m128i __W, __mmask8 __U, __m128i __X,
       __m128i __Y)
{
  return (__m128i) __builtin_ia32_psllv4si_mask ((__v4si) __X,
       (__v4si) __Y,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sllv_epi32 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psllv4si_mask ((__v4si) __X,
       (__v4si) __Y,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sllv_epi64 (__m256i __W, __mmask8 __U, __m256i __X,
   __m256i __Y)
{
  return (__m256i) __builtin_ia32_psllv4di_mask ((__v4di) __X,
       (__v4di) __Y,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sllv_epi64 (__mmask8 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psllv4di_mask ((__v4di) __X,
       (__v4di) __Y,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sllv_epi64 (__m128i __W, __mmask8 __U, __m128i __X,
       __m128i __Y)
{
  return (__m128i) __builtin_ia32_psllv2di_mask ((__v2di) __X,
       (__v2di) __Y,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sllv_epi64 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psllv2di_mask ((__v2di) __X,
       (__v2di) __Y,
       (__v2di)
       _mm_setzero_di (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srav_epi32 (__m256i __W, __mmask8 __U, __m256i __X,
   __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrav8si_mask ((__v8si) __X,
       (__v8si) __Y,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srav_epi32 (__mmask8 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrav8si_mask ((__v8si) __X,
       (__v8si) __Y,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srav_epi32 (__m128i __W, __mmask8 __U, __m128i __X,
       __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrav4si_mask ((__v4si) __X,
       (__v4si) __Y,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srav_epi32 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrav4si_mask ((__v4si) __X,
       (__v4si) __Y,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srlv_epi32 (__m256i __W, __mmask8 __U, __m256i __X,
   __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrlv8si_mask ((__v8si) __X,
       (__v8si) __Y,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srlv_epi32 (__mmask8 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrlv8si_mask ((__v8si) __X,
       (__v8si) __Y,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srlv_epi32 (__m128i __W, __mmask8 __U, __m128i __X,
       __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrlv4si_mask ((__v4si) __X,
       (__v4si) __Y,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srlv_epi32 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrlv4si_mask ((__v4si) __X,
       (__v4si) __Y,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srlv_epi64 (__m256i __W, __mmask8 __U, __m256i __X,
   __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrlv4di_mask ((__v4di) __X,
       (__v4di) __Y,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srlv_epi64 (__mmask8 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrlv4di_mask ((__v4di) __X,
       (__v4di) __Y,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srlv_epi64 (__m128i __W, __mmask8 __U, __m128i __X,
       __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrlv2di_mask ((__v2di) __X,
       (__v2di) __Y,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srlv_epi64 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrlv2di_mask ((__v2di) __X,
       (__v2di) __Y,
       (__v2di)
       _mm_setzero_di (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rolv_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prolvd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rolv_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_prolvd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W,
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rolv_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prolvd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rolv_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prolvd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rolv_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_prolvd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rolv_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prolvd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rorv_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prorvd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rorv_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_prorvd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W,
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rorv_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prorvd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rorv_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prorvd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rorv_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_prorvd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rorv_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prorvd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rolv_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prolvq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rolv_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_prolvq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W,
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rolv_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prolvq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rolv_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prolvq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_di (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rolv_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_prolvq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rolv_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prolvq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_di (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rorv_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prorvq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rorv_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_prorvq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W,
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rorv_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prorvq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rorv_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prorvq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_di (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rorv_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_prorvq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rorv_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prorvq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_di (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srav_epi64 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psravq256_mask ((__v4di) __X,
        (__v4di) __Y,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srav_epi64 (__m256i __W, __mmask8 __U, __m256i __X,
   __m256i __Y)
{
  return (__m256i) __builtin_ia32_psravq256_mask ((__v4di) __X,
        (__v4di) __Y,
        (__v4di) __W,
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srav_epi64 (__mmask8 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psravq256_mask ((__v4di) __X,
        (__v4di) __Y,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_and_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pandq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di) __W, __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_and_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pandq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di)
       _mm256_setzero_pd (),
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_and_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pandq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di) __W, __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_and_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pandq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_pd (),
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_andnot_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
     __m256i __B)
{
  return (__m256i) __builtin_ia32_pandnq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W, __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_andnot_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pandnq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_pd (),
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_andnot_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_pandnq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W, __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_andnot_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pandnq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_pd (),
        __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_or_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_porq256_mask ((__v4di) __A,
      (__v4di) __B,
      (__v4di) __W,
      (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_or_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_porq256_mask ((__v4di) __A,
      (__v4di) __B,
      (__v4di)
      _mm256_setzero_si256 (),
      (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_or_epi64 (__m128i __W, __mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_porq128_mask ((__v2di) __A,
      (__v2di) __B,
      (__v2di) __W,
      (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_or_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_porq128_mask ((__v2di) __A,
      (__v2di) __B,
      (__v2di)
      _mm_setzero_si128 (),
      (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_xor_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pxorq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_xor_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pxorq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_xor_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pxorq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_xor_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pxorq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_maxpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_maxpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_maxps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_maxps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_div_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_divps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_div_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_divps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_div_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_divpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_div_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_divpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_minpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_div_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_divpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_minpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_minps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_div_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_divpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_div_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_divps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_minps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_div_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_divps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_minps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mul_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_mulps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_minps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mul_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_mulps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_maxps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_maxps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_minpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_minpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_maxpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_maxpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mul_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_mulpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mul_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_mulpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mul_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_mulps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mul_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_mulps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mul_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_mulpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mul_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_mulpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epi64 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epi64 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epi64 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epi64 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epu64 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxuq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epu64 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxuq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epu64 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxuq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epu64 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminuq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epu64 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pminuq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epu64 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminuq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epi32 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epi32 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epi32 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epi32 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epu32 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxud256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epu32 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxud256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epu32 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminud256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epu32 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pminud256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epi64 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epi64 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_di (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epi64 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epi64 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epu64 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxuq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_di (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epu64 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxuq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_di (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epu64 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxuq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epu64 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminuq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_di (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epu64 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pminuq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epu64 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminuq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epi32 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epi32 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epi32 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epi32 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epu32 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxud128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epu32 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxud128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epu32 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminud128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epu32 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pminud128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W, __M);
}
#pragma GCC push_options
#pragma GCC target("avx512vl,avx512cd")
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcastmb_epi64 (__mmask8 __A)
{
  return (__m128i) __builtin_ia32_broadcastmb128 (__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastmb_epi64 (__mmask8 __A)
{
  return (__m256i) __builtin_ia32_broadcastmb256 (__A);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcastmw_epi32 (__mmask16 __A)
{
  return (__m128i) __builtin_ia32_broadcastmw128 (__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastmw_epi32 (__mmask16 __A)
{
  return (__m256i) __builtin_ia32_broadcastmw256 (__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_lzcnt_epi32 (__m256i __A)
{
  return (__m256i) __builtin_ia32_vplzcntd_256_mask ((__v8si) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_lzcnt_epi32 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vplzcntd_256_mask ((__v8si) __A,
           (__v8si) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_lzcnt_epi32 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vplzcntd_256_mask ((__v8si) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_lzcnt_epi64 (__m256i __A)
{
  return (__m256i) __builtin_ia32_vplzcntq_256_mask ((__v4di) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_lzcnt_epi64 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vplzcntq_256_mask ((__v4di) __A,
           (__v4di) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_lzcnt_epi64 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vplzcntq_256_mask ((__v4di) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_conflict_epi64 (__m256i __A)
{
  return (__m256i) __builtin_ia32_vpconflictdi_256_mask ((__v4di) __A,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -
        1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_conflict_epi64 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpconflictdi_256_mask ((__v4di) __A,
        (__v4di) __W,
        (__mmask8)
        __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_conflict_epi64 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpconflictdi_256_mask ((__v4di) __A,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8)
        __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_conflict_epi32 (__m256i __A)
{
  return (__m256i) __builtin_ia32_vpconflictsi_256_mask ((__v8si) __A,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8) -
        1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_conflict_epi32 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpconflictsi_256_mask ((__v8si) __A,
        (__v8si) __W,
        (__mmask8)
        __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_conflict_epi32 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpconflictsi_256_mask ((__v8si) __A,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_lzcnt_epi32 (__m128i __A)
{
  return (__m128i) __builtin_ia32_vplzcntd_128_mask ((__v4si) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_lzcnt_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vplzcntd_128_mask ((__v4si) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_lzcnt_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vplzcntd_128_mask ((__v4si) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_lzcnt_epi64 (__m128i __A)
{
  return (__m128i) __builtin_ia32_vplzcntq_128_mask ((__v2di) __A,
           (__v2di)
           _mm_setzero_di (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_lzcnt_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vplzcntq_128_mask ((__v2di) __A,
           (__v2di) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_lzcnt_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vplzcntq_128_mask ((__v2di) __A,
           (__v2di)
           _mm_setzero_di (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_conflict_epi64 (__m128i __A)
{
  return (__m128i) __builtin_ia32_vpconflictdi_128_mask ((__v2di) __A,
        (__v2di)
        _mm_setzero_di (),
        (__mmask8) -
        1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_conflict_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpconflictdi_128_mask ((__v2di) __A,
        (__v2di) __W,
        (__mmask8)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_conflict_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpconflictdi_128_mask ((__v2di) __A,
        (__v2di)
        _mm_setzero_di (),
        (__mmask8)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_conflict_epi32 (__m128i __A)
{
  return (__m128i) __builtin_ia32_vpconflictsi_128_mask ((__v4si) __A,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8) -
        1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_conflict_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpconflictsi_128_mask ((__v4si) __A,
        (__v4si) __W,
        (__mmask8)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_conflict_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpconflictsi_128_mask ((__v4si) __A,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8)
        __U);
}
#pragma GCC pop_options
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpacklo_pd (__m256d __W, __mmask8 __U, __m256d __A,
    __m256d __B)
{
  return (__m256d) __builtin_ia32_unpcklpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpacklo_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_unpcklpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpacklo_pd (__m128d __W, __mmask8 __U, __m128d __A,
        __m128d __B)
{
  return (__m128d) __builtin_ia32_unpcklpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpacklo_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_unpcklpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpacklo_ps (__m256 __W, __mmask8 __U, __m256 __A,
    __m256 __B)
{
  return (__m256) __builtin_ia32_unpcklps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpackhi_pd (__m256d __W, __mmask8 __U, __m256d __A,
    __m256d __B)
{
  return (__m256d) __builtin_ia32_unpckhpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpackhi_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_unpckhpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpackhi_pd (__m128d __W, __mmask8 __U, __m128d __A,
        __m128d __B)
{
  return (__m128d) __builtin_ia32_unpckhpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpackhi_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_unpckhpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpackhi_ps (__m256 __W, __mmask8 __U, __m256 __A,
    __m256 __B)
{
  return (__m256) __builtin_ia32_unpckhps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpackhi_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_unpckhps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpackhi_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_unpckhps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpackhi_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_unpckhps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtph_ps (__m128 __W, __mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_vcvtph2ps_mask ((__v8hi) __A,
       (__v4sf) __W,
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtph_ps (__mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_vcvtph2ps_mask ((__v8hi) __A,
       (__v4sf)
       _mm_setzero_ps (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpacklo_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_unpcklps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtph_ps (__m256 __W, __mmask8 __U, __m128i __A)
{
  return (__m256) __builtin_ia32_vcvtph2ps256_mask ((__v8hi) __A,
          (__v8sf) __W,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtph_ps (__mmask8 __U, __m128i __A)
{
  return (__m256) __builtin_ia32_vcvtph2ps256_mask ((__v8hi) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpacklo_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_unpcklps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpacklo_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_unpcklps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sra_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psrad256_mask ((__v8si) __A,
       (__v4si) __B,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sra_epi32 (__mmask8 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psrad256_mask ((__v8si) __A,
       (__v4si) __B,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sra_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psrad128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sra_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrad128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sra_epi64 (__m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psraq256_mask ((__v4di) __A,
       (__v2di) __B,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sra_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psraq256_mask ((__v4di) __A,
       (__v2di) __B,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sra_epi64 (__mmask8 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psraq256_mask ((__v4di) __A,
       (__v2di) __B,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sra_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psraq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_di (),
       (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sra_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psraq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sra_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psraq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_di (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sll_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pslld128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sll_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pslld128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sll_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psllq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sll_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psllq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_di (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sll_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_pslld256_mask ((__v8si) __A,
       (__v4si) __B,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sll_epi32 (__mmask8 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_pslld256_mask ((__v8si) __A,
       (__v4si) __B,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sll_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psllq256_mask ((__v4di) __A,
       (__v2di) __B,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sll_epi64 (__mmask8 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psllq256_mask ((__v4di) __A,
       (__v2di) __B,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutexvar_ps (__m256 __W, __mmask8 __U, __m256i __X,
       __m256 __Y)
{
  return (__m256) __builtin_ia32_permvarsf256_mask ((__v8sf) __Y,
          (__v8si) __X,
          (__v8sf) __W,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutexvar_ps (__mmask8 __U, __m256i __X, __m256 __Y)
{
  return (__m256) __builtin_ia32_permvarsf256_mask ((__v8sf) __Y,
          (__v8si) __X,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutexvar_pd (__m256i __X, __m256d __Y)
{
  return (__m256d) __builtin_ia32_permvardf256_mask ((__v4df) __Y,
           (__v4di) __X,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutexvar_pd (__m256d __W, __mmask8 __U, __m256i __X,
       __m256d __Y)
{
  return (__m256d) __builtin_ia32_permvardf256_mask ((__v4df) __Y,
           (__v4di) __X,
           (__v4df) __W,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutexvar_pd (__mmask8 __U, __m256i __X, __m256d __Y)
{
  return (__m256d) __builtin_ia32_permvardf256_mask ((__v4df) __Y,
           (__v4di) __X,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutevar_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256i __C)
{
  return (__m256d) __builtin_ia32_vpermilvarpd256_mask ((__v4df) __A,
       (__v4di) __C,
       (__v4df) __W,
       (__mmask8)
       __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutevar_pd (__mmask8 __U, __m256d __A, __m256i __C)
{
  return (__m256d) __builtin_ia32_vpermilvarpd256_mask ((__v4df) __A,
       (__v4di) __C,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8)
       __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutevar_ps (__m256 __W, __mmask8 __U, __m256 __A,
      __m256i __C)
{
  return (__m256) __builtin_ia32_vpermilvarps256_mask ((__v8sf) __A,
             (__v8si) __C,
             (__v8sf) __W,
             (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutevar_ps (__mmask8 __U, __m256 __A, __m256i __C)
{
  return (__m256) __builtin_ia32_vpermilvarps256_mask ((__v8sf) __A,
             (__v8si) __C,
             (__v8sf)
             _mm256_setzero_ps (),
             (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutevar_pd (__m128d __W, __mmask8 __U, __m128d __A,
   __m128i __C)
{
  return (__m128d) __builtin_ia32_vpermilvarpd_mask ((__v2df) __A,
           (__v2di) __C,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutevar_pd (__mmask8 __U, __m128d __A, __m128i __C)
{
  return (__m128d) __builtin_ia32_vpermilvarpd_mask ((__v2df) __A,
           (__v2di) __C,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutevar_ps (__m128 __W, __mmask8 __U, __m128 __A,
   __m128i __C)
{
  return (__m128) __builtin_ia32_vpermilvarps_mask ((__v4sf) __A,
          (__v4si) __C,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutevar_ps (__mmask8 __U, __m128 __A, __m128i __C)
{
  return (__m128) __builtin_ia32_vpermilvarps_mask ((__v4sf) __A,
          (__v4si) __C,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mullo_epi32 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmulld256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutexvar_epi64 (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_permvardi256_mask ((__v4di) __Y,
           (__v4di) __X,
           (__v4di)
           _mm256_setzero_si256 (),
           __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mullo_epi32 (__m256i __W, __mmask8 __M, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_pmulld256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mullo_epi32 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmulld128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mullo_epi32 (__m128i __W, __mmask16 __M, __m128i __A,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_pmulld128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mul_epi32 (__m256i __W, __mmask8 __M, __m256i __X,
         __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmuldq256_mask ((__v8si) __X,
        (__v8si) __Y,
        (__v4di) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mul_epi32 (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmuldq256_mask ((__v8si) __X,
        (__v8si) __Y,
        (__v4di)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mul_epi32 (__m128i __W, __mmask8 __M, __m128i __X,
      __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmuldq128_mask ((__v4si) __X,
        (__v4si) __Y,
        (__v2di) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mul_epi32 (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmuldq128_mask ((__v4si) __X,
        (__v4si) __Y,
        (__v2di)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutexvar_epi64 (__m256i __W, __mmask8 __M, __m256i __X,
          __m256i __Y)
{
  return (__m256i) __builtin_ia32_permvardi256_mask ((__v4di) __Y,
           (__v4di) __X,
           (__v4di) __W,
           __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mul_epu32 (__m256i __W, __mmask8 __M, __m256i __X,
         __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmuludq256_mask ((__v8si) __X,
         (__v8si) __Y,
         (__v4di) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutexvar_epi32 (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_permvarsi256_mask ((__v8si) __Y,
           (__v8si) __X,
           (__v8si)
           _mm256_setzero_si256 (),
           __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mul_epu32 (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmuludq256_mask ((__v8si) __X,
         (__v8si) __Y,
         (__v4di)
         _mm256_setzero_si256 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mul_epu32 (__m128i __W, __mmask8 __M, __m128i __X,
      __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmuludq128_mask ((__v4si) __X,
         (__v4si) __Y,
         (__v2di) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mul_epu32 (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmuludq128_mask ((__v4si) __X,
         (__v4si) __Y,
         (__v2di)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutexvar_epi32 (__m256i __W, __mmask8 __M, __m256i __X,
          __m256i __Y)
{
  return (__m256i) __builtin_ia32_permvarsi256_mask ((__v8si) __Y,
           (__v8si) __X,
           (__v8si) __W,
           __M);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512bw")
typedef short __v32hi __attribute__ ((__vector_size__ (64)));
typedef char __v64qi __attribute__ ((__vector_size__ (64)));
typedef unsigned long long __mmask64;
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_setzero_qi (void)
{
  return __extension__ (__m512i)(__v64qi){ 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0 };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_setzero_hi (void)
{
  return __extension__ (__m512i)(__v32hi){ 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0 };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mov_epi16 (__m512i __W, __mmask32 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdquhi512_mask ((__v32hi) __A,
          (__v32hi) __W,
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mov_epi16 (__mmask32 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdquhi512_mask ((__v32hi) __A,
          (__v32hi)
          _mm512_setzero_hi (),
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_loadu_epi16 (__m512i __W, __mmask32 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddquhi512_mask ((__v32hi *) __P,
           (__v32hi) __W,
           (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_loadu_epi16 (__mmask32 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddquhi512_mask ((__v32hi *) __P,
           (__v32hi)
           _mm512_setzero_hi (),
           (__mmask32) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_storeu_epi16 (void *__P, __mmask32 __U, __m512i __A)
{
  __builtin_ia32_storedquhi512_mask ((__v32hi *) __P,
         (__v32hi) __A,
         (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mov_epi8 (__m512i __W, __mmask64 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdquqi512_mask ((__v64qi) __A,
          (__v64qi) __W,
          (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mov_epi8 (__mmask64 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdquqi512_mask ((__v64qi) __A,
          (__v64qi)
          _mm512_setzero_hi (),
          (__mmask64) __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kunpackw (__mmask32 __A, __mmask32 __B)
{
  return (__mmask32) __builtin_ia32_kunpcksi ((__mmask32) __A,
           (__mmask32) __B);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kunpackd (__mmask64 __A, __mmask64 __B)
{
  return (__mmask64) __builtin_ia32_kunpckdi ((__mmask64) __A,
           (__mmask64) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_loadu_epi8 (__m512i __W, __mmask64 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddquqi512_mask ((__v64qi *) __P,
           (__v64qi) __W,
           (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_loadu_epi8 (__mmask64 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddquqi512_mask ((__v64qi *) __P,
           (__v64qi)
           _mm512_setzero_hi (),
           (__mmask64) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_storeu_epi8 (void *__P, __mmask64 __U, __m512i __A)
{
  __builtin_ia32_storedquqi512_mask ((__v64qi *) __P,
         (__v64qi) __A,
         (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sad_epu8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psadbw512 ((__v64qi) __A,
          (__v64qi) __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi16_epi8 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovwb512_mask ((__v32hi) __A,
        (__v32qi) _mm256_undefined_si256(),
        (__mmask32) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi16_epi8 (__m256i __O, __mmask32 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovwb512_mask ((__v32hi) __A,
        (__v32qi) __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi16_epi8 (__mmask32 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovwb512_mask ((__v32hi) __A,
        (__v32qi)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtsepi16_epi8 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovswb512_mask ((__v32hi) __A,
         (__v32qi)_mm256_undefined_si256(),
         (__mmask32) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi16_epi8 (__m256i __O, __mmask32 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovswb512_mask ((__v32hi) __A,
         (__v32qi)__O,
         __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtsepi16_epi8 (__mmask32 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovswb512_mask ((__v32hi) __A,
         (__v32qi)
         _mm256_setzero_si256 (),
         __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtusepi16_epi8 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovuswb512_mask ((__v32hi) __A,
          (__v32qi)_mm256_undefined_si256(),
          (__mmask32) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi16_epi8 (__m256i __O, __mmask32 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovuswb512_mask ((__v32hi) __A,
          (__v32qi) __O,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtusepi16_epi8 (__mmask32 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovuswb512_mask ((__v32hi) __A,
          (__v32qi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastb_epi8 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastb512_mask ((__v16qi) __A,
             (__v64qi)_mm512_undefined_si512(),
             (__mmask64) -
             1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcastb_epi8 (__m512i __O, __mmask64 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastb512_mask ((__v16qi) __A,
             (__v64qi) __O,
             __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcastb_epi8 (__mmask64 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastb512_mask ((__v16qi) __A,
             (__v64qi)
             _mm512_setzero_qi(),
             __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_set1_epi8 (__m512i __O, __mmask64 __M, char __A)
{
  return (__m512i) __builtin_ia32_pbroadcastb512_gpr_mask (__A,
          (__v64qi) __O,
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_set1_epi8 (__mmask64 __M, char __A)
{
  return (__m512i) __builtin_ia32_pbroadcastb512_gpr_mask (__A,
          (__v64qi)
          _mm512_setzero_qi(),
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastw_epi16 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastw512_mask ((__v8hi) __A,
             (__v32hi)_mm512_undefined_si512(),
             (__mmask32)-1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcastw_epi16 (__m512i __O, __mmask32 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastw512_mask ((__v8hi) __A,
             (__v32hi) __O,
             __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcastw_epi16 (__mmask32 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastw512_mask ((__v8hi) __A,
             (__v32hi)
             _mm512_setzero_hi(),
             __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_set1_epi16 (__m512i __O, __mmask32 __M, short __A)
{
  return (__m512i) __builtin_ia32_pbroadcastw512_gpr_mask (__A,
          (__v32hi) __O,
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_set1_epi16 (__mmask32 __M, short __A)
{
  return (__m512i) __builtin_ia32_pbroadcastw512_gpr_mask (__A,
          (__v32hi)
          _mm512_setzero_hi(),
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mulhrs_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhrsw512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v32hi)
          _mm512_setzero_hi (),
          (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mulhrs_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
     __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhrsw512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v32hi) __W,
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mulhrs_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhrsw512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v32hi)
          _mm512_setzero_hi (),
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mulhi_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mulhi_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mulhi_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mulhi_epu16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhuw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi)
         _mm512_setzero_hi (),
         (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mulhi_epu16 (__m512i __W, __mmask32 __U, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhuw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi) __W,
         (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mulhi_epu16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhuw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi)
         _mm512_setzero_hi (),
         (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mullo_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v32hu) __A * (__v32hu) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mullo_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_pmullw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mullo_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmullw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi8_epi16 (__m256i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbw512_mask ((__v32qi) __A,
          (__v32hi)
          _mm512_setzero_hi (),
          (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi8_epi16 (__m512i __W, __mmask32 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbw512_mask ((__v32qi) __A,
          (__v32hi) __W,
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi8_epi16 (__mmask32 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbw512_mask ((__v32qi) __A,
          (__v32hi)
          _mm512_setzero_hi(),
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu8_epi16 (__m256i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbw512_mask ((__v32qi) __A,
          (__v32hi)
          _mm512_setzero_hi (),
          (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu8_epi16 (__m512i __W, __mmask32 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbw512_mask ((__v32qi) __A,
          (__v32hi) __W,
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu8_epi16 (__mmask32 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbw512_mask ((__v32qi) __A,
          (__v32hi)
          _mm512_setzero_hi(),
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutexvar_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_permvarhi512_mask ((__v32hi) __B,
           (__v32hi) __A,
           (__v32hi)
           _mm512_setzero_hi (),
           (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutexvar_epi16 (__mmask32 __M, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_permvarhi512_mask ((__v32hi) __B,
           (__v32hi) __A,
           (__v32hi)
           _mm512_setzero_hi(),
           (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutexvar_epi16 (__m512i __W, __mmask32 __M, __m512i __A,
          __m512i __B)
{
  return (__m512i) __builtin_ia32_permvarhi512_mask ((__v32hi) __B,
           (__v32hi) __A,
           (__v32hi) __W,
           (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutex2var_epi16 (__m512i __A, __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varhi512_mask ((__v32hi) __I
                 ,
       (__v32hi) __A,
       (__v32hi) __B,
       (__mmask32) -
       1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutex2var_epi16 (__m512i __A, __mmask32 __U,
    __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varhi512_mask ((__v32hi) __I
                 ,
       (__v32hi) __A,
       (__v32hi) __B,
       (__mmask32)
       __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask2_permutex2var_epi16 (__m512i __A, __m512i __I,
     __mmask32 __U, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermi2varhi512_mask ((__v32hi) __A,
       (__v32hi) __I
                 ,
       (__v32hi) __B,
       (__mmask32)
       __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutex2var_epi16 (__mmask32 __U, __m512i __A,
     __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varhi512_maskz ((__v32hi) __I
                  ,
        (__v32hi) __A,
        (__v32hi) __B,
        (__mmask32)
        __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_avg_epu8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pavgb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__v64qi)
       _mm512_setzero_qi (),
       (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_avg_epu8 (__m512i __W, __mmask64 __U, __m512i __A,
        __m512i __B)
{
  return (__m512i) __builtin_ia32_pavgb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__v64qi) __W,
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_avg_epu8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pavgb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__v64qi)
       _mm512_setzero_qi(),
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_add_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v64qu) __A + (__v64qu) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_add_epi8 (__m512i __W, __mmask64 __U, __m512i __A,
        __m512i __B)
{
  return (__m512i) __builtin_ia32_paddb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__v64qi) __W,
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_add_epi8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__v64qi)
       _mm512_setzero_qi (),
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sub_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v64qu) __A - (__v64qu) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sub_epi8 (__m512i __W, __mmask64 __U, __m512i __A,
        __m512i __B)
{
  return (__m512i) __builtin_ia32_psubb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__v64qi) __W,
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sub_epi8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__v64qi)
       _mm512_setzero_qi (),
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_avg_epu16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pavgw512_mask ((__v32hi) __A,
       (__v32hi) __B,
       (__v32hi)
       _mm512_setzero_hi (),
       (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_avg_epu16 (__m512i __W, __mmask32 __U, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_pavgw512_mask ((__v32hi) __A,
       (__v32hi) __B,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_avg_epu16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pavgw512_mask ((__v32hi) __A,
       (__v32hi) __B,
       (__v32hi)
       _mm512_setzero_hi(),
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_subs_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_qi (),
        (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_subs_epi8 (__m512i __W, __mmask64 __U, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_psubsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi) __W,
        (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_subs_epi8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_qi (),
        (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_subs_epu8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubusb512_mask ((__v64qi) __A,
         (__v64qi) __B,
         (__v64qi)
         _mm512_setzero_qi (),
         (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_subs_epu8 (__m512i __W, __mmask64 __U, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_psubusb512_mask ((__v64qi) __A,
         (__v64qi) __B,
         (__v64qi) __W,
         (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_subs_epu8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubusb512_mask ((__v64qi) __A,
         (__v64qi) __B,
         (__v64qi)
         _mm512_setzero_qi (),
         (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_adds_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_qi (),
        (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_adds_epi8 (__m512i __W, __mmask64 __U, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_paddsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi) __W,
        (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_adds_epi8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_qi (),
        (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_adds_epu8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddusb512_mask ((__v64qi) __A,
         (__v64qi) __B,
         (__v64qi)
         _mm512_setzero_qi (),
         (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_adds_epu8 (__m512i __W, __mmask64 __U, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_paddusb512_mask ((__v64qi) __A,
         (__v64qi) __B,
         (__v64qi) __W,
         (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_adds_epu8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddusb512_mask ((__v64qi) __A,
         (__v64qi) __B,
         (__v64qi)
         _mm512_setzero_qi (),
         (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sub_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v32hu) __A - (__v32hu) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sub_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_psubw512_mask ((__v32hi) __A,
       (__v32hi) __B,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sub_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubw512_mask ((__v32hi) __A,
       (__v32hi) __B,
       (__v32hi)
       _mm512_setzero_hi (),
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_subs_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_subs_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_psubsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_subs_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_subs_epu16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubusw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi)
         _mm512_setzero_hi (),
         (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_subs_epu16 (__m512i __W, __mmask32 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_psubusw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi) __W,
         (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_subs_epu16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubusw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi)
         _mm512_setzero_hi (),
         (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_add_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v32hu) __A + (__v32hu) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_add_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_paddw512_mask ((__v32hi) __A,
       (__v32hi) __B,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_add_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddw512_mask ((__v32hi) __A,
       (__v32hi) __B,
       (__v32hi)
       _mm512_setzero_hi (),
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_adds_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_adds_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_paddsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_adds_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_adds_epu16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddusw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi)
         _mm512_setzero_hi (),
         (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_adds_epu16 (__m512i __W, __mmask32 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_paddusw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi) __W,
         (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_adds_epu16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddusw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi)
         _mm512_setzero_hi (),
         (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srl_epi16 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrlw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi)
       _mm512_setzero_hi (),
       (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srl_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
         __m128i __B)
{
  return (__m512i) __builtin_ia32_psrlw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srl_epi16 (__mmask32 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrlw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi)
       _mm512_setzero_hi (),
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_packs_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_packsswb512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v64qi)
          _mm512_setzero_qi (),
          (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sll_epi16 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psllw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi)
       _mm512_setzero_hi (),
       (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sll_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
         __m128i __B)
{
  return (__m512i) __builtin_ia32_psllw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sll_epi16 (__mmask32 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psllw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi)
       _mm512_setzero_hi (),
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maddubs_epi16 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmaddubsw512_mask ((__v64qi) __X,
           (__v64qi) __Y,
           (__v32hi)
           _mm512_setzero_hi (),
           (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_maddubs_epi16 (__m512i __W, __mmask32 __U, __m512i __X,
      __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmaddubsw512_mask ((__v64qi) __X,
           (__v64qi) __Y,
           (__v32hi) __W,
           (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_maddubs_epi16 (__mmask32 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmaddubsw512_mask ((__v64qi) __X,
           (__v64qi) __Y,
           (__v32hi)
           _mm512_setzero_hi (),
           (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_madd_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaddwd512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v16si)
         _mm512_setzero_si512 (),
         (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_madd_epi16 (__m512i __W, __mmask16 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaddwd512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v16si) __W,
         (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_madd_epi16 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaddwd512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v16si)
         _mm512_setzero_si512 (),
         (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpackhi_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhbw512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__v64qi)
           _mm512_setzero_qi (),
           (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpackhi_epi8 (__m512i __W, __mmask64 __U, __m512i __A,
      __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhbw512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__v64qi) __W,
           (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpackhi_epi8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhbw512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__v64qi)
           _mm512_setzero_qi(),
           (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpackhi_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhwd512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__v32hi)
           _mm512_setzero_hi (),
           (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpackhi_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
       __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhwd512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__v32hi) __W,
           (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpackhi_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhwd512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__v32hi)
           _mm512_setzero_hi(),
           (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpacklo_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklbw512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__v64qi)
           _mm512_setzero_qi (),
           (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpacklo_epi8 (__m512i __W, __mmask64 __U, __m512i __A,
      __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklbw512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__v64qi) __W,
           (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpacklo_epi8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklbw512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__v64qi)
           _mm512_setzero_qi(),
           (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpacklo_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklwd512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__v32hi)
           _mm512_setzero_hi (),
           (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpacklo_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
       __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklwd512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__v32hi) __W,
           (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpacklo_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklwd512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__v32hi)
           _mm512_setzero_hi(),
           (__mmask32) __U);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epu8_mask (__m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __A,
          (__v64qi) __B, 0,
          (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epi8_mask (__m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_pcmpeqb512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epu8_mask (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __A,
          (__v64qi) __B, 0,
          __U);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epi8_mask (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_pcmpeqb512_mask ((__v64qi) __A,
           (__v64qi) __B,
           __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epu16_mask (__m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __A,
          (__v32hi) __B, 0,
          (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epi16_mask (__m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_pcmpeqw512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epu16_mask (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __A,
          (__v32hi) __B, 0,
          __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epi16_mask (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_pcmpeqw512_mask ((__v32hi) __A,
           (__v32hi) __B,
           __U);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epu8_mask (__m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __A,
          (__v64qi) __B, 6,
          (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epi8_mask (__m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_pcmpgtb512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epu8_mask (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __A,
          (__v64qi) __B, 6,
          __U);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epi8_mask (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_pcmpgtb512_mask ((__v64qi) __A,
           (__v64qi) __B,
           __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epu16_mask (__m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __A,
          (__v32hi) __B, 6,
          (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epi16_mask (__m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_pcmpgtw512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epu16_mask (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __A,
          (__v32hi) __B, 6,
          __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epi16_mask (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_pcmpgtw512_mask ((__v32hi) __A,
           (__v32hi) __B,
           __U);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movepi8_mask (__m512i __A)
{
  return (__mmask64) __builtin_ia32_cvtb2mask512 ((__v64qi) __A);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movepi16_mask (__m512i __A)
{
  return (__mmask32) __builtin_ia32_cvtw2mask512 ((__v32hi) __A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movm_epi8 (__mmask64 __A)
{
  return (__m512i) __builtin_ia32_cvtmask2b512 (__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movm_epi16 (__mmask32 __A)
{
  return (__m512i) __builtin_ia32_cvtmask2w512 (__A);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_test_epi8_mask (__m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ptestmb512 ((__v64qi) __A,
      (__v64qi) __B,
      (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_test_epi8_mask (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ptestmb512 ((__v64qi) __A,
      (__v64qi) __B, __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_test_epi16_mask (__m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ptestmw512 ((__v32hi) __A,
      (__v32hi) __B,
      (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_test_epi16_mask (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ptestmw512 ((__v32hi) __A,
      (__v32hi) __B, __U);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_testn_epi8_mask (__m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ptestnmb512 ((__v64qi) __A,
       (__v64qi) __B,
       (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_testn_epi8_mask (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ptestnmb512 ((__v64qi) __A,
       (__v64qi) __B, __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_testn_epi16_mask (__m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ptestnmw512 ((__v32hi) __A,
       (__v32hi) __B,
       (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_testn_epi16_mask (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ptestnmw512 ((__v32hi) __A,
       (__v32hi) __B, __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_shuffle_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pshufb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_qi (),
        (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_shuffle_epi8 (__m512i __W, __mmask64 __U, __m512i __A,
     __m512i __B)
{
  return (__m512i) __builtin_ia32_pshufb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi) __W,
        (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_shuffle_epi8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pshufb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_qi (),
        (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epu16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminuw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epu16 (__mmask32 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminuw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi(),
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epu16 (__m512i __W, __mmask32 __M, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_pminuw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epi16 (__mmask32 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi(),
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epi16 (__m512i __W, __mmask32 __M, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epu8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxub512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_qi (),
        (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epu8 (__mmask64 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxub512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_qi(),
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epu8 (__m512i __W, __mmask64 __M, __m512i __A,
        __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxub512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi) __W,
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_qi (),
        (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epi8 (__mmask64 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_qi(),
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epi8 (__m512i __W, __mmask64 __M, __m512i __A,
        __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi) __W,
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epu8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminub512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_qi (),
        (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epu8 (__mmask64 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminub512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_qi(),
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epu8 (__m512i __W, __mmask64 __M, __m512i __A,
        __m512i __B)
{
  return (__m512i) __builtin_ia32_pminub512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi) __W,
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_qi (),
        (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epi8 (__mmask64 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_qi(),
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epi8 (__m512i __W, __mmask64 __M, __m512i __A,
        __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi) __W,
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epi16 (__mmask32 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi(),
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epi16 (__m512i __W, __mmask32 __M, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epu16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxuw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epu16 (__mmask32 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxuw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi(),
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epu16 (__m512i __W, __mmask32 __M, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxuw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sra_epi16 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psraw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi)
       _mm512_setzero_hi (),
       (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sra_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
         __m128i __B)
{
  return (__m512i) __builtin_ia32_psraw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sra_epi16 (__mmask32 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psraw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi)
       _mm512_setzero_hi (),
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srav_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psrav32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srav_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_psrav32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srav_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psrav32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srlv_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psrlv32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srlv_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_psrlv32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srlv_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psrlv32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sllv_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psllv32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sllv_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_psllv32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sllv_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psllv32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_hi (),
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_packs_epi16 (__m512i __W, __mmask64 __M, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_packsswb512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v64qi) __W,
          (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_packs_epi16 (__mmask64 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_packsswb512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v64qi)
          _mm512_setzero_qi(),
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_packus_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_packuswb512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v64qi)
          _mm512_setzero_qi (),
          (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_packus_epi16 (__m512i __W, __mmask64 __M, __m512i __A,
     __m512i __B)
{
  return (__m512i) __builtin_ia32_packuswb512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v64qi) __W,
          (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_packus_epi16 (__mmask64 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_packuswb512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v64qi)
          _mm512_setzero_qi(),
          (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_abs_epi8 (__m512i __A)
{
  return (__m512i) __builtin_ia32_pabsb512_mask ((__v64qi) __A,
       (__v64qi)
       _mm512_setzero_qi (),
       (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_abs_epi8 (__m512i __W, __mmask64 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsb512_mask ((__v64qi) __A,
       (__v64qi) __W,
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_abs_epi8 (__mmask64 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsb512_mask ((__v64qi) __A,
       (__v64qi)
       _mm512_setzero_qi (),
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_abs_epi16 (__m512i __A)
{
  return (__m512i) __builtin_ia32_pabsw512_mask ((__v32hi) __A,
       (__v32hi)
       _mm512_setzero_hi (),
       (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_abs_epi16 (__m512i __W, __mmask32 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsw512_mask ((__v32hi) __A,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_abs_epi16 (__mmask32 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsw512_mask ((__v32hi) __A,
       (__v32hi)
       _mm512_setzero_hi (),
       (__mmask32) __U);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epu8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 4,
         (__mmask64) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epu8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 1,
         (__mmask64) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epu8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 5,
         (__mmask64) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epu8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 2,
         (__mmask64) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epu16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 4,
         (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epu16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 1,
         (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epu16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 5,
         (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epu16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 2,
         (__mmask32) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epi8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 4,
        (__mmask64) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epi8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 1,
        (__mmask64) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epi8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 5,
        (__mmask64) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epi8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 2,
        (__mmask64) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epi16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 4,
        (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epi16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 1,
        (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epi16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 5,
        (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epi16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 2,
        (__mmask32) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epu8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 4,
         (__mmask64) - 1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epu8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 1,
         (__mmask64) - 1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epu8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 5,
         (__mmask64) - 1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epu8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 2,
         (__mmask64) - 1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epu16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 4,
         (__mmask32) - 1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epu16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 1,
         (__mmask32) - 1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epu16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 5,
         (__mmask32) - 1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epu16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 2,
         (__mmask32) - 1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epi8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 4,
        (__mmask64) - 1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epi8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 1,
        (__mmask64) - 1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epi8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 5,
        (__mmask64) - 1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epi8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 2,
        (__mmask64) - 1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epi16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 4,
        (__mmask32) - 1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epi16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 1,
        (__mmask32) - 1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epi16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 5,
        (__mmask32) - 1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epi16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 2,
        (__mmask32) - 1);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512dq")
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_f64x2 (__m128d __A)
{
  return (__m512d) __builtin_ia32_broadcastf64x2_512_mask ((__v2df)
          __A,
          _mm512_undefined_pd(),
          (__mmask8) -
          1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_f64x2 (__m512d __O, __mmask8 __M, __m128d __A)
{
  return (__m512d) __builtin_ia32_broadcastf64x2_512_mask ((__v2df)
          __A,
          (__v8df)
          __O, __M);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_f64x2 (__mmask8 __M, __m128d __A)
{
  return (__m512d) __builtin_ia32_broadcastf64x2_512_mask ((__v2df)
          __A,
          (__v8df)
          _mm512_setzero_ps (),
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_i64x2 (__m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti64x2_512_mask ((__v2di)
          __A,
          _mm512_undefined_si512(),
          (__mmask8) -
          1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_i64x2 (__m512i __O, __mmask8 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti64x2_512_mask ((__v2di)
          __A,
          (__v8di)
          __O, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_i64x2 (__mmask8 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti64x2_512_mask ((__v2di)
          __A,
          (__v8di)
          _mm512_setzero_si512 (),
          __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_f32x2 (__m128 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x2_512_mask ((__v4sf) __A,
         (__v16sf)_mm512_undefined_ps(),
         (__mmask16) -
         1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_f32x2 (__m512 __O, __mmask16 __M, __m128 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x2_512_mask ((__v4sf) __A,
         (__v16sf)
         __O, __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_f32x2 (__mmask16 __M, __m128 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x2_512_mask ((__v4sf) __A,
         (__v16sf)
         _mm512_setzero_ps (),
         __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_i32x2 (__m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x2_512_mask ((__v4si)
          __A,
          (__v16si)_mm512_undefined_si512(),
          (__mmask16)
          -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_i32x2 (__m512i __O, __mmask16 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x2_512_mask ((__v4si)
          __A,
          (__v16si)
          __O, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_i32x2 (__mmask16 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x2_512_mask ((__v4si)
          __A,
          (__v16si)
          _mm512_setzero_si512 (),
          __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_f32x8 (__m256 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x8_512_mask ((__v8sf) __A,
         _mm512_undefined_ps(),
         (__mmask16) -
         1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_f32x8 (__m512 __O, __mmask16 __M, __m256 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x8_512_mask ((__v8sf) __A,
         (__v16sf)__O,
         __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_f32x8 (__mmask16 __M, __m256 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x8_512_mask ((__v8sf) __A,
         (__v16sf)
         _mm512_setzero_ps (),
         __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_i32x8 (__m256i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x8_512_mask ((__v8si)
          __A,
          (__v16si)_mm512_undefined_si512(),
          (__mmask16)
          -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_i32x8 (__m512i __O, __mmask16 __M, __m256i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x8_512_mask ((__v8si)
          __A,
          (__v16si)__O,
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_i32x8 (__mmask16 __M, __m256i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x8_512_mask ((__v8si)
          __A,
          (__v16si)
          _mm512_setzero_si512 (),
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mullo_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v8du) __A * (__v8du) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mullo_epi64 (__m512i __W, __mmask8 __U, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_pmullq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W,
        (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mullo_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmullq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_si512 (),
        (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_xor_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_xorpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_xor_pd (__m512d __W, __mmask8 __U, __m512d __A,
      __m512d __B)
{
  return (__m512d) __builtin_ia32_xorpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __W,
       (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_xor_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_xorpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_xor_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_xorps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_xor_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_xorps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_xor_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_xorps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_or_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_orpd512_mask ((__v8df) __A,
      (__v8df) __B,
      (__v8df)
      _mm512_setzero_pd (),
      (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_or_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_orpd512_mask ((__v8df) __A,
      (__v8df) __B,
      (__v8df) __W,
      (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_or_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_orpd512_mask ((__v8df) __A,
      (__v8df) __B,
      (__v8df)
      _mm512_setzero_pd (),
      (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_or_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_orps512_mask ((__v16sf) __A,
            (__v16sf) __B,
            (__v16sf)
            _mm512_setzero_ps (),
            (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_or_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_orps512_mask ((__v16sf) __A,
            (__v16sf) __B,
            (__v16sf) __W,
            (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_or_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_orps512_mask ((__v16sf) __A,
            (__v16sf) __B,
            (__v16sf)
            _mm512_setzero_ps (),
            (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_and_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_andpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_and_pd (__m512d __W, __mmask8 __U, __m512d __A,
      __m512d __B)
{
  return (__m512d) __builtin_ia32_andpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __W,
       (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_and_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_andpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_and_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_andps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_and_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_andps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_and_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_andps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_andnot_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_andnpd512_mask ((__v8df) __A,
        (__v8df) __B,
        (__v8df)
        _mm512_setzero_pd (),
        (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_andnot_pd (__m512d __W, __mmask8 __U, __m512d __A,
         __m512d __B)
{
  return (__m512d) __builtin_ia32_andnpd512_mask ((__v8df) __A,
        (__v8df) __B,
        (__v8df) __W,
        (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_andnot_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_andnpd512_mask ((__v8df) __A,
        (__v8df) __B,
        (__v8df)
        _mm512_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_andnot_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_andnps512_mask ((__v16sf) __A,
       (__v16sf) __B,
       (__v16sf)
       _mm512_setzero_ps (),
       (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_andnot_ps (__m512 __W, __mmask16 __U, __m512 __A,
         __m512 __B)
{
  return (__m512) __builtin_ia32_andnps512_mask ((__v16sf) __A,
       (__v16sf) __B,
       (__v16sf) __W,
       (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_andnot_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_andnps512_mask ((__v16sf) __A,
       (__v16sf) __B,
       (__v16sf)
       _mm512_setzero_ps (),
       (__mmask16) __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movepi32_mask (__m512i __A)
{
  return (__mmask16) __builtin_ia32_cvtd2mask512 ((__v16si) __A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movepi64_mask (__m512i __A)
{
  return (__mmask8) __builtin_ia32_cvtq2mask512 ((__v8di) __A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movm_epi32 (__mmask16 __A)
{
  return (__m512i) __builtin_ia32_cvtmask2d512 (__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movm_epi64 (__mmask8 __A)
{
  return (__m512i) __builtin_ia32_cvtmask2q512 (__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttpd_epi64 (__m512d __A)
{
  return (__m512i) __builtin_ia32_cvttpd2qq512_mask ((__v8df) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) -1,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttpd_epi64 (__m512i __W, __mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvttpd2qq512_mask ((__v8df) __A,
           (__v8di) __W,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttpd_epi64 (__mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvttpd2qq512_mask ((__v8df) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttpd_epu64 (__m512d __A)
{
  return (__m512i) __builtin_ia32_cvttpd2uqq512_mask ((__v8df) __A,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) -1,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttpd_epu64 (__m512i __W, __mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvttpd2uqq512_mask ((__v8df) __A,
            (__v8di) __W,
            (__mmask8) __U,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttpd_epu64 (__mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvttpd2uqq512_mask ((__v8df) __A,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) __U,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttps_epi64 (__m256 __A)
{
  return (__m512i) __builtin_ia32_cvttps2qq512_mask ((__v8sf) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) -1,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttps_epi64 (__m512i __W, __mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvttps2qq512_mask ((__v8sf) __A,
           (__v8di) __W,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttps_epi64 (__mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvttps2qq512_mask ((__v8sf) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttps_epu64 (__m256 __A)
{
  return (__m512i) __builtin_ia32_cvttps2uqq512_mask ((__v8sf) __A,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) -1,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttps_epu64 (__m512i __W, __mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvttps2uqq512_mask ((__v8sf) __A,
            (__v8di) __W,
            (__mmask8) __U,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttps_epu64 (__mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvttps2uqq512_mask ((__v8sf) __A,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) __U,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtpd_epi64 (__m512d __A)
{
  return (__m512i) __builtin_ia32_cvtpd2qq512_mask ((__v8df) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtpd_epi64 (__m512i __W, __mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvtpd2qq512_mask ((__v8df) __A,
          (__v8di) __W,
          (__mmask8) __U,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtpd_epi64 (__mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvtpd2qq512_mask ((__v8df) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtpd_epu64 (__m512d __A)
{
  return (__m512i) __builtin_ia32_cvtpd2uqq512_mask ((__v8df) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) -1,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtpd_epu64 (__m512i __W, __mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvtpd2uqq512_mask ((__v8df) __A,
           (__v8di) __W,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtpd_epu64 (__mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvtpd2uqq512_mask ((__v8df) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtps_epi64 (__m256 __A)
{
  return (__m512i) __builtin_ia32_cvtps2qq512_mask ((__v8sf) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtps_epi64 (__m512i __W, __mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvtps2qq512_mask ((__v8sf) __A,
          (__v8di) __W,
          (__mmask8) __U,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtps_epi64 (__mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvtps2qq512_mask ((__v8sf) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtps_epu64 (__m256 __A)
{
  return (__m512i) __builtin_ia32_cvtps2uqq512_mask ((__v8sf) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) -1,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtps_epu64 (__m512i __W, __mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvtps2uqq512_mask ((__v8sf) __A,
           (__v8di) __W,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtps_epu64 (__mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvtps2uqq512_mask ((__v8sf) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) __U,
           0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi64_ps (__m512i __A)
{
  return (__m256) __builtin_ia32_cvtqq2ps512_mask ((__v8di) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) -1,
         0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_ps (__m256 __W, __mmask8 __U, __m512i __A)
{
  return (__m256) __builtin_ia32_cvtqq2ps512_mask ((__v8di) __A,
         (__v8sf) __W,
         (__mmask8) __U,
         0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi64_ps (__mmask8 __U, __m512i __A)
{
  return (__m256) __builtin_ia32_cvtqq2ps512_mask ((__v8di) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U,
         0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu64_ps (__m512i __A)
{
  return (__m256) __builtin_ia32_cvtuqq2ps512_mask ((__v8di) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu64_ps (__m256 __W, __mmask8 __U, __m512i __A)
{
  return (__m256) __builtin_ia32_cvtuqq2ps512_mask ((__v8di) __A,
          (__v8sf) __W,
          (__mmask8) __U,
          0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu64_ps (__mmask8 __U, __m512i __A)
{
  return (__m256) __builtin_ia32_cvtuqq2ps512_mask ((__v8di) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi64_pd (__m512i __A)
{
  return (__m512d) __builtin_ia32_cvtqq2pd512_mask ((__v8di) __A,
          (__v8df)
          _mm512_setzero_pd (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_pd (__m512d __W, __mmask8 __U, __m512i __A)
{
  return (__m512d) __builtin_ia32_cvtqq2pd512_mask ((__v8di) __A,
          (__v8df) __W,
          (__mmask8) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi64_pd (__mmask8 __U, __m512i __A)
{
  return (__m512d) __builtin_ia32_cvtqq2pd512_mask ((__v8di) __A,
          (__v8df)
          _mm512_setzero_pd (),
          (__mmask8) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu64_pd (__m512i __A)
{
  return (__m512d) __builtin_ia32_cvtuqq2pd512_mask ((__v8di) __A,
           (__v8df)
           _mm512_setzero_pd (),
           (__mmask8) -1,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu64_pd (__m512d __W, __mmask8 __U, __m512i __A)
{
  return (__m512d) __builtin_ia32_cvtuqq2pd512_mask ((__v8di) __A,
           (__v8df) __W,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu64_pd (__mmask8 __U, __m512i __A)
{
  return (__m512d) __builtin_ia32_cvtuqq2pd512_mask ((__v8di) __A,
           (__v8df)
           _mm512_setzero_pd (),
           (__mmask8) __U,
           0x04);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vl,avx512bw")
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mov_epi8 (__m256i __W, __mmask32 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdquqi256_mask ((__v32qi) __A,
          (__v32qi) __W,
          (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mov_epi8 (__mmask32 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdquqi256_mask ((__v32qi) __A,
          (__v32qi)
          _mm256_setzero_si256 (),
          (__mmask32) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mov_epi8 (__m128i __W, __mmask16 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdquqi128_mask ((__v16qi) __A,
          (__v16qi) __W,
          (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mov_epi8 (__mmask16 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdquqi128_mask ((__v16qi) __A,
          (__v16qi)
          _mm_setzero_hi (),
          (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_storeu_epi8 (void *__P, __mmask32 __U, __m256i __A)
{
  __builtin_ia32_storedquqi256_mask ((__v32qi *) __P,
         (__v32qi) __A,
         (__mmask32) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_storeu_epi8 (void *__P, __mmask16 __U, __m128i __A)
{
  __builtin_ia32_storedquqi128_mask ((__v16qi *) __P,
         (__v16qi) __A,
         (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_loadu_epi16 (__m256i __W, __mmask16 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddquhi256_mask ((__v16hi *) __P,
           (__v16hi) __W,
           (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_loadu_epi16 (__mmask16 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddquhi256_mask ((__v16hi *) __P,
           (__v16hi)
           _mm256_setzero_si256 (),
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_loadu_epi16 (__m128i __W, __mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddquhi128_mask ((__v8hi *) __P,
           (__v8hi) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_loadu_epi16 (__mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddquhi128_mask ((__v8hi *) __P,
           (__v8hi)
           _mm_setzero_hi (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mov_epi16 (__m256i __W, __mmask16 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdquhi256_mask ((__v16hi) __A,
          (__v16hi) __W,
          (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mov_epi16 (__mmask16 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdquhi256_mask ((__v16hi) __A,
          (__v16hi)
          _mm256_setzero_si256 (),
          (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mov_epi16 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdquhi128_mask ((__v8hi) __A,
          (__v8hi) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mov_epi16 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdquhi128_mask ((__v8hi) __A,
          (__v8hi)
          _mm_setzero_hi (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_loadu_epi8 (__m256i __W, __mmask32 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddquqi256_mask ((__v32qi *) __P,
           (__v32qi) __W,
           (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_loadu_epi8 (__mmask32 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddquqi256_mask ((__v32qi *) __P,
           (__v32qi)
           _mm256_setzero_si256 (),
           (__mmask32) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_loadu_epi8 (__m128i __W, __mmask16 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddquqi128_mask ((__v16qi *) __P,
           (__v16qi) __W,
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_loadu_epi8 (__mmask16 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddquqi128_mask ((__v16qi *) __P,
           (__v16qi)
           _mm_setzero_hi (),
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi16_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovwb256_mask ((__v16hi) __A,
        (__v16qi)_mm_undefined_si128(),
        (__mmask16) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi16_epi8 (__m128i __O, __mmask16 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovwb256_mask ((__v16hi) __A,
        (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi16_epi8 (__mmask16 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovwb256_mask ((__v16hi) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsepi16_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovswb128_mask ((__v8hi) __A,
         (__v16qi)_mm_undefined_si128(),
         (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi16_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovswb128_mask ((__v8hi) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtsepi16_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovswb128_mask ((__v8hi) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtsepi16_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovswb256_mask ((__v16hi) __A,
         (__v16qi)_mm_undefined_si128(),
         (__mmask16) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi16_epi8 (__m128i __O, __mmask16 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovswb256_mask ((__v16hi) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtsepi16_epi8 (__mmask16 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovswb256_mask ((__v16hi) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtusepi16_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovuswb128_mask ((__v8hi) __A,
          (__v16qi)_mm_undefined_si128(),
          (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi16_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovuswb128_mask ((__v8hi) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtusepi16_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovuswb128_mask ((__v8hi) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtusepi16_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovuswb256_mask ((__v16hi) __A,
          (__v16qi)_mm_undefined_si128(),
          (__mmask16) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi16_epi8 (__m128i __O, __mmask16 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovuswb256_mask ((__v16hi) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtusepi16_epi8 (__mmask16 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovuswb256_mask ((__v16hi) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcastb_epi8 (__m256i __O, __mmask32 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastb256_mask ((__v16qi) __A,
             (__v32qi) __O,
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcastb_epi8 (__mmask32 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastb256_mask ((__v16qi) __A,
             (__v32qi)
             _mm256_setzero_si256 (),
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_set1_epi8 (__m256i __O, __mmask32 __M, char __A)
{
  return (__m256i) __builtin_ia32_pbroadcastb256_gpr_mask (__A,
          (__v32qi) __O,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_set1_epi8 (__mmask32 __M, char __A)
{
  return (__m256i) __builtin_ia32_pbroadcastb256_gpr_mask (__A,
          (__v32qi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_broadcastb_epi8 (__m128i __O, __mmask16 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastb128_mask ((__v16qi) __A,
             (__v16qi) __O,
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_broadcastb_epi8 (__mmask16 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastb128_mask ((__v16qi) __A,
             (__v16qi)
             _mm_setzero_si128 (),
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_set1_epi8 (__m128i __O, __mmask16 __M, char __A)
{
  return (__m128i) __builtin_ia32_pbroadcastb128_gpr_mask (__A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_set1_epi8 (__mmask16 __M, char __A)
{
  return (__m128i) __builtin_ia32_pbroadcastb128_gpr_mask (__A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcastw_epi16 (__m256i __O, __mmask16 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastw256_mask ((__v8hi) __A,
             (__v16hi) __O,
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcastw_epi16 (__mmask16 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastw256_mask ((__v8hi) __A,
             (__v16hi)
             _mm256_setzero_si256 (),
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_set1_epi16 (__m256i __O, __mmask16 __M, short __A)
{
  return (__m256i) __builtin_ia32_pbroadcastw256_gpr_mask (__A,
          (__v16hi) __O,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_set1_epi16 (__mmask16 __M, short __A)
{
  return (__m256i) __builtin_ia32_pbroadcastw256_gpr_mask (__A,
          (__v16hi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_broadcastw_epi16 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastw128_mask ((__v8hi) __A,
             (__v8hi) __O,
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_broadcastw_epi16 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastw128_mask ((__v8hi) __A,
             (__v8hi)
             _mm_setzero_si128 (),
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_set1_epi16 (__m128i __O, __mmask8 __M, short __A)
{
  return (__m128i) __builtin_ia32_pbroadcastw128_gpr_mask (__A,
          (__v8hi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_set1_epi16 (__mmask8 __M, short __A)
{
  return (__m128i) __builtin_ia32_pbroadcastw128_gpr_mask (__A,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutexvar_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_permvarhi256_mask ((__v16hi) __B,
           (__v16hi) __A,
           (__v16hi)
           _mm256_setzero_si256 (),
           (__mmask16) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutexvar_epi16 (__mmask16 __M, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_permvarhi256_mask ((__v16hi) __B,
           (__v16hi) __A,
           (__v16hi)
           _mm256_setzero_si256 (),
           (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutexvar_epi16 (__m256i __W, __mmask16 __M, __m256i __A,
          __m256i __B)
{
  return (__m256i) __builtin_ia32_permvarhi256_mask ((__v16hi) __B,
           (__v16hi) __A,
           (__v16hi) __W,
           (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutexvar_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_permvarhi128_mask ((__v8hi) __B,
           (__v8hi) __A,
           (__v8hi)
           _mm_setzero_hi (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutexvar_epi16 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_permvarhi128_mask ((__v8hi) __B,
           (__v8hi) __A,
           (__v8hi)
           _mm_setzero_si128 (),
           (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutexvar_epi16 (__m128i __W, __mmask8 __M, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_permvarhi128_mask ((__v8hi) __B,
           (__v8hi) __A,
           (__v8hi) __W,
           (__mmask8) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutex2var_epi16 (__m256i __A, __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varhi256_mask ((__v16hi) __I
                 ,
       (__v16hi) __A,
       (__v16hi) __B,
       (__mmask16) -
       1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutex2var_epi16 (__m256i __A, __mmask16 __U,
    __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varhi256_mask ((__v16hi) __I
                 ,
       (__v16hi) __A,
       (__v16hi) __B,
       (__mmask16)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask2_permutex2var_epi16 (__m256i __A, __m256i __I,
     __mmask16 __U, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermi2varhi256_mask ((__v16hi) __A,
       (__v16hi) __I
                 ,
       (__v16hi) __B,
       (__mmask16)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutex2var_epi16 (__mmask16 __U, __m256i __A,
     __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varhi256_maskz ((__v16hi) __I
                  ,
        (__v16hi) __A,
        (__v16hi) __B,
        (__mmask16)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutex2var_epi16 (__m128i __A, __m128i __I, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varhi128_mask ((__v8hi) __I
                 ,
       (__v8hi) __A,
       (__v8hi) __B,
       (__mmask8) -
       1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutex2var_epi16 (__m128i __A, __mmask8 __U, __m128i __I,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varhi128_mask ((__v8hi) __I
                 ,
       (__v8hi) __A,
       (__v8hi) __B,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask2_permutex2var_epi16 (__m128i __A, __m128i __I, __mmask8 __U,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermi2varhi128_mask ((__v8hi) __A,
       (__v8hi) __I
                 ,
       (__v8hi) __B,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutex2var_epi16 (__mmask8 __U, __m128i __A, __m128i __I,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varhi128_maskz ((__v8hi) __I
                  ,
        (__v8hi) __A,
        (__v8hi) __B,
        (__mmask8)
        __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_maddubs_epi16 (__m256i __W, __mmask16 __U, __m256i __X,
      __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmaddubsw256_mask ((__v32qi) __X,
           (__v32qi) __Y,
           (__v16hi) __W,
           (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_maddubs_epi16 (__mmask16 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmaddubsw256_mask ((__v32qi) __X,
           (__v32qi) __Y,
           (__v16hi)
           _mm256_setzero_si256 (),
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_maddubs_epi16 (__m128i __W, __mmask8 __U, __m128i __X,
   __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmaddubsw128_mask ((__v16qi) __X,
           (__v16qi) __Y,
           (__v8hi) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_maddubs_epi16 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmaddubsw128_mask ((__v16qi) __X,
           (__v16qi) __Y,
           (__v8hi)
           _mm_setzero_hi (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_madd_epi16 (__m256i __W, __mmask8 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaddwd256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v8si) __W,
         (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_madd_epi16 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaddwd256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v8si)
         _mm256_setzero_si256 (),
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_madd_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaddwd128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v4si) __W,
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_madd_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaddwd128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v4si)
         _mm_setzero_si128 (),
         (__mmask8) __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movepi8_mask (__m128i __A)
{
  return (__mmask16) __builtin_ia32_cvtb2mask128 ((__v16qi) __A);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movepi8_mask (__m256i __A)
{
  return (__mmask32) __builtin_ia32_cvtb2mask256 ((__v32qi) __A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movepi16_mask (__m128i __A)
{
  return (__mmask8) __builtin_ia32_cvtw2mask128 ((__v8hi) __A);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movepi16_mask (__m256i __A)
{
  return (__mmask16) __builtin_ia32_cvtw2mask256 ((__v16hi) __A);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movm_epi8 (__mmask16 __A)
{
  return (__m128i) __builtin_ia32_cvtmask2b128 (__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movm_epi8 (__mmask32 __A)
{
  return (__m256i) __builtin_ia32_cvtmask2b256 (__A);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movm_epi16 (__mmask8 __A)
{
  return (__m128i) __builtin_ia32_cvtmask2w128 (__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movm_epi16 (__mmask16 __A)
{
  return (__m256i) __builtin_ia32_cvtmask2w256 (__A);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_test_epi8_mask (__m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ptestmb128 ((__v16qi) __A,
      (__v16qi) __B,
      (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_test_epi8_mask (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ptestmb128 ((__v16qi) __A,
      (__v16qi) __B, __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_test_epi8_mask (__m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ptestmb256 ((__v32qi) __A,
      (__v32qi) __B,
      (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_test_epi8_mask (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ptestmb256 ((__v32qi) __A,
      (__v32qi) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_test_epi16_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestmw128 ((__v8hi) __A,
            (__v8hi) __B,
            (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_test_epi16_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestmw128 ((__v8hi) __A,
            (__v8hi) __B, __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_test_epi16_mask (__m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ptestmw256 ((__v16hi) __A,
      (__v16hi) __B,
      (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_test_epi16_mask (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ptestmw256 ((__v16hi) __A,
      (__v16hi) __B, __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epu16 (__mmask16 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminuw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epu16 (__m256i __W, __mmask16 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pminuw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epu16 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminuw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_di (),
        (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epu16 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pminuw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epi16 (__mmask16 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epi16 (__m256i __W, __mmask16 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epu8 (__mmask32 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxub256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi)
        _mm256_setzero_si256 (),
        (__mmask32) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epu8 (__m256i __W, __mmask32 __M, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxub256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi) __W,
        (__mmask32) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epu8 (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxub128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi)
        _mm_setzero_di (),
        (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epu8 (__m128i __W, __mmask16 __M, __m128i __A,
     __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxub128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi) __W,
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epi8 (__mmask32 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi)
        _mm256_setzero_si256 (),
        (__mmask32) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epi8 (__m256i __W, __mmask32 __M, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi) __W,
        (__mmask32) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epi8 (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi)
        _mm_setzero_di (),
        (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epi8 (__m128i __W, __mmask16 __M, __m128i __A,
     __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi) __W,
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epu8 (__mmask32 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminub256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi)
        _mm256_setzero_si256 (),
        (__mmask32) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epu8 (__m256i __W, __mmask32 __M, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_pminub256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi) __W,
        (__mmask32) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epu8 (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminub128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi)
        _mm_setzero_di (),
        (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epu8 (__m128i __W, __mmask16 __M, __m128i __A,
     __m128i __B)
{
  return (__m128i) __builtin_ia32_pminub128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi) __W,
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epi8 (__mmask32 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi)
        _mm256_setzero_si256 (),
        (__mmask32) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epi8 (__m256i __W, __mmask32 __M, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi) __W,
        (__mmask32) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epi8 (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi)
        _mm_setzero_di (),
        (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epi8 (__m128i __W, __mmask16 __M, __m128i __A,
     __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi) __W,
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epi16 (__mmask16 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epi16 (__m256i __W, __mmask16 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epi16 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_di (),
        (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epi16 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epu16 (__mmask16 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxuw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epu16 (__m256i __W, __mmask16 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxuw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epu16 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxuw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_di (),
        (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epu16 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxuw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epi16 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_di (),
        (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epi16 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __M);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpneq_epi8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 4,
        (__mmask32) - 1);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmplt_epi8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 1,
        (__mmask32) - 1);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpge_epi8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 5,
        (__mmask32) - 1);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmple_epi8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 2,
        (__mmask32) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpneq_epi16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 4,
        (__mmask16) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmplt_epi16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 1,
        (__mmask16) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpge_epi16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 5,
        (__mmask16) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmple_epi16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 2,
        (__mmask16) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_epu8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 4,
         (__mmask16) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epu8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 1,
         (__mmask16) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_epu8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 5,
         (__mmask16) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_epu8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 2,
         (__mmask16) - 1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_epu16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 4,
        (__mmask8) - 1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epu16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 1,
        (__mmask8) - 1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_epu16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 5,
        (__mmask8) - 1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_epu16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 2,
        (__mmask8) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_epi8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 4,
        (__mmask16) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epi8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 1,
        (__mmask16) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_epi8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 5,
        (__mmask16) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_epi8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 2,
        (__mmask16) - 1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_epi16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 4,
       (__mmask8) - 1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epi16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 1,
       (__mmask8) - 1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_epi16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 5,
       (__mmask8) - 1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_epi16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 2,
       (__mmask8) - 1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mulhrs_epi16 (__m256i __W, __mmask16 __U, __m256i __X,
     __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmulhrsw256_mask ((__v16hi) __X,
          (__v16hi) __Y,
          (__v16hi) __W,
          (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mulhrs_epi16 (__mmask16 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmulhrsw256_mask ((__v16hi) __X,
          (__v16hi) __Y,
          (__v16hi)
          _mm256_setzero_si256 (),
          (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mulhi_epu16 (__m256i __W, __mmask16 __U, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_pmulhuw256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v16hi) __W,
         (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mulhi_epu16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmulhuw256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v16hi)
         _mm256_setzero_si256 (),
         (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mulhi_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_pmulhw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mulhi_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmulhw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mulhi_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_pmulhw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mulhi_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmulhw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_hi (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mulhi_epu16 (__m128i __W, __mmask8 __U, __m128i __A,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_pmulhuw128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v8hi) __W,
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mulhi_epu16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmulhuw128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v8hi)
         _mm_setzero_hi (),
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mulhrs_epi16 (__m128i __W, __mmask8 __U, __m128i __X,
         __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmulhrsw128_mask ((__v8hi) __X,
          (__v8hi) __Y,
          (__v8hi) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mulhrs_epi16 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmulhrsw128_mask ((__v8hi) __X,
          (__v8hi) __Y,
          (__v8hi)
          _mm_setzero_hi (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mullo_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_pmullw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mullo_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmullw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mullo_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_pmullw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mullo_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmullw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_hi (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi8_epi16 (__m256i __W, __mmask32 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxbw256_mask ((__v16qi) __A,
          (__v16hi) __W,
          (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi8_epi16 (__mmask16 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxbw256_mask ((__v16qi) __A,
          (__v16hi)
          _mm256_setzero_si256 (),
          (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi8_epi16 (__m128i __W, __mmask32 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxbw128_mask ((__v16qi) __A,
          (__v8hi) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi8_epi16 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxbw128_mask ((__v16qi) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu8_epi16 (__m256i __W, __mmask32 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxbw256_mask ((__v16qi) __A,
          (__v16hi) __W,
          (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu8_epi16 (__mmask16 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxbw256_mask ((__v16qi) __A,
          (__v16hi)
          _mm256_setzero_si256 (),
          (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu8_epi16 (__m128i __W, __mmask32 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxbw128_mask ((__v16qi) __A,
          (__v8hi) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu8_epi16 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxbw128_mask ((__v16qi) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_avg_epu8 (__m256i __W, __mmask32 __U, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_pavgb256_mask ((__v32qi) __A,
       (__v32qi) __B,
       (__v32qi) __W,
       (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_avg_epu8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pavgb256_mask ((__v32qi) __A,
       (__v32qi) __B,
       (__v32qi)
       _mm256_setzero_si256 (),
       (__mmask32) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_avg_epu8 (__m128i __W, __mmask16 __U, __m128i __A,
     __m128i __B)
{
  return (__m128i) __builtin_ia32_pavgb128_mask ((__v16qi) __A,
       (__v16qi) __B,
       (__v16qi) __W,
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_avg_epu8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pavgb128_mask ((__v16qi) __A,
       (__v16qi) __B,
       (__v16qi)
       _mm_setzero_si128 (),
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_avg_epu16 (__m256i __W, __mmask16 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pavgw256_mask ((__v16hi) __A,
       (__v16hi) __B,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_avg_epu16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pavgw256_mask ((__v16hi) __A,
       (__v16hi) __B,
       (__v16hi)
       _mm256_setzero_si256 (),
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_avg_epu16 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pavgw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_avg_epu16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pavgw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_add_epi8 (__m256i __W, __mmask32 __U, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_paddb256_mask ((__v32qi) __A,
       (__v32qi) __B,
       (__v32qi) __W,
       (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_add_epi8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddb256_mask ((__v32qi) __A,
       (__v32qi) __B,
       (__v32qi)
       _mm256_setzero_si256 (),
       (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_add_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_paddw256_mask ((__v16hi) __A,
       (__v16hi) __B,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_add_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddw256_mask ((__v16hi) __A,
       (__v16hi) __B,
       (__v16hi)
       _mm256_setzero_si256 (),
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_adds_epi8 (__m256i __W, __mmask32 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_paddsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi) __W,
        (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_adds_epi8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi)
        _mm256_setzero_si256 (),
        (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_adds_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_paddsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_adds_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_adds_epu8 (__m256i __W, __mmask32 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_paddusb256_mask ((__v32qi) __A,
         (__v32qi) __B,
         (__v32qi) __W,
         (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_adds_epu8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddusb256_mask ((__v32qi) __A,
         (__v32qi) __B,
         (__v32qi)
         _mm256_setzero_si256 (),
         (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_adds_epu16 (__m256i __W, __mmask16 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_paddusw256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v16hi) __W,
         (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_adds_epu16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddusw256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v16hi)
         _mm256_setzero_si256 (),
         (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sub_epi8 (__m256i __W, __mmask32 __U, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_psubb256_mask ((__v32qi) __A,
       (__v32qi) __B,
       (__v32qi) __W,
       (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sub_epi8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubb256_mask ((__v32qi) __A,
       (__v32qi) __B,
       (__v32qi)
       _mm256_setzero_si256 (),
       (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sub_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_psubw256_mask ((__v16hi) __A,
       (__v16hi) __B,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sub_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubw256_mask ((__v16hi) __A,
       (__v16hi) __B,
       (__v16hi)
       _mm256_setzero_si256 (),
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_subs_epi8 (__m256i __W, __mmask32 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_psubsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi) __W,
        (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_subs_epi8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi)
        _mm256_setzero_si256 (),
        (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_subs_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_psubsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_subs_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_subs_epu8 (__m256i __W, __mmask32 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_psubusb256_mask ((__v32qi) __A,
         (__v32qi) __B,
         (__v32qi) __W,
         (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_subs_epu8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubusb256_mask ((__v32qi) __A,
         (__v32qi) __B,
         (__v32qi)
         _mm256_setzero_si256 (),
         (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_subs_epu16 (__m256i __W, __mmask16 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_psubusw256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v16hi) __W,
         (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_subs_epu16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubusw256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v16hi)
         _mm256_setzero_si256 (),
         (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_add_epi8 (__m128i __W, __mmask16 __U, __m128i __A,
     __m128i __B)
{
  return (__m128i) __builtin_ia32_paddb128_mask ((__v16qi) __A,
       (__v16qi) __B,
       (__v16qi) __W,
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_add_epi8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddb128_mask ((__v16qi) __A,
       (__v16qi) __B,
       (__v16qi)
       _mm_setzero_si128 (),
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_add_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_paddw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_add_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpackhi_epi8 (__m256i __W, __mmask32 __U, __m256i __A,
      __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhbw256_mask ((__v32qi) __A,
           (__v32qi) __B,
           (__v32qi) __W,
           (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpackhi_epi8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhbw256_mask ((__v32qi) __A,
           (__v32qi) __B,
           (__v32qi)
           _mm256_setzero_si256 (),
           (__mmask32) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpackhi_epi8 (__m128i __W, __mmask16 __U, __m128i __A,
   __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhbw128_mask ((__v16qi) __A,
           (__v16qi) __B,
           (__v16qi) __W,
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpackhi_epi8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhbw128_mask ((__v16qi) __A,
           (__v16qi) __B,
           (__v16qi)
           _mm_setzero_si128 (),
           (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpackhi_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
       __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhwd256_mask ((__v16hi) __A,
           (__v16hi) __B,
           (__v16hi) __W,
           (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpackhi_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhwd256_mask ((__v16hi) __A,
           (__v16hi) __B,
           (__v16hi)
           _mm256_setzero_si256 (),
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpackhi_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
    __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhwd128_mask ((__v8hi) __A,
           (__v8hi) __B,
           (__v8hi) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpackhi_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhwd128_mask ((__v8hi) __A,
           (__v8hi) __B,
           (__v8hi)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpacklo_epi8 (__m256i __W, __mmask32 __U, __m256i __A,
      __m256i __B)
{
  return (__m256i) __builtin_ia32_punpcklbw256_mask ((__v32qi) __A,
           (__v32qi) __B,
           (__v32qi) __W,
           (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpacklo_epi8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpcklbw256_mask ((__v32qi) __A,
           (__v32qi) __B,
           (__v32qi)
           _mm256_setzero_si256 (),
           (__mmask32) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpacklo_epi8 (__m128i __W, __mmask16 __U, __m128i __A,
   __m128i __B)
{
  return (__m128i) __builtin_ia32_punpcklbw128_mask ((__v16qi) __A,
           (__v16qi) __B,
           (__v16qi) __W,
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpacklo_epi8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpcklbw128_mask ((__v16qi) __A,
           (__v16qi) __B,
           (__v16qi)
           _mm_setzero_si128 (),
           (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpacklo_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
       __m256i __B)
{
  return (__m256i) __builtin_ia32_punpcklwd256_mask ((__v16hi) __A,
           (__v16hi) __B,
           (__v16hi) __W,
           (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpacklo_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpcklwd256_mask ((__v16hi) __A,
           (__v16hi) __B,
           (__v16hi)
           _mm256_setzero_si256 (),
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpacklo_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
    __m128i __B)
{
  return (__m128i) __builtin_ia32_punpcklwd128_mask ((__v8hi) __A,
           (__v8hi) __B,
           (__v8hi) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpacklo_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpcklwd128_mask ((__v8hi) __A,
           (__v8hi) __B,
           (__v8hi)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi8_mask (__m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_pcmpeqb128_mask ((__v16qi) __A,
           (__v16qi) __B,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epu8_mask (__m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __A,
          (__v16qi) __B, 0,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epu8_mask (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __A,
          (__v16qi) __B, 0,
          __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epi8_mask (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_pcmpeqb128_mask ((__v16qi) __A,
           (__v16qi) __B,
           __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epu8_mask (__m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __A,
          (__v32qi) __B, 0,
          (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi8_mask (__m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_pcmpeqb256_mask ((__v32qi) __A,
           (__v32qi) __B,
           (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epu8_mask (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __A,
          (__v32qi) __B, 0,
          __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epi8_mask (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_pcmpeqb256_mask ((__v32qi) __A,
           (__v32qi) __B,
           __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epu16_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __A,
         (__v8hi) __B, 0,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi16_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqw128_mask ((__v8hi) __A,
          (__v8hi) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epu16_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __A,
         (__v8hi) __B, 0, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epi16_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqw128_mask ((__v8hi) __A,
          (__v8hi) __B, __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epu16_mask (__m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __A,
          (__v16hi) __B, 0,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi16_mask (__m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_pcmpeqw256_mask ((__v16hi) __A,
           (__v16hi) __B,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epu16_mask (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __A,
          (__v16hi) __B, 0,
          __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epi16_mask (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_pcmpeqw256_mask ((__v16hi) __A,
           (__v16hi) __B,
           __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epu8_mask (__m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __A,
          (__v16qi) __B, 6,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi8_mask (__m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_pcmpgtb128_mask ((__v16qi) __A,
           (__v16qi) __B,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epu8_mask (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __A,
          (__v16qi) __B, 6,
          __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epi8_mask (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_pcmpgtb128_mask ((__v16qi) __A,
           (__v16qi) __B,
           __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epu8_mask (__m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __A,
          (__v32qi) __B, 6,
          (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi8_mask (__m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_pcmpgtb256_mask ((__v32qi) __A,
           (__v32qi) __B,
           (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epu8_mask (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __A,
          (__v32qi) __B, 6,
          __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epi8_mask (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_pcmpgtb256_mask ((__v32qi) __A,
           (__v32qi) __B,
           __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epu16_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __A,
         (__v8hi) __B, 6,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi16_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtw128_mask ((__v8hi) __A,
          (__v8hi) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epu16_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __A,
         (__v8hi) __B, 6, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epi16_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtw128_mask ((__v8hi) __A,
          (__v8hi) __B, __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epu16_mask (__m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __A,
          (__v16hi) __B, 6,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi16_mask (__m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_pcmpgtw256_mask ((__v16hi) __A,
           (__v16hi) __B,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epu16_mask (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __A,
          (__v16hi) __B, 6,
          __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epi16_mask (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_pcmpgtw256_mask ((__v16hi) __A,
           (__v16hi) __B,
           __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_testn_epi8_mask (__m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ptestnmb128 ((__v16qi) __A,
       (__v16qi) __B,
       (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_testn_epi8_mask (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ptestnmb128 ((__v16qi) __A,
       (__v16qi) __B, __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testn_epi8_mask (__m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ptestnmb256 ((__v32qi) __A,
       (__v32qi) __B,
       (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_testn_epi8_mask (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ptestnmb256 ((__v32qi) __A,
       (__v32qi) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_testn_epi16_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmw128 ((__v8hi) __A,
      (__v8hi) __B,
      (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_testn_epi16_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmw128 ((__v8hi) __A,
      (__v8hi) __B, __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testn_epi16_mask (__m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ptestnmw256 ((__v16hi) __A,
       (__v16hi) __B,
       (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_testn_epi16_mask (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ptestnmw256 ((__v16hi) __A,
       (__v16hi) __B, __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_shuffle_epi8 (__m256i __W, __mmask32 __U, __m256i __A,
     __m256i __B)
{
  return (__m256i) __builtin_ia32_pshufb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi) __W,
        (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_shuffle_epi8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pshufb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi)
        _mm256_setzero_si256 (),
        (__mmask32) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_shuffle_epi8 (__m128i __W, __mmask16 __U, __m128i __A,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_pshufb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi) __W,
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_shuffle_epi8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pshufb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi)
        _mm_setzero_si128 (),
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_packs_epi16 (__mmask32 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_packsswb256_mask ((__v16hi) __A,
          (__v16hi) __B,
          (__v32qi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_packs_epi16 (__m256i __W, __mmask32 __M, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_packsswb256_mask ((__v16hi) __A,
          (__v16hi) __B,
          (__v32qi) __W,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_packs_epi16 (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_packsswb128_mask ((__v8hi) __A,
          (__v8hi) __B,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_packs_epi16 (__m128i __W, __mmask16 __M, __m128i __A,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_packsswb128_mask ((__v8hi) __A,
          (__v8hi) __B,
          (__v16qi) __W,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_packus_epi16 (__mmask32 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_packuswb256_mask ((__v16hi) __A,
          (__v16hi) __B,
          (__v32qi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_packus_epi16 (__m256i __W, __mmask32 __M, __m256i __A,
     __m256i __B)
{
  return (__m256i) __builtin_ia32_packuswb256_mask ((__v16hi) __A,
          (__v16hi) __B,
          (__v32qi) __W,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_packus_epi16 (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_packuswb128_mask ((__v8hi) __A,
          (__v8hi) __B,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_packus_epi16 (__m128i __W, __mmask16 __M, __m128i __A,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_packuswb128_mask ((__v8hi) __A,
          (__v8hi) __B,
          (__v16qi) __W,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_abs_epi8 (__m256i __W, __mmask32 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsb256_mask ((__v32qi) __A,
       (__v32qi) __W,
       (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_abs_epi8 (__mmask32 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsb256_mask ((__v32qi) __A,
       (__v32qi)
       _mm256_setzero_si256 (),
       (__mmask32) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_abs_epi8 (__m128i __W, __mmask16 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsb128_mask ((__v16qi) __A,
       (__v16qi) __W,
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_abs_epi8 (__mmask16 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsb128_mask ((__v16qi) __A,
       (__v16qi)
       _mm_setzero_si128 (),
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_abs_epi16 (__m256i __W, __mmask16 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsw256_mask ((__v16hi) __A,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_abs_epi16 (__mmask16 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsw256_mask ((__v16hi) __A,
       (__v16hi)
       _mm256_setzero_si256 (),
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_abs_epi16 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsw128_mask ((__v8hi) __A,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_abs_epi16 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsw128_mask ((__v8hi) __A,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpneq_epu8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
         (__v32qi) __Y, 4,
         (__mmask32) - 1);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmplt_epu8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
         (__v32qi) __Y, 1,
         (__mmask32) - 1);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpge_epu8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
         (__v32qi) __Y, 5,
         (__mmask32) - 1);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmple_epu8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
         (__v32qi) __Y, 2,
         (__mmask32) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpneq_epu16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
         (__v16hi) __Y, 4,
         (__mmask16) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmplt_epu16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
         (__v16hi) __Y, 1,
         (__mmask16) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpge_epu16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
         (__v16hi) __Y, 5,
         (__mmask16) - 1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmple_epu16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
         (__v16hi) __Y, 2,
         (__mmask16) - 1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_storeu_epi16 (void *__P, __mmask16 __U, __m256i __A)
{
  __builtin_ia32_storedquhi256_mask ((__v16hi *) __P,
         (__v16hi) __A,
         (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_storeu_epi16 (void *__P, __mmask8 __U, __m128i __A)
{
  __builtin_ia32_storedquhi128_mask ((__v8hi *) __P,
         (__v8hi) __A,
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_adds_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_paddsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_subs_epi8 (__m128i __W, __mmask16 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psubsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi) __W,
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_subs_epi8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi)
        _mm_setzero_si128 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_subs_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_psubsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_subs_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_subs_epu8 (__m128i __W, __mmask16 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psubusb128_mask ((__v16qi) __A,
         (__v16qi) __B,
         (__v16qi) __W,
         (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_subs_epu8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubusb128_mask ((__v16qi) __A,
         (__v16qi) __B,
         (__v16qi)
         _mm_setzero_si128 (),
         (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_subs_epu16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_psubusw128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v8hi) __W,
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_subs_epu16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubusw128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v8hi)
         _mm_setzero_si128 (),
         (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srl_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psrlw256_mask ((__v16hi) __A,
       (__v8hi) __B,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srl_epi16 (__mmask16 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psrlw256_mask ((__v16hi) __A,
       (__v8hi) __B,
       (__v16hi)
       _mm256_setzero_si256 (),
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srl_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psrlw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srl_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrlw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sra_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psraw256_mask ((__v16hi) __A,
       (__v8hi) __B,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sra_epi16 (__mmask16 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psraw256_mask ((__v16hi) __A,
       (__v8hi) __B,
       (__v16hi)
       _mm256_setzero_si256 (),
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sra_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psraw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sra_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psraw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_adds_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_adds_epu8 (__m128i __W, __mmask16 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_paddusb128_mask ((__v16qi) __A,
         (__v16qi) __B,
         (__v16qi) __W,
         (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_adds_epu8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddusb128_mask ((__v16qi) __A,
         (__v16qi) __B,
         (__v16qi)
         _mm_setzero_si128 (),
         (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_adds_epu16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_paddusw128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v8hi) __W,
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_adds_epu16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddusw128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v8hi)
         _mm_setzero_si128 (),
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sub_epi8 (__m128i __W, __mmask16 __U, __m128i __A,
     __m128i __B)
{
  return (__m128i) __builtin_ia32_psubb128_mask ((__v16qi) __A,
       (__v16qi) __B,
       (__v16qi) __W,
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sub_epi8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubb128_mask ((__v16qi) __A,
       (__v16qi) __B,
       (__v16qi)
       _mm_setzero_si128 (),
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sub_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psubw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sub_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_adds_epi8 (__m128i __W, __mmask16 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_paddsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi) __W,
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_adds_epi8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi)
        _mm_setzero_si128 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi16_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovwb128_mask ((__v8hi) __A,
        (__v16qi)_mm_undefined_si128(),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi16_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovwb128_mask ((__v8hi) __A,
        (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi16_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovwb128_mask ((__v8hi) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srav_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psrav16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srav_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_psrav16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srav_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psrav16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_srav_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrav8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_hi (),
       (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srav_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_psrav8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srav_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrav8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srlv_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psrlv16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srlv_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_psrlv16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srlv_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psrlv16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_srlv_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrlv8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_hi (),
       (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srlv_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_psrlv8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srlv_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrlv8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sllv_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psllv16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sllv_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_psllv16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sllv_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psllv16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sllv_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psllv8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_hi (),
       (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sllv_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_psllv8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sllv_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psllv8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sll_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psllw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sll_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psllw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sll_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psllw256_mask ((__v16hi) __A,
       (__v8hi) __B,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sll_epi16 (__mmask16 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psllw256_mask ((__v16hi) __A,
       (__v8hi) __B,
       (__v16hi)
       _mm256_setzero_si256 (),
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_packus_epi32 (__mmask16 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_packusdw256_mask ((__v8si) __A,
          (__v8si) __B,
          (__v16hi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_packus_epi32 (__m256i __W, __mmask16 __M, __m256i __A,
     __m256i __B)
{
  return (__m256i) __builtin_ia32_packusdw256_mask ((__v8si) __A,
          (__v8si) __B,
          (__v16hi) __W,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_packus_epi32 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_packusdw128_mask ((__v4si) __A,
          (__v4si) __B,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_packus_epi32 (__m128i __W, __mmask16 __M, __m128i __A,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_packusdw128_mask ((__v4si) __A,
          (__v4si) __B,
          (__v8hi) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_packs_epi32 (__mmask16 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_packssdw256_mask ((__v8si) __A,
          (__v8si) __B,
          (__v16hi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_packs_epi32 (__m256i __W, __mmask16 __M, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_packssdw256_mask ((__v8si) __A,
          (__v8si) __B,
          (__v16hi) __W,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_packs_epi32 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_packssdw128_mask ((__v4si) __A,
          (__v4si) __B,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_packs_epi32 (__m128i __W, __mmask16 __M, __m128i __A,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_packssdw128_mask ((__v4si) __A,
          (__v4si) __B,
          (__v8hi) __W, __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpneq_epu8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 4,
         (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmplt_epu8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 1,
         (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpge_epu8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 5,
         (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmple_epu8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 2,
         (__mmask16) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpneq_epu16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 4,
        (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmplt_epu16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 1,
        (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpge_epu16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 5,
        (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmple_epu16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 2,
        (__mmask8) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpneq_epi8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 4,
        (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmplt_epi8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 1,
        (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpge_epi8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 5,
        (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmple_epi8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 2,
        (__mmask16) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpneq_epi16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 4,
       (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmplt_epi16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 1,
       (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpge_epi16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 5,
       (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmple_epi16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 2,
       (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpneq_epu8_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 4,
        (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmplt_epu8_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 1,
        (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpge_epu8_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 5,
        (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmple_epu8_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 2,
        (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpneq_epu16_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 4,
        (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmplt_epu16_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 1,
        (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpge_epu16_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 5,
        (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmple_epu16_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 2,
        (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpneq_epi8_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
       (__v32qi) __Y, 4,
       (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmplt_epi8_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
       (__v32qi) __Y, 1,
       (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpge_epi8_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
       (__v32qi) __Y, 5,
       (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmple_epi8_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
       (__v32qi) __Y, 2,
       (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpneq_epi16_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
       (__v16hi) __Y, 4,
       (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmplt_epi16_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
       (__v16hi) __Y, 1,
       (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpge_epi16_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
       (__v16hi) __Y, 5,
       (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmple_epi16_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
       (__v16hi) __Y, 2,
       (__mmask8) __M);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vl,avx512dq")
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttpd_epi64 (__m256d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2qq256_mask ((__v4df) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttpd_epi64 (__m256i __W, __mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2qq256_mask ((__v4df) __A,
           (__v4di) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttpd_epi64 (__mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2qq256_mask ((__v4df) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttpd_epi64 (__m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2qq128_mask ((__v2df) __A,
           (__v2di)
           _mm_setzero_di (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttpd_epi64 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2qq128_mask ((__v2df) __A,
           (__v2di) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttpd_epi64 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2qq128_mask ((__v2df) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttpd_epu64 (__m256d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2uqq256_mask ((__v4df) __A,
            (__v4di)
            _mm256_setzero_si256 (),
            (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttpd_epu64 (__m256i __W, __mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2uqq256_mask ((__v4df) __A,
            (__v4di) __W,
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttpd_epu64 (__mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2uqq256_mask ((__v4df) __A,
            (__v4di)
            _mm256_setzero_si256 (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttpd_epu64 (__m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2uqq128_mask ((__v2df) __A,
            (__v2di)
            _mm_setzero_di (),
            (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttpd_epu64 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2uqq128_mask ((__v2df) __A,
            (__v2di) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttpd_epu64 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2uqq128_mask ((__v2df) __A,
            (__v2di)
            _mm_setzero_si128 (),
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtpd_epi64 (__m256d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2qq256_mask ((__v4df) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtpd_epi64 (__m256i __W, __mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2qq256_mask ((__v4df) __A,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtpd_epi64 (__mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2qq256_mask ((__v4df) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpd_epi64 (__m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2qq128_mask ((__v2df) __A,
          (__v2di)
          _mm_setzero_di (),
          (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtpd_epi64 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2qq128_mask ((__v2df) __A,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtpd_epi64 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2qq128_mask ((__v2df) __A,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtpd_epu64 (__m256d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2uqq256_mask ((__v4df) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtpd_epu64 (__m256i __W, __mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2uqq256_mask ((__v4df) __A,
           (__v4di) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtpd_epu64 (__mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2uqq256_mask ((__v4df) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpd_epu64 (__m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2uqq128_mask ((__v2df) __A,
           (__v2di)
           _mm_setzero_di (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtpd_epu64 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2uqq128_mask ((__v2df) __A,
           (__v2di) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtpd_epu64 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2uqq128_mask ((__v2df) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttps_epi64 (__m128 __A)
{
  return (__m256i) __builtin_ia32_cvttps2qq256_mask ((__v4sf) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttps_epi64 (__m256i __W, __mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvttps2qq256_mask ((__v4sf) __A,
           (__v4di) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttps_epi64 (__mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvttps2qq256_mask ((__v4sf) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttps_epi64 (__m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2qq128_mask ((__v4sf) __A,
           (__v2di)
           _mm_setzero_di (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttps_epi64 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2qq128_mask ((__v4sf) __A,
           (__v2di) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttps_epi64 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2qq128_mask ((__v4sf) __A,
           (__v2di)
           _mm_setzero_di (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttps_epu64 (__m128 __A)
{
  return (__m256i) __builtin_ia32_cvttps2uqq256_mask ((__v4sf) __A,
            (__v4di)
            _mm256_setzero_si256 (),
            (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttps_epu64 (__m256i __W, __mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvttps2uqq256_mask ((__v4sf) __A,
            (__v4di) __W,
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttps_epu64 (__mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvttps2uqq256_mask ((__v4sf) __A,
            (__v4di)
            _mm256_setzero_si256 (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttps_epu64 (__m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2uqq128_mask ((__v4sf) __A,
            (__v2di)
            _mm_setzero_di (),
            (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttps_epu64 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2uqq128_mask ((__v4sf) __A,
            (__v2di) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttps_epu64 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2uqq128_mask ((__v4sf) __A,
            (__v2di)
            _mm_setzero_di (),
            (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_f64x2 (__m128d __A)
{
  return (__m256d) __builtin_ia32_broadcastf64x2_256_mask ((__v2df)
          __A,
                 (__v4df)_mm256_undefined_pd(),
          (__mmask8) -
          1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcast_f64x2 (__m256d __O, __mmask8 __M, __m128d __A)
{
  return (__m256d) __builtin_ia32_broadcastf64x2_256_mask ((__v2df)
          __A,
          (__v4df)
          __O, __M);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcast_f64x2 (__mmask8 __M, __m128d __A)
{
  return (__m256d) __builtin_ia32_broadcastf64x2_256_mask ((__v2df)
          __A,
          (__v4df)
          _mm256_setzero_ps (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_i64x2 (__m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti64x2_256_mask ((__v2di)
          __A,
                 (__v4di)_mm256_undefined_si256(),
          (__mmask8) -
          1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcast_i64x2 (__m256i __O, __mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti64x2_256_mask ((__v2di)
          __A,
          (__v4di)
          __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcast_i64x2 (__mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti64x2_256_mask ((__v2di)
          __A,
          (__v4di)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_f32x2 (__m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x2_256_mask ((__v4sf) __A,
                (__v8sf)_mm256_undefined_ps(),
         (__mmask8) -
         1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcast_f32x2 (__m256 __O, __mmask8 __M, __m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x2_256_mask ((__v4sf) __A,
         (__v8sf) __O,
         __M);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcast_f32x2 (__mmask8 __M, __m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x2_256_mask ((__v4sf) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_i32x2 (__m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x2_256_mask ((__v4si)
          __A,
                (__v8si)_mm256_undefined_si256(),
          (__mmask8) -
          1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcast_i32x2 (__m256i __O, __mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x2_256_mask ((__v4si)
          __A,
          (__v8si)
          __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcast_i32x2 (__mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x2_256_mask ((__v4si)
          __A,
          (__v8si)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcast_i32x2 (__m128i __A)
{
  return (__m128i) __builtin_ia32_broadcasti32x2_128_mask ((__v4si)
          __A,
                (__v4si)_mm_undefined_si128(),
          (__mmask8) -
          1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_broadcast_i32x2 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_broadcasti32x2_128_mask ((__v4si)
          __A,
          (__v4si)
          __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_broadcast_i32x2 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_broadcasti32x2_128_mask ((__v4si)
          __A,
          (__v4si)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mullo_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4du) __A * (__v4du) __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mullo_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_pmullq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W,
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mullo_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmullq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mullo_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v2du) __A * (__v2du) __B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mullo_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_pmullq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mullo_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmullq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_di (),
        (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_andnot_pd (__m256d __W, __mmask8 __U, __m256d __A,
         __m256d __B)
{
  return (__m256d) __builtin_ia32_andnpd256_mask ((__v4df) __A,
        (__v4df) __B,
        (__v4df) __W,
        (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_andnot_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_andnpd256_mask ((__v4df) __A,
        (__v4df) __B,
        (__v4df)
        _mm256_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_andnot_pd (__m128d __W, __mmask8 __U, __m128d __A,
      __m128d __B)
{
  return (__m128d) __builtin_ia32_andnpd128_mask ((__v2df) __A,
        (__v2df) __B,
        (__v2df) __W,
        (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_andnot_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_andnpd128_mask ((__v2df) __A,
        (__v2df) __B,
        (__v2df)
        _mm_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_andnot_ps (__m256 __W, __mmask8 __U, __m256 __A,
         __m256 __B)
{
  return (__m256) __builtin_ia32_andnps256_mask ((__v8sf) __A,
       (__v8sf) __B,
       (__v8sf) __W,
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_andnot_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_andnps256_mask ((__v8sf) __A,
       (__v8sf) __B,
       (__v8sf)
       _mm256_setzero_ps (),
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_andnot_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_andnps128_mask ((__v4sf) __A,
       (__v4sf) __B,
       (__v4sf) __W,
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_andnot_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_andnps128_mask ((__v4sf) __A,
       (__v4sf) __B,
       (__v4sf)
       _mm_setzero_ps (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtps_epi64 (__m128 __A)
{
  return (__m256i) __builtin_ia32_cvtps2qq256_mask ((__v4sf) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtps_epi64 (__m256i __W, __mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvtps2qq256_mask ((__v4sf) __A,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtps_epi64 (__mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvtps2qq256_mask ((__v4sf) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_epi64 (__m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2qq128_mask ((__v4sf) __A,
          (__v2di)
          _mm_setzero_di (),
          (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtps_epi64 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2qq128_mask ((__v4sf) __A,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtps_epi64 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2qq128_mask ((__v4sf) __A,
          (__v2di)
          _mm_setzero_di (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtps_epu64 (__m128 __A)
{
  return (__m256i) __builtin_ia32_cvtps2uqq256_mask ((__v4sf) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtps_epu64 (__m256i __W, __mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvtps2uqq256_mask ((__v4sf) __A,
           (__v4di) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtps_epu64 (__mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvtps2uqq256_mask ((__v4sf) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_epu64 (__m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2uqq128_mask ((__v4sf) __A,
           (__v2di)
           _mm_setzero_di (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtps_epu64 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2uqq128_mask ((__v4sf) __A,
           (__v2di) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtps_epu64 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2uqq128_mask ((__v4sf) __A,
           (__v2di)
           _mm_setzero_di (),
           (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi64_ps (__m256i __A)
{
  return (__m128) __builtin_ia32_cvtqq2ps256_mask ((__v4di) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_ps (__m128 __W, __mmask8 __U, __m256i __A)
{
  return (__m128) __builtin_ia32_cvtqq2ps256_mask ((__v4di) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi64_ps (__mmask8 __U, __m256i __A)
{
  return (__m128) __builtin_ia32_cvtqq2ps256_mask ((__v4di) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi64_ps (__m128i __A)
{
  return (__m128) __builtin_ia32_cvtqq2ps128_mask ((__v2di) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_ps (__m128 __W, __mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtqq2ps128_mask ((__v2di) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi64_ps (__mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtqq2ps128_mask ((__v2di) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu64_ps (__m256i __A)
{
  return (__m128) __builtin_ia32_cvtuqq2ps256_mask ((__v4di) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu64_ps (__m128 __W, __mmask8 __U, __m256i __A)
{
  return (__m128) __builtin_ia32_cvtuqq2ps256_mask ((__v4di) __A,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu64_ps (__mmask8 __U, __m256i __A)
{
  return (__m128) __builtin_ia32_cvtuqq2ps256_mask ((__v4di) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu64_ps (__m128i __A)
{
  return (__m128) __builtin_ia32_cvtuqq2ps128_mask ((__v2di) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu64_ps (__m128 __W, __mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtuqq2ps128_mask ((__v2di) __A,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu64_ps (__mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtuqq2ps128_mask ((__v2di) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi64_pd (__m256i __A)
{
  return (__m256d) __builtin_ia32_cvtqq2pd256_mask ((__v4di) __A,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_pd (__m256d __W, __mmask8 __U, __m256i __A)
{
  return (__m256d) __builtin_ia32_cvtqq2pd256_mask ((__v4di) __A,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi64_pd (__mmask8 __U, __m256i __A)
{
  return (__m256d) __builtin_ia32_cvtqq2pd256_mask ((__v4di) __A,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi64_pd (__m128i __A)
{
  return (__m128d) __builtin_ia32_cvtqq2pd128_mask ((__v2di) __A,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_pd (__m128d __W, __mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtqq2pd128_mask ((__v2di) __A,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi64_pd (__mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtqq2pd128_mask ((__v2di) __A,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu64_pd (__m256i __A)
{
  return (__m256d) __builtin_ia32_cvtuqq2pd256_mask ((__v4di) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu64_pd (__m256d __W, __mmask8 __U, __m256i __A)
{
  return (__m256d) __builtin_ia32_cvtuqq2pd256_mask ((__v4di) __A,
           (__v4df) __W,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu64_pd (__mmask8 __U, __m256i __A)
{
  return (__m256d) __builtin_ia32_cvtuqq2pd256_mask ((__v4di) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_and_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_andpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_and_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_andpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_and_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_andpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __W,
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_and_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_andpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df)
       _mm_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_and_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_andps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_and_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_andps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_and_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_andps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf) __W,
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_and_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_andps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf)
      _mm_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu64_pd (__m128i __A)
{
  return (__m128d) __builtin_ia32_cvtuqq2pd128_mask ((__v2di) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu64_pd (__m128d __W, __mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtuqq2pd128_mask ((__v2di) __A,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu64_pd (__mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtuqq2pd128_mask ((__v2di) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_xor_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_xorpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_xor_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_xorpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_xor_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_xorpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __W,
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_xor_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_xorpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df)
       _mm_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_xor_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_xorps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_xor_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_xorps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_xor_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_xorps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf) __W,
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_xor_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_xorps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf)
      _mm_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_or_pd (__m256d __W, __mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_orpd256_mask ((__v4df) __A,
      (__v4df) __B,
      (__v4df) __W,
      (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_or_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_orpd256_mask ((__v4df) __A,
      (__v4df) __B,
      (__v4df)
      _mm256_setzero_pd (),
      (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_or_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_orpd128_mask ((__v2df) __A,
      (__v2df) __B,
      (__v2df) __W,
      (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_or_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_orpd128_mask ((__v2df) __A,
      (__v2df) __B,
      (__v2df)
      _mm_setzero_pd (),
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_or_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_orps256_mask ((__v8sf) __A,
            (__v8sf) __B,
            (__v8sf) __W,
            (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_or_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_orps256_mask ((__v8sf) __A,
            (__v8sf) __B,
            (__v8sf)
            _mm256_setzero_ps (),
            (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_or_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_orps128_mask ((__v4sf) __A,
            (__v4sf) __B,
            (__v4sf) __W,
            (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_or_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_orps128_mask ((__v4sf) __A,
            (__v4sf) __B,
            (__v4sf)
            _mm_setzero_ps (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movm_epi32 (__mmask8 __A)
{
  return (__m128i) __builtin_ia32_cvtmask2d128 (__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movm_epi32 (__mmask8 __A)
{
  return (__m256i) __builtin_ia32_cvtmask2d256 (__A);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movm_epi64 (__mmask8 __A)
{
  return (__m128i) __builtin_ia32_cvtmask2q128 (__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movm_epi64 (__mmask8 __A)
{
  return (__m256i) __builtin_ia32_cvtmask2q256 (__A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movepi32_mask (__m128i __A)
{
  return (__mmask8) __builtin_ia32_cvtd2mask128 ((__v4si) __A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movepi32_mask (__m256i __A)
{
  return (__mmask8) __builtin_ia32_cvtd2mask256 ((__v8si) __A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movepi64_mask (__m128i __A)
{
  return (__mmask8) __builtin_ia32_cvtq2mask128 ((__v2di) __A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movepi64_mask (__m256i __A)
{
  return (__mmask8) __builtin_ia32_cvtq2mask256 ((__v4di) __A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512ifma")
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_madd52lo_epu64 (__m512i __X, __m512i __Y, __m512i __Z)
{
  return (__m512i) __builtin_ia32_vpmadd52luq512_mask ((__v8di) __X,
             (__v8di) __Y,
             (__v8di) __Z,
             (__mmask8) - 1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_madd52hi_epu64 (__m512i __X, __m512i __Y, __m512i __Z)
{
  return (__m512i) __builtin_ia32_vpmadd52huq512_mask ((__v8di) __X,
             (__v8di) __Y,
             (__v8di) __Z,
             (__mmask8) - 1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_madd52lo_epu64 (__m512i __W, __mmask8 __M, __m512i __X,
       __m512i __Y)
{
  return (__m512i) __builtin_ia32_vpmadd52luq512_mask ((__v8di) __W,
             (__v8di) __X,
             (__v8di) __Y,
             (__mmask8) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_madd52hi_epu64 (__m512i __W, __mmask8 __M, __m512i __X,
       __m512i __Y)
{
  return (__m512i) __builtin_ia32_vpmadd52huq512_mask ((__v8di) __W,
             (__v8di) __X,
             (__v8di) __Y,
             (__mmask8) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_madd52lo_epu64 (__mmask8 __M, __m512i __X, __m512i __Y, __m512i __Z)
{
  return (__m512i) __builtin_ia32_vpmadd52luq512_maskz ((__v8di) __X,
       (__v8di) __Y,
       (__v8di) __Z,
       (__mmask8) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_madd52hi_epu64 (__mmask8 __M, __m512i __X, __m512i __Y, __m512i __Z)
{
  return (__m512i) __builtin_ia32_vpmadd52huq512_maskz ((__v8di) __X,
       (__v8di) __Y,
       (__v8di) __Z,
       (__mmask8) __M);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512ifma,avx512vl")
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_madd52lo_epu64 (__m128i __X, __m128i __Y, __m128i __Z)
{
  return (__m128i) __builtin_ia32_vpmadd52luq128_mask ((__v2di) __X,
             (__v2di) __Y,
             (__v2di) __Z,
             (__mmask8) - 1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_madd52hi_epu64 (__m128i __X, __m128i __Y, __m128i __Z)
{
  return (__m128i) __builtin_ia32_vpmadd52huq128_mask ((__v2di) __X,
             (__v2di) __Y,
             (__v2di) __Z,
             (__mmask8) - 1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_madd52lo_epu64 (__m256i __X, __m256i __Y, __m256i __Z)
{
  return (__m256i) __builtin_ia32_vpmadd52luq256_mask ((__v4di) __X,
             (__v4di) __Y,
             (__v4di) __Z,
             (__mmask8) - 1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_madd52hi_epu64 (__m256i __X, __m256i __Y, __m256i __Z)
{
  return (__m256i) __builtin_ia32_vpmadd52huq256_mask ((__v4di) __X,
             (__v4di) __Y,
             (__v4di) __Z,
             (__mmask8) - 1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_madd52lo_epu64 (__m128i __W, __mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_vpmadd52luq128_mask ((__v2di) __W,
             (__v2di) __X,
             (__v2di) __Y,
             (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_madd52hi_epu64 (__m128i __W, __mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_vpmadd52huq128_mask ((__v2di) __W,
             (__v2di) __X,
             (__v2di) __Y,
             (__mmask8) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_madd52lo_epu64 (__m256i __W, __mmask8 __M, __m256i __X,
       __m256i __Y)
{
  return (__m256i) __builtin_ia32_vpmadd52luq256_mask ((__v4di) __W,
             (__v4di) __X,
             (__v4di) __Y,
             (__mmask8) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_madd52hi_epu64 (__m256i __W, __mmask8 __M, __m256i __X,
       __m256i __Y)
{
  return (__m256i) __builtin_ia32_vpmadd52huq256_mask ((__v4di) __W,
             (__v4di) __X,
             (__v4di) __Y,
             (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_madd52lo_epu64 (__mmask8 __M, __m128i __X, __m128i __Y, __m128i __Z)
{
  return (__m128i) __builtin_ia32_vpmadd52luq128_maskz ((__v2di) __X,
       (__v2di) __Y,
       (__v2di) __Z,
       (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_madd52hi_epu64 (__mmask8 __M, __m128i __X, __m128i __Y, __m128i __Z)
{
  return (__m128i) __builtin_ia32_vpmadd52huq128_maskz ((__v2di) __X,
       (__v2di) __Y,
       (__v2di) __Z,
       (__mmask8) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_madd52lo_epu64 (__mmask8 __M, __m256i __X, __m256i __Y, __m256i __Z)
{
  return (__m256i) __builtin_ia32_vpmadd52luq256_maskz ((__v4di) __X,
       (__v4di) __Y,
       (__v4di) __Z,
       (__mmask8) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_madd52hi_epu64 (__mmask8 __M, __m256i __X, __m256i __Y, __m256i __Z)
{
  return (__m256i) __builtin_ia32_vpmadd52huq256_maskz ((__v4di) __X,
       (__v4di) __Y,
       (__v4di) __Z,
       (__mmask8) __M);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vbmi")
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_multishift_epi64_epi8 (__m512i __W, __mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_vpmultishiftqb512_mask ((__v64qi) __X,
         (__v64qi) __Y,
         (__v64qi) __W,
         (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_multishift_epi64_epi8 (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_vpmultishiftqb512_mask ((__v64qi) __X,
         (__v64qi) __Y,
         (__v64qi)
         _mm512_setzero_si512 (),
         (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_multishift_epi64_epi8 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_vpmultishiftqb512_mask ((__v64qi) __X,
         (__v64qi) __Y,
         (__v64qi)
         _mm512_undefined_si512 (),
         (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutexvar_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_permvarqi512_mask ((__v64qi) __B,
           (__v64qi) __A,
           (__v64qi)
           _mm512_undefined_si512 (),
           (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutexvar_epi8 (__mmask64 __M, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_permvarqi512_mask ((__v64qi) __B,
           (__v64qi) __A,
           (__v64qi)
           _mm512_setzero_si512(),
           (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutexvar_epi8 (__m512i __W, __mmask64 __M, __m512i __A,
          __m512i __B)
{
  return (__m512i) __builtin_ia32_permvarqi512_mask ((__v64qi) __B,
           (__v64qi) __A,
           (__v64qi) __W,
           (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutex2var_epi8 (__m512i __A, __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varqi512_mask ((__v64qi) __I
                 ,
       (__v64qi) __A,
       (__v64qi) __B,
       (__mmask64) -
       1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutex2var_epi8 (__m512i __A, __mmask64 __U,
    __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varqi512_mask ((__v64qi) __I
                 ,
       (__v64qi) __A,
       (__v64qi) __B,
       (__mmask64)
       __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask2_permutex2var_epi8 (__m512i __A, __m512i __I,
     __mmask64 __U, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermi2varqi512_mask ((__v64qi) __A,
       (__v64qi) __I
                 ,
       (__v64qi) __B,
       (__mmask64)
       __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutex2var_epi8 (__mmask64 __U, __m512i __A,
     __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varqi512_maskz ((__v64qi) __I
                  ,
        (__v64qi) __A,
        (__v64qi) __B,
        (__mmask64)
        __U);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vbmi,avx512vl")
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_multishift_epi64_epi8 (__m256i __W, __mmask32 __M, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_vpmultishiftqb256_mask ((__v32qi) __X,
         (__v32qi) __Y,
         (__v32qi) __W,
         (__mmask32) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_multishift_epi64_epi8 (__mmask32 __M, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_vpmultishiftqb256_mask ((__v32qi) __X,
         (__v32qi) __Y,
         (__v32qi)
         _mm256_setzero_si256 (),
         (__mmask32) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_multishift_epi64_epi8 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_vpmultishiftqb256_mask ((__v32qi) __X,
         (__v32qi) __Y,
         (__v32qi)
         _mm256_undefined_si256 (),
         (__mmask32) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_multishift_epi64_epi8 (__m128i __W, __mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_vpmultishiftqb128_mask ((__v16qi) __X,
         (__v16qi) __Y,
         (__v16qi) __W,
         (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_multishift_epi64_epi8 (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_vpmultishiftqb128_mask ((__v16qi) __X,
         (__v16qi) __Y,
         (__v16qi)
         _mm_setzero_si128 (),
         (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_multishift_epi64_epi8 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_vpmultishiftqb128_mask ((__v16qi) __X,
         (__v16qi) __Y,
         (__v16qi)
         _mm_undefined_si128 (),
         (__mmask16) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutexvar_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_permvarqi256_mask ((__v32qi) __B,
           (__v32qi) __A,
           (__v32qi)
           _mm256_undefined_si256 (),
           (__mmask32) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutexvar_epi8 (__mmask32 __M, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_permvarqi256_mask ((__v32qi) __B,
           (__v32qi) __A,
           (__v32qi)
           _mm256_setzero_si256 (),
           (__mmask32) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutexvar_epi8 (__m256i __W, __mmask32 __M, __m256i __A,
          __m256i __B)
{
  return (__m256i) __builtin_ia32_permvarqi256_mask ((__v32qi) __B,
           (__v32qi) __A,
           (__v32qi) __W,
           (__mmask32) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutexvar_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_permvarqi128_mask ((__v16qi) __B,
           (__v16qi) __A,
           (__v16qi)
           _mm_undefined_si128 (),
           (__mmask16) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutexvar_epi8 (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_permvarqi128_mask ((__v16qi) __B,
           (__v16qi) __A,
           (__v16qi)
           _mm_setzero_si128 (),
           (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutexvar_epi8 (__m128i __W, __mmask16 __M, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_permvarqi128_mask ((__v16qi) __B,
           (__v16qi) __A,
           (__v16qi) __W,
           (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutex2var_epi8 (__m256i __A, __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varqi256_mask ((__v32qi) __I
                 ,
       (__v32qi) __A,
       (__v32qi) __B,
       (__mmask32) -
       1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutex2var_epi8 (__m256i __A, __mmask32 __U,
    __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varqi256_mask ((__v32qi) __I
                 ,
       (__v32qi) __A,
       (__v32qi) __B,
       (__mmask32)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask2_permutex2var_epi8 (__m256i __A, __m256i __I,
     __mmask32 __U, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermi2varqi256_mask ((__v32qi) __A,
       (__v32qi) __I
                 ,
       (__v32qi) __B,
       (__mmask32)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutex2var_epi8 (__mmask32 __U, __m256i __A,
     __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varqi256_maskz ((__v32qi) __I
                  ,
        (__v32qi) __A,
        (__v32qi) __B,
        (__mmask32)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutex2var_epi8 (__m128i __A, __m128i __I, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varqi128_mask ((__v16qi) __I
                 ,
       (__v16qi) __A,
       (__v16qi) __B,
       (__mmask16) -
       1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutex2var_epi8 (__m128i __A, __mmask16 __U, __m128i __I,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varqi128_mask ((__v16qi) __I
                 ,
       (__v16qi) __A,
       (__v16qi) __B,
       (__mmask16)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask2_permutex2var_epi8 (__m128i __A, __m128i __I, __mmask16 __U,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermi2varqi128_mask ((__v16qi) __A,
       (__v16qi) __I
                 ,
       (__v16qi) __B,
       (__mmask16)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutex2var_epi8 (__mmask16 __U, __m128i __A, __m128i __I,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varqi128_maskz ((__v16qi) __I
                  ,
        (__v16qi) __A,
        (__v16qi) __B,
        (__mmask16)
        __U);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("sha")
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha1msg1_epu32 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_sha1msg1 ((__v4si) __A, (__v4si) __B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha1msg2_epu32 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_sha1msg2 ((__v4si) __A, (__v4si) __B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha1nexte_epu32 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_sha1nexte ((__v4si) __A, (__v4si) __B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha256msg1_epu32 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_sha256msg1 ((__v4si) __A, (__v4si) __B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha256msg2_epu32 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_sha256msg2 ((__v4si) __A, (__v4si) __B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha256rnds2_epu32 (__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_sha256rnds2 ((__v4si) __A, (__v4si) __B,
            (__v4si) __C);
}
#pragma GCC pop_options
extern __inline unsigned short __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__lzcnt16 (unsigned short __X)
{
  return __builtin_clzs (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__lzcnt32 (unsigned int __X)
{
  return __builtin_clz (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_lzcnt_u32 (unsigned int __X)
{
  return __builtin_clz (__X);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__lzcnt64 (unsigned long long __X)
{
  return __builtin_clzll (__X);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_lzcnt_u64 (unsigned long long __X)
{
  return __builtin_clzll (__X);
}
extern __inline unsigned short __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__tzcnt_u16 (unsigned short __X)
{
  return __builtin_ctzs (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__andn_u32 (unsigned int __X, unsigned int __Y)
{
  return ~__X & __Y;
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__bextr_u32 (unsigned int __X, unsigned int __Y)
{
  return __builtin_ia32_bextr_u32 (__X, __Y);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_bextr_u32 (unsigned int __X, unsigned int __Y, unsigned __Z)
{
  return __builtin_ia32_bextr_u32 (__X, ((__Y & 0xff) | ((__Z & 0xff) << 8)));
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsi_u32 (unsigned int __X)
{
  return __X & -__X;
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_blsi_u32 (unsigned int __X)
{
  return __blsi_u32 (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsmsk_u32 (unsigned int __X)
{
  return __X ^ (__X - 1);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_blsmsk_u32 (unsigned int __X)
{
  return __blsmsk_u32 (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsr_u32 (unsigned int __X)
{
  return __X & (__X - 1);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_blsr_u32 (unsigned int __X)
{
  return __blsr_u32 (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__tzcnt_u32 (unsigned int __X)
{
  return __builtin_ctz (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_tzcnt_u32 (unsigned int __X)
{
  return __builtin_ctz (__X);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__andn_u64 (unsigned long long __X, unsigned long long __Y)
{
  return ~__X & __Y;
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__bextr_u64 (unsigned long long __X, unsigned long long __Y)
{
  return __builtin_ia32_bextr_u64 (__X, __Y);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_bextr_u64 (unsigned long long __X, unsigned int __Y, unsigned int __Z)
{
  return __builtin_ia32_bextr_u64 (__X, ((__Y & 0xff) | ((__Z & 0xff) << 8)));
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsi_u64 (unsigned long long __X)
{
  return __X & -__X;
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_blsi_u64 (unsigned long long __X)
{
  return __blsi_u64 (__X);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsmsk_u64 (unsigned long long __X)
{
  return __X ^ (__X - 1);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_blsmsk_u64 (unsigned long long __X)
{
  return __blsmsk_u64 (__X);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsr_u64 (unsigned long long __X)
{
  return __X & (__X - 1);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_blsr_u64 (unsigned long long __X)
{
  return __blsr_u64 (__X);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__tzcnt_u64 (unsigned long long __X)
{
  return __builtin_ctzll (__X);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_tzcnt_u64 (unsigned long long __X)
{
  return __builtin_ctzll (__X);
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_bzhi_u32 (unsigned int __X, unsigned int __Y)
{
  return __builtin_ia32_bzhi_si (__X, __Y);
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_pdep_u32 (unsigned int __X, unsigned int __Y)
{
  return __builtin_ia32_pdep_si (__X, __Y);
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_pext_u32 (unsigned int __X, unsigned int __Y)
{
  return __builtin_ia32_pext_si (__X, __Y);
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_bzhi_u64 (unsigned long long __X, unsigned long long __Y)
{
  return __builtin_ia32_bzhi_di (__X, __Y);
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_pdep_u64 (unsigned long long __X, unsigned long long __Y)
{
  return __builtin_ia32_pdep_di (__X, __Y);
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_pext_u64 (unsigned long long __X, unsigned long long __Y)
{
  return __builtin_ia32_pext_di (__X, __Y);
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mulx_u64 (unsigned long long __X, unsigned long long __Y,
    unsigned long long *__P)
{
  unsigned __int128 __res = (unsigned __int128) __X * __Y;
  *__P = (unsigned long long) (__res >> 64);
  return (unsigned long long) __res;
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmadd_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfmaddpd ((__v2df)__A, (__v2df)__B,
                                           (__v2df)__C);
}
extern __inline __m256d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmadd_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d)__builtin_ia32_vfmaddpd256 ((__v4df)__A, (__v4df)__B,
                                              (__v4df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmadd_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfmaddps ((__v4sf)__A, (__v4sf)__B,
                                          (__v4sf)__C);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmadd_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256)__builtin_ia32_vfmaddps256 ((__v8sf)__A, (__v8sf)__B,
                                             (__v8sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmadd_sd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsd3 ((__v2df)__A, (__v2df)__B,
                                             (__v2df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmadd_ss (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddss3 ((__v4sf)__A, (__v4sf)__B,
                                            (__v4sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmsub_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfmaddpd ((__v2df)__A, (__v2df)__B,
                                           -(__v2df)__C);
}
extern __inline __m256d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmsub_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d)__builtin_ia32_vfmaddpd256 ((__v4df)__A, (__v4df)__B,
                                              -(__v4df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmsub_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfmaddps ((__v4sf)__A, (__v4sf)__B,
                                          -(__v4sf)__C);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmsub_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256)__builtin_ia32_vfmaddps256 ((__v8sf)__A, (__v8sf)__B,
                                             -(__v8sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmsub_sd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfmaddsd3 ((__v2df)__A, (__v2df)__B,
                                            -(__v2df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmsub_ss (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfmaddss3 ((__v4sf)__A, (__v4sf)__B,
                                           -(__v4sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmadd_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfmaddpd (-(__v2df)__A, (__v2df)__B,
                                           (__v2df)__C);
}
extern __inline __m256d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fnmadd_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d)__builtin_ia32_vfmaddpd256 (-(__v4df)__A, (__v4df)__B,
                                              (__v4df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmadd_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfmaddps (-(__v4sf)__A, (__v4sf)__B,
                                          (__v4sf)__C);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fnmadd_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256)__builtin_ia32_vfmaddps256 (-(__v8sf)__A, (__v8sf)__B,
                                             (__v8sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmadd_sd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfmaddsd3 ((__v2df)__A, -(__v2df)__B,
                                            (__v2df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmadd_ss (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfmaddss3 ((__v4sf)__A, -(__v4sf)__B,
                                           (__v4sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmsub_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfmaddpd (-(__v2df)__A, (__v2df)__B,
                                           -(__v2df)__C);
}
extern __inline __m256d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fnmsub_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d)__builtin_ia32_vfmaddpd256 (-(__v4df)__A, (__v4df)__B,
                                              -(__v4df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmsub_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfmaddps (-(__v4sf)__A, (__v4sf)__B,
                                          -(__v4sf)__C);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fnmsub_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256)__builtin_ia32_vfmaddps256 (-(__v8sf)__A, (__v8sf)__B,
                                             -(__v8sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmsub_sd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfmaddsd3 ((__v2df)__A, -(__v2df)__B,
                                            -(__v2df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmsub_ss (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfmaddss3 ((__v4sf)__A, -(__v4sf)__B,
                                           -(__v4sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmaddsub_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfmaddsubpd ((__v2df)__A, (__v2df)__B,
                                              (__v2df)__C);
}
extern __inline __m256d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmaddsub_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d)__builtin_ia32_vfmaddsubpd256 ((__v4df)__A,
                                                 (__v4df)__B,
                                                 (__v4df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmaddsub_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfmaddsubps ((__v4sf)__A, (__v4sf)__B,
                                             (__v4sf)__C);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmaddsub_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256)__builtin_ia32_vfmaddsubps256 ((__v8sf)__A,
                                                (__v8sf)__B,
                                                (__v8sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmsubadd_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfmaddsubpd ((__v2df)__A, (__v2df)__B,
                                              -(__v2df)__C);
}
extern __inline __m256d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmsubadd_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d)__builtin_ia32_vfmaddsubpd256 ((__v4df)__A,
                                                 (__v4df)__B,
                                                 -(__v4df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmsubadd_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfmaddsubps ((__v4sf)__A, (__v4sf)__B,
                                             -(__v4sf)__C);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmsubadd_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256)__builtin_ia32_vfmaddsubps256 ((__v8sf)__A,
                                                (__v8sf)__B,
                                                -(__v8sf)__C);
}
extern __inline float __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_cvtsh_ss (unsigned short __S)
{
  __v8hi __H = __extension__ (__v8hi){ (short) __S, 0, 0, 0, 0, 0, 0, 0 };
  __v4sf __A = __builtin_ia32_vcvtph2ps (__H);
  return __builtin_ia32_vec_ext_v4sf (__A, 0);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtph_ps (__m128i __A)
{
  return (__m128) __builtin_ia32_vcvtph2ps ((__v8hi) __A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtph_ps (__m128i __A)
{
  return (__m256) __builtin_ia32_vcvtph2ps256 ((__v8hi) __A);
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xbegin (void)
{
  return __builtin_ia32_xbegin ();
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xend (void)
{
  __builtin_ia32_xend ();
}
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xtest (void)
{
  return __builtin_ia32_xtest ();
}
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_rdrand16_step (unsigned short *__P)
{
  return __builtin_ia32_rdrand16_step (__P);
}
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_rdrand32_step (unsigned int *__P)
{
  return __builtin_ia32_rdrand32_step (__P);
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_readfsbase_u32 (void)
{
  return __builtin_ia32_rdfsbase32 ();
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_readfsbase_u64 (void)
{
  return __builtin_ia32_rdfsbase64 ();
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_readgsbase_u32 (void)
{
  return __builtin_ia32_rdgsbase32 ();
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_readgsbase_u64 (void)
{
  return __builtin_ia32_rdgsbase64 ();
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_writefsbase_u32 (unsigned int __B)
{
  __builtin_ia32_wrfsbase32 (__B);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_writefsbase_u64 (unsigned long long __B)
{
  __builtin_ia32_wrfsbase64 (__B);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_writegsbase_u32 (unsigned int __B)
{
  __builtin_ia32_wrgsbase32 (__B);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_writegsbase_u64 (unsigned long long __B)
{
  __builtin_ia32_wrgsbase64 (__B);
}
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_rdrand64_step (unsigned long long *__P)
{
  return __builtin_ia32_rdrand64_step (__P);
}
unsigned bit8( uint8_t *in, unsigned n);
unsigned bit16( uint16_t *in, unsigned n);
unsigned bit32( uint32_t *in, unsigned n);
unsigned bit64( uint64_t *in, unsigned n);
unsigned bitd8( uint8_t *in, unsigned n, uint8_t start);
unsigned bitd16( uint16_t *in, unsigned n, uint16_t start);
unsigned bitd32( uint32_t *in, unsigned n, uint32_t start);
unsigned bitd64( uint64_t *in, unsigned n, uint64_t start);
void bitddec8( uint8_t *p, unsigned n, uint8_t start);
void bitddec16( uint16_t *p, unsigned n, uint16_t start);
void bitddec32( uint32_t *p, unsigned n, uint32_t start);
void bitddec64( uint64_t *p, unsigned n, uint64_t start);
unsigned bitd18( uint8_t *in, unsigned n, uint8_t start);
unsigned bitd116( uint16_t *in, unsigned n, uint16_t start);
unsigned bitd132( uint32_t *in, unsigned n, uint32_t start);
unsigned bitd164( uint64_t *in, unsigned n, uint64_t start);
void bitd1dec8( uint8_t *p, unsigned n, uint8_t start);
void bitd1dec16( uint16_t *p, unsigned n, uint16_t start);
void bitd1dec32( uint32_t *p, unsigned n, uint32_t start);
void bitd1dec64( uint64_t *p, unsigned n, uint64_t start);
unsigned bitdd8( uint8_t *in, unsigned n, uint8_t start);
unsigned bitdd16( uint16_t *in, unsigned n, uint16_t start);
unsigned bitdd32( uint32_t *in, unsigned n, uint32_t start);
unsigned bitdd64( uint64_t *in, unsigned n, uint64_t start);
unsigned bitddenc8( uint8_t *in, unsigned n, uint8_t *out, uint8_t start, uint8_t mindelta);
unsigned bitddenc16(uint16_t *in, unsigned n, uint16_t *out, uint16_t start, uint16_t mindelta);
unsigned bitddenc32(uint32_t *in, unsigned n, uint32_t *out, uint32_t start, uint32_t mindelta);
unsigned bitddenc64(uint64_t *in, unsigned n, uint64_t *out, uint64_t start, uint64_t mindelta);
void bitdddec8( uint8_t *p, unsigned n, uint8_t start);
void bitdddec16( uint16_t *p, unsigned n, uint16_t start);
void bitdddec32( uint32_t *p, unsigned n, uint32_t start);
void bitdddec64( uint64_t *p, unsigned n, uint64_t start);
uint8_t bitdi8( uint8_t *in, unsigned n, uint8_t start);
uint16_t bitdi16( uint16_t *in, unsigned n, uint16_t start);
uint32_t bitdi32( uint32_t *in, unsigned n, uint32_t start);
uint64_t bitdi64( uint64_t *in, unsigned n, uint64_t start);
unsigned bitdienc8( uint8_t *in, unsigned n, uint8_t *out, uint8_t start, uint8_t mindelta);
unsigned bitdienc16(uint16_t *in, unsigned n, uint16_t *out, uint16_t start, uint16_t mindelta);
unsigned bitdienc32(uint32_t *in, unsigned n, uint32_t *out, uint32_t start, uint32_t mindelta);
unsigned bitdienc64(uint64_t *in, unsigned n, uint64_t *out, uint64_t start, uint64_t mindelta);
void bitdidec8( uint8_t *p, unsigned n, uint8_t start, uint8_t mindelta);
void bitdidec16( uint16_t *p, unsigned n, uint16_t start, uint16_t mindelta);
void bitdidec32( uint32_t *p, unsigned n, uint32_t start, uint32_t mindelta);
void bitdidec64( uint64_t *p, unsigned n, uint64_t start, uint64_t mindelta);
unsigned bitf8( uint8_t *in, unsigned n, uint8_t start);
unsigned bitf18( uint8_t *in, unsigned n, uint8_t start);
unsigned bitf16( uint16_t *in, unsigned n, uint16_t start);
unsigned bitf116( uint16_t *in, unsigned n, uint16_t start);
unsigned bitf32( uint32_t *in, unsigned n, uint32_t start);
unsigned bitf132( uint32_t *in, unsigned n, uint32_t start);
unsigned bitf64( uint64_t *in, unsigned n, uint64_t start);
unsigned bitf164( uint64_t *in, unsigned n, uint64_t start);
unsigned bitfm8( uint8_t *in, unsigned n, uint8_t *pmin);
unsigned bitfm16( uint16_t *in, unsigned n, uint16_t *pmin);
unsigned bitfm32( uint32_t *in, unsigned n, uint32_t *pmin);
unsigned bitfm64( uint64_t *in, unsigned n, uint64_t *pmin);
unsigned bitz8( uint8_t *in, unsigned n, uint8_t start);
unsigned bitz16( uint16_t *in, unsigned n, uint16_t start);
unsigned bitz32( uint32_t *in, unsigned n, uint32_t start);
unsigned bitz64( uint64_t *in, unsigned n, uint64_t start);
unsigned bitzenc8( uint8_t *in, unsigned n, uint8_t *out, uint8_t start, uint8_t mindelta);
unsigned bitzenc16( uint16_t *in, unsigned n, uint16_t *out, uint16_t start, uint16_t mindelta);
unsigned bitzenc32( uint32_t *in, unsigned n, uint32_t *out, uint32_t start, uint32_t mindelta);
unsigned bitzenc64( uint64_t *in, unsigned n, uint64_t *out, uint64_t start, uint64_t mindelta);
void bitzdec8( uint8_t *p, unsigned n, uint8_t start);
void bitzdec16( uint16_t *p, unsigned n, uint16_t start);
void bitzdec32( uint32_t *p, unsigned n, uint32_t start);
void bitzdec64( uint64_t *p, unsigned n, uint64_t start);
unsigned bitx8( uint8_t *in, unsigned n, uint8_t start);
unsigned bitx16( uint16_t *in, unsigned n, uint16_t start);
unsigned bitx32( uint32_t *in, unsigned n, uint32_t start);
unsigned bitx64( uint64_t *in, unsigned n, uint64_t start);
unsigned bitxenc8( uint8_t *in, unsigned n, uint8_t *out, uint8_t start);
unsigned bitxenc16( uint16_t *in, unsigned n, uint16_t *out, uint16_t start);
unsigned bitxenc32( uint32_t *in, unsigned n, uint32_t *out, uint32_t start);
unsigned bitxenc64( uint64_t *in, unsigned n, uint64_t *out, uint64_t start);
void bitxdec8( uint8_t *p, unsigned n, uint8_t start);
void bitxdec16( uint16_t *p, unsigned n, uint16_t start);
void bitxdec32( uint32_t *p, unsigned n, uint32_t start);
void bitxdec64( uint64_t *p, unsigned n, uint64_t start);
void padfloat32(float *in, size_t n, float *out, float e);
void padfloat64(double *in, size_t n, double *out, double e);
#pragma warning( disable : 4005)
#pragma warning( disable : 4090)
#pragma warning( disable : 4068)
#pragma GCC push_options
#pragma GCC optimize ("align-functions=16")
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wunsequenced"
typedef unsigned char *(*BITUNPACK_F8)( const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out);
typedef unsigned char *(*BITUNPACK_D8)( const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out, uint8_t start);
typedef unsigned char *(*BITUNPACK_F16)(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out);
typedef unsigned char *(*BITUNPACK_D16)(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out, uint16_t start);
typedef unsigned char *(*BITUNPACK_F32)(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out);
typedef unsigned char *(*BITUNPACK_D32)(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out, uint32_t start);
typedef unsigned char *(*BITUNPACK_F64)(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out);
typedef unsigned char *(*BITUNPACK_D64)(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out, uint64_t start);
unsigned char *bitunpack8_0(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out ) { unsigned char *in_=in+(((n*0)+7)/8); const uint8_t *out_ = out+n; do { { { out[0*0+ 0] = 0; out[0*0+ 1] = 0; out[0*0+ 2] = 0; out[0*0+ 3] = 0; out[0*0+ 4] = 0; out[0*0+ 5] = 0; out[0*0+ 6] = 0; out[0*0+ 7] = 0; out[0*0+ 8] = 0; out[0*0+ 9] = 0; out[0*0+10] = 0; out[0*0+11] = 0; out[0*0+12] = 0; out[0*0+13] = 0; out[0*0+14] = 0; out[0*0+15] = 0; out[0*0+16] = 0; out[0*0+17] = 0; out[0*0+18] = 0; out[0*0+19] = 0; out[0*0+20] = 0; out[0*0+21] = 0; out[0*0+22] = 0; out[0*0+23] = 0; out[0*0+24] = 0; out[0*0+25] = 0; out[0*0+26] = 0; out[0*0+27] = 0; out[0*0+28] = 0; out[0*0+29] = 0; out[0*0+30] = 0; out[0*0+31] = 0;;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitunpack8_1(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out ) { unsigned char *in_=in+(((n*1)+7)/8); do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x1; out[0*32+ 1] = (w0 >> 1) & 0x1; out[0*32+ 2] = (w0 >> 2) & 0x1; out[0*32+ 3] = (w0 >> 3) & 0x1; out[0*32+ 4] = (w0 >> 4) & 0x1; out[0*32+ 5] = (w0 >> 5) & 0x1; out[0*32+ 6] = (w0 >> 6) & 0x1; out[0*32+ 7] = (w0 >> 7) & 0x1; out[0*32+ 8] = (w0 >> 8) & 0x1; out[0*32+ 9] = (w0 >> 9) & 0x1; out[0*32+10] = (w0 >> 10) & 0x1; out[0*32+11] = (w0 >> 11) & 0x1; out[0*32+12] = (w0 >> 12) & 0x1; out[0*32+13] = (w0 >> 13) & 0x1; out[0*32+14] = (w0 >> 14) & 0x1; out[0*32+15] = (w0 >> 15) & 0x1; out[0*32+16] = (w0 >> 16) & 0x1; out[0*32+17] = (w0 >> 17) & 0x1; out[0*32+18] = (w0 >> 18) & 0x1; out[0*32+19] = (w0 >> 19) & 0x1; out[0*32+20] = (w0 >> 20) & 0x1; out[0*32+21] = (w0 >> 21) & 0x1; out[0*32+22] = (w0 >> 22) & 0x1; out[0*32+23] = (w0 >> 23) & 0x1; out[0*32+24] = (w0 >> 24) & 0x1; out[0*32+25] = (w0 >> 25) & 0x1; out[0*32+26] = (w0 >> 26) & 0x1; out[0*32+27] = (w0 >> 27) & 0x1; out[0*32+28] = (w0 >> 28) & 0x1; out[0*32+29] = (w0 >> 29) & 0x1; out[0*32+30] = (w0 >> 30) & 0x1; out[0*32+31] = (w0 >> 31);;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack8_2(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out ) { unsigned char *in_=in+(((n*2)+7)/8); do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3; out[0*32+ 1] = (w0 >> 2) & 0x3; out[0*32+ 2] = (w0 >> 4) & 0x3; out[0*32+ 3] = (w0 >> 6) & 0x3; out[0*32+ 4] = (w0 >> 8) & 0x3; out[0*32+ 5] = (w0 >> 10) & 0x3; out[0*32+ 6] = (w0 >> 12) & 0x3; out[0*32+ 7] = (w0 >> 14) & 0x3; out[0*32+ 8] = (w0 >> 16) & 0x3; out[0*32+ 9] = (w0 >> 18) & 0x3; out[0*32+10] = (w0 >> 20) & 0x3; out[0*32+11] = (w0 >> 22) & 0x3; out[0*32+12] = (w0 >> 24) & 0x3; out[0*32+13] = (w0 >> 26) & 0x3; out[0*32+14] = (w0 >> 28) & 0x3; out[0*32+15] = (w0 >> 30) & 0x3; out[0*32+16] = (w0 >> 32) & 0x3; out[0*32+17] = (w0 >> 34) & 0x3; out[0*32+18] = (w0 >> 36) & 0x3; out[0*32+19] = (w0 >> 38) & 0x3; out[0*32+20] = (w0 >> 40) & 0x3; out[0*32+21] = (w0 >> 42) & 0x3; out[0*32+22] = (w0 >> 44) & 0x3; out[0*32+23] = (w0 >> 46) & 0x3; out[0*32+24] = (w0 >> 48) & 0x3; out[0*32+25] = (w0 >> 50) & 0x3; out[0*32+26] = (w0 >> 52) & 0x3; out[0*32+27] = (w0 >> 54) & 0x3; out[0*32+28] = (w0 >> 56) & 0x3; out[0*32+29] = (w0 >> 58) & 0x3; out[0*32+30] = (w0 >> 60) & 0x3; out[0*32+31] = (w0 >> 62);;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack8_3(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out ) { unsigned char *in_=in+(((n*3)+7)/8); do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7; out[0*64+ 1] = (w0 >> 3) & 0x7; out[0*64+ 2] = (w0 >> 6) & 0x7; out[0*64+ 3] = (w0 >> 9) & 0x7; out[0*64+ 4] = (w0 >> 12) & 0x7; out[0*64+ 5] = (w0 >> 15) & 0x7; out[0*64+ 6] = (w0 >> 18) & 0x7; out[0*64+ 7] = (w0 >> 21) & 0x7; out[0*64+ 8] = (w0 >> 24) & 0x7; out[0*64+ 9] = (w0 >> 27) & 0x7; out[0*64+10] = (w0 >> 30) & 0x7; out[0*64+11] = (w0 >> 33) & 0x7; out[0*64+12] = (w0 >> 36) & 0x7; out[0*64+13] = (w0 >> 39) & 0x7; out[0*64+14] = (w0 >> 42) & 0x7; out[0*64+15] = (w0 >> 45) & 0x7; out[0*64+16] = (w0 >> 48) & 0x7; out[0*64+17] = (w0 >> 51) & 0x7; out[0*64+18] = (w0 >> 54) & 0x7; out[0*64+19] = (w0 >> 57) & 0x7; out[0*64+20] = (w0 >> 60) & 0x7; w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (w0 >> 63) | (w1 << 1) & 0x7; out[0*64+22] = (w1 >> 2) & 0x7; out[0*64+23] = (w1 >> 5) & 0x7; out[0*64+24] = (w1 >> 8) & 0x7; out[0*64+25] = (w1 >> 11) & 0x7; out[0*64+26] = (w1 >> 14) & 0x7; out[0*64+27] = (w1 >> 17) & 0x7; out[0*64+28] = (w1 >> 20) & 0x7; out[0*64+29] = (w1 >> 23) & 0x7; out[0*64+30] = (w1 >> 26) & 0x7; out[0*64+31] = (w1 >> 29) & 0x7;;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack8_4(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out ) { unsigned char *in_=in+(((n*4)+7)/8); do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xf; out[0*16+ 1] = (w0 >> 4) & 0xf; out[0*16+ 2] = (w0 >> 8) & 0xf; out[0*16+ 3] = (w0 >> 12) & 0xf; out[0*16+ 4] = (w0 >> 16) & 0xf; out[0*16+ 5] = (w0 >> 20) & 0xf; out[0*16+ 6] = (w0 >> 24) & 0xf; out[0*16+ 7] = (w0 >> 28) & 0xf; out[0*16+ 8] = (w0 >> 32) & 0xf; out[0*16+ 9] = (w0 >> 36) & 0xf; out[0*16+10] = (w0 >> 40) & 0xf; out[0*16+11] = (w0 >> 44) & 0xf; out[0*16+12] = (w0 >> 48) & 0xf; out[0*16+13] = (w0 >> 52) & 0xf; out[0*16+14] = (w0 >> 56) & 0xf; out[0*16+15] = (w0 >> 60);;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xf; out[1*16+ 1] = (w0 >> 4) & 0xf; out[1*16+ 2] = (w0 >> 8) & 0xf; out[1*16+ 3] = (w0 >> 12) & 0xf; out[1*16+ 4] = (w0 >> 16) & 0xf; out[1*16+ 5] = (w0 >> 20) & 0xf; out[1*16+ 6] = (w0 >> 24) & 0xf; out[1*16+ 7] = (w0 >> 28) & 0xf; out[1*16+ 8] = (w0 >> 32) & 0xf; out[1*16+ 9] = (w0 >> 36) & 0xf; out[1*16+10] = (w0 >> 40) & 0xf; out[1*16+11] = (w0 >> 44) & 0xf; out[1*16+12] = (w0 >> 48) & 0xf; out[1*16+13] = (w0 >> 52) & 0xf; out[1*16+14] = (w0 >> 56) & 0xf; out[1*16+15] = (w0 >> 60);;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack8_5(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out ) { unsigned char *in_=in+(((n*5)+7)/8); do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1f; out[0*64+ 1] = (w0 >> 5) & 0x1f; out[0*64+ 2] = (w0 >> 10) & 0x1f; out[0*64+ 3] = (w0 >> 15) & 0x1f; out[0*64+ 4] = (w0 >> 20) & 0x1f; out[0*64+ 5] = (w0 >> 25) & 0x1f; out[0*64+ 6] = (w0 >> 30) & 0x1f; out[0*64+ 7] = (w0 >> 35) & 0x1f; out[0*64+ 8] = (w0 >> 40) & 0x1f; out[0*64+ 9] = (w0 >> 45) & 0x1f; out[0*64+10] = (w0 >> 50) & 0x1f; out[0*64+11] = (w0 >> 55) & 0x1f; w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (w0 >> 60) | (w1 << 4) & 0x1f; out[0*64+13] = (w1 >> 1) & 0x1f; out[0*64+14] = (w1 >> 6) & 0x1f; out[0*64+15] = (w1 >> 11) & 0x1f; out[0*64+16] = (w1 >> 16) & 0x1f; out[0*64+17] = (w1 >> 21) & 0x1f; out[0*64+18] = (w1 >> 26) & 0x1f; out[0*64+19] = (w1 >> 31) & 0x1f; out[0*64+20] = (w1 >> 36) & 0x1f; out[0*64+21] = (w1 >> 41) & 0x1f; out[0*64+22] = (w1 >> 46) & 0x1f; out[0*64+23] = (w1 >> 51) & 0x1f; out[0*64+24] = (w1 >> 56) & 0x1f; w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (w1 >> 61) | (w2 << 3) & 0x1f; out[0*64+26] = (w2 >> 2) & 0x1f; out[0*64+27] = (w2 >> 7) & 0x1f; out[0*64+28] = (w2 >> 12) & 0x1f; out[0*64+29] = (w2 >> 17) & 0x1f; out[0*64+30] = (w2 >> 22) & 0x1f; out[0*64+31] = (w2 >> 27) & 0x1f;;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack8_6(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out ) { unsigned char *in_=in+(((n*6)+7)/8); do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3f; out[0*32+ 1] = (w0 >> 6) & 0x3f; out[0*32+ 2] = (w0 >> 12) & 0x3f; out[0*32+ 3] = (w0 >> 18) & 0x3f; out[0*32+ 4] = (w0 >> 24) & 0x3f; out[0*32+ 5] = (w0 >> 30) & 0x3f; out[0*32+ 6] = (w0 >> 36) & 0x3f; out[0*32+ 7] = (w0 >> 42) & 0x3f; out[0*32+ 8] = (w0 >> 48) & 0x3f; out[0*32+ 9] = (w0 >> 54) & 0x3f; w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (w0 >> 60) | (w1 << 4) & 0x3f; out[0*32+11] = (w1 >> 2) & 0x3f; out[0*32+12] = (w1 >> 8) & 0x3f; out[0*32+13] = (w1 >> 14) & 0x3f; out[0*32+14] = (w1 >> 20) & 0x3f; out[0*32+15] = (w1 >> 26) & 0x3f; out[0*32+16] = (w1 >> 32) & 0x3f; out[0*32+17] = (w1 >> 38) & 0x3f; out[0*32+18] = (w1 >> 44) & 0x3f; out[0*32+19] = (w1 >> 50) & 0x3f; out[0*32+20] = (w1 >> 56) & 0x3f; w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (w1 >> 62) | (w2 << 2) & 0x3f; out[0*32+22] = (w2 >> 4) & 0x3f; out[0*32+23] = (w2 >> 10) & 0x3f; out[0*32+24] = (w2 >> 16) & 0x3f; out[0*32+25] = (w2 >> 22) & 0x3f; out[0*32+26] = (w2 >> 28) & 0x3f; out[0*32+27] = (w2 >> 34) & 0x3f; out[0*32+28] = (w2 >> 40) & 0x3f; out[0*32+29] = (w2 >> 46) & 0x3f; out[0*32+30] = (w2 >> 52) & 0x3f; out[0*32+31] = (w2 >> 58);;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack8_7(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out ) { unsigned char *in_=in+(((n*7)+7)/8); do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7f; out[0*64+ 1] = (w0 >> 7) & 0x7f; out[0*64+ 2] = (w0 >> 14) & 0x7f; out[0*64+ 3] = (w0 >> 21) & 0x7f; out[0*64+ 4] = (w0 >> 28) & 0x7f; out[0*64+ 5] = (w0 >> 35) & 0x7f; out[0*64+ 6] = (w0 >> 42) & 0x7f; out[0*64+ 7] = (w0 >> 49) & 0x7f; out[0*64+ 8] = (w0 >> 56) & 0x7f; w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (w0 >> 63) | (w1 << 1) & 0x7f; out[0*64+10] = (w1 >> 6) & 0x7f; out[0*64+11] = (w1 >> 13) & 0x7f; out[0*64+12] = (w1 >> 20) & 0x7f; out[0*64+13] = (w1 >> 27) & 0x7f; out[0*64+14] = (w1 >> 34) & 0x7f; out[0*64+15] = (w1 >> 41) & 0x7f; out[0*64+16] = (w1 >> 48) & 0x7f; out[0*64+17] = (w1 >> 55) & 0x7f; w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (w1 >> 62) | (w2 << 2) & 0x7f; out[0*64+19] = (w2 >> 5) & 0x7f; out[0*64+20] = (w2 >> 12) & 0x7f; out[0*64+21] = (w2 >> 19) & 0x7f; out[0*64+22] = (w2 >> 26) & 0x7f; out[0*64+23] = (w2 >> 33) & 0x7f; out[0*64+24] = (w2 >> 40) & 0x7f; out[0*64+25] = (w2 >> 47) & 0x7f; out[0*64+26] = (w2 >> 54) & 0x7f; w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (w2 >> 61) | (w3 << 3) & 0x7f; out[0*64+28] = (w3 >> 4) & 0x7f; out[0*64+29] = (w3 >> 11) & 0x7f; out[0*64+30] = (w3 >> 18) & 0x7f; out[0*64+31] = (w3 >> 25) & 0x7f;;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack8_8(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out ) { unsigned char *in_=in+(((n*8)+7)/8); do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (w0 ) & 0xff; out[0*8+ 1] = (w0 >> 8) & 0xff; out[0*8+ 2] = (w0 >> 16) & 0xff; out[0*8+ 3] = (w0 >> 24) & 0xff; out[0*8+ 4] = (w0 >> 32) & 0xff; out[0*8+ 5] = (w0 >> 40) & 0xff; out[0*8+ 6] = (w0 >> 48) & 0xff; out[0*8+ 7] = (w0 >> 56);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (w0 ) & 0xff; out[1*8+ 1] = (w0 >> 8) & 0xff; out[1*8+ 2] = (w0 >> 16) & 0xff; out[1*8+ 3] = (w0 >> 24) & 0xff; out[1*8+ 4] = (w0 >> 32) & 0xff; out[1*8+ 5] = (w0 >> 40) & 0xff; out[1*8+ 6] = (w0 >> 48) & 0xff; out[1*8+ 7] = (w0 >> 56);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (w0 ) & 0xff; out[2*8+ 1] = (w0 >> 8) & 0xff; out[2*8+ 2] = (w0 >> 16) & 0xff; out[2*8+ 3] = (w0 >> 24) & 0xff; out[2*8+ 4] = (w0 >> 32) & 0xff; out[2*8+ 5] = (w0 >> 40) & 0xff; out[2*8+ 6] = (w0 >> 48) & 0xff; out[2*8+ 7] = (w0 >> 56);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (w0 ) & 0xff; out[3*8+ 1] = (w0 >> 8) & 0xff; out[3*8+ 2] = (w0 >> 16) & 0xff; out[3*8+ 3] = (w0 >> 24) & 0xff; out[3*8+ 4] = (w0 >> 32) & 0xff; out[3*8+ 5] = (w0 >> 40) & 0xff; out[3*8+ 6] = (w0 >> 48) & 0xff; out[3*8+ 7] = (w0 >> 56);;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_F8 bitunpacka8[] = {
  &bitunpack8_0,
  &bitunpack8_1,
  &bitunpack8_2,
  &bitunpack8_3,
  &bitunpack8_4,
  &bitunpack8_5,
  &bitunpack8_6,
  &bitunpack8_7,
  &bitunpack8_8
};
unsigned char *bitunpack8( const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , unsigned b) { return bitunpacka8[ b](in, n, out); }
unsigned char *bitunpack16_0(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*0)+7)/8); const uint16_t *out_ = out+n; do { { { out[0*0+ 0] = 0; out[0*0+ 1] = 0; out[0*0+ 2] = 0; out[0*0+ 3] = 0; out[0*0+ 4] = 0; out[0*0+ 5] = 0; out[0*0+ 6] = 0; out[0*0+ 7] = 0; out[0*0+ 8] = 0; out[0*0+ 9] = 0; out[0*0+10] = 0; out[0*0+11] = 0; out[0*0+12] = 0; out[0*0+13] = 0; out[0*0+14] = 0; out[0*0+15] = 0; out[0*0+16] = 0; out[0*0+17] = 0; out[0*0+18] = 0; out[0*0+19] = 0; out[0*0+20] = 0; out[0*0+21] = 0; out[0*0+22] = 0; out[0*0+23] = 0; out[0*0+24] = 0; out[0*0+25] = 0; out[0*0+26] = 0; out[0*0+27] = 0; out[0*0+28] = 0; out[0*0+29] = 0; out[0*0+30] = 0; out[0*0+31] = 0;;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitunpack16_1(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*1)+7)/8); do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x1; out[0*32+ 1] = (w0 >> 1) & 0x1; out[0*32+ 2] = (w0 >> 2) & 0x1; out[0*32+ 3] = (w0 >> 3) & 0x1; out[0*32+ 4] = (w0 >> 4) & 0x1; out[0*32+ 5] = (w0 >> 5) & 0x1; out[0*32+ 6] = (w0 >> 6) & 0x1; out[0*32+ 7] = (w0 >> 7) & 0x1; out[0*32+ 8] = (w0 >> 8) & 0x1; out[0*32+ 9] = (w0 >> 9) & 0x1; out[0*32+10] = (w0 >> 10) & 0x1; out[0*32+11] = (w0 >> 11) & 0x1; out[0*32+12] = (w0 >> 12) & 0x1; out[0*32+13] = (w0 >> 13) & 0x1; out[0*32+14] = (w0 >> 14) & 0x1; out[0*32+15] = (w0 >> 15) & 0x1; out[0*32+16] = (w0 >> 16) & 0x1; out[0*32+17] = (w0 >> 17) & 0x1; out[0*32+18] = (w0 >> 18) & 0x1; out[0*32+19] = (w0 >> 19) & 0x1; out[0*32+20] = (w0 >> 20) & 0x1; out[0*32+21] = (w0 >> 21) & 0x1; out[0*32+22] = (w0 >> 22) & 0x1; out[0*32+23] = (w0 >> 23) & 0x1; out[0*32+24] = (w0 >> 24) & 0x1; out[0*32+25] = (w0 >> 25) & 0x1; out[0*32+26] = (w0 >> 26) & 0x1; out[0*32+27] = (w0 >> 27) & 0x1; out[0*32+28] = (w0 >> 28) & 0x1; out[0*32+29] = (w0 >> 29) & 0x1; out[0*32+30] = (w0 >> 30) & 0x1; out[0*32+31] = (w0 >> 31);;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_2(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*2)+7)/8); do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3; out[0*32+ 1] = (w0 >> 2) & 0x3; out[0*32+ 2] = (w0 >> 4) & 0x3; out[0*32+ 3] = (w0 >> 6) & 0x3; out[0*32+ 4] = (w0 >> 8) & 0x3; out[0*32+ 5] = (w0 >> 10) & 0x3; out[0*32+ 6] = (w0 >> 12) & 0x3; out[0*32+ 7] = (w0 >> 14) & 0x3; out[0*32+ 8] = (w0 >> 16) & 0x3; out[0*32+ 9] = (w0 >> 18) & 0x3; out[0*32+10] = (w0 >> 20) & 0x3; out[0*32+11] = (w0 >> 22) & 0x3; out[0*32+12] = (w0 >> 24) & 0x3; out[0*32+13] = (w0 >> 26) & 0x3; out[0*32+14] = (w0 >> 28) & 0x3; out[0*32+15] = (w0 >> 30) & 0x3; out[0*32+16] = (w0 >> 32) & 0x3; out[0*32+17] = (w0 >> 34) & 0x3; out[0*32+18] = (w0 >> 36) & 0x3; out[0*32+19] = (w0 >> 38) & 0x3; out[0*32+20] = (w0 >> 40) & 0x3; out[0*32+21] = (w0 >> 42) & 0x3; out[0*32+22] = (w0 >> 44) & 0x3; out[0*32+23] = (w0 >> 46) & 0x3; out[0*32+24] = (w0 >> 48) & 0x3; out[0*32+25] = (w0 >> 50) & 0x3; out[0*32+26] = (w0 >> 52) & 0x3; out[0*32+27] = (w0 >> 54) & 0x3; out[0*32+28] = (w0 >> 56) & 0x3; out[0*32+29] = (w0 >> 58) & 0x3; out[0*32+30] = (w0 >> 60) & 0x3; out[0*32+31] = (w0 >> 62);;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_3(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*3)+7)/8); do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7; out[0*64+ 1] = (w0 >> 3) & 0x7; out[0*64+ 2] = (w0 >> 6) & 0x7; out[0*64+ 3] = (w0 >> 9) & 0x7; out[0*64+ 4] = (w0 >> 12) & 0x7; out[0*64+ 5] = (w0 >> 15) & 0x7; out[0*64+ 6] = (w0 >> 18) & 0x7; out[0*64+ 7] = (w0 >> 21) & 0x7; out[0*64+ 8] = (w0 >> 24) & 0x7; out[0*64+ 9] = (w0 >> 27) & 0x7; out[0*64+10] = (w0 >> 30) & 0x7; out[0*64+11] = (w0 >> 33) & 0x7; out[0*64+12] = (w0 >> 36) & 0x7; out[0*64+13] = (w0 >> 39) & 0x7; out[0*64+14] = (w0 >> 42) & 0x7; out[0*64+15] = (w0 >> 45) & 0x7; out[0*64+16] = (w0 >> 48) & 0x7; out[0*64+17] = (w0 >> 51) & 0x7; out[0*64+18] = (w0 >> 54) & 0x7; out[0*64+19] = (w0 >> 57) & 0x7; out[0*64+20] = (w0 >> 60) & 0x7; w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (w0 >> 63) | (w1 << 1) & 0x7; out[0*64+22] = (w1 >> 2) & 0x7; out[0*64+23] = (w1 >> 5) & 0x7; out[0*64+24] = (w1 >> 8) & 0x7; out[0*64+25] = (w1 >> 11) & 0x7; out[0*64+26] = (w1 >> 14) & 0x7; out[0*64+27] = (w1 >> 17) & 0x7; out[0*64+28] = (w1 >> 20) & 0x7; out[0*64+29] = (w1 >> 23) & 0x7; out[0*64+30] = (w1 >> 26) & 0x7; out[0*64+31] = (w1 >> 29) & 0x7;;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_4(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*4)+7)/8); do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xf; out[0*16+ 1] = (w0 >> 4) & 0xf; out[0*16+ 2] = (w0 >> 8) & 0xf; out[0*16+ 3] = (w0 >> 12) & 0xf; out[0*16+ 4] = (w0 >> 16) & 0xf; out[0*16+ 5] = (w0 >> 20) & 0xf; out[0*16+ 6] = (w0 >> 24) & 0xf; out[0*16+ 7] = (w0 >> 28) & 0xf; out[0*16+ 8] = (w0 >> 32) & 0xf; out[0*16+ 9] = (w0 >> 36) & 0xf; out[0*16+10] = (w0 >> 40) & 0xf; out[0*16+11] = (w0 >> 44) & 0xf; out[0*16+12] = (w0 >> 48) & 0xf; out[0*16+13] = (w0 >> 52) & 0xf; out[0*16+14] = (w0 >> 56) & 0xf; out[0*16+15] = (w0 >> 60);;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xf; out[1*16+ 1] = (w0 >> 4) & 0xf; out[1*16+ 2] = (w0 >> 8) & 0xf; out[1*16+ 3] = (w0 >> 12) & 0xf; out[1*16+ 4] = (w0 >> 16) & 0xf; out[1*16+ 5] = (w0 >> 20) & 0xf; out[1*16+ 6] = (w0 >> 24) & 0xf; out[1*16+ 7] = (w0 >> 28) & 0xf; out[1*16+ 8] = (w0 >> 32) & 0xf; out[1*16+ 9] = (w0 >> 36) & 0xf; out[1*16+10] = (w0 >> 40) & 0xf; out[1*16+11] = (w0 >> 44) & 0xf; out[1*16+12] = (w0 >> 48) & 0xf; out[1*16+13] = (w0 >> 52) & 0xf; out[1*16+14] = (w0 >> 56) & 0xf; out[1*16+15] = (w0 >> 60);;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_5(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*5)+7)/8); do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1f; out[0*64+ 1] = (w0 >> 5) & 0x1f; out[0*64+ 2] = (w0 >> 10) & 0x1f; out[0*64+ 3] = (w0 >> 15) & 0x1f; out[0*64+ 4] = (w0 >> 20) & 0x1f; out[0*64+ 5] = (w0 >> 25) & 0x1f; out[0*64+ 6] = (w0 >> 30) & 0x1f; out[0*64+ 7] = (w0 >> 35) & 0x1f; out[0*64+ 8] = (w0 >> 40) & 0x1f; out[0*64+ 9] = (w0 >> 45) & 0x1f; out[0*64+10] = (w0 >> 50) & 0x1f; out[0*64+11] = (w0 >> 55) & 0x1f; w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (w0 >> 60) | (w1 << 4) & 0x1f; out[0*64+13] = (w1 >> 1) & 0x1f; out[0*64+14] = (w1 >> 6) & 0x1f; out[0*64+15] = (w1 >> 11) & 0x1f; out[0*64+16] = (w1 >> 16) & 0x1f; out[0*64+17] = (w1 >> 21) & 0x1f; out[0*64+18] = (w1 >> 26) & 0x1f; out[0*64+19] = (w1 >> 31) & 0x1f; out[0*64+20] = (w1 >> 36) & 0x1f; out[0*64+21] = (w1 >> 41) & 0x1f; out[0*64+22] = (w1 >> 46) & 0x1f; out[0*64+23] = (w1 >> 51) & 0x1f; out[0*64+24] = (w1 >> 56) & 0x1f; w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (w1 >> 61) | (w2 << 3) & 0x1f; out[0*64+26] = (w2 >> 2) & 0x1f; out[0*64+27] = (w2 >> 7) & 0x1f; out[0*64+28] = (w2 >> 12) & 0x1f; out[0*64+29] = (w2 >> 17) & 0x1f; out[0*64+30] = (w2 >> 22) & 0x1f; out[0*64+31] = (w2 >> 27) & 0x1f;;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_6(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*6)+7)/8); do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3f; out[0*32+ 1] = (w0 >> 6) & 0x3f; out[0*32+ 2] = (w0 >> 12) & 0x3f; out[0*32+ 3] = (w0 >> 18) & 0x3f; out[0*32+ 4] = (w0 >> 24) & 0x3f; out[0*32+ 5] = (w0 >> 30) & 0x3f; out[0*32+ 6] = (w0 >> 36) & 0x3f; out[0*32+ 7] = (w0 >> 42) & 0x3f; out[0*32+ 8] = (w0 >> 48) & 0x3f; out[0*32+ 9] = (w0 >> 54) & 0x3f; w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (w0 >> 60) | (w1 << 4) & 0x3f; out[0*32+11] = (w1 >> 2) & 0x3f; out[0*32+12] = (w1 >> 8) & 0x3f; out[0*32+13] = (w1 >> 14) & 0x3f; out[0*32+14] = (w1 >> 20) & 0x3f; out[0*32+15] = (w1 >> 26) & 0x3f; out[0*32+16] = (w1 >> 32) & 0x3f; out[0*32+17] = (w1 >> 38) & 0x3f; out[0*32+18] = (w1 >> 44) & 0x3f; out[0*32+19] = (w1 >> 50) & 0x3f; out[0*32+20] = (w1 >> 56) & 0x3f; w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (w1 >> 62) | (w2 << 2) & 0x3f; out[0*32+22] = (w2 >> 4) & 0x3f; out[0*32+23] = (w2 >> 10) & 0x3f; out[0*32+24] = (w2 >> 16) & 0x3f; out[0*32+25] = (w2 >> 22) & 0x3f; out[0*32+26] = (w2 >> 28) & 0x3f; out[0*32+27] = (w2 >> 34) & 0x3f; out[0*32+28] = (w2 >> 40) & 0x3f; out[0*32+29] = (w2 >> 46) & 0x3f; out[0*32+30] = (w2 >> 52) & 0x3f; out[0*32+31] = (w2 >> 58);;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_7(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*7)+7)/8); do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7f; out[0*64+ 1] = (w0 >> 7) & 0x7f; out[0*64+ 2] = (w0 >> 14) & 0x7f; out[0*64+ 3] = (w0 >> 21) & 0x7f; out[0*64+ 4] = (w0 >> 28) & 0x7f; out[0*64+ 5] = (w0 >> 35) & 0x7f; out[0*64+ 6] = (w0 >> 42) & 0x7f; out[0*64+ 7] = (w0 >> 49) & 0x7f; out[0*64+ 8] = (w0 >> 56) & 0x7f; w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (w0 >> 63) | (w1 << 1) & 0x7f; out[0*64+10] = (w1 >> 6) & 0x7f; out[0*64+11] = (w1 >> 13) & 0x7f; out[0*64+12] = (w1 >> 20) & 0x7f; out[0*64+13] = (w1 >> 27) & 0x7f; out[0*64+14] = (w1 >> 34) & 0x7f; out[0*64+15] = (w1 >> 41) & 0x7f; out[0*64+16] = (w1 >> 48) & 0x7f; out[0*64+17] = (w1 >> 55) & 0x7f; w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (w1 >> 62) | (w2 << 2) & 0x7f; out[0*64+19] = (w2 >> 5) & 0x7f; out[0*64+20] = (w2 >> 12) & 0x7f; out[0*64+21] = (w2 >> 19) & 0x7f; out[0*64+22] = (w2 >> 26) & 0x7f; out[0*64+23] = (w2 >> 33) & 0x7f; out[0*64+24] = (w2 >> 40) & 0x7f; out[0*64+25] = (w2 >> 47) & 0x7f; out[0*64+26] = (w2 >> 54) & 0x7f; w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (w2 >> 61) | (w3 << 3) & 0x7f; out[0*64+28] = (w3 >> 4) & 0x7f; out[0*64+29] = (w3 >> 11) & 0x7f; out[0*64+30] = (w3 >> 18) & 0x7f; out[0*64+31] = (w3 >> 25) & 0x7f;;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_8(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*8)+7)/8); do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (w0 ) & 0xff; out[0*8+ 1] = (w0 >> 8) & 0xff; out[0*8+ 2] = (w0 >> 16) & 0xff; out[0*8+ 3] = (w0 >> 24) & 0xff; out[0*8+ 4] = (w0 >> 32) & 0xff; out[0*8+ 5] = (w0 >> 40) & 0xff; out[0*8+ 6] = (w0 >> 48) & 0xff; out[0*8+ 7] = (w0 >> 56);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (w0 ) & 0xff; out[1*8+ 1] = (w0 >> 8) & 0xff; out[1*8+ 2] = (w0 >> 16) & 0xff; out[1*8+ 3] = (w0 >> 24) & 0xff; out[1*8+ 4] = (w0 >> 32) & 0xff; out[1*8+ 5] = (w0 >> 40) & 0xff; out[1*8+ 6] = (w0 >> 48) & 0xff; out[1*8+ 7] = (w0 >> 56);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (w0 ) & 0xff; out[2*8+ 1] = (w0 >> 8) & 0xff; out[2*8+ 2] = (w0 >> 16) & 0xff; out[2*8+ 3] = (w0 >> 24) & 0xff; out[2*8+ 4] = (w0 >> 32) & 0xff; out[2*8+ 5] = (w0 >> 40) & 0xff; out[2*8+ 6] = (w0 >> 48) & 0xff; out[2*8+ 7] = (w0 >> 56);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (w0 ) & 0xff; out[3*8+ 1] = (w0 >> 8) & 0xff; out[3*8+ 2] = (w0 >> 16) & 0xff; out[3*8+ 3] = (w0 >> 24) & 0xff; out[3*8+ 4] = (w0 >> 32) & 0xff; out[3*8+ 5] = (w0 >> 40) & 0xff; out[3*8+ 6] = (w0 >> 48) & 0xff; out[3*8+ 7] = (w0 >> 56);;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_9(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*9)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1ff; out[0*64+ 1] = (w0 >> 9) & 0x1ff; out[0*64+ 2] = (w0 >> 18) & 0x1ff; out[0*64+ 3] = (w0 >> 27) & 0x1ff; out[0*64+ 4] = (w0 >> 36) & 0x1ff; out[0*64+ 5] = (w0 >> 45) & 0x1ff; out[0*64+ 6] = (w0 >> 54) & 0x1ff; w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (w0 >> 63) | (w1 << 1) & 0x1ff; out[0*64+ 8] = (w1 >> 8) & 0x1ff; out[0*64+ 9] = (w1 >> 17) & 0x1ff; out[0*64+10] = (w1 >> 26) & 0x1ff; out[0*64+11] = (w1 >> 35) & 0x1ff; out[0*64+12] = (w1 >> 44) & 0x1ff; out[0*64+13] = (w1 >> 53) & 0x1ff; w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (w1 >> 62) | (w2 << 2) & 0x1ff; out[0*64+15] = (w2 >> 7) & 0x1ff; out[0*64+16] = (w2 >> 16) & 0x1ff; out[0*64+17] = (w2 >> 25) & 0x1ff; out[0*64+18] = (w2 >> 34) & 0x1ff; out[0*64+19] = (w2 >> 43) & 0x1ff; out[0*64+20] = (w2 >> 52) & 0x1ff; w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (w2 >> 61) | (w3 << 3) & 0x1ff; out[0*64+22] = (w3 >> 6) & 0x1ff; out[0*64+23] = (w3 >> 15) & 0x1ff; out[0*64+24] = (w3 >> 24) & 0x1ff; out[0*64+25] = (w3 >> 33) & 0x1ff; out[0*64+26] = (w3 >> 42) & 0x1ff; out[0*64+27] = (w3 >> 51) & 0x1ff; w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (w3 >> 60) | (w4 << 4) & 0x1ff; out[0*64+29] = (w4 >> 5) & 0x1ff; out[0*64+30] = (w4 >> 14) & 0x1ff; out[0*64+31] = (w4 >> 23) & 0x1ff;;}; out += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_10(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*10)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3ff; out[0*32+ 1] = (w0 >> 10) & 0x3ff; out[0*32+ 2] = (w0 >> 20) & 0x3ff; out[0*32+ 3] = (w0 >> 30) & 0x3ff; out[0*32+ 4] = (w0 >> 40) & 0x3ff; out[0*32+ 5] = (w0 >> 50) & 0x3ff; w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (w0 >> 60) | (w1 << 4) & 0x3ff; out[0*32+ 7] = (w1 >> 6) & 0x3ff; out[0*32+ 8] = (w1 >> 16) & 0x3ff; out[0*32+ 9] = (w1 >> 26) & 0x3ff; out[0*32+10] = (w1 >> 36) & 0x3ff; out[0*32+11] = (w1 >> 46) & 0x3ff; w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (w1 >> 56) | (w2 << 8) & 0x3ff; out[0*32+13] = (w2 >> 2) & 0x3ff; out[0*32+14] = (w2 >> 12) & 0x3ff; out[0*32+15] = (w2 >> 22) & 0x3ff; out[0*32+16] = (w2 >> 32) & 0x3ff; out[0*32+17] = (w2 >> 42) & 0x3ff; out[0*32+18] = (w2 >> 52) & 0x3ff; w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (w2 >> 62) | (w3 << 2) & 0x3ff; out[0*32+20] = (w3 >> 8) & 0x3ff; out[0*32+21] = (w3 >> 18) & 0x3ff; out[0*32+22] = (w3 >> 28) & 0x3ff; out[0*32+23] = (w3 >> 38) & 0x3ff; out[0*32+24] = (w3 >> 48) & 0x3ff; w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (w3 >> 58) | (w4 << 6) & 0x3ff; out[0*32+26] = (w4 >> 4) & 0x3ff; out[0*32+27] = (w4 >> 14) & 0x3ff; out[0*32+28] = (w4 >> 24) & 0x3ff; out[0*32+29] = (w4 >> 34) & 0x3ff; out[0*32+30] = (w4 >> 44) & 0x3ff; out[0*32+31] = (w4 >> 54);;}; out += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_11(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*11)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7ff; out[0*64+ 1] = (w0 >> 11) & 0x7ff; out[0*64+ 2] = (w0 >> 22) & 0x7ff; out[0*64+ 3] = (w0 >> 33) & 0x7ff; out[0*64+ 4] = (w0 >> 44) & 0x7ff; w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (w0 >> 55) | (w1 << 9) & 0x7ff; out[0*64+ 6] = (w1 >> 2) & 0x7ff; out[0*64+ 7] = (w1 >> 13) & 0x7ff; out[0*64+ 8] = (w1 >> 24) & 0x7ff; out[0*64+ 9] = (w1 >> 35) & 0x7ff; out[0*64+10] = (w1 >> 46) & 0x7ff; w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (w1 >> 57) | (w2 << 7) & 0x7ff; out[0*64+12] = (w2 >> 4) & 0x7ff; out[0*64+13] = (w2 >> 15) & 0x7ff; out[0*64+14] = (w2 >> 26) & 0x7ff; out[0*64+15] = (w2 >> 37) & 0x7ff; out[0*64+16] = (w2 >> 48) & 0x7ff; w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (w2 >> 59) | (w3 << 5) & 0x7ff; out[0*64+18] = (w3 >> 6) & 0x7ff; out[0*64+19] = (w3 >> 17) & 0x7ff; out[0*64+20] = (w3 >> 28) & 0x7ff; out[0*64+21] = (w3 >> 39) & 0x7ff; out[0*64+22] = (w3 >> 50) & 0x7ff; w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (w3 >> 61) | (w4 << 3) & 0x7ff; out[0*64+24] = (w4 >> 8) & 0x7ff; out[0*64+25] = (w4 >> 19) & 0x7ff; out[0*64+26] = (w4 >> 30) & 0x7ff; out[0*64+27] = (w4 >> 41) & 0x7ff; out[0*64+28] = (w4 >> 52) & 0x7ff; w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (w4 >> 63) | (w5 << 1) & 0x7ff; out[0*64+30] = (w5 >> 10) & 0x7ff; out[0*64+31] = (w5 >> 21) & 0x7ff;;}; out += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_12(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*12)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xfff; out[0*16+ 1] = (w0 >> 12) & 0xfff; out[0*16+ 2] = (w0 >> 24) & 0xfff; out[0*16+ 3] = (w0 >> 36) & 0xfff; out[0*16+ 4] = (w0 >> 48) & 0xfff; w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (w0 >> 60) | (w1 << 4) & 0xfff; out[0*16+ 6] = (w1 >> 8) & 0xfff; out[0*16+ 7] = (w1 >> 20) & 0xfff; out[0*16+ 8] = (w1 >> 32) & 0xfff; out[0*16+ 9] = (w1 >> 44) & 0xfff; w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (w1 >> 56) | (w2 << 8) & 0xfff; out[0*16+11] = (w2 >> 4) & 0xfff; out[0*16+12] = (w2 >> 16) & 0xfff; out[0*16+13] = (w2 >> 28) & 0xfff; out[0*16+14] = (w2 >> 40) & 0xfff; out[0*16+15] = (w2 >> 52);;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xfff; out[1*16+ 1] = (w0 >> 12) & 0xfff; out[1*16+ 2] = (w0 >> 24) & 0xfff; out[1*16+ 3] = (w0 >> 36) & 0xfff; out[1*16+ 4] = (w0 >> 48) & 0xfff; w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (w0 >> 60) | (w1 << 4) & 0xfff; out[1*16+ 6] = (w1 >> 8) & 0xfff; out[1*16+ 7] = (w1 >> 20) & 0xfff; out[1*16+ 8] = (w1 >> 32) & 0xfff; out[1*16+ 9] = (w1 >> 44) & 0xfff; w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (w1 >> 56) | (w2 << 8) & 0xfff; out[1*16+11] = (w2 >> 4) & 0xfff; out[1*16+12] = (w2 >> 16) & 0xfff; out[1*16+13] = (w2 >> 28) & 0xfff; out[1*16+14] = (w2 >> 40) & 0xfff; out[1*16+15] = (w2 >> 52);;}; out += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_13(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*13)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1fff; out[0*64+ 1] = (w0 >> 13) & 0x1fff; out[0*64+ 2] = (w0 >> 26) & 0x1fff; out[0*64+ 3] = (w0 >> 39) & 0x1fff; w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (w0 >> 52) | (w1 << 12) & 0x1fff; out[0*64+ 5] = (w1 >> 1) & 0x1fff; out[0*64+ 6] = (w1 >> 14) & 0x1fff; out[0*64+ 7] = (w1 >> 27) & 0x1fff; out[0*64+ 8] = (w1 >> 40) & 0x1fff; w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (w1 >> 53) | (w2 << 11) & 0x1fff; out[0*64+10] = (w2 >> 2) & 0x1fff; out[0*64+11] = (w2 >> 15) & 0x1fff; out[0*64+12] = (w2 >> 28) & 0x1fff; out[0*64+13] = (w2 >> 41) & 0x1fff; w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (w2 >> 54) | (w3 << 10) & 0x1fff; out[0*64+15] = (w3 >> 3) & 0x1fff; out[0*64+16] = (w3 >> 16) & 0x1fff; out[0*64+17] = (w3 >> 29) & 0x1fff; out[0*64+18] = (w3 >> 42) & 0x1fff; w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (w3 >> 55) | (w4 << 9) & 0x1fff; out[0*64+20] = (w4 >> 4) & 0x1fff; out[0*64+21] = (w4 >> 17) & 0x1fff; out[0*64+22] = (w4 >> 30) & 0x1fff; out[0*64+23] = (w4 >> 43) & 0x1fff; w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (w4 >> 56) | (w5 << 8) & 0x1fff; out[0*64+25] = (w5 >> 5) & 0x1fff; out[0*64+26] = (w5 >> 18) & 0x1fff; out[0*64+27] = (w5 >> 31) & 0x1fff; out[0*64+28] = (w5 >> 44) & 0x1fff; w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (w5 >> 57) | (w6 << 7) & 0x1fff; out[0*64+30] = (w6 >> 6) & 0x1fff; out[0*64+31] = (w6 >> 19) & 0x1fff;;}; out += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_14(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*14)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3fff; out[0*32+ 1] = (w0 >> 14) & 0x3fff; out[0*32+ 2] = (w0 >> 28) & 0x3fff; out[0*32+ 3] = (w0 >> 42) & 0x3fff; w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (w0 >> 56) | (w1 << 8) & 0x3fff; out[0*32+ 5] = (w1 >> 6) & 0x3fff; out[0*32+ 6] = (w1 >> 20) & 0x3fff; out[0*32+ 7] = (w1 >> 34) & 0x3fff; out[0*32+ 8] = (w1 >> 48) & 0x3fff; w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (w1 >> 62) | (w2 << 2) & 0x3fff; out[0*32+10] = (w2 >> 12) & 0x3fff; out[0*32+11] = (w2 >> 26) & 0x3fff; out[0*32+12] = (w2 >> 40) & 0x3fff; w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (w2 >> 54) | (w3 << 10) & 0x3fff; out[0*32+14] = (w3 >> 4) & 0x3fff; out[0*32+15] = (w3 >> 18) & 0x3fff; out[0*32+16] = (w3 >> 32) & 0x3fff; out[0*32+17] = (w3 >> 46) & 0x3fff; w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (w3 >> 60) | (w4 << 4) & 0x3fff; out[0*32+19] = (w4 >> 10) & 0x3fff; out[0*32+20] = (w4 >> 24) & 0x3fff; out[0*32+21] = (w4 >> 38) & 0x3fff; w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (w4 >> 52) | (w5 << 12) & 0x3fff; out[0*32+23] = (w5 >> 2) & 0x3fff; out[0*32+24] = (w5 >> 16) & 0x3fff; out[0*32+25] = (w5 >> 30) & 0x3fff; out[0*32+26] = (w5 >> 44) & 0x3fff; w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (w5 >> 58) | (w6 << 6) & 0x3fff; out[0*32+28] = (w6 >> 8) & 0x3fff; out[0*32+29] = (w6 >> 22) & 0x3fff; out[0*32+30] = (w6 >> 36) & 0x3fff; out[0*32+31] = (w6 >> 50);;}; out += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_15(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*15)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7fff; out[0*64+ 1] = (w0 >> 15) & 0x7fff; out[0*64+ 2] = (w0 >> 30) & 0x7fff; out[0*64+ 3] = (w0 >> 45) & 0x7fff; w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (w0 >> 60) | (w1 << 4) & 0x7fff; out[0*64+ 5] = (w1 >> 11) & 0x7fff; out[0*64+ 6] = (w1 >> 26) & 0x7fff; out[0*64+ 7] = (w1 >> 41) & 0x7fff; w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (w1 >> 56) | (w2 << 8) & 0x7fff; out[0*64+ 9] = (w2 >> 7) & 0x7fff; out[0*64+10] = (w2 >> 22) & 0x7fff; out[0*64+11] = (w2 >> 37) & 0x7fff; w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (w2 >> 52) | (w3 << 12) & 0x7fff; out[0*64+13] = (w3 >> 3) & 0x7fff; out[0*64+14] = (w3 >> 18) & 0x7fff; out[0*64+15] = (w3 >> 33) & 0x7fff; out[0*64+16] = (w3 >> 48) & 0x7fff; w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (w3 >> 63) | (w4 << 1) & 0x7fff; out[0*64+18] = (w4 >> 14) & 0x7fff; out[0*64+19] = (w4 >> 29) & 0x7fff; out[0*64+20] = (w4 >> 44) & 0x7fff; w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (w4 >> 59) | (w5 << 5) & 0x7fff; out[0*64+22] = (w5 >> 10) & 0x7fff; out[0*64+23] = (w5 >> 25) & 0x7fff; out[0*64+24] = (w5 >> 40) & 0x7fff; w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (w5 >> 55) | (w6 << 9) & 0x7fff; out[0*64+26] = (w6 >> 6) & 0x7fff; out[0*64+27] = (w6 >> 21) & 0x7fff; out[0*64+28] = (w6 >> 36) & 0x7fff; w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (w6 >> 51) | (w7 << 13) & 0x7fff; out[0*64+30] = (w7 >> 2) & 0x7fff; out[0*64+31] = (w7 >> 17) & 0x7fff;;}; out += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack16_16(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out ) { unsigned char *in_=in+(((n*16)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = *(uint16_t *)(in+0*8+ 0); out[0*4+ 1] = *(uint16_t *)(in+0*8+ 2); out[0*4+ 2] = *(uint16_t *)(in+0*8+ 4); out[0*4+ 3] = *(uint16_t *)(in+0*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = *(uint16_t *)(in+1*8+ 0); out[1*4+ 1] = *(uint16_t *)(in+1*8+ 2); out[1*4+ 2] = *(uint16_t *)(in+1*8+ 4); out[1*4+ 3] = *(uint16_t *)(in+1*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = *(uint16_t *)(in+2*8+ 0); out[2*4+ 1] = *(uint16_t *)(in+2*8+ 2); out[2*4+ 2] = *(uint16_t *)(in+2*8+ 4); out[2*4+ 3] = *(uint16_t *)(in+2*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = *(uint16_t *)(in+3*8+ 0); out[3*4+ 1] = *(uint16_t *)(in+3*8+ 2); out[3*4+ 2] = *(uint16_t *)(in+3*8+ 4); out[3*4+ 3] = *(uint16_t *)(in+3*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = *(uint16_t *)(in+4*8+ 0); out[4*4+ 1] = *(uint16_t *)(in+4*8+ 2); out[4*4+ 2] = *(uint16_t *)(in+4*8+ 4); out[4*4+ 3] = *(uint16_t *)(in+4*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = *(uint16_t *)(in+5*8+ 0); out[5*4+ 1] = *(uint16_t *)(in+5*8+ 2); out[5*4+ 2] = *(uint16_t *)(in+5*8+ 4); out[5*4+ 3] = *(uint16_t *)(in+5*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = *(uint16_t *)(in+6*8+ 0); out[6*4+ 1] = *(uint16_t *)(in+6*8+ 2); out[6*4+ 2] = *(uint16_t *)(in+6*8+ 4); out[6*4+ 3] = *(uint16_t *)(in+6*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = *(uint16_t *)(in+7*8+ 0); out[7*4+ 1] = *(uint16_t *)(in+7*8+ 2); out[7*4+ 2] = *(uint16_t *)(in+7*8+ 4); out[7*4+ 3] = *(uint16_t *)(in+7*8+ 6);;}; out += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_F16 bitunpacka16[] = {
  &bitunpack16_0,
  &bitunpack16_1,
  &bitunpack16_2,
  &bitunpack16_3,
  &bitunpack16_4,
  &bitunpack16_5,
  &bitunpack16_6,
  &bitunpack16_7,
  &bitunpack16_8,
  &bitunpack16_9,
  &bitunpack16_10,
  &bitunpack16_11,
  &bitunpack16_12,
  &bitunpack16_13,
  &bitunpack16_14,
  &bitunpack16_15,
  &bitunpack16_16
};
unsigned char *bitunpack16( const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , unsigned b) { return bitunpacka16[ b](in, n, out); }
unsigned char *bitunpack32_0(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*0)+7)/8); const uint32_t *out_ = out+n; do { { { out[0*0+ 0] = 0; out[0*0+ 1] = 0; out[0*0+ 2] = 0; out[0*0+ 3] = 0; out[0*0+ 4] = 0; out[0*0+ 5] = 0; out[0*0+ 6] = 0; out[0*0+ 7] = 0; out[0*0+ 8] = 0; out[0*0+ 9] = 0; out[0*0+10] = 0; out[0*0+11] = 0; out[0*0+12] = 0; out[0*0+13] = 0; out[0*0+14] = 0; out[0*0+15] = 0; out[0*0+16] = 0; out[0*0+17] = 0; out[0*0+18] = 0; out[0*0+19] = 0; out[0*0+20] = 0; out[0*0+21] = 0; out[0*0+22] = 0; out[0*0+23] = 0; out[0*0+24] = 0; out[0*0+25] = 0; out[0*0+26] = 0; out[0*0+27] = 0; out[0*0+28] = 0; out[0*0+29] = 0; out[0*0+30] = 0; out[0*0+31] = 0;;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitunpack32_1(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*1)+7)/8); do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x1; out[0*32+ 1] = (w0 >> 1) & 0x1; out[0*32+ 2] = (w0 >> 2) & 0x1; out[0*32+ 3] = (w0 >> 3) & 0x1; out[0*32+ 4] = (w0 >> 4) & 0x1; out[0*32+ 5] = (w0 >> 5) & 0x1; out[0*32+ 6] = (w0 >> 6) & 0x1; out[0*32+ 7] = (w0 >> 7) & 0x1; out[0*32+ 8] = (w0 >> 8) & 0x1; out[0*32+ 9] = (w0 >> 9) & 0x1; out[0*32+10] = (w0 >> 10) & 0x1; out[0*32+11] = (w0 >> 11) & 0x1; out[0*32+12] = (w0 >> 12) & 0x1; out[0*32+13] = (w0 >> 13) & 0x1; out[0*32+14] = (w0 >> 14) & 0x1; out[0*32+15] = (w0 >> 15) & 0x1; out[0*32+16] = (w0 >> 16) & 0x1; out[0*32+17] = (w0 >> 17) & 0x1; out[0*32+18] = (w0 >> 18) & 0x1; out[0*32+19] = (w0 >> 19) & 0x1; out[0*32+20] = (w0 >> 20) & 0x1; out[0*32+21] = (w0 >> 21) & 0x1; out[0*32+22] = (w0 >> 22) & 0x1; out[0*32+23] = (w0 >> 23) & 0x1; out[0*32+24] = (w0 >> 24) & 0x1; out[0*32+25] = (w0 >> 25) & 0x1; out[0*32+26] = (w0 >> 26) & 0x1; out[0*32+27] = (w0 >> 27) & 0x1; out[0*32+28] = (w0 >> 28) & 0x1; out[0*32+29] = (w0 >> 29) & 0x1; out[0*32+30] = (w0 >> 30) & 0x1; out[0*32+31] = (w0 >> 31);;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_2(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*2)+7)/8); do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3; out[0*32+ 1] = (w0 >> 2) & 0x3; out[0*32+ 2] = (w0 >> 4) & 0x3; out[0*32+ 3] = (w0 >> 6) & 0x3; out[0*32+ 4] = (w0 >> 8) & 0x3; out[0*32+ 5] = (w0 >> 10) & 0x3; out[0*32+ 6] = (w0 >> 12) & 0x3; out[0*32+ 7] = (w0 >> 14) & 0x3; out[0*32+ 8] = (w0 >> 16) & 0x3; out[0*32+ 9] = (w0 >> 18) & 0x3; out[0*32+10] = (w0 >> 20) & 0x3; out[0*32+11] = (w0 >> 22) & 0x3; out[0*32+12] = (w0 >> 24) & 0x3; out[0*32+13] = (w0 >> 26) & 0x3; out[0*32+14] = (w0 >> 28) & 0x3; out[0*32+15] = (w0 >> 30) & 0x3; out[0*32+16] = (w0 >> 32) & 0x3; out[0*32+17] = (w0 >> 34) & 0x3; out[0*32+18] = (w0 >> 36) & 0x3; out[0*32+19] = (w0 >> 38) & 0x3; out[0*32+20] = (w0 >> 40) & 0x3; out[0*32+21] = (w0 >> 42) & 0x3; out[0*32+22] = (w0 >> 44) & 0x3; out[0*32+23] = (w0 >> 46) & 0x3; out[0*32+24] = (w0 >> 48) & 0x3; out[0*32+25] = (w0 >> 50) & 0x3; out[0*32+26] = (w0 >> 52) & 0x3; out[0*32+27] = (w0 >> 54) & 0x3; out[0*32+28] = (w0 >> 56) & 0x3; out[0*32+29] = (w0 >> 58) & 0x3; out[0*32+30] = (w0 >> 60) & 0x3; out[0*32+31] = (w0 >> 62);;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_3(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*3)+7)/8); do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7; out[0*64+ 1] = (w0 >> 3) & 0x7; out[0*64+ 2] = (w0 >> 6) & 0x7; out[0*64+ 3] = (w0 >> 9) & 0x7; out[0*64+ 4] = (w0 >> 12) & 0x7; out[0*64+ 5] = (w0 >> 15) & 0x7; out[0*64+ 6] = (w0 >> 18) & 0x7; out[0*64+ 7] = (w0 >> 21) & 0x7; out[0*64+ 8] = (w0 >> 24) & 0x7; out[0*64+ 9] = (w0 >> 27) & 0x7; out[0*64+10] = (w0 >> 30) & 0x7; out[0*64+11] = (w0 >> 33) & 0x7; out[0*64+12] = (w0 >> 36) & 0x7; out[0*64+13] = (w0 >> 39) & 0x7; out[0*64+14] = (w0 >> 42) & 0x7; out[0*64+15] = (w0 >> 45) & 0x7; out[0*64+16] = (w0 >> 48) & 0x7; out[0*64+17] = (w0 >> 51) & 0x7; out[0*64+18] = (w0 >> 54) & 0x7; out[0*64+19] = (w0 >> 57) & 0x7; out[0*64+20] = (w0 >> 60) & 0x7; w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (w0 >> 63) | (w1 << 1) & 0x7; out[0*64+22] = (w1 >> 2) & 0x7; out[0*64+23] = (w1 >> 5) & 0x7; out[0*64+24] = (w1 >> 8) & 0x7; out[0*64+25] = (w1 >> 11) & 0x7; out[0*64+26] = (w1 >> 14) & 0x7; out[0*64+27] = (w1 >> 17) & 0x7; out[0*64+28] = (w1 >> 20) & 0x7; out[0*64+29] = (w1 >> 23) & 0x7; out[0*64+30] = (w1 >> 26) & 0x7; out[0*64+31] = (w1 >> 29) & 0x7;;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_4(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*4)+7)/8); do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xf; out[0*16+ 1] = (w0 >> 4) & 0xf; out[0*16+ 2] = (w0 >> 8) & 0xf; out[0*16+ 3] = (w0 >> 12) & 0xf; out[0*16+ 4] = (w0 >> 16) & 0xf; out[0*16+ 5] = (w0 >> 20) & 0xf; out[0*16+ 6] = (w0 >> 24) & 0xf; out[0*16+ 7] = (w0 >> 28) & 0xf; out[0*16+ 8] = (w0 >> 32) & 0xf; out[0*16+ 9] = (w0 >> 36) & 0xf; out[0*16+10] = (w0 >> 40) & 0xf; out[0*16+11] = (w0 >> 44) & 0xf; out[0*16+12] = (w0 >> 48) & 0xf; out[0*16+13] = (w0 >> 52) & 0xf; out[0*16+14] = (w0 >> 56) & 0xf; out[0*16+15] = (w0 >> 60);;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xf; out[1*16+ 1] = (w0 >> 4) & 0xf; out[1*16+ 2] = (w0 >> 8) & 0xf; out[1*16+ 3] = (w0 >> 12) & 0xf; out[1*16+ 4] = (w0 >> 16) & 0xf; out[1*16+ 5] = (w0 >> 20) & 0xf; out[1*16+ 6] = (w0 >> 24) & 0xf; out[1*16+ 7] = (w0 >> 28) & 0xf; out[1*16+ 8] = (w0 >> 32) & 0xf; out[1*16+ 9] = (w0 >> 36) & 0xf; out[1*16+10] = (w0 >> 40) & 0xf; out[1*16+11] = (w0 >> 44) & 0xf; out[1*16+12] = (w0 >> 48) & 0xf; out[1*16+13] = (w0 >> 52) & 0xf; out[1*16+14] = (w0 >> 56) & 0xf; out[1*16+15] = (w0 >> 60);;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_5(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*5)+7)/8); do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1f; out[0*64+ 1] = (w0 >> 5) & 0x1f; out[0*64+ 2] = (w0 >> 10) & 0x1f; out[0*64+ 3] = (w0 >> 15) & 0x1f; out[0*64+ 4] = (w0 >> 20) & 0x1f; out[0*64+ 5] = (w0 >> 25) & 0x1f; out[0*64+ 6] = (w0 >> 30) & 0x1f; out[0*64+ 7] = (w0 >> 35) & 0x1f; out[0*64+ 8] = (w0 >> 40) & 0x1f; out[0*64+ 9] = (w0 >> 45) & 0x1f; out[0*64+10] = (w0 >> 50) & 0x1f; out[0*64+11] = (w0 >> 55) & 0x1f; w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (w0 >> 60) | (w1 << 4) & 0x1f; out[0*64+13] = (w1 >> 1) & 0x1f; out[0*64+14] = (w1 >> 6) & 0x1f; out[0*64+15] = (w1 >> 11) & 0x1f; out[0*64+16] = (w1 >> 16) & 0x1f; out[0*64+17] = (w1 >> 21) & 0x1f; out[0*64+18] = (w1 >> 26) & 0x1f; out[0*64+19] = (w1 >> 31) & 0x1f; out[0*64+20] = (w1 >> 36) & 0x1f; out[0*64+21] = (w1 >> 41) & 0x1f; out[0*64+22] = (w1 >> 46) & 0x1f; out[0*64+23] = (w1 >> 51) & 0x1f; out[0*64+24] = (w1 >> 56) & 0x1f; w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (w1 >> 61) | (w2 << 3) & 0x1f; out[0*64+26] = (w2 >> 2) & 0x1f; out[0*64+27] = (w2 >> 7) & 0x1f; out[0*64+28] = (w2 >> 12) & 0x1f; out[0*64+29] = (w2 >> 17) & 0x1f; out[0*64+30] = (w2 >> 22) & 0x1f; out[0*64+31] = (w2 >> 27) & 0x1f;;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_6(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*6)+7)/8); do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3f; out[0*32+ 1] = (w0 >> 6) & 0x3f; out[0*32+ 2] = (w0 >> 12) & 0x3f; out[0*32+ 3] = (w0 >> 18) & 0x3f; out[0*32+ 4] = (w0 >> 24) & 0x3f; out[0*32+ 5] = (w0 >> 30) & 0x3f; out[0*32+ 6] = (w0 >> 36) & 0x3f; out[0*32+ 7] = (w0 >> 42) & 0x3f; out[0*32+ 8] = (w0 >> 48) & 0x3f; out[0*32+ 9] = (w0 >> 54) & 0x3f; w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (w0 >> 60) | (w1 << 4) & 0x3f; out[0*32+11] = (w1 >> 2) & 0x3f; out[0*32+12] = (w1 >> 8) & 0x3f; out[0*32+13] = (w1 >> 14) & 0x3f; out[0*32+14] = (w1 >> 20) & 0x3f; out[0*32+15] = (w1 >> 26) & 0x3f; out[0*32+16] = (w1 >> 32) & 0x3f; out[0*32+17] = (w1 >> 38) & 0x3f; out[0*32+18] = (w1 >> 44) & 0x3f; out[0*32+19] = (w1 >> 50) & 0x3f; out[0*32+20] = (w1 >> 56) & 0x3f; w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (w1 >> 62) | (w2 << 2) & 0x3f; out[0*32+22] = (w2 >> 4) & 0x3f; out[0*32+23] = (w2 >> 10) & 0x3f; out[0*32+24] = (w2 >> 16) & 0x3f; out[0*32+25] = (w2 >> 22) & 0x3f; out[0*32+26] = (w2 >> 28) & 0x3f; out[0*32+27] = (w2 >> 34) & 0x3f; out[0*32+28] = (w2 >> 40) & 0x3f; out[0*32+29] = (w2 >> 46) & 0x3f; out[0*32+30] = (w2 >> 52) & 0x3f; out[0*32+31] = (w2 >> 58);;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_7(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*7)+7)/8); do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7f; out[0*64+ 1] = (w0 >> 7) & 0x7f; out[0*64+ 2] = (w0 >> 14) & 0x7f; out[0*64+ 3] = (w0 >> 21) & 0x7f; out[0*64+ 4] = (w0 >> 28) & 0x7f; out[0*64+ 5] = (w0 >> 35) & 0x7f; out[0*64+ 6] = (w0 >> 42) & 0x7f; out[0*64+ 7] = (w0 >> 49) & 0x7f; out[0*64+ 8] = (w0 >> 56) & 0x7f; w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (w0 >> 63) | (w1 << 1) & 0x7f; out[0*64+10] = (w1 >> 6) & 0x7f; out[0*64+11] = (w1 >> 13) & 0x7f; out[0*64+12] = (w1 >> 20) & 0x7f; out[0*64+13] = (w1 >> 27) & 0x7f; out[0*64+14] = (w1 >> 34) & 0x7f; out[0*64+15] = (w1 >> 41) & 0x7f; out[0*64+16] = (w1 >> 48) & 0x7f; out[0*64+17] = (w1 >> 55) & 0x7f; w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (w1 >> 62) | (w2 << 2) & 0x7f; out[0*64+19] = (w2 >> 5) & 0x7f; out[0*64+20] = (w2 >> 12) & 0x7f; out[0*64+21] = (w2 >> 19) & 0x7f; out[0*64+22] = (w2 >> 26) & 0x7f; out[0*64+23] = (w2 >> 33) & 0x7f; out[0*64+24] = (w2 >> 40) & 0x7f; out[0*64+25] = (w2 >> 47) & 0x7f; out[0*64+26] = (w2 >> 54) & 0x7f; w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (w2 >> 61) | (w3 << 3) & 0x7f; out[0*64+28] = (w3 >> 4) & 0x7f; out[0*64+29] = (w3 >> 11) & 0x7f; out[0*64+30] = (w3 >> 18) & 0x7f; out[0*64+31] = (w3 >> 25) & 0x7f;;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_8(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*8)+7)/8); do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (w0 ) & 0xff; out[0*8+ 1] = (w0 >> 8) & 0xff; out[0*8+ 2] = (w0 >> 16) & 0xff; out[0*8+ 3] = (w0 >> 24) & 0xff; out[0*8+ 4] = (w0 >> 32) & 0xff; out[0*8+ 5] = (w0 >> 40) & 0xff; out[0*8+ 6] = (w0 >> 48) & 0xff; out[0*8+ 7] = (w0 >> 56);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (w0 ) & 0xff; out[1*8+ 1] = (w0 >> 8) & 0xff; out[1*8+ 2] = (w0 >> 16) & 0xff; out[1*8+ 3] = (w0 >> 24) & 0xff; out[1*8+ 4] = (w0 >> 32) & 0xff; out[1*8+ 5] = (w0 >> 40) & 0xff; out[1*8+ 6] = (w0 >> 48) & 0xff; out[1*8+ 7] = (w0 >> 56);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (w0 ) & 0xff; out[2*8+ 1] = (w0 >> 8) & 0xff; out[2*8+ 2] = (w0 >> 16) & 0xff; out[2*8+ 3] = (w0 >> 24) & 0xff; out[2*8+ 4] = (w0 >> 32) & 0xff; out[2*8+ 5] = (w0 >> 40) & 0xff; out[2*8+ 6] = (w0 >> 48) & 0xff; out[2*8+ 7] = (w0 >> 56);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (w0 ) & 0xff; out[3*8+ 1] = (w0 >> 8) & 0xff; out[3*8+ 2] = (w0 >> 16) & 0xff; out[3*8+ 3] = (w0 >> 24) & 0xff; out[3*8+ 4] = (w0 >> 32) & 0xff; out[3*8+ 5] = (w0 >> 40) & 0xff; out[3*8+ 6] = (w0 >> 48) & 0xff; out[3*8+ 7] = (w0 >> 56);;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_9(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*9)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1ff; out[0*64+ 1] = (w0 >> 9) & 0x1ff; out[0*64+ 2] = (w0 >> 18) & 0x1ff; out[0*64+ 3] = (w0 >> 27) & 0x1ff; out[0*64+ 4] = (w0 >> 36) & 0x1ff; out[0*64+ 5] = (w0 >> 45) & 0x1ff; out[0*64+ 6] = (w0 >> 54) & 0x1ff; w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (w0 >> 63) | (w1 << 1) & 0x1ff; out[0*64+ 8] = (w1 >> 8) & 0x1ff; out[0*64+ 9] = (w1 >> 17) & 0x1ff; out[0*64+10] = (w1 >> 26) & 0x1ff; out[0*64+11] = (w1 >> 35) & 0x1ff; out[0*64+12] = (w1 >> 44) & 0x1ff; out[0*64+13] = (w1 >> 53) & 0x1ff; w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (w1 >> 62) | (w2 << 2) & 0x1ff; out[0*64+15] = (w2 >> 7) & 0x1ff; out[0*64+16] = (w2 >> 16) & 0x1ff; out[0*64+17] = (w2 >> 25) & 0x1ff; out[0*64+18] = (w2 >> 34) & 0x1ff; out[0*64+19] = (w2 >> 43) & 0x1ff; out[0*64+20] = (w2 >> 52) & 0x1ff; w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (w2 >> 61) | (w3 << 3) & 0x1ff; out[0*64+22] = (w3 >> 6) & 0x1ff; out[0*64+23] = (w3 >> 15) & 0x1ff; out[0*64+24] = (w3 >> 24) & 0x1ff; out[0*64+25] = (w3 >> 33) & 0x1ff; out[0*64+26] = (w3 >> 42) & 0x1ff; out[0*64+27] = (w3 >> 51) & 0x1ff; w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (w3 >> 60) | (w4 << 4) & 0x1ff; out[0*64+29] = (w4 >> 5) & 0x1ff; out[0*64+30] = (w4 >> 14) & 0x1ff; out[0*64+31] = (w4 >> 23) & 0x1ff;;}; out += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_10(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*10)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3ff; out[0*32+ 1] = (w0 >> 10) & 0x3ff; out[0*32+ 2] = (w0 >> 20) & 0x3ff; out[0*32+ 3] = (w0 >> 30) & 0x3ff; out[0*32+ 4] = (w0 >> 40) & 0x3ff; out[0*32+ 5] = (w0 >> 50) & 0x3ff; w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (w0 >> 60) | (w1 << 4) & 0x3ff; out[0*32+ 7] = (w1 >> 6) & 0x3ff; out[0*32+ 8] = (w1 >> 16) & 0x3ff; out[0*32+ 9] = (w1 >> 26) & 0x3ff; out[0*32+10] = (w1 >> 36) & 0x3ff; out[0*32+11] = (w1 >> 46) & 0x3ff; w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (w1 >> 56) | (w2 << 8) & 0x3ff; out[0*32+13] = (w2 >> 2) & 0x3ff; out[0*32+14] = (w2 >> 12) & 0x3ff; out[0*32+15] = (w2 >> 22) & 0x3ff; out[0*32+16] = (w2 >> 32) & 0x3ff; out[0*32+17] = (w2 >> 42) & 0x3ff; out[0*32+18] = (w2 >> 52) & 0x3ff; w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (w2 >> 62) | (w3 << 2) & 0x3ff; out[0*32+20] = (w3 >> 8) & 0x3ff; out[0*32+21] = (w3 >> 18) & 0x3ff; out[0*32+22] = (w3 >> 28) & 0x3ff; out[0*32+23] = (w3 >> 38) & 0x3ff; out[0*32+24] = (w3 >> 48) & 0x3ff; w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (w3 >> 58) | (w4 << 6) & 0x3ff; out[0*32+26] = (w4 >> 4) & 0x3ff; out[0*32+27] = (w4 >> 14) & 0x3ff; out[0*32+28] = (w4 >> 24) & 0x3ff; out[0*32+29] = (w4 >> 34) & 0x3ff; out[0*32+30] = (w4 >> 44) & 0x3ff; out[0*32+31] = (w4 >> 54);;}; out += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_11(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*11)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7ff; out[0*64+ 1] = (w0 >> 11) & 0x7ff; out[0*64+ 2] = (w0 >> 22) & 0x7ff; out[0*64+ 3] = (w0 >> 33) & 0x7ff; out[0*64+ 4] = (w0 >> 44) & 0x7ff; w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (w0 >> 55) | (w1 << 9) & 0x7ff; out[0*64+ 6] = (w1 >> 2) & 0x7ff; out[0*64+ 7] = (w1 >> 13) & 0x7ff; out[0*64+ 8] = (w1 >> 24) & 0x7ff; out[0*64+ 9] = (w1 >> 35) & 0x7ff; out[0*64+10] = (w1 >> 46) & 0x7ff; w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (w1 >> 57) | (w2 << 7) & 0x7ff; out[0*64+12] = (w2 >> 4) & 0x7ff; out[0*64+13] = (w2 >> 15) & 0x7ff; out[0*64+14] = (w2 >> 26) & 0x7ff; out[0*64+15] = (w2 >> 37) & 0x7ff; out[0*64+16] = (w2 >> 48) & 0x7ff; w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (w2 >> 59) | (w3 << 5) & 0x7ff; out[0*64+18] = (w3 >> 6) & 0x7ff; out[0*64+19] = (w3 >> 17) & 0x7ff; out[0*64+20] = (w3 >> 28) & 0x7ff; out[0*64+21] = (w3 >> 39) & 0x7ff; out[0*64+22] = (w3 >> 50) & 0x7ff; w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (w3 >> 61) | (w4 << 3) & 0x7ff; out[0*64+24] = (w4 >> 8) & 0x7ff; out[0*64+25] = (w4 >> 19) & 0x7ff; out[0*64+26] = (w4 >> 30) & 0x7ff; out[0*64+27] = (w4 >> 41) & 0x7ff; out[0*64+28] = (w4 >> 52) & 0x7ff; w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (w4 >> 63) | (w5 << 1) & 0x7ff; out[0*64+30] = (w5 >> 10) & 0x7ff; out[0*64+31] = (w5 >> 21) & 0x7ff;;}; out += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_12(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*12)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xfff; out[0*16+ 1] = (w0 >> 12) & 0xfff; out[0*16+ 2] = (w0 >> 24) & 0xfff; out[0*16+ 3] = (w0 >> 36) & 0xfff; out[0*16+ 4] = (w0 >> 48) & 0xfff; w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (w0 >> 60) | (w1 << 4) & 0xfff; out[0*16+ 6] = (w1 >> 8) & 0xfff; out[0*16+ 7] = (w1 >> 20) & 0xfff; out[0*16+ 8] = (w1 >> 32) & 0xfff; out[0*16+ 9] = (w1 >> 44) & 0xfff; w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (w1 >> 56) | (w2 << 8) & 0xfff; out[0*16+11] = (w2 >> 4) & 0xfff; out[0*16+12] = (w2 >> 16) & 0xfff; out[0*16+13] = (w2 >> 28) & 0xfff; out[0*16+14] = (w2 >> 40) & 0xfff; out[0*16+15] = (w2 >> 52);;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xfff; out[1*16+ 1] = (w0 >> 12) & 0xfff; out[1*16+ 2] = (w0 >> 24) & 0xfff; out[1*16+ 3] = (w0 >> 36) & 0xfff; out[1*16+ 4] = (w0 >> 48) & 0xfff; w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (w0 >> 60) | (w1 << 4) & 0xfff; out[1*16+ 6] = (w1 >> 8) & 0xfff; out[1*16+ 7] = (w1 >> 20) & 0xfff; out[1*16+ 8] = (w1 >> 32) & 0xfff; out[1*16+ 9] = (w1 >> 44) & 0xfff; w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (w1 >> 56) | (w2 << 8) & 0xfff; out[1*16+11] = (w2 >> 4) & 0xfff; out[1*16+12] = (w2 >> 16) & 0xfff; out[1*16+13] = (w2 >> 28) & 0xfff; out[1*16+14] = (w2 >> 40) & 0xfff; out[1*16+15] = (w2 >> 52);;}; out += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_13(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*13)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1fff; out[0*64+ 1] = (w0 >> 13) & 0x1fff; out[0*64+ 2] = (w0 >> 26) & 0x1fff; out[0*64+ 3] = (w0 >> 39) & 0x1fff; w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (w0 >> 52) | (w1 << 12) & 0x1fff; out[0*64+ 5] = (w1 >> 1) & 0x1fff; out[0*64+ 6] = (w1 >> 14) & 0x1fff; out[0*64+ 7] = (w1 >> 27) & 0x1fff; out[0*64+ 8] = (w1 >> 40) & 0x1fff; w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (w1 >> 53) | (w2 << 11) & 0x1fff; out[0*64+10] = (w2 >> 2) & 0x1fff; out[0*64+11] = (w2 >> 15) & 0x1fff; out[0*64+12] = (w2 >> 28) & 0x1fff; out[0*64+13] = (w2 >> 41) & 0x1fff; w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (w2 >> 54) | (w3 << 10) & 0x1fff; out[0*64+15] = (w3 >> 3) & 0x1fff; out[0*64+16] = (w3 >> 16) & 0x1fff; out[0*64+17] = (w3 >> 29) & 0x1fff; out[0*64+18] = (w3 >> 42) & 0x1fff; w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (w3 >> 55) | (w4 << 9) & 0x1fff; out[0*64+20] = (w4 >> 4) & 0x1fff; out[0*64+21] = (w4 >> 17) & 0x1fff; out[0*64+22] = (w4 >> 30) & 0x1fff; out[0*64+23] = (w4 >> 43) & 0x1fff; w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (w4 >> 56) | (w5 << 8) & 0x1fff; out[0*64+25] = (w5 >> 5) & 0x1fff; out[0*64+26] = (w5 >> 18) & 0x1fff; out[0*64+27] = (w5 >> 31) & 0x1fff; out[0*64+28] = (w5 >> 44) & 0x1fff; w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (w5 >> 57) | (w6 << 7) & 0x1fff; out[0*64+30] = (w6 >> 6) & 0x1fff; out[0*64+31] = (w6 >> 19) & 0x1fff;;}; out += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_14(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*14)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3fff; out[0*32+ 1] = (w0 >> 14) & 0x3fff; out[0*32+ 2] = (w0 >> 28) & 0x3fff; out[0*32+ 3] = (w0 >> 42) & 0x3fff; w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (w0 >> 56) | (w1 << 8) & 0x3fff; out[0*32+ 5] = (w1 >> 6) & 0x3fff; out[0*32+ 6] = (w1 >> 20) & 0x3fff; out[0*32+ 7] = (w1 >> 34) & 0x3fff; out[0*32+ 8] = (w1 >> 48) & 0x3fff; w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (w1 >> 62) | (w2 << 2) & 0x3fff; out[0*32+10] = (w2 >> 12) & 0x3fff; out[0*32+11] = (w2 >> 26) & 0x3fff; out[0*32+12] = (w2 >> 40) & 0x3fff; w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (w2 >> 54) | (w3 << 10) & 0x3fff; out[0*32+14] = (w3 >> 4) & 0x3fff; out[0*32+15] = (w3 >> 18) & 0x3fff; out[0*32+16] = (w3 >> 32) & 0x3fff; out[0*32+17] = (w3 >> 46) & 0x3fff; w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (w3 >> 60) | (w4 << 4) & 0x3fff; out[0*32+19] = (w4 >> 10) & 0x3fff; out[0*32+20] = (w4 >> 24) & 0x3fff; out[0*32+21] = (w4 >> 38) & 0x3fff; w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (w4 >> 52) | (w5 << 12) & 0x3fff; out[0*32+23] = (w5 >> 2) & 0x3fff; out[0*32+24] = (w5 >> 16) & 0x3fff; out[0*32+25] = (w5 >> 30) & 0x3fff; out[0*32+26] = (w5 >> 44) & 0x3fff; w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (w5 >> 58) | (w6 << 6) & 0x3fff; out[0*32+28] = (w6 >> 8) & 0x3fff; out[0*32+29] = (w6 >> 22) & 0x3fff; out[0*32+30] = (w6 >> 36) & 0x3fff; out[0*32+31] = (w6 >> 50);;}; out += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_15(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*15)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7fff; out[0*64+ 1] = (w0 >> 15) & 0x7fff; out[0*64+ 2] = (w0 >> 30) & 0x7fff; out[0*64+ 3] = (w0 >> 45) & 0x7fff; w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (w0 >> 60) | (w1 << 4) & 0x7fff; out[0*64+ 5] = (w1 >> 11) & 0x7fff; out[0*64+ 6] = (w1 >> 26) & 0x7fff; out[0*64+ 7] = (w1 >> 41) & 0x7fff; w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (w1 >> 56) | (w2 << 8) & 0x7fff; out[0*64+ 9] = (w2 >> 7) & 0x7fff; out[0*64+10] = (w2 >> 22) & 0x7fff; out[0*64+11] = (w2 >> 37) & 0x7fff; w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (w2 >> 52) | (w3 << 12) & 0x7fff; out[0*64+13] = (w3 >> 3) & 0x7fff; out[0*64+14] = (w3 >> 18) & 0x7fff; out[0*64+15] = (w3 >> 33) & 0x7fff; out[0*64+16] = (w3 >> 48) & 0x7fff; w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (w3 >> 63) | (w4 << 1) & 0x7fff; out[0*64+18] = (w4 >> 14) & 0x7fff; out[0*64+19] = (w4 >> 29) & 0x7fff; out[0*64+20] = (w4 >> 44) & 0x7fff; w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (w4 >> 59) | (w5 << 5) & 0x7fff; out[0*64+22] = (w5 >> 10) & 0x7fff; out[0*64+23] = (w5 >> 25) & 0x7fff; out[0*64+24] = (w5 >> 40) & 0x7fff; w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (w5 >> 55) | (w6 << 9) & 0x7fff; out[0*64+26] = (w6 >> 6) & 0x7fff; out[0*64+27] = (w6 >> 21) & 0x7fff; out[0*64+28] = (w6 >> 36) & 0x7fff; w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (w6 >> 51) | (w7 << 13) & 0x7fff; out[0*64+30] = (w7 >> 2) & 0x7fff; out[0*64+31] = (w7 >> 17) & 0x7fff;;}; out += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_16(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*16)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = *(uint16_t *)(in+0*8+ 0); out[0*4+ 1] = *(uint16_t *)(in+0*8+ 2); out[0*4+ 2] = *(uint16_t *)(in+0*8+ 4); out[0*4+ 3] = *(uint16_t *)(in+0*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = *(uint16_t *)(in+1*8+ 0); out[1*4+ 1] = *(uint16_t *)(in+1*8+ 2); out[1*4+ 2] = *(uint16_t *)(in+1*8+ 4); out[1*4+ 3] = *(uint16_t *)(in+1*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = *(uint16_t *)(in+2*8+ 0); out[2*4+ 1] = *(uint16_t *)(in+2*8+ 2); out[2*4+ 2] = *(uint16_t *)(in+2*8+ 4); out[2*4+ 3] = *(uint16_t *)(in+2*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = *(uint16_t *)(in+3*8+ 0); out[3*4+ 1] = *(uint16_t *)(in+3*8+ 2); out[3*4+ 2] = *(uint16_t *)(in+3*8+ 4); out[3*4+ 3] = *(uint16_t *)(in+3*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = *(uint16_t *)(in+4*8+ 0); out[4*4+ 1] = *(uint16_t *)(in+4*8+ 2); out[4*4+ 2] = *(uint16_t *)(in+4*8+ 4); out[4*4+ 3] = *(uint16_t *)(in+4*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = *(uint16_t *)(in+5*8+ 0); out[5*4+ 1] = *(uint16_t *)(in+5*8+ 2); out[5*4+ 2] = *(uint16_t *)(in+5*8+ 4); out[5*4+ 3] = *(uint16_t *)(in+5*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = *(uint16_t *)(in+6*8+ 0); out[6*4+ 1] = *(uint16_t *)(in+6*8+ 2); out[6*4+ 2] = *(uint16_t *)(in+6*8+ 4); out[6*4+ 3] = *(uint16_t *)(in+6*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = *(uint16_t *)(in+7*8+ 0); out[7*4+ 1] = *(uint16_t *)(in+7*8+ 2); out[7*4+ 2] = *(uint16_t *)(in+7*8+ 4); out[7*4+ 3] = *(uint16_t *)(in+7*8+ 6);;}; out += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_17(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*17)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1ffff; out[0*64+ 1] = (w0 >> 17) & 0x1ffff; out[0*64+ 2] = (w0 >> 34) & 0x1ffff; w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*64+ 3] = (w0 >> 51) | (w1 << 13) & 0x1ffff; out[0*64+ 4] = (w1 >> 4) & 0x1ffff; out[0*64+ 5] = (w1 >> 21) & 0x1ffff; out[0*64+ 6] = (w1 >> 38) & 0x1ffff; w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*64+ 7] = (w1 >> 55) | (w2 << 9) & 0x1ffff; out[0*64+ 8] = (w2 >> 8) & 0x1ffff; out[0*64+ 9] = (w2 >> 25) & 0x1ffff; out[0*64+10] = (w2 >> 42) & 0x1ffff; w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*64+11] = (w2 >> 59) | (w3 << 5) & 0x1ffff; out[0*64+12] = (w3 >> 12) & 0x1ffff; out[0*64+13] = (w3 >> 29) & 0x1ffff; out[0*64+14] = (w3 >> 46) & 0x1ffff; w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*64+15] = (w3 >> 63) | (w4 << 1) & 0x1ffff; out[0*64+16] = (w4 >> 16) & 0x1ffff; out[0*64+17] = (w4 >> 33) & 0x1ffff; w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*64+18] = (w4 >> 50) | (w5 << 14) & 0x1ffff; out[0*64+19] = (w5 >> 3) & 0x1ffff; out[0*64+20] = (w5 >> 20) & 0x1ffff; out[0*64+21] = (w5 >> 37) & 0x1ffff; w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*64+22] = (w5 >> 54) | (w6 << 10) & 0x1ffff; out[0*64+23] = (w6 >> 7) & 0x1ffff; out[0*64+24] = (w6 >> 24) & 0x1ffff; out[0*64+25] = (w6 >> 41) & 0x1ffff; w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*64+26] = (w6 >> 58) | (w7 << 6) & 0x1ffff; out[0*64+27] = (w7 >> 11) & 0x1ffff; out[0*64+28] = (w7 >> 28) & 0x1ffff; out[0*64+29] = (w7 >> 45) & 0x1ffff; w8 = *(uint32_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*64+30] = (w7 >> 62) | (w8 << 2) & 0x1ffff; out[0*64+31] = (w8 >> 15) & 0x1ffff;;}; out += 32; in += 17*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_18(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*18)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3ffff; out[0*32+ 1] = (w0 >> 18) & 0x3ffff; out[0*32+ 2] = (w0 >> 36) & 0x3ffff; w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*32+ 3] = (w0 >> 54) | (w1 << 10) & 0x3ffff; out[0*32+ 4] = (w1 >> 8) & 0x3ffff; out[0*32+ 5] = (w1 >> 26) & 0x3ffff; out[0*32+ 6] = (w1 >> 44) & 0x3ffff; w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*32+ 7] = (w1 >> 62) | (w2 << 2) & 0x3ffff; out[0*32+ 8] = (w2 >> 16) & 0x3ffff; out[0*32+ 9] = (w2 >> 34) & 0x3ffff; w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*32+10] = (w2 >> 52) | (w3 << 12) & 0x3ffff; out[0*32+11] = (w3 >> 6) & 0x3ffff; out[0*32+12] = (w3 >> 24) & 0x3ffff; out[0*32+13] = (w3 >> 42) & 0x3ffff; w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*32+14] = (w3 >> 60) | (w4 << 4) & 0x3ffff; out[0*32+15] = (w4 >> 14) & 0x3ffff; out[0*32+16] = (w4 >> 32) & 0x3ffff; w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*32+17] = (w4 >> 50) | (w5 << 14) & 0x3ffff; out[0*32+18] = (w5 >> 4) & 0x3ffff; out[0*32+19] = (w5 >> 22) & 0x3ffff; out[0*32+20] = (w5 >> 40) & 0x3ffff; w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*32+21] = (w5 >> 58) | (w6 << 6) & 0x3ffff; out[0*32+22] = (w6 >> 12) & 0x3ffff; out[0*32+23] = (w6 >> 30) & 0x3ffff; w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*32+24] = (w6 >> 48) | (w7 << 16) & 0x3ffff; out[0*32+25] = (w7 >> 2) & 0x3ffff; out[0*32+26] = (w7 >> 20) & 0x3ffff; out[0*32+27] = (w7 >> 38) & 0x3ffff; w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*32+28] = (w7 >> 56) | (w8 << 8) & 0x3ffff; out[0*32+29] = (w8 >> 10) & 0x3ffff; out[0*32+30] = (w8 >> 28) & 0x3ffff; out[0*32+31] = (w8 >> 46);;}; out += 32; in += 18*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_19(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*19)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7ffff; out[0*64+ 1] = (w0 >> 19) & 0x7ffff; out[0*64+ 2] = (w0 >> 38) & 0x7ffff; w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*64+ 3] = (w0 >> 57) | (w1 << 7) & 0x7ffff; out[0*64+ 4] = (w1 >> 12) & 0x7ffff; out[0*64+ 5] = (w1 >> 31) & 0x7ffff; w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*64+ 6] = (w1 >> 50) | (w2 << 14) & 0x7ffff; out[0*64+ 7] = (w2 >> 5) & 0x7ffff; out[0*64+ 8] = (w2 >> 24) & 0x7ffff; out[0*64+ 9] = (w2 >> 43) & 0x7ffff; w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*64+10] = (w2 >> 62) | (w3 << 2) & 0x7ffff; out[0*64+11] = (w3 >> 17) & 0x7ffff; out[0*64+12] = (w3 >> 36) & 0x7ffff; w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*64+13] = (w3 >> 55) | (w4 << 9) & 0x7ffff; out[0*64+14] = (w4 >> 10) & 0x7ffff; out[0*64+15] = (w4 >> 29) & 0x7ffff; w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*64+16] = (w4 >> 48) | (w5 << 16) & 0x7ffff; out[0*64+17] = (w5 >> 3) & 0x7ffff; out[0*64+18] = (w5 >> 22) & 0x7ffff; out[0*64+19] = (w5 >> 41) & 0x7ffff; w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*64+20] = (w5 >> 60) | (w6 << 4) & 0x7ffff; out[0*64+21] = (w6 >> 15) & 0x7ffff; out[0*64+22] = (w6 >> 34) & 0x7ffff; w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*64+23] = (w6 >> 53) | (w7 << 11) & 0x7ffff; out[0*64+24] = (w7 >> 8) & 0x7ffff; out[0*64+25] = (w7 >> 27) & 0x7ffff; w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*64+26] = (w7 >> 46) | (w8 << 18) & 0x7ffff; out[0*64+27] = (w8 >> 1) & 0x7ffff; out[0*64+28] = (w8 >> 20) & 0x7ffff; out[0*64+29] = (w8 >> 39) & 0x7ffff; w9 = *(uint32_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*64+30] = (w8 >> 58) | (w9 << 6) & 0x7ffff; out[0*64+31] = (w9 >> 13) & 0x7ffff;;}; out += 32; in += 19*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_20(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*20)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xfffff; out[0*16+ 1] = (w0 >> 20) & 0xfffff; out[0*16+ 2] = (w0 >> 40) & 0xfffff; w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*16+ 3] = (w0 >> 60) | (w1 << 4) & 0xfffff; out[0*16+ 4] = (w1 >> 16) & 0xfffff; out[0*16+ 5] = (w1 >> 36) & 0xfffff; w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*16+ 6] = (w1 >> 56) | (w2 << 8) & 0xfffff; out[0*16+ 7] = (w2 >> 12) & 0xfffff; out[0*16+ 8] = (w2 >> 32) & 0xfffff; w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*16+ 9] = (w2 >> 52) | (w3 << 12) & 0xfffff; out[0*16+10] = (w3 >> 8) & 0xfffff; out[0*16+11] = (w3 >> 28) & 0xfffff; w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*16+12] = (w3 >> 48) | (w4 << 16) & 0xfffff; out[0*16+13] = (w4 >> 4) & 0xfffff; out[0*16+14] = (w4 >> 24) & 0xfffff; out[0*16+15] = (w4 >> 44);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xfffff; out[1*16+ 1] = (w0 >> 20) & 0xfffff; out[1*16+ 2] = (w0 >> 40) & 0xfffff; w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*16+ 3] = (w0 >> 60) | (w1 << 4) & 0xfffff; out[1*16+ 4] = (w1 >> 16) & 0xfffff; out[1*16+ 5] = (w1 >> 36) & 0xfffff; w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*16+ 6] = (w1 >> 56) | (w2 << 8) & 0xfffff; out[1*16+ 7] = (w2 >> 12) & 0xfffff; out[1*16+ 8] = (w2 >> 32) & 0xfffff; w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*16+ 9] = (w2 >> 52) | (w3 << 12) & 0xfffff; out[1*16+10] = (w3 >> 8) & 0xfffff; out[1*16+11] = (w3 >> 28) & 0xfffff; w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*16+12] = (w3 >> 48) | (w4 << 16) & 0xfffff; out[1*16+13] = (w4 >> 4) & 0xfffff; out[1*16+14] = (w4 >> 24) & 0xfffff; out[1*16+15] = (w4 >> 44);;}; out += 32; in += 20*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_21(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*21)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1fffff; out[0*64+ 1] = (w0 >> 21) & 0x1fffff; out[0*64+ 2] = (w0 >> 42) & 0x1fffff; w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*64+ 3] = (w0 >> 63) | (w1 << 1) & 0x1fffff; out[0*64+ 4] = (w1 >> 20) & 0x1fffff; out[0*64+ 5] = (w1 >> 41) & 0x1fffff; w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*64+ 6] = (w1 >> 62) | (w2 << 2) & 0x1fffff; out[0*64+ 7] = (w2 >> 19) & 0x1fffff; out[0*64+ 8] = (w2 >> 40) & 0x1fffff; w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*64+ 9] = (w2 >> 61) | (w3 << 3) & 0x1fffff; out[0*64+10] = (w3 >> 18) & 0x1fffff; out[0*64+11] = (w3 >> 39) & 0x1fffff; w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*64+12] = (w3 >> 60) | (w4 << 4) & 0x1fffff; out[0*64+13] = (w4 >> 17) & 0x1fffff; out[0*64+14] = (w4 >> 38) & 0x1fffff; w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*64+15] = (w4 >> 59) | (w5 << 5) & 0x1fffff; out[0*64+16] = (w5 >> 16) & 0x1fffff; out[0*64+17] = (w5 >> 37) & 0x1fffff; w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*64+18] = (w5 >> 58) | (w6 << 6) & 0x1fffff; out[0*64+19] = (w6 >> 15) & 0x1fffff; out[0*64+20] = (w6 >> 36) & 0x1fffff; w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*64+21] = (w6 >> 57) | (w7 << 7) & 0x1fffff; out[0*64+22] = (w7 >> 14) & 0x1fffff; out[0*64+23] = (w7 >> 35) & 0x1fffff; w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*64+24] = (w7 >> 56) | (w8 << 8) & 0x1fffff; out[0*64+25] = (w8 >> 13) & 0x1fffff; out[0*64+26] = (w8 >> 34) & 0x1fffff; w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*64+27] = (w8 >> 55) | (w9 << 9) & 0x1fffff; out[0*64+28] = (w9 >> 12) & 0x1fffff; out[0*64+29] = (w9 >> 33) & 0x1fffff; w10 = *(uint32_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*64+30] = (w9 >> 54) | (w10 << 10) & 0x1fffff; out[0*64+31] = (w10 >> 11) & 0x1fffff;;}; out += 32; in += 21*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_22(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*22)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3fffff; out[0*32+ 1] = (w0 >> 22) & 0x3fffff; w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*32+ 2] = (w0 >> 44) | (w1 << 20) & 0x3fffff; out[0*32+ 3] = (w1 >> 2) & 0x3fffff; out[0*32+ 4] = (w1 >> 24) & 0x3fffff; w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*32+ 5] = (w1 >> 46) | (w2 << 18) & 0x3fffff; out[0*32+ 6] = (w2 >> 4) & 0x3fffff; out[0*32+ 7] = (w2 >> 26) & 0x3fffff; w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*32+ 8] = (w2 >> 48) | (w3 << 16) & 0x3fffff; out[0*32+ 9] = (w3 >> 6) & 0x3fffff; out[0*32+10] = (w3 >> 28) & 0x3fffff; w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*32+11] = (w3 >> 50) | (w4 << 14) & 0x3fffff; out[0*32+12] = (w4 >> 8) & 0x3fffff; out[0*32+13] = (w4 >> 30) & 0x3fffff; w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*32+14] = (w4 >> 52) | (w5 << 12) & 0x3fffff; out[0*32+15] = (w5 >> 10) & 0x3fffff; out[0*32+16] = (w5 >> 32) & 0x3fffff; w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*32+17] = (w5 >> 54) | (w6 << 10) & 0x3fffff; out[0*32+18] = (w6 >> 12) & 0x3fffff; out[0*32+19] = (w6 >> 34) & 0x3fffff; w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*32+20] = (w6 >> 56) | (w7 << 8) & 0x3fffff; out[0*32+21] = (w7 >> 14) & 0x3fffff; out[0*32+22] = (w7 >> 36) & 0x3fffff; w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*32+23] = (w7 >> 58) | (w8 << 6) & 0x3fffff; out[0*32+24] = (w8 >> 16) & 0x3fffff; out[0*32+25] = (w8 >> 38) & 0x3fffff; w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*32+26] = (w8 >> 60) | (w9 << 4) & 0x3fffff; out[0*32+27] = (w9 >> 18) & 0x3fffff; out[0*32+28] = (w9 >> 40) & 0x3fffff; w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*32+29] = (w9 >> 62) | (w10 << 2) & 0x3fffff; out[0*32+30] = (w10 >> 20) & 0x3fffff; out[0*32+31] = (w10 >> 42);;}; out += 32; in += 22*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_23(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*23)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7fffff; out[0*64+ 1] = (w0 >> 23) & 0x7fffff; w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*64+ 2] = (w0 >> 46) | (w1 << 18) & 0x7fffff; out[0*64+ 3] = (w1 >> 5) & 0x7fffff; out[0*64+ 4] = (w1 >> 28) & 0x7fffff; w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*64+ 5] = (w1 >> 51) | (w2 << 13) & 0x7fffff; out[0*64+ 6] = (w2 >> 10) & 0x7fffff; out[0*64+ 7] = (w2 >> 33) & 0x7fffff; w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*64+ 8] = (w2 >> 56) | (w3 << 8) & 0x7fffff; out[0*64+ 9] = (w3 >> 15) & 0x7fffff; out[0*64+10] = (w3 >> 38) & 0x7fffff; w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*64+11] = (w3 >> 61) | (w4 << 3) & 0x7fffff; out[0*64+12] = (w4 >> 20) & 0x7fffff; w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*64+13] = (w4 >> 43) | (w5 << 21) & 0x7fffff; out[0*64+14] = (w5 >> 2) & 0x7fffff; out[0*64+15] = (w5 >> 25) & 0x7fffff; w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*64+16] = (w5 >> 48) | (w6 << 16) & 0x7fffff; out[0*64+17] = (w6 >> 7) & 0x7fffff; out[0*64+18] = (w6 >> 30) & 0x7fffff; w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*64+19] = (w6 >> 53) | (w7 << 11) & 0x7fffff; out[0*64+20] = (w7 >> 12) & 0x7fffff; out[0*64+21] = (w7 >> 35) & 0x7fffff; w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*64+22] = (w7 >> 58) | (w8 << 6) & 0x7fffff; out[0*64+23] = (w8 >> 17) & 0x7fffff; out[0*64+24] = (w8 >> 40) & 0x7fffff; w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*64+25] = (w8 >> 63) | (w9 << 1) & 0x7fffff; out[0*64+26] = (w9 >> 22) & 0x7fffff; w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*64+27] = (w9 >> 45) | (w10 << 19) & 0x7fffff; out[0*64+28] = (w10 >> 4) & 0x7fffff; out[0*64+29] = (w10 >> 27) & 0x7fffff; w11 = *(uint32_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*64+30] = (w10 >> 50) | (w11 << 14) & 0x7fffff; out[0*64+31] = (w11 >> 9) & 0x7fffff;;}; out += 32; in += 23*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_24(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*24)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*8+ 0] = (w0 ) & 0xffffff; out[0*8+ 1] = (w0 >> 24) & 0xffffff; w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*8+ 2] = (w0 >> 48) | (w1 << 16) & 0xffffff; out[0*8+ 3] = (w1 >> 8) & 0xffffff; out[0*8+ 4] = (w1 >> 32) & 0xffffff; w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*8+ 5] = (w1 >> 56) | (w2 << 8) & 0xffffff; out[0*8+ 6] = (w2 >> 16) & 0xffffff; out[0*8+ 7] = (w2 >> 40);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*8+ 0] = (w0 ) & 0xffffff; out[1*8+ 1] = (w0 >> 24) & 0xffffff; w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*8+ 2] = (w0 >> 48) | (w1 << 16) & 0xffffff; out[1*8+ 3] = (w1 >> 8) & 0xffffff; out[1*8+ 4] = (w1 >> 32) & 0xffffff; w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*8+ 5] = (w1 >> 56) | (w2 << 8) & 0xffffff; out[1*8+ 6] = (w2 >> 16) & 0xffffff; out[1*8+ 7] = (w2 >> 40);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*8+ 0] = (w0 ) & 0xffffff; out[2*8+ 1] = (w0 >> 24) & 0xffffff; w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*8+ 2] = (w0 >> 48) | (w1 << 16) & 0xffffff; out[2*8+ 3] = (w1 >> 8) & 0xffffff; out[2*8+ 4] = (w1 >> 32) & 0xffffff; w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*8+ 5] = (w1 >> 56) | (w2 << 8) & 0xffffff; out[2*8+ 6] = (w2 >> 16) & 0xffffff; out[2*8+ 7] = (w2 >> 40);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*8+ 0] = (w0 ) & 0xffffff; out[3*8+ 1] = (w0 >> 24) & 0xffffff; w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*8+ 2] = (w0 >> 48) | (w1 << 16) & 0xffffff; out[3*8+ 3] = (w1 >> 8) & 0xffffff; out[3*8+ 4] = (w1 >> 32) & 0xffffff; w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*8+ 5] = (w1 >> 56) | (w2 << 8) & 0xffffff; out[3*8+ 6] = (w2 >> 16) & 0xffffff; out[3*8+ 7] = (w2 >> 40);;}; out += 32; in += 24*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_25(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*25)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1ffffff; out[0*64+ 1] = (w0 >> 25) & 0x1ffffff; w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*64+ 2] = (w0 >> 50) | (w1 << 14) & 0x1ffffff; out[0*64+ 3] = (w1 >> 11) & 0x1ffffff; out[0*64+ 4] = (w1 >> 36) & 0x1ffffff; w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*64+ 5] = (w1 >> 61) | (w2 << 3) & 0x1ffffff; out[0*64+ 6] = (w2 >> 22) & 0x1ffffff; w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*64+ 7] = (w2 >> 47) | (w3 << 17) & 0x1ffffff; out[0*64+ 8] = (w3 >> 8) & 0x1ffffff; out[0*64+ 9] = (w3 >> 33) & 0x1ffffff; w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*64+10] = (w3 >> 58) | (w4 << 6) & 0x1ffffff; out[0*64+11] = (w4 >> 19) & 0x1ffffff; w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*64+12] = (w4 >> 44) | (w5 << 20) & 0x1ffffff; out[0*64+13] = (w5 >> 5) & 0x1ffffff; out[0*64+14] = (w5 >> 30) & 0x1ffffff; w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*64+15] = (w5 >> 55) | (w6 << 9) & 0x1ffffff; out[0*64+16] = (w6 >> 16) & 0x1ffffff; w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*64+17] = (w6 >> 41) | (w7 << 23) & 0x1ffffff; out[0*64+18] = (w7 >> 2) & 0x1ffffff; out[0*64+19] = (w7 >> 27) & 0x1ffffff; w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*64+20] = (w7 >> 52) | (w8 << 12) & 0x1ffffff; out[0*64+21] = (w8 >> 13) & 0x1ffffff; out[0*64+22] = (w8 >> 38) & 0x1ffffff; w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*64+23] = (w8 >> 63) | (w9 << 1) & 0x1ffffff; out[0*64+24] = (w9 >> 24) & 0x1ffffff; w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*64+25] = (w9 >> 49) | (w10 << 15) & 0x1ffffff; out[0*64+26] = (w10 >> 10) & 0x1ffffff; out[0*64+27] = (w10 >> 35) & 0x1ffffff; w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*64+28] = (w10 >> 60) | (w11 << 4) & 0x1ffffff; out[0*64+29] = (w11 >> 21) & 0x1ffffff; w12 = *(uint32_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*64+30] = (w11 >> 46) | (w12 << 18) & 0x1ffffff; out[0*64+31] = (w12 >> 7) & 0x1ffffff;;}; out += 32; in += 25*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_26(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*26)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3ffffff; out[0*32+ 1] = (w0 >> 26) & 0x3ffffff; w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*32+ 2] = (w0 >> 52) | (w1 << 12) & 0x3ffffff; out[0*32+ 3] = (w1 >> 14) & 0x3ffffff; w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*32+ 4] = (w1 >> 40) | (w2 << 24) & 0x3ffffff; out[0*32+ 5] = (w2 >> 2) & 0x3ffffff; out[0*32+ 6] = (w2 >> 28) & 0x3ffffff; w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*32+ 7] = (w2 >> 54) | (w3 << 10) & 0x3ffffff; out[0*32+ 8] = (w3 >> 16) & 0x3ffffff; w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*32+ 9] = (w3 >> 42) | (w4 << 22) & 0x3ffffff; out[0*32+10] = (w4 >> 4) & 0x3ffffff; out[0*32+11] = (w4 >> 30) & 0x3ffffff; w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*32+12] = (w4 >> 56) | (w5 << 8) & 0x3ffffff; out[0*32+13] = (w5 >> 18) & 0x3ffffff; w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*32+14] = (w5 >> 44) | (w6 << 20) & 0x3ffffff; out[0*32+15] = (w6 >> 6) & 0x3ffffff; out[0*32+16] = (w6 >> 32) & 0x3ffffff; w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*32+17] = (w6 >> 58) | (w7 << 6) & 0x3ffffff; out[0*32+18] = (w7 >> 20) & 0x3ffffff; w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*32+19] = (w7 >> 46) | (w8 << 18) & 0x3ffffff; out[0*32+20] = (w8 >> 8) & 0x3ffffff; out[0*32+21] = (w8 >> 34) & 0x3ffffff; w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*32+22] = (w8 >> 60) | (w9 << 4) & 0x3ffffff; out[0*32+23] = (w9 >> 22) & 0x3ffffff; w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*32+24] = (w9 >> 48) | (w10 << 16) & 0x3ffffff; out[0*32+25] = (w10 >> 10) & 0x3ffffff; out[0*32+26] = (w10 >> 36) & 0x3ffffff; w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*32+27] = (w10 >> 62) | (w11 << 2) & 0x3ffffff; out[0*32+28] = (w11 >> 24) & 0x3ffffff; w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*32+29] = (w11 >> 50) | (w12 << 14) & 0x3ffffff; out[0*32+30] = (w12 >> 12) & 0x3ffffff; out[0*32+31] = (w12 >> 38);;}; out += 32; in += 26*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_27(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*27)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7ffffff; out[0*64+ 1] = (w0 >> 27) & 0x7ffffff; w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*64+ 2] = (w0 >> 54) | (w1 << 10) & 0x7ffffff; out[0*64+ 3] = (w1 >> 17) & 0x7ffffff; w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*64+ 4] = (w1 >> 44) | (w2 << 20) & 0x7ffffff; out[0*64+ 5] = (w2 >> 7) & 0x7ffffff; out[0*64+ 6] = (w2 >> 34) & 0x7ffffff; w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*64+ 7] = (w2 >> 61) | (w3 << 3) & 0x7ffffff; out[0*64+ 8] = (w3 >> 24) & 0x7ffffff; w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*64+ 9] = (w3 >> 51) | (w4 << 13) & 0x7ffffff; out[0*64+10] = (w4 >> 14) & 0x7ffffff; w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*64+11] = (w4 >> 41) | (w5 << 23) & 0x7ffffff; out[0*64+12] = (w5 >> 4) & 0x7ffffff; out[0*64+13] = (w5 >> 31) & 0x7ffffff; w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*64+14] = (w5 >> 58) | (w6 << 6) & 0x7ffffff; out[0*64+15] = (w6 >> 21) & 0x7ffffff; w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*64+16] = (w6 >> 48) | (w7 << 16) & 0x7ffffff; out[0*64+17] = (w7 >> 11) & 0x7ffffff; w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*64+18] = (w7 >> 38) | (w8 << 26) & 0x7ffffff; out[0*64+19] = (w8 >> 1) & 0x7ffffff; out[0*64+20] = (w8 >> 28) & 0x7ffffff; w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*64+21] = (w8 >> 55) | (w9 << 9) & 0x7ffffff; out[0*64+22] = (w9 >> 18) & 0x7ffffff; w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*64+23] = (w9 >> 45) | (w10 << 19) & 0x7ffffff; out[0*64+24] = (w10 >> 8) & 0x7ffffff; out[0*64+25] = (w10 >> 35) & 0x7ffffff; w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*64+26] = (w10 >> 62) | (w11 << 2) & 0x7ffffff; out[0*64+27] = (w11 >> 25) & 0x7ffffff; w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*64+28] = (w11 >> 52) | (w12 << 12) & 0x7ffffff; out[0*64+29] = (w12 >> 15) & 0x7ffffff; w13 = *(uint32_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*64+30] = (w12 >> 42) | (w13 << 22) & 0x7ffffff; out[0*64+31] = (w13 >> 5) & 0x7ffffff;;}; out += 32; in += 27*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_28(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*28)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xfffffff; out[0*16+ 1] = (w0 >> 28) & 0xfffffff; w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*16+ 2] = (w0 >> 56) | (w1 << 8) & 0xfffffff; out[0*16+ 3] = (w1 >> 20) & 0xfffffff; w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*16+ 4] = (w1 >> 48) | (w2 << 16) & 0xfffffff; out[0*16+ 5] = (w2 >> 12) & 0xfffffff; w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*16+ 6] = (w2 >> 40) | (w3 << 24) & 0xfffffff; out[0*16+ 7] = (w3 >> 4) & 0xfffffff; out[0*16+ 8] = (w3 >> 32) & 0xfffffff; w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*16+ 9] = (w3 >> 60) | (w4 << 4) & 0xfffffff; out[0*16+10] = (w4 >> 24) & 0xfffffff; w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*16+11] = (w4 >> 52) | (w5 << 12) & 0xfffffff; out[0*16+12] = (w5 >> 16) & 0xfffffff; w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*16+13] = (w5 >> 44) | (w6 << 20) & 0xfffffff; out[0*16+14] = (w6 >> 8) & 0xfffffff; out[0*16+15] = (w6 >> 36);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xfffffff; out[1*16+ 1] = (w0 >> 28) & 0xfffffff; w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*16+ 2] = (w0 >> 56) | (w1 << 8) & 0xfffffff; out[1*16+ 3] = (w1 >> 20) & 0xfffffff; w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*16+ 4] = (w1 >> 48) | (w2 << 16) & 0xfffffff; out[1*16+ 5] = (w2 >> 12) & 0xfffffff; w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*16+ 6] = (w2 >> 40) | (w3 << 24) & 0xfffffff; out[1*16+ 7] = (w3 >> 4) & 0xfffffff; out[1*16+ 8] = (w3 >> 32) & 0xfffffff; w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*16+ 9] = (w3 >> 60) | (w4 << 4) & 0xfffffff; out[1*16+10] = (w4 >> 24) & 0xfffffff; w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*16+11] = (w4 >> 52) | (w5 << 12) & 0xfffffff; out[1*16+12] = (w5 >> 16) & 0xfffffff; w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*16+13] = (w5 >> 44) | (w6 << 20) & 0xfffffff; out[1*16+14] = (w6 >> 8) & 0xfffffff; out[1*16+15] = (w6 >> 36);;}; out += 32; in += 28*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_29(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*29)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1fffffff; out[0*64+ 1] = (w0 >> 29) & 0x1fffffff; w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*64+ 2] = (w0 >> 58) | (w1 << 6) & 0x1fffffff; out[0*64+ 3] = (w1 >> 23) & 0x1fffffff; w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*64+ 4] = (w1 >> 52) | (w2 << 12) & 0x1fffffff; out[0*64+ 5] = (w2 >> 17) & 0x1fffffff; w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*64+ 6] = (w2 >> 46) | (w3 << 18) & 0x1fffffff; out[0*64+ 7] = (w3 >> 11) & 0x1fffffff; w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*64+ 8] = (w3 >> 40) | (w4 << 24) & 0x1fffffff; out[0*64+ 9] = (w4 >> 5) & 0x1fffffff; out[0*64+10] = (w4 >> 34) & 0x1fffffff; w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*64+11] = (w4 >> 63) | (w5 << 1) & 0x1fffffff; out[0*64+12] = (w5 >> 28) & 0x1fffffff; w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*64+13] = (w5 >> 57) | (w6 << 7) & 0x1fffffff; out[0*64+14] = (w6 >> 22) & 0x1fffffff; w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*64+15] = (w6 >> 51) | (w7 << 13) & 0x1fffffff; out[0*64+16] = (w7 >> 16) & 0x1fffffff; w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*64+17] = (w7 >> 45) | (w8 << 19) & 0x1fffffff; out[0*64+18] = (w8 >> 10) & 0x1fffffff; w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*64+19] = (w8 >> 39) | (w9 << 25) & 0x1fffffff; out[0*64+20] = (w9 >> 4) & 0x1fffffff; out[0*64+21] = (w9 >> 33) & 0x1fffffff; w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*64+22] = (w9 >> 62) | (w10 << 2) & 0x1fffffff; out[0*64+23] = (w10 >> 27) & 0x1fffffff; w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*64+24] = (w10 >> 56) | (w11 << 8) & 0x1fffffff; out[0*64+25] = (w11 >> 21) & 0x1fffffff; w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*64+26] = (w11 >> 50) | (w12 << 14) & 0x1fffffff; out[0*64+27] = (w12 >> 15) & 0x1fffffff; w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*64+28] = (w12 >> 44) | (w13 << 20) & 0x1fffffff; out[0*64+29] = (w13 >> 9) & 0x1fffffff; w14 = *(uint32_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*64+30] = (w13 >> 38) | (w14 << 26) & 0x1fffffff; out[0*64+31] = (w14 >> 3) & 0x1fffffff;;}; out += 32; in += 29*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_30(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*30)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3fffffff; out[0*32+ 1] = (w0 >> 30) & 0x3fffffff; w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*32+ 2] = (w0 >> 60) | (w1 << 4) & 0x3fffffff; out[0*32+ 3] = (w1 >> 26) & 0x3fffffff; w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*32+ 4] = (w1 >> 56) | (w2 << 8) & 0x3fffffff; out[0*32+ 5] = (w2 >> 22) & 0x3fffffff; w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*32+ 6] = (w2 >> 52) | (w3 << 12) & 0x3fffffff; out[0*32+ 7] = (w3 >> 18) & 0x3fffffff; w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*32+ 8] = (w3 >> 48) | (w4 << 16) & 0x3fffffff; out[0*32+ 9] = (w4 >> 14) & 0x3fffffff; w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*32+10] = (w4 >> 44) | (w5 << 20) & 0x3fffffff; out[0*32+11] = (w5 >> 10) & 0x3fffffff; w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*32+12] = (w5 >> 40) | (w6 << 24) & 0x3fffffff; out[0*32+13] = (w6 >> 6) & 0x3fffffff; w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*32+14] = (w6 >> 36) | (w7 << 28) & 0x3fffffff; out[0*32+15] = (w7 >> 2) & 0x3fffffff; out[0*32+16] = (w7 >> 32) & 0x3fffffff; w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*32+17] = (w7 >> 62) | (w8 << 2) & 0x3fffffff; out[0*32+18] = (w8 >> 28) & 0x3fffffff; w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*32+19] = (w8 >> 58) | (w9 << 6) & 0x3fffffff; out[0*32+20] = (w9 >> 24) & 0x3fffffff; w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*32+21] = (w9 >> 54) | (w10 << 10) & 0x3fffffff; out[0*32+22] = (w10 >> 20) & 0x3fffffff; w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*32+23] = (w10 >> 50) | (w11 << 14) & 0x3fffffff; out[0*32+24] = (w11 >> 16) & 0x3fffffff; w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*32+25] = (w11 >> 46) | (w12 << 18) & 0x3fffffff; out[0*32+26] = (w12 >> 12) & 0x3fffffff; w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*32+27] = (w12 >> 42) | (w13 << 22) & 0x3fffffff; out[0*32+28] = (w13 >> 8) & 0x3fffffff; w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*32+29] = (w13 >> 38) | (w14 << 26) & 0x3fffffff; out[0*32+30] = (w14 >> 4) & 0x3fffffff; out[0*32+31] = (w14 >> 34);;}; out += 32; in += 30*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_31(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*31)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7fffffff; out[0*64+ 1] = (w0 >> 31) & 0x7fffffff; w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*64+ 2] = (w0 >> 62) | (w1 << 2) & 0x7fffffff; out[0*64+ 3] = (w1 >> 29) & 0x7fffffff; w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*64+ 4] = (w1 >> 60) | (w2 << 4) & 0x7fffffff; out[0*64+ 5] = (w2 >> 27) & 0x7fffffff; w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*64+ 6] = (w2 >> 58) | (w3 << 6) & 0x7fffffff; out[0*64+ 7] = (w3 >> 25) & 0x7fffffff; w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*64+ 8] = (w3 >> 56) | (w4 << 8) & 0x7fffffff; out[0*64+ 9] = (w4 >> 23) & 0x7fffffff; w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*64+10] = (w4 >> 54) | (w5 << 10) & 0x7fffffff; out[0*64+11] = (w5 >> 21) & 0x7fffffff; w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*64+12] = (w5 >> 52) | (w6 << 12) & 0x7fffffff; out[0*64+13] = (w6 >> 19) & 0x7fffffff; w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*64+14] = (w6 >> 50) | (w7 << 14) & 0x7fffffff; out[0*64+15] = (w7 >> 17) & 0x7fffffff; w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*64+16] = (w7 >> 48) | (w8 << 16) & 0x7fffffff; out[0*64+17] = (w8 >> 15) & 0x7fffffff; w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*64+18] = (w8 >> 46) | (w9 << 18) & 0x7fffffff; out[0*64+19] = (w9 >> 13) & 0x7fffffff; w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*64+20] = (w9 >> 44) | (w10 << 20) & 0x7fffffff; out[0*64+21] = (w10 >> 11) & 0x7fffffff; w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*64+22] = (w10 >> 42) | (w11 << 22) & 0x7fffffff; out[0*64+23] = (w11 >> 9) & 0x7fffffff; w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*64+24] = (w11 >> 40) | (w12 << 24) & 0x7fffffff; out[0*64+25] = (w12 >> 7) & 0x7fffffff; w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*64+26] = (w12 >> 38) | (w13 << 26) & 0x7fffffff; out[0*64+27] = (w13 >> 5) & 0x7fffffff; w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*64+28] = (w13 >> 36) | (w14 << 28) & 0x7fffffff; out[0*64+29] = (w14 >> 3) & 0x7fffffff; w15 = *(uint32_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*64+30] = (w14 >> 34) | (w15 << 30) & 0x7fffffff; out[0*64+31] = (w15 >> 1) & 0x7fffffff;;}; out += 32; in += 31*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack32_32(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out ) { unsigned char *in_=in+(((n*32)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[0*2+ 0] = *(uint32_t *)(in+0*8+ 0); out[0*2+ 1] = *(uint32_t *)(in+0*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[1*2+ 0] = *(uint32_t *)(in+1*8+ 0); out[1*2+ 1] = *(uint32_t *)(in+1*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[2*2+ 0] = *(uint32_t *)(in+2*8+ 0); out[2*2+ 1] = *(uint32_t *)(in+2*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[3*2+ 0] = *(uint32_t *)(in+3*8+ 0); out[3*2+ 1] = *(uint32_t *)(in+3*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[4*2+ 0] = *(uint32_t *)(in+4*8+ 0); out[4*2+ 1] = *(uint32_t *)(in+4*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[5*2+ 0] = *(uint32_t *)(in+5*8+ 0); out[5*2+ 1] = *(uint32_t *)(in+5*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[6*2+ 0] = *(uint32_t *)(in+6*8+ 0); out[6*2+ 1] = *(uint32_t *)(in+6*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[7*2+ 0] = *(uint32_t *)(in+7*8+ 0); out[7*2+ 1] = *(uint32_t *)(in+7*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[8*2+ 0] = *(uint32_t *)(in+8*8+ 0); out[8*2+ 1] = *(uint32_t *)(in+8*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[9*2+ 0] = *(uint32_t *)(in+9*8+ 0); out[9*2+ 1] = *(uint32_t *)(in+9*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[10*2+ 0] = *(uint32_t *)(in+10*8+ 0); out[10*2+ 1] = *(uint32_t *)(in+10*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[11*2+ 0] = *(uint32_t *)(in+11*8+ 0); out[11*2+ 1] = *(uint32_t *)(in+11*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[12*2+ 0] = *(uint32_t *)(in+12*8+ 0); out[12*2+ 1] = *(uint32_t *)(in+12*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[13*2+ 0] = *(uint32_t *)(in+13*8+ 0); out[13*2+ 1] = *(uint32_t *)(in+13*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[14*2+ 0] = *(uint32_t *)(in+14*8+ 0); out[14*2+ 1] = *(uint32_t *)(in+14*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[15*2+ 0] = *(uint32_t *)(in+15*8+ 0); out[15*2+ 1] = *(uint32_t *)(in+15*8+ 4);;}; out += 32; in += 32*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_F32 bitunpacka32[] = {
  &bitunpack32_0,
  &bitunpack32_1,
  &bitunpack32_2,
  &bitunpack32_3,
  &bitunpack32_4,
  &bitunpack32_5,
  &bitunpack32_6,
  &bitunpack32_7,
  &bitunpack32_8,
  &bitunpack32_9,
  &bitunpack32_10,
  &bitunpack32_11,
  &bitunpack32_12,
  &bitunpack32_13,
  &bitunpack32_14,
  &bitunpack32_15,
  &bitunpack32_16,
  &bitunpack32_17,
  &bitunpack32_18,
  &bitunpack32_19,
  &bitunpack32_20,
  &bitunpack32_21,
  &bitunpack32_22,
  &bitunpack32_23,
  &bitunpack32_24,
  &bitunpack32_25,
  &bitunpack32_26,
  &bitunpack32_27,
  &bitunpack32_28,
  &bitunpack32_29,
  &bitunpack32_30,
  &bitunpack32_31,
  &bitunpack32_32
};
unsigned char *bitunpack32( const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , unsigned b) { return bitunpacka32[ b](in, n, out); }
unsigned char *bitunpack64_0(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*0)+7)/8); const uint64_t *out_ = out+n; do { { { out[0*0+ 0] = 0; out[0*0+ 1] = 0; out[0*0+ 2] = 0; out[0*0+ 3] = 0; out[0*0+ 4] = 0; out[0*0+ 5] = 0; out[0*0+ 6] = 0; out[0*0+ 7] = 0; out[0*0+ 8] = 0; out[0*0+ 9] = 0; out[0*0+10] = 0; out[0*0+11] = 0; out[0*0+12] = 0; out[0*0+13] = 0; out[0*0+14] = 0; out[0*0+15] = 0; out[0*0+16] = 0; out[0*0+17] = 0; out[0*0+18] = 0; out[0*0+19] = 0; out[0*0+20] = 0; out[0*0+21] = 0; out[0*0+22] = 0; out[0*0+23] = 0; out[0*0+24] = 0; out[0*0+25] = 0; out[0*0+26] = 0; out[0*0+27] = 0; out[0*0+28] = 0; out[0*0+29] = 0; out[0*0+30] = 0; out[0*0+31] = 0;;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitunpack64_1(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*1)+7)/8); do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x1; out[0*32+ 1] = (w0 >> 1) & 0x1; out[0*32+ 2] = (w0 >> 2) & 0x1; out[0*32+ 3] = (w0 >> 3) & 0x1; out[0*32+ 4] = (w0 >> 4) & 0x1; out[0*32+ 5] = (w0 >> 5) & 0x1; out[0*32+ 6] = (w0 >> 6) & 0x1; out[0*32+ 7] = (w0 >> 7) & 0x1; out[0*32+ 8] = (w0 >> 8) & 0x1; out[0*32+ 9] = (w0 >> 9) & 0x1; out[0*32+10] = (w0 >> 10) & 0x1; out[0*32+11] = (w0 >> 11) & 0x1; out[0*32+12] = (w0 >> 12) & 0x1; out[0*32+13] = (w0 >> 13) & 0x1; out[0*32+14] = (w0 >> 14) & 0x1; out[0*32+15] = (w0 >> 15) & 0x1; out[0*32+16] = (w0 >> 16) & 0x1; out[0*32+17] = (w0 >> 17) & 0x1; out[0*32+18] = (w0 >> 18) & 0x1; out[0*32+19] = (w0 >> 19) & 0x1; out[0*32+20] = (w0 >> 20) & 0x1; out[0*32+21] = (w0 >> 21) & 0x1; out[0*32+22] = (w0 >> 22) & 0x1; out[0*32+23] = (w0 >> 23) & 0x1; out[0*32+24] = (w0 >> 24) & 0x1; out[0*32+25] = (w0 >> 25) & 0x1; out[0*32+26] = (w0 >> 26) & 0x1; out[0*32+27] = (w0 >> 27) & 0x1; out[0*32+28] = (w0 >> 28) & 0x1; out[0*32+29] = (w0 >> 29) & 0x1; out[0*32+30] = (w0 >> 30) & 0x1; out[0*32+31] = (w0 >> 31);;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_2(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*2)+7)/8); do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3; out[0*32+ 1] = (w0 >> 2) & 0x3; out[0*32+ 2] = (w0 >> 4) & 0x3; out[0*32+ 3] = (w0 >> 6) & 0x3; out[0*32+ 4] = (w0 >> 8) & 0x3; out[0*32+ 5] = (w0 >> 10) & 0x3; out[0*32+ 6] = (w0 >> 12) & 0x3; out[0*32+ 7] = (w0 >> 14) & 0x3; out[0*32+ 8] = (w0 >> 16) & 0x3; out[0*32+ 9] = (w0 >> 18) & 0x3; out[0*32+10] = (w0 >> 20) & 0x3; out[0*32+11] = (w0 >> 22) & 0x3; out[0*32+12] = (w0 >> 24) & 0x3; out[0*32+13] = (w0 >> 26) & 0x3; out[0*32+14] = (w0 >> 28) & 0x3; out[0*32+15] = (w0 >> 30) & 0x3; out[0*32+16] = (w0 >> 32) & 0x3; out[0*32+17] = (w0 >> 34) & 0x3; out[0*32+18] = (w0 >> 36) & 0x3; out[0*32+19] = (w0 >> 38) & 0x3; out[0*32+20] = (w0 >> 40) & 0x3; out[0*32+21] = (w0 >> 42) & 0x3; out[0*32+22] = (w0 >> 44) & 0x3; out[0*32+23] = (w0 >> 46) & 0x3; out[0*32+24] = (w0 >> 48) & 0x3; out[0*32+25] = (w0 >> 50) & 0x3; out[0*32+26] = (w0 >> 52) & 0x3; out[0*32+27] = (w0 >> 54) & 0x3; out[0*32+28] = (w0 >> 56) & 0x3; out[0*32+29] = (w0 >> 58) & 0x3; out[0*32+30] = (w0 >> 60) & 0x3; out[0*32+31] = (w0 >> 62);;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_3(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*3)+7)/8); do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7; out[0*64+ 1] = (w0 >> 3) & 0x7; out[0*64+ 2] = (w0 >> 6) & 0x7; out[0*64+ 3] = (w0 >> 9) & 0x7; out[0*64+ 4] = (w0 >> 12) & 0x7; out[0*64+ 5] = (w0 >> 15) & 0x7; out[0*64+ 6] = (w0 >> 18) & 0x7; out[0*64+ 7] = (w0 >> 21) & 0x7; out[0*64+ 8] = (w0 >> 24) & 0x7; out[0*64+ 9] = (w0 >> 27) & 0x7; out[0*64+10] = (w0 >> 30) & 0x7; out[0*64+11] = (w0 >> 33) & 0x7; out[0*64+12] = (w0 >> 36) & 0x7; out[0*64+13] = (w0 >> 39) & 0x7; out[0*64+14] = (w0 >> 42) & 0x7; out[0*64+15] = (w0 >> 45) & 0x7; out[0*64+16] = (w0 >> 48) & 0x7; out[0*64+17] = (w0 >> 51) & 0x7; out[0*64+18] = (w0 >> 54) & 0x7; out[0*64+19] = (w0 >> 57) & 0x7; out[0*64+20] = (w0 >> 60) & 0x7; w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (w0 >> 63) | (w1 << 1) & 0x7; out[0*64+22] = (w1 >> 2) & 0x7; out[0*64+23] = (w1 >> 5) & 0x7; out[0*64+24] = (w1 >> 8) & 0x7; out[0*64+25] = (w1 >> 11) & 0x7; out[0*64+26] = (w1 >> 14) & 0x7; out[0*64+27] = (w1 >> 17) & 0x7; out[0*64+28] = (w1 >> 20) & 0x7; out[0*64+29] = (w1 >> 23) & 0x7; out[0*64+30] = (w1 >> 26) & 0x7; out[0*64+31] = (w1 >> 29) & 0x7;;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_4(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*4)+7)/8); do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xf; out[0*16+ 1] = (w0 >> 4) & 0xf; out[0*16+ 2] = (w0 >> 8) & 0xf; out[0*16+ 3] = (w0 >> 12) & 0xf; out[0*16+ 4] = (w0 >> 16) & 0xf; out[0*16+ 5] = (w0 >> 20) & 0xf; out[0*16+ 6] = (w0 >> 24) & 0xf; out[0*16+ 7] = (w0 >> 28) & 0xf; out[0*16+ 8] = (w0 >> 32) & 0xf; out[0*16+ 9] = (w0 >> 36) & 0xf; out[0*16+10] = (w0 >> 40) & 0xf; out[0*16+11] = (w0 >> 44) & 0xf; out[0*16+12] = (w0 >> 48) & 0xf; out[0*16+13] = (w0 >> 52) & 0xf; out[0*16+14] = (w0 >> 56) & 0xf; out[0*16+15] = (w0 >> 60);;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xf; out[1*16+ 1] = (w0 >> 4) & 0xf; out[1*16+ 2] = (w0 >> 8) & 0xf; out[1*16+ 3] = (w0 >> 12) & 0xf; out[1*16+ 4] = (w0 >> 16) & 0xf; out[1*16+ 5] = (w0 >> 20) & 0xf; out[1*16+ 6] = (w0 >> 24) & 0xf; out[1*16+ 7] = (w0 >> 28) & 0xf; out[1*16+ 8] = (w0 >> 32) & 0xf; out[1*16+ 9] = (w0 >> 36) & 0xf; out[1*16+10] = (w0 >> 40) & 0xf; out[1*16+11] = (w0 >> 44) & 0xf; out[1*16+12] = (w0 >> 48) & 0xf; out[1*16+13] = (w0 >> 52) & 0xf; out[1*16+14] = (w0 >> 56) & 0xf; out[1*16+15] = (w0 >> 60);;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_5(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*5)+7)/8); do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1f; out[0*64+ 1] = (w0 >> 5) & 0x1f; out[0*64+ 2] = (w0 >> 10) & 0x1f; out[0*64+ 3] = (w0 >> 15) & 0x1f; out[0*64+ 4] = (w0 >> 20) & 0x1f; out[0*64+ 5] = (w0 >> 25) & 0x1f; out[0*64+ 6] = (w0 >> 30) & 0x1f; out[0*64+ 7] = (w0 >> 35) & 0x1f; out[0*64+ 8] = (w0 >> 40) & 0x1f; out[0*64+ 9] = (w0 >> 45) & 0x1f; out[0*64+10] = (w0 >> 50) & 0x1f; out[0*64+11] = (w0 >> 55) & 0x1f; w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (w0 >> 60) | (w1 << 4) & 0x1f; out[0*64+13] = (w1 >> 1) & 0x1f; out[0*64+14] = (w1 >> 6) & 0x1f; out[0*64+15] = (w1 >> 11) & 0x1f; out[0*64+16] = (w1 >> 16) & 0x1f; out[0*64+17] = (w1 >> 21) & 0x1f; out[0*64+18] = (w1 >> 26) & 0x1f; out[0*64+19] = (w1 >> 31) & 0x1f; out[0*64+20] = (w1 >> 36) & 0x1f; out[0*64+21] = (w1 >> 41) & 0x1f; out[0*64+22] = (w1 >> 46) & 0x1f; out[0*64+23] = (w1 >> 51) & 0x1f; out[0*64+24] = (w1 >> 56) & 0x1f; w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (w1 >> 61) | (w2 << 3) & 0x1f; out[0*64+26] = (w2 >> 2) & 0x1f; out[0*64+27] = (w2 >> 7) & 0x1f; out[0*64+28] = (w2 >> 12) & 0x1f; out[0*64+29] = (w2 >> 17) & 0x1f; out[0*64+30] = (w2 >> 22) & 0x1f; out[0*64+31] = (w2 >> 27) & 0x1f;;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_6(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*6)+7)/8); do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3f; out[0*32+ 1] = (w0 >> 6) & 0x3f; out[0*32+ 2] = (w0 >> 12) & 0x3f; out[0*32+ 3] = (w0 >> 18) & 0x3f; out[0*32+ 4] = (w0 >> 24) & 0x3f; out[0*32+ 5] = (w0 >> 30) & 0x3f; out[0*32+ 6] = (w0 >> 36) & 0x3f; out[0*32+ 7] = (w0 >> 42) & 0x3f; out[0*32+ 8] = (w0 >> 48) & 0x3f; out[0*32+ 9] = (w0 >> 54) & 0x3f; w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (w0 >> 60) | (w1 << 4) & 0x3f; out[0*32+11] = (w1 >> 2) & 0x3f; out[0*32+12] = (w1 >> 8) & 0x3f; out[0*32+13] = (w1 >> 14) & 0x3f; out[0*32+14] = (w1 >> 20) & 0x3f; out[0*32+15] = (w1 >> 26) & 0x3f; out[0*32+16] = (w1 >> 32) & 0x3f; out[0*32+17] = (w1 >> 38) & 0x3f; out[0*32+18] = (w1 >> 44) & 0x3f; out[0*32+19] = (w1 >> 50) & 0x3f; out[0*32+20] = (w1 >> 56) & 0x3f; w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (w1 >> 62) | (w2 << 2) & 0x3f; out[0*32+22] = (w2 >> 4) & 0x3f; out[0*32+23] = (w2 >> 10) & 0x3f; out[0*32+24] = (w2 >> 16) & 0x3f; out[0*32+25] = (w2 >> 22) & 0x3f; out[0*32+26] = (w2 >> 28) & 0x3f; out[0*32+27] = (w2 >> 34) & 0x3f; out[0*32+28] = (w2 >> 40) & 0x3f; out[0*32+29] = (w2 >> 46) & 0x3f; out[0*32+30] = (w2 >> 52) & 0x3f; out[0*32+31] = (w2 >> 58);;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_7(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*7)+7)/8); do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7f; out[0*64+ 1] = (w0 >> 7) & 0x7f; out[0*64+ 2] = (w0 >> 14) & 0x7f; out[0*64+ 3] = (w0 >> 21) & 0x7f; out[0*64+ 4] = (w0 >> 28) & 0x7f; out[0*64+ 5] = (w0 >> 35) & 0x7f; out[0*64+ 6] = (w0 >> 42) & 0x7f; out[0*64+ 7] = (w0 >> 49) & 0x7f; out[0*64+ 8] = (w0 >> 56) & 0x7f; w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (w0 >> 63) | (w1 << 1) & 0x7f; out[0*64+10] = (w1 >> 6) & 0x7f; out[0*64+11] = (w1 >> 13) & 0x7f; out[0*64+12] = (w1 >> 20) & 0x7f; out[0*64+13] = (w1 >> 27) & 0x7f; out[0*64+14] = (w1 >> 34) & 0x7f; out[0*64+15] = (w1 >> 41) & 0x7f; out[0*64+16] = (w1 >> 48) & 0x7f; out[0*64+17] = (w1 >> 55) & 0x7f; w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (w1 >> 62) | (w2 << 2) & 0x7f; out[0*64+19] = (w2 >> 5) & 0x7f; out[0*64+20] = (w2 >> 12) & 0x7f; out[0*64+21] = (w2 >> 19) & 0x7f; out[0*64+22] = (w2 >> 26) & 0x7f; out[0*64+23] = (w2 >> 33) & 0x7f; out[0*64+24] = (w2 >> 40) & 0x7f; out[0*64+25] = (w2 >> 47) & 0x7f; out[0*64+26] = (w2 >> 54) & 0x7f; w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (w2 >> 61) | (w3 << 3) & 0x7f; out[0*64+28] = (w3 >> 4) & 0x7f; out[0*64+29] = (w3 >> 11) & 0x7f; out[0*64+30] = (w3 >> 18) & 0x7f; out[0*64+31] = (w3 >> 25) & 0x7f;;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_8(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*8)+7)/8); do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (w0 ) & 0xff; out[0*8+ 1] = (w0 >> 8) & 0xff; out[0*8+ 2] = (w0 >> 16) & 0xff; out[0*8+ 3] = (w0 >> 24) & 0xff; out[0*8+ 4] = (w0 >> 32) & 0xff; out[0*8+ 5] = (w0 >> 40) & 0xff; out[0*8+ 6] = (w0 >> 48) & 0xff; out[0*8+ 7] = (w0 >> 56);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (w0 ) & 0xff; out[1*8+ 1] = (w0 >> 8) & 0xff; out[1*8+ 2] = (w0 >> 16) & 0xff; out[1*8+ 3] = (w0 >> 24) & 0xff; out[1*8+ 4] = (w0 >> 32) & 0xff; out[1*8+ 5] = (w0 >> 40) & 0xff; out[1*8+ 6] = (w0 >> 48) & 0xff; out[1*8+ 7] = (w0 >> 56);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (w0 ) & 0xff; out[2*8+ 1] = (w0 >> 8) & 0xff; out[2*8+ 2] = (w0 >> 16) & 0xff; out[2*8+ 3] = (w0 >> 24) & 0xff; out[2*8+ 4] = (w0 >> 32) & 0xff; out[2*8+ 5] = (w0 >> 40) & 0xff; out[2*8+ 6] = (w0 >> 48) & 0xff; out[2*8+ 7] = (w0 >> 56);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (w0 ) & 0xff; out[3*8+ 1] = (w0 >> 8) & 0xff; out[3*8+ 2] = (w0 >> 16) & 0xff; out[3*8+ 3] = (w0 >> 24) & 0xff; out[3*8+ 4] = (w0 >> 32) & 0xff; out[3*8+ 5] = (w0 >> 40) & 0xff; out[3*8+ 6] = (w0 >> 48) & 0xff; out[3*8+ 7] = (w0 >> 56);;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_9(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*9)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1ff; out[0*64+ 1] = (w0 >> 9) & 0x1ff; out[0*64+ 2] = (w0 >> 18) & 0x1ff; out[0*64+ 3] = (w0 >> 27) & 0x1ff; out[0*64+ 4] = (w0 >> 36) & 0x1ff; out[0*64+ 5] = (w0 >> 45) & 0x1ff; out[0*64+ 6] = (w0 >> 54) & 0x1ff; w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (w0 >> 63) | (w1 << 1) & 0x1ff; out[0*64+ 8] = (w1 >> 8) & 0x1ff; out[0*64+ 9] = (w1 >> 17) & 0x1ff; out[0*64+10] = (w1 >> 26) & 0x1ff; out[0*64+11] = (w1 >> 35) & 0x1ff; out[0*64+12] = (w1 >> 44) & 0x1ff; out[0*64+13] = (w1 >> 53) & 0x1ff; w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (w1 >> 62) | (w2 << 2) & 0x1ff; out[0*64+15] = (w2 >> 7) & 0x1ff; out[0*64+16] = (w2 >> 16) & 0x1ff; out[0*64+17] = (w2 >> 25) & 0x1ff; out[0*64+18] = (w2 >> 34) & 0x1ff; out[0*64+19] = (w2 >> 43) & 0x1ff; out[0*64+20] = (w2 >> 52) & 0x1ff; w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (w2 >> 61) | (w3 << 3) & 0x1ff; out[0*64+22] = (w3 >> 6) & 0x1ff; out[0*64+23] = (w3 >> 15) & 0x1ff; out[0*64+24] = (w3 >> 24) & 0x1ff; out[0*64+25] = (w3 >> 33) & 0x1ff; out[0*64+26] = (w3 >> 42) & 0x1ff; out[0*64+27] = (w3 >> 51) & 0x1ff; w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (w3 >> 60) | (w4 << 4) & 0x1ff; out[0*64+29] = (w4 >> 5) & 0x1ff; out[0*64+30] = (w4 >> 14) & 0x1ff; out[0*64+31] = (w4 >> 23) & 0x1ff;;}; out += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_10(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*10)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3ff; out[0*32+ 1] = (w0 >> 10) & 0x3ff; out[0*32+ 2] = (w0 >> 20) & 0x3ff; out[0*32+ 3] = (w0 >> 30) & 0x3ff; out[0*32+ 4] = (w0 >> 40) & 0x3ff; out[0*32+ 5] = (w0 >> 50) & 0x3ff; w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (w0 >> 60) | (w1 << 4) & 0x3ff; out[0*32+ 7] = (w1 >> 6) & 0x3ff; out[0*32+ 8] = (w1 >> 16) & 0x3ff; out[0*32+ 9] = (w1 >> 26) & 0x3ff; out[0*32+10] = (w1 >> 36) & 0x3ff; out[0*32+11] = (w1 >> 46) & 0x3ff; w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (w1 >> 56) | (w2 << 8) & 0x3ff; out[0*32+13] = (w2 >> 2) & 0x3ff; out[0*32+14] = (w2 >> 12) & 0x3ff; out[0*32+15] = (w2 >> 22) & 0x3ff; out[0*32+16] = (w2 >> 32) & 0x3ff; out[0*32+17] = (w2 >> 42) & 0x3ff; out[0*32+18] = (w2 >> 52) & 0x3ff; w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (w2 >> 62) | (w3 << 2) & 0x3ff; out[0*32+20] = (w3 >> 8) & 0x3ff; out[0*32+21] = (w3 >> 18) & 0x3ff; out[0*32+22] = (w3 >> 28) & 0x3ff; out[0*32+23] = (w3 >> 38) & 0x3ff; out[0*32+24] = (w3 >> 48) & 0x3ff; w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (w3 >> 58) | (w4 << 6) & 0x3ff; out[0*32+26] = (w4 >> 4) & 0x3ff; out[0*32+27] = (w4 >> 14) & 0x3ff; out[0*32+28] = (w4 >> 24) & 0x3ff; out[0*32+29] = (w4 >> 34) & 0x3ff; out[0*32+30] = (w4 >> 44) & 0x3ff; out[0*32+31] = (w4 >> 54);;}; out += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_11(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*11)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7ff; out[0*64+ 1] = (w0 >> 11) & 0x7ff; out[0*64+ 2] = (w0 >> 22) & 0x7ff; out[0*64+ 3] = (w0 >> 33) & 0x7ff; out[0*64+ 4] = (w0 >> 44) & 0x7ff; w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (w0 >> 55) | (w1 << 9) & 0x7ff; out[0*64+ 6] = (w1 >> 2) & 0x7ff; out[0*64+ 7] = (w1 >> 13) & 0x7ff; out[0*64+ 8] = (w1 >> 24) & 0x7ff; out[0*64+ 9] = (w1 >> 35) & 0x7ff; out[0*64+10] = (w1 >> 46) & 0x7ff; w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (w1 >> 57) | (w2 << 7) & 0x7ff; out[0*64+12] = (w2 >> 4) & 0x7ff; out[0*64+13] = (w2 >> 15) & 0x7ff; out[0*64+14] = (w2 >> 26) & 0x7ff; out[0*64+15] = (w2 >> 37) & 0x7ff; out[0*64+16] = (w2 >> 48) & 0x7ff; w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (w2 >> 59) | (w3 << 5) & 0x7ff; out[0*64+18] = (w3 >> 6) & 0x7ff; out[0*64+19] = (w3 >> 17) & 0x7ff; out[0*64+20] = (w3 >> 28) & 0x7ff; out[0*64+21] = (w3 >> 39) & 0x7ff; out[0*64+22] = (w3 >> 50) & 0x7ff; w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (w3 >> 61) | (w4 << 3) & 0x7ff; out[0*64+24] = (w4 >> 8) & 0x7ff; out[0*64+25] = (w4 >> 19) & 0x7ff; out[0*64+26] = (w4 >> 30) & 0x7ff; out[0*64+27] = (w4 >> 41) & 0x7ff; out[0*64+28] = (w4 >> 52) & 0x7ff; w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (w4 >> 63) | (w5 << 1) & 0x7ff; out[0*64+30] = (w5 >> 10) & 0x7ff; out[0*64+31] = (w5 >> 21) & 0x7ff;;}; out += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_12(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*12)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xfff; out[0*16+ 1] = (w0 >> 12) & 0xfff; out[0*16+ 2] = (w0 >> 24) & 0xfff; out[0*16+ 3] = (w0 >> 36) & 0xfff; out[0*16+ 4] = (w0 >> 48) & 0xfff; w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (w0 >> 60) | (w1 << 4) & 0xfff; out[0*16+ 6] = (w1 >> 8) & 0xfff; out[0*16+ 7] = (w1 >> 20) & 0xfff; out[0*16+ 8] = (w1 >> 32) & 0xfff; out[0*16+ 9] = (w1 >> 44) & 0xfff; w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (w1 >> 56) | (w2 << 8) & 0xfff; out[0*16+11] = (w2 >> 4) & 0xfff; out[0*16+12] = (w2 >> 16) & 0xfff; out[0*16+13] = (w2 >> 28) & 0xfff; out[0*16+14] = (w2 >> 40) & 0xfff; out[0*16+15] = (w2 >> 52);;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xfff; out[1*16+ 1] = (w0 >> 12) & 0xfff; out[1*16+ 2] = (w0 >> 24) & 0xfff; out[1*16+ 3] = (w0 >> 36) & 0xfff; out[1*16+ 4] = (w0 >> 48) & 0xfff; w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (w0 >> 60) | (w1 << 4) & 0xfff; out[1*16+ 6] = (w1 >> 8) & 0xfff; out[1*16+ 7] = (w1 >> 20) & 0xfff; out[1*16+ 8] = (w1 >> 32) & 0xfff; out[1*16+ 9] = (w1 >> 44) & 0xfff; w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (w1 >> 56) | (w2 << 8) & 0xfff; out[1*16+11] = (w2 >> 4) & 0xfff; out[1*16+12] = (w2 >> 16) & 0xfff; out[1*16+13] = (w2 >> 28) & 0xfff; out[1*16+14] = (w2 >> 40) & 0xfff; out[1*16+15] = (w2 >> 52);;}; out += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_13(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*13)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1fff; out[0*64+ 1] = (w0 >> 13) & 0x1fff; out[0*64+ 2] = (w0 >> 26) & 0x1fff; out[0*64+ 3] = (w0 >> 39) & 0x1fff; w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (w0 >> 52) | (w1 << 12) & 0x1fff; out[0*64+ 5] = (w1 >> 1) & 0x1fff; out[0*64+ 6] = (w1 >> 14) & 0x1fff; out[0*64+ 7] = (w1 >> 27) & 0x1fff; out[0*64+ 8] = (w1 >> 40) & 0x1fff; w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (w1 >> 53) | (w2 << 11) & 0x1fff; out[0*64+10] = (w2 >> 2) & 0x1fff; out[0*64+11] = (w2 >> 15) & 0x1fff; out[0*64+12] = (w2 >> 28) & 0x1fff; out[0*64+13] = (w2 >> 41) & 0x1fff; w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (w2 >> 54) | (w3 << 10) & 0x1fff; out[0*64+15] = (w3 >> 3) & 0x1fff; out[0*64+16] = (w3 >> 16) & 0x1fff; out[0*64+17] = (w3 >> 29) & 0x1fff; out[0*64+18] = (w3 >> 42) & 0x1fff; w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (w3 >> 55) | (w4 << 9) & 0x1fff; out[0*64+20] = (w4 >> 4) & 0x1fff; out[0*64+21] = (w4 >> 17) & 0x1fff; out[0*64+22] = (w4 >> 30) & 0x1fff; out[0*64+23] = (w4 >> 43) & 0x1fff; w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (w4 >> 56) | (w5 << 8) & 0x1fff; out[0*64+25] = (w5 >> 5) & 0x1fff; out[0*64+26] = (w5 >> 18) & 0x1fff; out[0*64+27] = (w5 >> 31) & 0x1fff; out[0*64+28] = (w5 >> 44) & 0x1fff; w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (w5 >> 57) | (w6 << 7) & 0x1fff; out[0*64+30] = (w6 >> 6) & 0x1fff; out[0*64+31] = (w6 >> 19) & 0x1fff;;}; out += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_14(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*14)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3fff; out[0*32+ 1] = (w0 >> 14) & 0x3fff; out[0*32+ 2] = (w0 >> 28) & 0x3fff; out[0*32+ 3] = (w0 >> 42) & 0x3fff; w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (w0 >> 56) | (w1 << 8) & 0x3fff; out[0*32+ 5] = (w1 >> 6) & 0x3fff; out[0*32+ 6] = (w1 >> 20) & 0x3fff; out[0*32+ 7] = (w1 >> 34) & 0x3fff; out[0*32+ 8] = (w1 >> 48) & 0x3fff; w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (w1 >> 62) | (w2 << 2) & 0x3fff; out[0*32+10] = (w2 >> 12) & 0x3fff; out[0*32+11] = (w2 >> 26) & 0x3fff; out[0*32+12] = (w2 >> 40) & 0x3fff; w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (w2 >> 54) | (w3 << 10) & 0x3fff; out[0*32+14] = (w3 >> 4) & 0x3fff; out[0*32+15] = (w3 >> 18) & 0x3fff; out[0*32+16] = (w3 >> 32) & 0x3fff; out[0*32+17] = (w3 >> 46) & 0x3fff; w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (w3 >> 60) | (w4 << 4) & 0x3fff; out[0*32+19] = (w4 >> 10) & 0x3fff; out[0*32+20] = (w4 >> 24) & 0x3fff; out[0*32+21] = (w4 >> 38) & 0x3fff; w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (w4 >> 52) | (w5 << 12) & 0x3fff; out[0*32+23] = (w5 >> 2) & 0x3fff; out[0*32+24] = (w5 >> 16) & 0x3fff; out[0*32+25] = (w5 >> 30) & 0x3fff; out[0*32+26] = (w5 >> 44) & 0x3fff; w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (w5 >> 58) | (w6 << 6) & 0x3fff; out[0*32+28] = (w6 >> 8) & 0x3fff; out[0*32+29] = (w6 >> 22) & 0x3fff; out[0*32+30] = (w6 >> 36) & 0x3fff; out[0*32+31] = (w6 >> 50);;}; out += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_15(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*15)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7fff; out[0*64+ 1] = (w0 >> 15) & 0x7fff; out[0*64+ 2] = (w0 >> 30) & 0x7fff; out[0*64+ 3] = (w0 >> 45) & 0x7fff; w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (w0 >> 60) | (w1 << 4) & 0x7fff; out[0*64+ 5] = (w1 >> 11) & 0x7fff; out[0*64+ 6] = (w1 >> 26) & 0x7fff; out[0*64+ 7] = (w1 >> 41) & 0x7fff; w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (w1 >> 56) | (w2 << 8) & 0x7fff; out[0*64+ 9] = (w2 >> 7) & 0x7fff; out[0*64+10] = (w2 >> 22) & 0x7fff; out[0*64+11] = (w2 >> 37) & 0x7fff; w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (w2 >> 52) | (w3 << 12) & 0x7fff; out[0*64+13] = (w3 >> 3) & 0x7fff; out[0*64+14] = (w3 >> 18) & 0x7fff; out[0*64+15] = (w3 >> 33) & 0x7fff; out[0*64+16] = (w3 >> 48) & 0x7fff; w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (w3 >> 63) | (w4 << 1) & 0x7fff; out[0*64+18] = (w4 >> 14) & 0x7fff; out[0*64+19] = (w4 >> 29) & 0x7fff; out[0*64+20] = (w4 >> 44) & 0x7fff; w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (w4 >> 59) | (w5 << 5) & 0x7fff; out[0*64+22] = (w5 >> 10) & 0x7fff; out[0*64+23] = (w5 >> 25) & 0x7fff; out[0*64+24] = (w5 >> 40) & 0x7fff; w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (w5 >> 55) | (w6 << 9) & 0x7fff; out[0*64+26] = (w6 >> 6) & 0x7fff; out[0*64+27] = (w6 >> 21) & 0x7fff; out[0*64+28] = (w6 >> 36) & 0x7fff; w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (w6 >> 51) | (w7 << 13) & 0x7fff; out[0*64+30] = (w7 >> 2) & 0x7fff; out[0*64+31] = (w7 >> 17) & 0x7fff;;}; out += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_16(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*16)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = *(uint16_t *)(in+0*8+ 0); out[0*4+ 1] = *(uint16_t *)(in+0*8+ 2); out[0*4+ 2] = *(uint16_t *)(in+0*8+ 4); out[0*4+ 3] = *(uint16_t *)(in+0*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = *(uint16_t *)(in+1*8+ 0); out[1*4+ 1] = *(uint16_t *)(in+1*8+ 2); out[1*4+ 2] = *(uint16_t *)(in+1*8+ 4); out[1*4+ 3] = *(uint16_t *)(in+1*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = *(uint16_t *)(in+2*8+ 0); out[2*4+ 1] = *(uint16_t *)(in+2*8+ 2); out[2*4+ 2] = *(uint16_t *)(in+2*8+ 4); out[2*4+ 3] = *(uint16_t *)(in+2*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = *(uint16_t *)(in+3*8+ 0); out[3*4+ 1] = *(uint16_t *)(in+3*8+ 2); out[3*4+ 2] = *(uint16_t *)(in+3*8+ 4); out[3*4+ 3] = *(uint16_t *)(in+3*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = *(uint16_t *)(in+4*8+ 0); out[4*4+ 1] = *(uint16_t *)(in+4*8+ 2); out[4*4+ 2] = *(uint16_t *)(in+4*8+ 4); out[4*4+ 3] = *(uint16_t *)(in+4*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = *(uint16_t *)(in+5*8+ 0); out[5*4+ 1] = *(uint16_t *)(in+5*8+ 2); out[5*4+ 2] = *(uint16_t *)(in+5*8+ 4); out[5*4+ 3] = *(uint16_t *)(in+5*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = *(uint16_t *)(in+6*8+ 0); out[6*4+ 1] = *(uint16_t *)(in+6*8+ 2); out[6*4+ 2] = *(uint16_t *)(in+6*8+ 4); out[6*4+ 3] = *(uint16_t *)(in+6*8+ 6);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = *(uint16_t *)(in+7*8+ 0); out[7*4+ 1] = *(uint16_t *)(in+7*8+ 2); out[7*4+ 2] = *(uint16_t *)(in+7*8+ 4); out[7*4+ 3] = *(uint16_t *)(in+7*8+ 6);;}; out += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_17(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*17)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1ffff; out[0*64+ 1] = (w0 >> 17) & 0x1ffff; out[0*64+ 2] = (w0 >> 34) & 0x1ffff; w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*64+ 3] = (w0 >> 51) | (w1 << 13) & 0x1ffff; out[0*64+ 4] = (w1 >> 4) & 0x1ffff; out[0*64+ 5] = (w1 >> 21) & 0x1ffff; out[0*64+ 6] = (w1 >> 38) & 0x1ffff; w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*64+ 7] = (w1 >> 55) | (w2 << 9) & 0x1ffff; out[0*64+ 8] = (w2 >> 8) & 0x1ffff; out[0*64+ 9] = (w2 >> 25) & 0x1ffff; out[0*64+10] = (w2 >> 42) & 0x1ffff; w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*64+11] = (w2 >> 59) | (w3 << 5) & 0x1ffff; out[0*64+12] = (w3 >> 12) & 0x1ffff; out[0*64+13] = (w3 >> 29) & 0x1ffff; out[0*64+14] = (w3 >> 46) & 0x1ffff; w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*64+15] = (w3 >> 63) | (w4 << 1) & 0x1ffff; out[0*64+16] = (w4 >> 16) & 0x1ffff; out[0*64+17] = (w4 >> 33) & 0x1ffff; w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*64+18] = (w4 >> 50) | (w5 << 14) & 0x1ffff; out[0*64+19] = (w5 >> 3) & 0x1ffff; out[0*64+20] = (w5 >> 20) & 0x1ffff; out[0*64+21] = (w5 >> 37) & 0x1ffff; w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*64+22] = (w5 >> 54) | (w6 << 10) & 0x1ffff; out[0*64+23] = (w6 >> 7) & 0x1ffff; out[0*64+24] = (w6 >> 24) & 0x1ffff; out[0*64+25] = (w6 >> 41) & 0x1ffff; w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*64+26] = (w6 >> 58) | (w7 << 6) & 0x1ffff; out[0*64+27] = (w7 >> 11) & 0x1ffff; out[0*64+28] = (w7 >> 28) & 0x1ffff; out[0*64+29] = (w7 >> 45) & 0x1ffff; w8 = *(uint32_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*64+30] = (w7 >> 62) | (w8 << 2) & 0x1ffff; out[0*64+31] = (w8 >> 15) & 0x1ffff;;}; out += 32; in += 17*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_18(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*18)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3ffff; out[0*32+ 1] = (w0 >> 18) & 0x3ffff; out[0*32+ 2] = (w0 >> 36) & 0x3ffff; w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*32+ 3] = (w0 >> 54) | (w1 << 10) & 0x3ffff; out[0*32+ 4] = (w1 >> 8) & 0x3ffff; out[0*32+ 5] = (w1 >> 26) & 0x3ffff; out[0*32+ 6] = (w1 >> 44) & 0x3ffff; w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*32+ 7] = (w1 >> 62) | (w2 << 2) & 0x3ffff; out[0*32+ 8] = (w2 >> 16) & 0x3ffff; out[0*32+ 9] = (w2 >> 34) & 0x3ffff; w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*32+10] = (w2 >> 52) | (w3 << 12) & 0x3ffff; out[0*32+11] = (w3 >> 6) & 0x3ffff; out[0*32+12] = (w3 >> 24) & 0x3ffff; out[0*32+13] = (w3 >> 42) & 0x3ffff; w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*32+14] = (w3 >> 60) | (w4 << 4) & 0x3ffff; out[0*32+15] = (w4 >> 14) & 0x3ffff; out[0*32+16] = (w4 >> 32) & 0x3ffff; w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*32+17] = (w4 >> 50) | (w5 << 14) & 0x3ffff; out[0*32+18] = (w5 >> 4) & 0x3ffff; out[0*32+19] = (w5 >> 22) & 0x3ffff; out[0*32+20] = (w5 >> 40) & 0x3ffff; w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*32+21] = (w5 >> 58) | (w6 << 6) & 0x3ffff; out[0*32+22] = (w6 >> 12) & 0x3ffff; out[0*32+23] = (w6 >> 30) & 0x3ffff; w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*32+24] = (w6 >> 48) | (w7 << 16) & 0x3ffff; out[0*32+25] = (w7 >> 2) & 0x3ffff; out[0*32+26] = (w7 >> 20) & 0x3ffff; out[0*32+27] = (w7 >> 38) & 0x3ffff; w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*32+28] = (w7 >> 56) | (w8 << 8) & 0x3ffff; out[0*32+29] = (w8 >> 10) & 0x3ffff; out[0*32+30] = (w8 >> 28) & 0x3ffff; out[0*32+31] = (w8 >> 46);;}; out += 32; in += 18*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_19(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*19)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7ffff; out[0*64+ 1] = (w0 >> 19) & 0x7ffff; out[0*64+ 2] = (w0 >> 38) & 0x7ffff; w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*64+ 3] = (w0 >> 57) | (w1 << 7) & 0x7ffff; out[0*64+ 4] = (w1 >> 12) & 0x7ffff; out[0*64+ 5] = (w1 >> 31) & 0x7ffff; w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*64+ 6] = (w1 >> 50) | (w2 << 14) & 0x7ffff; out[0*64+ 7] = (w2 >> 5) & 0x7ffff; out[0*64+ 8] = (w2 >> 24) & 0x7ffff; out[0*64+ 9] = (w2 >> 43) & 0x7ffff; w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*64+10] = (w2 >> 62) | (w3 << 2) & 0x7ffff; out[0*64+11] = (w3 >> 17) & 0x7ffff; out[0*64+12] = (w3 >> 36) & 0x7ffff; w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*64+13] = (w3 >> 55) | (w4 << 9) & 0x7ffff; out[0*64+14] = (w4 >> 10) & 0x7ffff; out[0*64+15] = (w4 >> 29) & 0x7ffff; w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*64+16] = (w4 >> 48) | (w5 << 16) & 0x7ffff; out[0*64+17] = (w5 >> 3) & 0x7ffff; out[0*64+18] = (w5 >> 22) & 0x7ffff; out[0*64+19] = (w5 >> 41) & 0x7ffff; w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*64+20] = (w5 >> 60) | (w6 << 4) & 0x7ffff; out[0*64+21] = (w6 >> 15) & 0x7ffff; out[0*64+22] = (w6 >> 34) & 0x7ffff; w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*64+23] = (w6 >> 53) | (w7 << 11) & 0x7ffff; out[0*64+24] = (w7 >> 8) & 0x7ffff; out[0*64+25] = (w7 >> 27) & 0x7ffff; w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*64+26] = (w7 >> 46) | (w8 << 18) & 0x7ffff; out[0*64+27] = (w8 >> 1) & 0x7ffff; out[0*64+28] = (w8 >> 20) & 0x7ffff; out[0*64+29] = (w8 >> 39) & 0x7ffff; w9 = *(uint32_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*64+30] = (w8 >> 58) | (w9 << 6) & 0x7ffff; out[0*64+31] = (w9 >> 13) & 0x7ffff;;}; out += 32; in += 19*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_20(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*20)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xfffff; out[0*16+ 1] = (w0 >> 20) & 0xfffff; out[0*16+ 2] = (w0 >> 40) & 0xfffff; w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*16+ 3] = (w0 >> 60) | (w1 << 4) & 0xfffff; out[0*16+ 4] = (w1 >> 16) & 0xfffff; out[0*16+ 5] = (w1 >> 36) & 0xfffff; w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*16+ 6] = (w1 >> 56) | (w2 << 8) & 0xfffff; out[0*16+ 7] = (w2 >> 12) & 0xfffff; out[0*16+ 8] = (w2 >> 32) & 0xfffff; w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*16+ 9] = (w2 >> 52) | (w3 << 12) & 0xfffff; out[0*16+10] = (w3 >> 8) & 0xfffff; out[0*16+11] = (w3 >> 28) & 0xfffff; w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*16+12] = (w3 >> 48) | (w4 << 16) & 0xfffff; out[0*16+13] = (w4 >> 4) & 0xfffff; out[0*16+14] = (w4 >> 24) & 0xfffff; out[0*16+15] = (w4 >> 44);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xfffff; out[1*16+ 1] = (w0 >> 20) & 0xfffff; out[1*16+ 2] = (w0 >> 40) & 0xfffff; w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*16+ 3] = (w0 >> 60) | (w1 << 4) & 0xfffff; out[1*16+ 4] = (w1 >> 16) & 0xfffff; out[1*16+ 5] = (w1 >> 36) & 0xfffff; w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*16+ 6] = (w1 >> 56) | (w2 << 8) & 0xfffff; out[1*16+ 7] = (w2 >> 12) & 0xfffff; out[1*16+ 8] = (w2 >> 32) & 0xfffff; w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*16+ 9] = (w2 >> 52) | (w3 << 12) & 0xfffff; out[1*16+10] = (w3 >> 8) & 0xfffff; out[1*16+11] = (w3 >> 28) & 0xfffff; w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*16+12] = (w3 >> 48) | (w4 << 16) & 0xfffff; out[1*16+13] = (w4 >> 4) & 0xfffff; out[1*16+14] = (w4 >> 24) & 0xfffff; out[1*16+15] = (w4 >> 44);;}; out += 32; in += 20*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_21(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*21)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1fffff; out[0*64+ 1] = (w0 >> 21) & 0x1fffff; out[0*64+ 2] = (w0 >> 42) & 0x1fffff; w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*64+ 3] = (w0 >> 63) | (w1 << 1) & 0x1fffff; out[0*64+ 4] = (w1 >> 20) & 0x1fffff; out[0*64+ 5] = (w1 >> 41) & 0x1fffff; w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*64+ 6] = (w1 >> 62) | (w2 << 2) & 0x1fffff; out[0*64+ 7] = (w2 >> 19) & 0x1fffff; out[0*64+ 8] = (w2 >> 40) & 0x1fffff; w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*64+ 9] = (w2 >> 61) | (w3 << 3) & 0x1fffff; out[0*64+10] = (w3 >> 18) & 0x1fffff; out[0*64+11] = (w3 >> 39) & 0x1fffff; w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*64+12] = (w3 >> 60) | (w4 << 4) & 0x1fffff; out[0*64+13] = (w4 >> 17) & 0x1fffff; out[0*64+14] = (w4 >> 38) & 0x1fffff; w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*64+15] = (w4 >> 59) | (w5 << 5) & 0x1fffff; out[0*64+16] = (w5 >> 16) & 0x1fffff; out[0*64+17] = (w5 >> 37) & 0x1fffff; w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*64+18] = (w5 >> 58) | (w6 << 6) & 0x1fffff; out[0*64+19] = (w6 >> 15) & 0x1fffff; out[0*64+20] = (w6 >> 36) & 0x1fffff; w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*64+21] = (w6 >> 57) | (w7 << 7) & 0x1fffff; out[0*64+22] = (w7 >> 14) & 0x1fffff; out[0*64+23] = (w7 >> 35) & 0x1fffff; w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*64+24] = (w7 >> 56) | (w8 << 8) & 0x1fffff; out[0*64+25] = (w8 >> 13) & 0x1fffff; out[0*64+26] = (w8 >> 34) & 0x1fffff; w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*64+27] = (w8 >> 55) | (w9 << 9) & 0x1fffff; out[0*64+28] = (w9 >> 12) & 0x1fffff; out[0*64+29] = (w9 >> 33) & 0x1fffff; w10 = *(uint32_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*64+30] = (w9 >> 54) | (w10 << 10) & 0x1fffff; out[0*64+31] = (w10 >> 11) & 0x1fffff;;}; out += 32; in += 21*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_22(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*22)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3fffff; out[0*32+ 1] = (w0 >> 22) & 0x3fffff; w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*32+ 2] = (w0 >> 44) | (w1 << 20) & 0x3fffff; out[0*32+ 3] = (w1 >> 2) & 0x3fffff; out[0*32+ 4] = (w1 >> 24) & 0x3fffff; w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*32+ 5] = (w1 >> 46) | (w2 << 18) & 0x3fffff; out[0*32+ 6] = (w2 >> 4) & 0x3fffff; out[0*32+ 7] = (w2 >> 26) & 0x3fffff; w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*32+ 8] = (w2 >> 48) | (w3 << 16) & 0x3fffff; out[0*32+ 9] = (w3 >> 6) & 0x3fffff; out[0*32+10] = (w3 >> 28) & 0x3fffff; w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*32+11] = (w3 >> 50) | (w4 << 14) & 0x3fffff; out[0*32+12] = (w4 >> 8) & 0x3fffff; out[0*32+13] = (w4 >> 30) & 0x3fffff; w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*32+14] = (w4 >> 52) | (w5 << 12) & 0x3fffff; out[0*32+15] = (w5 >> 10) & 0x3fffff; out[0*32+16] = (w5 >> 32) & 0x3fffff; w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*32+17] = (w5 >> 54) | (w6 << 10) & 0x3fffff; out[0*32+18] = (w6 >> 12) & 0x3fffff; out[0*32+19] = (w6 >> 34) & 0x3fffff; w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*32+20] = (w6 >> 56) | (w7 << 8) & 0x3fffff; out[0*32+21] = (w7 >> 14) & 0x3fffff; out[0*32+22] = (w7 >> 36) & 0x3fffff; w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*32+23] = (w7 >> 58) | (w8 << 6) & 0x3fffff; out[0*32+24] = (w8 >> 16) & 0x3fffff; out[0*32+25] = (w8 >> 38) & 0x3fffff; w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*32+26] = (w8 >> 60) | (w9 << 4) & 0x3fffff; out[0*32+27] = (w9 >> 18) & 0x3fffff; out[0*32+28] = (w9 >> 40) & 0x3fffff; w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*32+29] = (w9 >> 62) | (w10 << 2) & 0x3fffff; out[0*32+30] = (w10 >> 20) & 0x3fffff; out[0*32+31] = (w10 >> 42);;}; out += 32; in += 22*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_23(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*23)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7fffff; out[0*64+ 1] = (w0 >> 23) & 0x7fffff; w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*64+ 2] = (w0 >> 46) | (w1 << 18) & 0x7fffff; out[0*64+ 3] = (w1 >> 5) & 0x7fffff; out[0*64+ 4] = (w1 >> 28) & 0x7fffff; w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*64+ 5] = (w1 >> 51) | (w2 << 13) & 0x7fffff; out[0*64+ 6] = (w2 >> 10) & 0x7fffff; out[0*64+ 7] = (w2 >> 33) & 0x7fffff; w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*64+ 8] = (w2 >> 56) | (w3 << 8) & 0x7fffff; out[0*64+ 9] = (w3 >> 15) & 0x7fffff; out[0*64+10] = (w3 >> 38) & 0x7fffff; w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*64+11] = (w3 >> 61) | (w4 << 3) & 0x7fffff; out[0*64+12] = (w4 >> 20) & 0x7fffff; w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*64+13] = (w4 >> 43) | (w5 << 21) & 0x7fffff; out[0*64+14] = (w5 >> 2) & 0x7fffff; out[0*64+15] = (w5 >> 25) & 0x7fffff; w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*64+16] = (w5 >> 48) | (w6 << 16) & 0x7fffff; out[0*64+17] = (w6 >> 7) & 0x7fffff; out[0*64+18] = (w6 >> 30) & 0x7fffff; w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*64+19] = (w6 >> 53) | (w7 << 11) & 0x7fffff; out[0*64+20] = (w7 >> 12) & 0x7fffff; out[0*64+21] = (w7 >> 35) & 0x7fffff; w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*64+22] = (w7 >> 58) | (w8 << 6) & 0x7fffff; out[0*64+23] = (w8 >> 17) & 0x7fffff; out[0*64+24] = (w8 >> 40) & 0x7fffff; w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*64+25] = (w8 >> 63) | (w9 << 1) & 0x7fffff; out[0*64+26] = (w9 >> 22) & 0x7fffff; w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*64+27] = (w9 >> 45) | (w10 << 19) & 0x7fffff; out[0*64+28] = (w10 >> 4) & 0x7fffff; out[0*64+29] = (w10 >> 27) & 0x7fffff; w11 = *(uint32_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*64+30] = (w10 >> 50) | (w11 << 14) & 0x7fffff; out[0*64+31] = (w11 >> 9) & 0x7fffff;;}; out += 32; in += 23*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_24(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*24)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*8+ 0] = (w0 ) & 0xffffff; out[0*8+ 1] = (w0 >> 24) & 0xffffff; w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*8+ 2] = (w0 >> 48) | (w1 << 16) & 0xffffff; out[0*8+ 3] = (w1 >> 8) & 0xffffff; out[0*8+ 4] = (w1 >> 32) & 0xffffff; w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*8+ 5] = (w1 >> 56) | (w2 << 8) & 0xffffff; out[0*8+ 6] = (w2 >> 16) & 0xffffff; out[0*8+ 7] = (w2 >> 40);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*8+ 0] = (w0 ) & 0xffffff; out[1*8+ 1] = (w0 >> 24) & 0xffffff; w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*8+ 2] = (w0 >> 48) | (w1 << 16) & 0xffffff; out[1*8+ 3] = (w1 >> 8) & 0xffffff; out[1*8+ 4] = (w1 >> 32) & 0xffffff; w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*8+ 5] = (w1 >> 56) | (w2 << 8) & 0xffffff; out[1*8+ 6] = (w2 >> 16) & 0xffffff; out[1*8+ 7] = (w2 >> 40);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*8+ 0] = (w0 ) & 0xffffff; out[2*8+ 1] = (w0 >> 24) & 0xffffff; w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*8+ 2] = (w0 >> 48) | (w1 << 16) & 0xffffff; out[2*8+ 3] = (w1 >> 8) & 0xffffff; out[2*8+ 4] = (w1 >> 32) & 0xffffff; w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*8+ 5] = (w1 >> 56) | (w2 << 8) & 0xffffff; out[2*8+ 6] = (w2 >> 16) & 0xffffff; out[2*8+ 7] = (w2 >> 40);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*8+ 0] = (w0 ) & 0xffffff; out[3*8+ 1] = (w0 >> 24) & 0xffffff; w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*8+ 2] = (w0 >> 48) | (w1 << 16) & 0xffffff; out[3*8+ 3] = (w1 >> 8) & 0xffffff; out[3*8+ 4] = (w1 >> 32) & 0xffffff; w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*8+ 5] = (w1 >> 56) | (w2 << 8) & 0xffffff; out[3*8+ 6] = (w2 >> 16) & 0xffffff; out[3*8+ 7] = (w2 >> 40);;}; out += 32; in += 24*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_25(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*25)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1ffffff; out[0*64+ 1] = (w0 >> 25) & 0x1ffffff; w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*64+ 2] = (w0 >> 50) | (w1 << 14) & 0x1ffffff; out[0*64+ 3] = (w1 >> 11) & 0x1ffffff; out[0*64+ 4] = (w1 >> 36) & 0x1ffffff; w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*64+ 5] = (w1 >> 61) | (w2 << 3) & 0x1ffffff; out[0*64+ 6] = (w2 >> 22) & 0x1ffffff; w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*64+ 7] = (w2 >> 47) | (w3 << 17) & 0x1ffffff; out[0*64+ 8] = (w3 >> 8) & 0x1ffffff; out[0*64+ 9] = (w3 >> 33) & 0x1ffffff; w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*64+10] = (w3 >> 58) | (w4 << 6) & 0x1ffffff; out[0*64+11] = (w4 >> 19) & 0x1ffffff; w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*64+12] = (w4 >> 44) | (w5 << 20) & 0x1ffffff; out[0*64+13] = (w5 >> 5) & 0x1ffffff; out[0*64+14] = (w5 >> 30) & 0x1ffffff; w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*64+15] = (w5 >> 55) | (w6 << 9) & 0x1ffffff; out[0*64+16] = (w6 >> 16) & 0x1ffffff; w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*64+17] = (w6 >> 41) | (w7 << 23) & 0x1ffffff; out[0*64+18] = (w7 >> 2) & 0x1ffffff; out[0*64+19] = (w7 >> 27) & 0x1ffffff; w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*64+20] = (w7 >> 52) | (w8 << 12) & 0x1ffffff; out[0*64+21] = (w8 >> 13) & 0x1ffffff; out[0*64+22] = (w8 >> 38) & 0x1ffffff; w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*64+23] = (w8 >> 63) | (w9 << 1) & 0x1ffffff; out[0*64+24] = (w9 >> 24) & 0x1ffffff; w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*64+25] = (w9 >> 49) | (w10 << 15) & 0x1ffffff; out[0*64+26] = (w10 >> 10) & 0x1ffffff; out[0*64+27] = (w10 >> 35) & 0x1ffffff; w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*64+28] = (w10 >> 60) | (w11 << 4) & 0x1ffffff; out[0*64+29] = (w11 >> 21) & 0x1ffffff; w12 = *(uint32_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*64+30] = (w11 >> 46) | (w12 << 18) & 0x1ffffff; out[0*64+31] = (w12 >> 7) & 0x1ffffff;;}; out += 32; in += 25*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_26(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*26)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3ffffff; out[0*32+ 1] = (w0 >> 26) & 0x3ffffff; w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*32+ 2] = (w0 >> 52) | (w1 << 12) & 0x3ffffff; out[0*32+ 3] = (w1 >> 14) & 0x3ffffff; w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*32+ 4] = (w1 >> 40) | (w2 << 24) & 0x3ffffff; out[0*32+ 5] = (w2 >> 2) & 0x3ffffff; out[0*32+ 6] = (w2 >> 28) & 0x3ffffff; w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*32+ 7] = (w2 >> 54) | (w3 << 10) & 0x3ffffff; out[0*32+ 8] = (w3 >> 16) & 0x3ffffff; w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*32+ 9] = (w3 >> 42) | (w4 << 22) & 0x3ffffff; out[0*32+10] = (w4 >> 4) & 0x3ffffff; out[0*32+11] = (w4 >> 30) & 0x3ffffff; w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*32+12] = (w4 >> 56) | (w5 << 8) & 0x3ffffff; out[0*32+13] = (w5 >> 18) & 0x3ffffff; w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*32+14] = (w5 >> 44) | (w6 << 20) & 0x3ffffff; out[0*32+15] = (w6 >> 6) & 0x3ffffff; out[0*32+16] = (w6 >> 32) & 0x3ffffff; w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*32+17] = (w6 >> 58) | (w7 << 6) & 0x3ffffff; out[0*32+18] = (w7 >> 20) & 0x3ffffff; w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*32+19] = (w7 >> 46) | (w8 << 18) & 0x3ffffff; out[0*32+20] = (w8 >> 8) & 0x3ffffff; out[0*32+21] = (w8 >> 34) & 0x3ffffff; w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*32+22] = (w8 >> 60) | (w9 << 4) & 0x3ffffff; out[0*32+23] = (w9 >> 22) & 0x3ffffff; w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*32+24] = (w9 >> 48) | (w10 << 16) & 0x3ffffff; out[0*32+25] = (w10 >> 10) & 0x3ffffff; out[0*32+26] = (w10 >> 36) & 0x3ffffff; w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*32+27] = (w10 >> 62) | (w11 << 2) & 0x3ffffff; out[0*32+28] = (w11 >> 24) & 0x3ffffff; w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*32+29] = (w11 >> 50) | (w12 << 14) & 0x3ffffff; out[0*32+30] = (w12 >> 12) & 0x3ffffff; out[0*32+31] = (w12 >> 38);;}; out += 32; in += 26*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_27(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*27)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7ffffff; out[0*64+ 1] = (w0 >> 27) & 0x7ffffff; w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*64+ 2] = (w0 >> 54) | (w1 << 10) & 0x7ffffff; out[0*64+ 3] = (w1 >> 17) & 0x7ffffff; w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*64+ 4] = (w1 >> 44) | (w2 << 20) & 0x7ffffff; out[0*64+ 5] = (w2 >> 7) & 0x7ffffff; out[0*64+ 6] = (w2 >> 34) & 0x7ffffff; w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*64+ 7] = (w2 >> 61) | (w3 << 3) & 0x7ffffff; out[0*64+ 8] = (w3 >> 24) & 0x7ffffff; w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*64+ 9] = (w3 >> 51) | (w4 << 13) & 0x7ffffff; out[0*64+10] = (w4 >> 14) & 0x7ffffff; w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*64+11] = (w4 >> 41) | (w5 << 23) & 0x7ffffff; out[0*64+12] = (w5 >> 4) & 0x7ffffff; out[0*64+13] = (w5 >> 31) & 0x7ffffff; w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*64+14] = (w5 >> 58) | (w6 << 6) & 0x7ffffff; out[0*64+15] = (w6 >> 21) & 0x7ffffff; w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*64+16] = (w6 >> 48) | (w7 << 16) & 0x7ffffff; out[0*64+17] = (w7 >> 11) & 0x7ffffff; w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*64+18] = (w7 >> 38) | (w8 << 26) & 0x7ffffff; out[0*64+19] = (w8 >> 1) & 0x7ffffff; out[0*64+20] = (w8 >> 28) & 0x7ffffff; w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*64+21] = (w8 >> 55) | (w9 << 9) & 0x7ffffff; out[0*64+22] = (w9 >> 18) & 0x7ffffff; w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*64+23] = (w9 >> 45) | (w10 << 19) & 0x7ffffff; out[0*64+24] = (w10 >> 8) & 0x7ffffff; out[0*64+25] = (w10 >> 35) & 0x7ffffff; w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*64+26] = (w10 >> 62) | (w11 << 2) & 0x7ffffff; out[0*64+27] = (w11 >> 25) & 0x7ffffff; w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*64+28] = (w11 >> 52) | (w12 << 12) & 0x7ffffff; out[0*64+29] = (w12 >> 15) & 0x7ffffff; w13 = *(uint32_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*64+30] = (w12 >> 42) | (w13 << 22) & 0x7ffffff; out[0*64+31] = (w13 >> 5) & 0x7ffffff;;}; out += 32; in += 27*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_28(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*28)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xfffffff; out[0*16+ 1] = (w0 >> 28) & 0xfffffff; w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*16+ 2] = (w0 >> 56) | (w1 << 8) & 0xfffffff; out[0*16+ 3] = (w1 >> 20) & 0xfffffff; w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*16+ 4] = (w1 >> 48) | (w2 << 16) & 0xfffffff; out[0*16+ 5] = (w2 >> 12) & 0xfffffff; w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*16+ 6] = (w2 >> 40) | (w3 << 24) & 0xfffffff; out[0*16+ 7] = (w3 >> 4) & 0xfffffff; out[0*16+ 8] = (w3 >> 32) & 0xfffffff; w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*16+ 9] = (w3 >> 60) | (w4 << 4) & 0xfffffff; out[0*16+10] = (w4 >> 24) & 0xfffffff; w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*16+11] = (w4 >> 52) | (w5 << 12) & 0xfffffff; out[0*16+12] = (w5 >> 16) & 0xfffffff; w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*16+13] = (w5 >> 44) | (w6 << 20) & 0xfffffff; out[0*16+14] = (w6 >> 8) & 0xfffffff; out[0*16+15] = (w6 >> 36);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xfffffff; out[1*16+ 1] = (w0 >> 28) & 0xfffffff; w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*16+ 2] = (w0 >> 56) | (w1 << 8) & 0xfffffff; out[1*16+ 3] = (w1 >> 20) & 0xfffffff; w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*16+ 4] = (w1 >> 48) | (w2 << 16) & 0xfffffff; out[1*16+ 5] = (w2 >> 12) & 0xfffffff; w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*16+ 6] = (w2 >> 40) | (w3 << 24) & 0xfffffff; out[1*16+ 7] = (w3 >> 4) & 0xfffffff; out[1*16+ 8] = (w3 >> 32) & 0xfffffff; w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*16+ 9] = (w3 >> 60) | (w4 << 4) & 0xfffffff; out[1*16+10] = (w4 >> 24) & 0xfffffff; w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*16+11] = (w4 >> 52) | (w5 << 12) & 0xfffffff; out[1*16+12] = (w5 >> 16) & 0xfffffff; w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*16+13] = (w5 >> 44) | (w6 << 20) & 0xfffffff; out[1*16+14] = (w6 >> 8) & 0xfffffff; out[1*16+15] = (w6 >> 36);;}; out += 32; in += 28*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_29(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*29)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1fffffff; out[0*64+ 1] = (w0 >> 29) & 0x1fffffff; w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*64+ 2] = (w0 >> 58) | (w1 << 6) & 0x1fffffff; out[0*64+ 3] = (w1 >> 23) & 0x1fffffff; w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*64+ 4] = (w1 >> 52) | (w2 << 12) & 0x1fffffff; out[0*64+ 5] = (w2 >> 17) & 0x1fffffff; w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*64+ 6] = (w2 >> 46) | (w3 << 18) & 0x1fffffff; out[0*64+ 7] = (w3 >> 11) & 0x1fffffff; w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*64+ 8] = (w3 >> 40) | (w4 << 24) & 0x1fffffff; out[0*64+ 9] = (w4 >> 5) & 0x1fffffff; out[0*64+10] = (w4 >> 34) & 0x1fffffff; w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*64+11] = (w4 >> 63) | (w5 << 1) & 0x1fffffff; out[0*64+12] = (w5 >> 28) & 0x1fffffff; w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*64+13] = (w5 >> 57) | (w6 << 7) & 0x1fffffff; out[0*64+14] = (w6 >> 22) & 0x1fffffff; w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*64+15] = (w6 >> 51) | (w7 << 13) & 0x1fffffff; out[0*64+16] = (w7 >> 16) & 0x1fffffff; w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*64+17] = (w7 >> 45) | (w8 << 19) & 0x1fffffff; out[0*64+18] = (w8 >> 10) & 0x1fffffff; w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*64+19] = (w8 >> 39) | (w9 << 25) & 0x1fffffff; out[0*64+20] = (w9 >> 4) & 0x1fffffff; out[0*64+21] = (w9 >> 33) & 0x1fffffff; w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*64+22] = (w9 >> 62) | (w10 << 2) & 0x1fffffff; out[0*64+23] = (w10 >> 27) & 0x1fffffff; w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*64+24] = (w10 >> 56) | (w11 << 8) & 0x1fffffff; out[0*64+25] = (w11 >> 21) & 0x1fffffff; w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*64+26] = (w11 >> 50) | (w12 << 14) & 0x1fffffff; out[0*64+27] = (w12 >> 15) & 0x1fffffff; w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*64+28] = (w12 >> 44) | (w13 << 20) & 0x1fffffff; out[0*64+29] = (w13 >> 9) & 0x1fffffff; w14 = *(uint32_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*64+30] = (w13 >> 38) | (w14 << 26) & 0x1fffffff; out[0*64+31] = (w14 >> 3) & 0x1fffffff;;}; out += 32; in += 29*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_30(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*30)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3fffffff; out[0*32+ 1] = (w0 >> 30) & 0x3fffffff; w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*32+ 2] = (w0 >> 60) | (w1 << 4) & 0x3fffffff; out[0*32+ 3] = (w1 >> 26) & 0x3fffffff; w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*32+ 4] = (w1 >> 56) | (w2 << 8) & 0x3fffffff; out[0*32+ 5] = (w2 >> 22) & 0x3fffffff; w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*32+ 6] = (w2 >> 52) | (w3 << 12) & 0x3fffffff; out[0*32+ 7] = (w3 >> 18) & 0x3fffffff; w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*32+ 8] = (w3 >> 48) | (w4 << 16) & 0x3fffffff; out[0*32+ 9] = (w4 >> 14) & 0x3fffffff; w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*32+10] = (w4 >> 44) | (w5 << 20) & 0x3fffffff; out[0*32+11] = (w5 >> 10) & 0x3fffffff; w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*32+12] = (w5 >> 40) | (w6 << 24) & 0x3fffffff; out[0*32+13] = (w6 >> 6) & 0x3fffffff; w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*32+14] = (w6 >> 36) | (w7 << 28) & 0x3fffffff; out[0*32+15] = (w7 >> 2) & 0x3fffffff; out[0*32+16] = (w7 >> 32) & 0x3fffffff; w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*32+17] = (w7 >> 62) | (w8 << 2) & 0x3fffffff; out[0*32+18] = (w8 >> 28) & 0x3fffffff; w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*32+19] = (w8 >> 58) | (w9 << 6) & 0x3fffffff; out[0*32+20] = (w9 >> 24) & 0x3fffffff; w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*32+21] = (w9 >> 54) | (w10 << 10) & 0x3fffffff; out[0*32+22] = (w10 >> 20) & 0x3fffffff; w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*32+23] = (w10 >> 50) | (w11 << 14) & 0x3fffffff; out[0*32+24] = (w11 >> 16) & 0x3fffffff; w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*32+25] = (w11 >> 46) | (w12 << 18) & 0x3fffffff; out[0*32+26] = (w12 >> 12) & 0x3fffffff; w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*32+27] = (w12 >> 42) | (w13 << 22) & 0x3fffffff; out[0*32+28] = (w13 >> 8) & 0x3fffffff; w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*32+29] = (w13 >> 38) | (w14 << 26) & 0x3fffffff; out[0*32+30] = (w14 >> 4) & 0x3fffffff; out[0*32+31] = (w14 >> 34);;}; out += 32; in += 30*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_31(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*31)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7fffffff; out[0*64+ 1] = (w0 >> 31) & 0x7fffffff; w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*64+ 2] = (w0 >> 62) | (w1 << 2) & 0x7fffffff; out[0*64+ 3] = (w1 >> 29) & 0x7fffffff; w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*64+ 4] = (w1 >> 60) | (w2 << 4) & 0x7fffffff; out[0*64+ 5] = (w2 >> 27) & 0x7fffffff; w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*64+ 6] = (w2 >> 58) | (w3 << 6) & 0x7fffffff; out[0*64+ 7] = (w3 >> 25) & 0x7fffffff; w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*64+ 8] = (w3 >> 56) | (w4 << 8) & 0x7fffffff; out[0*64+ 9] = (w4 >> 23) & 0x7fffffff; w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*64+10] = (w4 >> 54) | (w5 << 10) & 0x7fffffff; out[0*64+11] = (w5 >> 21) & 0x7fffffff; w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*64+12] = (w5 >> 52) | (w6 << 12) & 0x7fffffff; out[0*64+13] = (w6 >> 19) & 0x7fffffff; w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*64+14] = (w6 >> 50) | (w7 << 14) & 0x7fffffff; out[0*64+15] = (w7 >> 17) & 0x7fffffff; w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*64+16] = (w7 >> 48) | (w8 << 16) & 0x7fffffff; out[0*64+17] = (w8 >> 15) & 0x7fffffff; w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*64+18] = (w8 >> 46) | (w9 << 18) & 0x7fffffff; out[0*64+19] = (w9 >> 13) & 0x7fffffff; w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*64+20] = (w9 >> 44) | (w10 << 20) & 0x7fffffff; out[0*64+21] = (w10 >> 11) & 0x7fffffff; w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*64+22] = (w10 >> 42) | (w11 << 22) & 0x7fffffff; out[0*64+23] = (w11 >> 9) & 0x7fffffff; w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*64+24] = (w11 >> 40) | (w12 << 24) & 0x7fffffff; out[0*64+25] = (w12 >> 7) & 0x7fffffff; w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*64+26] = (w12 >> 38) | (w13 << 26) & 0x7fffffff; out[0*64+27] = (w13 >> 5) & 0x7fffffff; w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*64+28] = (w13 >> 36) | (w14 << 28) & 0x7fffffff; out[0*64+29] = (w14 >> 3) & 0x7fffffff; w15 = *(uint32_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*64+30] = (w14 >> 34) | (w15 << 30) & 0x7fffffff; out[0*64+31] = (w15 >> 1) & 0x7fffffff;;}; out += 32; in += 31*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_32(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*32)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[0*2+ 0] = *(uint32_t *)(in+0*8+ 0); out[0*2+ 1] = *(uint32_t *)(in+0*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[1*2+ 0] = *(uint32_t *)(in+1*8+ 0); out[1*2+ 1] = *(uint32_t *)(in+1*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[2*2+ 0] = *(uint32_t *)(in+2*8+ 0); out[2*2+ 1] = *(uint32_t *)(in+2*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[3*2+ 0] = *(uint32_t *)(in+3*8+ 0); out[3*2+ 1] = *(uint32_t *)(in+3*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[4*2+ 0] = *(uint32_t *)(in+4*8+ 0); out[4*2+ 1] = *(uint32_t *)(in+4*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[5*2+ 0] = *(uint32_t *)(in+5*8+ 0); out[5*2+ 1] = *(uint32_t *)(in+5*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[6*2+ 0] = *(uint32_t *)(in+6*8+ 0); out[6*2+ 1] = *(uint32_t *)(in+6*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[7*2+ 0] = *(uint32_t *)(in+7*8+ 0); out[7*2+ 1] = *(uint32_t *)(in+7*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[8*2+ 0] = *(uint32_t *)(in+8*8+ 0); out[8*2+ 1] = *(uint32_t *)(in+8*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[9*2+ 0] = *(uint32_t *)(in+9*8+ 0); out[9*2+ 1] = *(uint32_t *)(in+9*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[10*2+ 0] = *(uint32_t *)(in+10*8+ 0); out[10*2+ 1] = *(uint32_t *)(in+10*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[11*2+ 0] = *(uint32_t *)(in+11*8+ 0); out[11*2+ 1] = *(uint32_t *)(in+11*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[12*2+ 0] = *(uint32_t *)(in+12*8+ 0); out[12*2+ 1] = *(uint32_t *)(in+12*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[13*2+ 0] = *(uint32_t *)(in+13*8+ 0); out[13*2+ 1] = *(uint32_t *)(in+13*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[14*2+ 0] = *(uint32_t *)(in+14*8+ 0); out[14*2+ 1] = *(uint32_t *)(in+14*8+ 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[15*2+ 0] = *(uint32_t *)(in+15*8+ 0); out[15*2+ 1] = *(uint32_t *)(in+15*8+ 4);;}; out += 32; in += 32*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_33(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*33)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16; w0 = *(uint64_t *)(in+(0*33+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1ffffffff; w1 = *(uint64_t *)(in+(0*33+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 33) | (w1 << 31) & 0x1ffffffff; out[0*64+ 2] = (w1 >> 2) & 0x1ffffffff; w2 = *(uint64_t *)(in+(0*33+2)*8/sizeof(in[0])); out[0*64+ 3] = (w1 >> 35) | (w2 << 29) & 0x1ffffffff; out[0*64+ 4] = (w2 >> 4) & 0x1ffffffff; w3 = *(uint64_t *)(in+(0*33+3)*8/sizeof(in[0])); out[0*64+ 5] = (w2 >> 37) | (w3 << 27) & 0x1ffffffff; out[0*64+ 6] = (w3 >> 6) & 0x1ffffffff; w4 = *(uint64_t *)(in+(0*33+4)*8/sizeof(in[0])); out[0*64+ 7] = (w3 >> 39) | (w4 << 25) & 0x1ffffffff; out[0*64+ 8] = (w4 >> 8) & 0x1ffffffff; w5 = *(uint64_t *)(in+(0*33+5)*8/sizeof(in[0])); out[0*64+ 9] = (w4 >> 41) | (w5 << 23) & 0x1ffffffff; out[0*64+10] = (w5 >> 10) & 0x1ffffffff; w6 = *(uint64_t *)(in+(0*33+6)*8/sizeof(in[0])); out[0*64+11] = (w5 >> 43) | (w6 << 21) & 0x1ffffffff; out[0*64+12] = (w6 >> 12) & 0x1ffffffff; w7 = *(uint64_t *)(in+(0*33+7)*8/sizeof(in[0])); out[0*64+13] = (w6 >> 45) | (w7 << 19) & 0x1ffffffff; out[0*64+14] = (w7 >> 14) & 0x1ffffffff; w8 = *(uint64_t *)(in+(0*33+8)*8/sizeof(in[0])); out[0*64+15] = (w7 >> 47) | (w8 << 17) & 0x1ffffffff; out[0*64+16] = (w8 >> 16) & 0x1ffffffff; w9 = *(uint64_t *)(in+(0*33+9)*8/sizeof(in[0])); out[0*64+17] = (w8 >> 49) | (w9 << 15) & 0x1ffffffff; out[0*64+18] = (w9 >> 18) & 0x1ffffffff; w10 = *(uint64_t *)(in+(0*33+10)*8/sizeof(in[0])); out[0*64+19] = (w9 >> 51) | (w10 << 13) & 0x1ffffffff; out[0*64+20] = (w10 >> 20) & 0x1ffffffff; w11 = *(uint64_t *)(in+(0*33+11)*8/sizeof(in[0])); out[0*64+21] = (w10 >> 53) | (w11 << 11) & 0x1ffffffff; out[0*64+22] = (w11 >> 22) & 0x1ffffffff; w12 = *(uint64_t *)(in+(0*33+12)*8/sizeof(in[0])); out[0*64+23] = (w11 >> 55) | (w12 << 9) & 0x1ffffffff; out[0*64+24] = (w12 >> 24) & 0x1ffffffff; w13 = *(uint64_t *)(in+(0*33+13)*8/sizeof(in[0])); out[0*64+25] = (w12 >> 57) | (w13 << 7) & 0x1ffffffff; out[0*64+26] = (w13 >> 26) & 0x1ffffffff; w14 = *(uint64_t *)(in+(0*33+14)*8/sizeof(in[0])); out[0*64+27] = (w13 >> 59) | (w14 << 5) & 0x1ffffffff; out[0*64+28] = (w14 >> 28) & 0x1ffffffff; w15 = *(uint64_t *)(in+(0*33+15)*8/sizeof(in[0])); out[0*64+29] = (w14 >> 61) | (w15 << 3) & 0x1ffffffff; out[0*64+30] = (w15 >> 30) & 0x1ffffffff; w16 = *(uint32_t *)(in+(0*33+16)*8/sizeof(in[0])); out[0*64+31] = (w15 >> 63) | (w16 << 1) & 0x1ffffffff;;}; out += 32; in += 33*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_34(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*34)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3ffffffff; w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*32+ 1] = (w0 >> 34) | (w1 << 30) & 0x3ffffffff; out[0*32+ 2] = (w1 >> 4) & 0x3ffffffff; w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*32+ 3] = (w1 >> 38) | (w2 << 26) & 0x3ffffffff; out[0*32+ 4] = (w2 >> 8) & 0x3ffffffff; w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*32+ 5] = (w2 >> 42) | (w3 << 22) & 0x3ffffffff; out[0*32+ 6] = (w3 >> 12) & 0x3ffffffff; w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*32+ 7] = (w3 >> 46) | (w4 << 18) & 0x3ffffffff; out[0*32+ 8] = (w4 >> 16) & 0x3ffffffff; w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*32+ 9] = (w4 >> 50) | (w5 << 14) & 0x3ffffffff; out[0*32+10] = (w5 >> 20) & 0x3ffffffff; w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*32+11] = (w5 >> 54) | (w6 << 10) & 0x3ffffffff; out[0*32+12] = (w6 >> 24) & 0x3ffffffff; w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*32+13] = (w6 >> 58) | (w7 << 6) & 0x3ffffffff; out[0*32+14] = (w7 >> 28) & 0x3ffffffff; w8 = *(uint64_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*32+15] = (w7 >> 62) | (w8 << 2) & 0x3ffffffff; w9 = *(uint64_t *)(in+(0*17+9)*8/sizeof(in[0])); out[0*32+16] = (w8 >> 32) | (w9 << 32) & 0x3ffffffff; out[0*32+17] = (w9 >> 2) & 0x3ffffffff; w10 = *(uint64_t *)(in+(0*17+10)*8/sizeof(in[0])); out[0*32+18] = (w9 >> 36) | (w10 << 28) & 0x3ffffffff; out[0*32+19] = (w10 >> 6) & 0x3ffffffff; w11 = *(uint64_t *)(in+(0*17+11)*8/sizeof(in[0])); out[0*32+20] = (w10 >> 40) | (w11 << 24) & 0x3ffffffff; out[0*32+21] = (w11 >> 10) & 0x3ffffffff; w12 = *(uint64_t *)(in+(0*17+12)*8/sizeof(in[0])); out[0*32+22] = (w11 >> 44) | (w12 << 20) & 0x3ffffffff; out[0*32+23] = (w12 >> 14) & 0x3ffffffff; w13 = *(uint64_t *)(in+(0*17+13)*8/sizeof(in[0])); out[0*32+24] = (w12 >> 48) | (w13 << 16) & 0x3ffffffff; out[0*32+25] = (w13 >> 18) & 0x3ffffffff; w14 = *(uint64_t *)(in+(0*17+14)*8/sizeof(in[0])); out[0*32+26] = (w13 >> 52) | (w14 << 12) & 0x3ffffffff; out[0*32+27] = (w14 >> 22) & 0x3ffffffff; w15 = *(uint64_t *)(in+(0*17+15)*8/sizeof(in[0])); out[0*32+28] = (w14 >> 56) | (w15 << 8) & 0x3ffffffff; out[0*32+29] = (w15 >> 26) & 0x3ffffffff; w16 = *(uint64_t *)(in+(0*17+16)*8/sizeof(in[0])); out[0*32+30] = (w15 >> 60) | (w16 << 4) & 0x3ffffffff; out[0*32+31] = (w16 >> 30);;}; out += 32; in += 34*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_35(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*35)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(0*35+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7ffffffff; w1 = *(uint64_t *)(in+(0*35+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 35) | (w1 << 29) & 0x7ffffffff; out[0*64+ 2] = (w1 >> 6) & 0x7ffffffff; w2 = *(uint64_t *)(in+(0*35+2)*8/sizeof(in[0])); out[0*64+ 3] = (w1 >> 41) | (w2 << 23) & 0x7ffffffff; out[0*64+ 4] = (w2 >> 12) & 0x7ffffffff; w3 = *(uint64_t *)(in+(0*35+3)*8/sizeof(in[0])); out[0*64+ 5] = (w2 >> 47) | (w3 << 17) & 0x7ffffffff; out[0*64+ 6] = (w3 >> 18) & 0x7ffffffff; w4 = *(uint64_t *)(in+(0*35+4)*8/sizeof(in[0])); out[0*64+ 7] = (w3 >> 53) | (w4 << 11) & 0x7ffffffff; out[0*64+ 8] = (w4 >> 24) & 0x7ffffffff; w5 = *(uint64_t *)(in+(0*35+5)*8/sizeof(in[0])); out[0*64+ 9] = (w4 >> 59) | (w5 << 5) & 0x7ffffffff; w6 = *(uint64_t *)(in+(0*35+6)*8/sizeof(in[0])); out[0*64+10] = (w5 >> 30) | (w6 << 34) & 0x7ffffffff; out[0*64+11] = (w6 >> 1) & 0x7ffffffff; w7 = *(uint64_t *)(in+(0*35+7)*8/sizeof(in[0])); out[0*64+12] = (w6 >> 36) | (w7 << 28) & 0x7ffffffff; out[0*64+13] = (w7 >> 7) & 0x7ffffffff; w8 = *(uint64_t *)(in+(0*35+8)*8/sizeof(in[0])); out[0*64+14] = (w7 >> 42) | (w8 << 22) & 0x7ffffffff; out[0*64+15] = (w8 >> 13) & 0x7ffffffff; w9 = *(uint64_t *)(in+(0*35+9)*8/sizeof(in[0])); out[0*64+16] = (w8 >> 48) | (w9 << 16) & 0x7ffffffff; out[0*64+17] = (w9 >> 19) & 0x7ffffffff; w10 = *(uint64_t *)(in+(0*35+10)*8/sizeof(in[0])); out[0*64+18] = (w9 >> 54) | (w10 << 10) & 0x7ffffffff; out[0*64+19] = (w10 >> 25) & 0x7ffffffff; w11 = *(uint64_t *)(in+(0*35+11)*8/sizeof(in[0])); out[0*64+20] = (w10 >> 60) | (w11 << 4) & 0x7ffffffff; w12 = *(uint64_t *)(in+(0*35+12)*8/sizeof(in[0])); out[0*64+21] = (w11 >> 31) | (w12 << 33) & 0x7ffffffff; out[0*64+22] = (w12 >> 2) & 0x7ffffffff; w13 = *(uint64_t *)(in+(0*35+13)*8/sizeof(in[0])); out[0*64+23] = (w12 >> 37) | (w13 << 27) & 0x7ffffffff; out[0*64+24] = (w13 >> 8) & 0x7ffffffff; w14 = *(uint64_t *)(in+(0*35+14)*8/sizeof(in[0])); out[0*64+25] = (w13 >> 43) | (w14 << 21) & 0x7ffffffff; out[0*64+26] = (w14 >> 14) & 0x7ffffffff; w15 = *(uint64_t *)(in+(0*35+15)*8/sizeof(in[0])); out[0*64+27] = (w14 >> 49) | (w15 << 15) & 0x7ffffffff; out[0*64+28] = (w15 >> 20) & 0x7ffffffff; w16 = *(uint64_t *)(in+(0*35+16)*8/sizeof(in[0])); out[0*64+29] = (w15 >> 55) | (w16 << 9) & 0x7ffffffff; out[0*64+30] = (w16 >> 26) & 0x7ffffffff; w17 = *(uint32_t *)(in+(0*35+17)*8/sizeof(in[0])); out[0*64+31] = (w16 >> 61) | (w17 << 3) & 0x7ffffffff;;}; out += 32; in += 35*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_36(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*36)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xfffffffff; w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*16+ 1] = (w0 >> 36) | (w1 << 28) & 0xfffffffff; out[0*16+ 2] = (w1 >> 8) & 0xfffffffff; w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*16+ 3] = (w1 >> 44) | (w2 << 20) & 0xfffffffff; out[0*16+ 4] = (w2 >> 16) & 0xfffffffff; w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*16+ 5] = (w2 >> 52) | (w3 << 12) & 0xfffffffff; out[0*16+ 6] = (w3 >> 24) & 0xfffffffff; w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*16+ 7] = (w3 >> 60) | (w4 << 4) & 0xfffffffff; w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*16+ 8] = (w4 >> 32) | (w5 << 32) & 0xfffffffff; out[0*16+ 9] = (w5 >> 4) & 0xfffffffff; w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*16+10] = (w5 >> 40) | (w6 << 24) & 0xfffffffff; out[0*16+11] = (w6 >> 12) & 0xfffffffff; w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*16+12] = (w6 >> 48) | (w7 << 16) & 0xfffffffff; out[0*16+13] = (w7 >> 20) & 0xfffffffff; w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*16+14] = (w7 >> 56) | (w8 << 8) & 0xfffffffff; out[0*16+15] = (w8 >> 28);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(1*9+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xfffffffff; w1 = *(uint64_t *)(in+(1*9+1)*8/sizeof(in[0])); out[1*16+ 1] = (w0 >> 36) | (w1 << 28) & 0xfffffffff; out[1*16+ 2] = (w1 >> 8) & 0xfffffffff; w2 = *(uint64_t *)(in+(1*9+2)*8/sizeof(in[0])); out[1*16+ 3] = (w1 >> 44) | (w2 << 20) & 0xfffffffff; out[1*16+ 4] = (w2 >> 16) & 0xfffffffff; w3 = *(uint64_t *)(in+(1*9+3)*8/sizeof(in[0])); out[1*16+ 5] = (w2 >> 52) | (w3 << 12) & 0xfffffffff; out[1*16+ 6] = (w3 >> 24) & 0xfffffffff; w4 = *(uint64_t *)(in+(1*9+4)*8/sizeof(in[0])); out[1*16+ 7] = (w3 >> 60) | (w4 << 4) & 0xfffffffff; w5 = *(uint64_t *)(in+(1*9+5)*8/sizeof(in[0])); out[1*16+ 8] = (w4 >> 32) | (w5 << 32) & 0xfffffffff; out[1*16+ 9] = (w5 >> 4) & 0xfffffffff; w6 = *(uint64_t *)(in+(1*9+6)*8/sizeof(in[0])); out[1*16+10] = (w5 >> 40) | (w6 << 24) & 0xfffffffff; out[1*16+11] = (w6 >> 12) & 0xfffffffff; w7 = *(uint64_t *)(in+(1*9+7)*8/sizeof(in[0])); out[1*16+12] = (w6 >> 48) | (w7 << 16) & 0xfffffffff; out[1*16+13] = (w7 >> 20) & 0xfffffffff; w8 = *(uint64_t *)(in+(1*9+8)*8/sizeof(in[0])); out[1*16+14] = (w7 >> 56) | (w8 << 8) & 0xfffffffff; out[1*16+15] = (w8 >> 28);;}; out += 32; in += 36*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_37(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*37)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18; w0 = *(uint64_t *)(in+(0*37+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1fffffffff; w1 = *(uint64_t *)(in+(0*37+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 37) | (w1 << 27) & 0x1fffffffff; out[0*64+ 2] = (w1 >> 10) & 0x1fffffffff; w2 = *(uint64_t *)(in+(0*37+2)*8/sizeof(in[0])); out[0*64+ 3] = (w1 >> 47) | (w2 << 17) & 0x1fffffffff; out[0*64+ 4] = (w2 >> 20) & 0x1fffffffff; w3 = *(uint64_t *)(in+(0*37+3)*8/sizeof(in[0])); out[0*64+ 5] = (w2 >> 57) | (w3 << 7) & 0x1fffffffff; w4 = *(uint64_t *)(in+(0*37+4)*8/sizeof(in[0])); out[0*64+ 6] = (w3 >> 30) | (w4 << 34) & 0x1fffffffff; out[0*64+ 7] = (w4 >> 3) & 0x1fffffffff; w5 = *(uint64_t *)(in+(0*37+5)*8/sizeof(in[0])); out[0*64+ 8] = (w4 >> 40) | (w5 << 24) & 0x1fffffffff; out[0*64+ 9] = (w5 >> 13) & 0x1fffffffff; w6 = *(uint64_t *)(in+(0*37+6)*8/sizeof(in[0])); out[0*64+10] = (w5 >> 50) | (w6 << 14) & 0x1fffffffff; out[0*64+11] = (w6 >> 23) & 0x1fffffffff; w7 = *(uint64_t *)(in+(0*37+7)*8/sizeof(in[0])); out[0*64+12] = (w6 >> 60) | (w7 << 4) & 0x1fffffffff; w8 = *(uint64_t *)(in+(0*37+8)*8/sizeof(in[0])); out[0*64+13] = (w7 >> 33) | (w8 << 31) & 0x1fffffffff; out[0*64+14] = (w8 >> 6) & 0x1fffffffff; w9 = *(uint64_t *)(in+(0*37+9)*8/sizeof(in[0])); out[0*64+15] = (w8 >> 43) | (w9 << 21) & 0x1fffffffff; out[0*64+16] = (w9 >> 16) & 0x1fffffffff; w10 = *(uint64_t *)(in+(0*37+10)*8/sizeof(in[0])); out[0*64+17] = (w9 >> 53) | (w10 << 11) & 0x1fffffffff; out[0*64+18] = (w10 >> 26) & 0x1fffffffff; w11 = *(uint64_t *)(in+(0*37+11)*8/sizeof(in[0])); out[0*64+19] = (w10 >> 63) | (w11 << 1) & 0x1fffffffff; w12 = *(uint64_t *)(in+(0*37+12)*8/sizeof(in[0])); out[0*64+20] = (w11 >> 36) | (w12 << 28) & 0x1fffffffff; out[0*64+21] = (w12 >> 9) & 0x1fffffffff; w13 = *(uint64_t *)(in+(0*37+13)*8/sizeof(in[0])); out[0*64+22] = (w12 >> 46) | (w13 << 18) & 0x1fffffffff; out[0*64+23] = (w13 >> 19) & 0x1fffffffff; w14 = *(uint64_t *)(in+(0*37+14)*8/sizeof(in[0])); out[0*64+24] = (w13 >> 56) | (w14 << 8) & 0x1fffffffff; w15 = *(uint64_t *)(in+(0*37+15)*8/sizeof(in[0])); out[0*64+25] = (w14 >> 29) | (w15 << 35) & 0x1fffffffff; out[0*64+26] = (w15 >> 2) & 0x1fffffffff; w16 = *(uint64_t *)(in+(0*37+16)*8/sizeof(in[0])); out[0*64+27] = (w15 >> 39) | (w16 << 25) & 0x1fffffffff; out[0*64+28] = (w16 >> 12) & 0x1fffffffff; w17 = *(uint64_t *)(in+(0*37+17)*8/sizeof(in[0])); out[0*64+29] = (w16 >> 49) | (w17 << 15) & 0x1fffffffff; out[0*64+30] = (w17 >> 22) & 0x1fffffffff; w18 = *(uint32_t *)(in+(0*37+18)*8/sizeof(in[0])); out[0*64+31] = (w17 >> 59) | (w18 << 5) & 0x1fffffffff;;}; out += 32; in += 37*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_38(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*38)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3fffffffff; w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*32+ 1] = (w0 >> 38) | (w1 << 26) & 0x3fffffffff; out[0*32+ 2] = (w1 >> 12) & 0x3fffffffff; w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*32+ 3] = (w1 >> 50) | (w2 << 14) & 0x3fffffffff; out[0*32+ 4] = (w2 >> 24) & 0x3fffffffff; w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*32+ 5] = (w2 >> 62) | (w3 << 2) & 0x3fffffffff; w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*32+ 6] = (w3 >> 36) | (w4 << 28) & 0x3fffffffff; out[0*32+ 7] = (w4 >> 10) & 0x3fffffffff; w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*32+ 8] = (w4 >> 48) | (w5 << 16) & 0x3fffffffff; out[0*32+ 9] = (w5 >> 22) & 0x3fffffffff; w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*32+10] = (w5 >> 60) | (w6 << 4) & 0x3fffffffff; w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*32+11] = (w6 >> 34) | (w7 << 30) & 0x3fffffffff; out[0*32+12] = (w7 >> 8) & 0x3fffffffff; w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*32+13] = (w7 >> 46) | (w8 << 18) & 0x3fffffffff; out[0*32+14] = (w8 >> 20) & 0x3fffffffff; w9 = *(uint64_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*32+15] = (w8 >> 58) | (w9 << 6) & 0x3fffffffff; w10 = *(uint64_t *)(in+(0*19+10)*8/sizeof(in[0])); out[0*32+16] = (w9 >> 32) | (w10 << 32) & 0x3fffffffff; out[0*32+17] = (w10 >> 6) & 0x3fffffffff; w11 = *(uint64_t *)(in+(0*19+11)*8/sizeof(in[0])); out[0*32+18] = (w10 >> 44) | (w11 << 20) & 0x3fffffffff; out[0*32+19] = (w11 >> 18) & 0x3fffffffff; w12 = *(uint64_t *)(in+(0*19+12)*8/sizeof(in[0])); out[0*32+20] = (w11 >> 56) | (w12 << 8) & 0x3fffffffff; w13 = *(uint64_t *)(in+(0*19+13)*8/sizeof(in[0])); out[0*32+21] = (w12 >> 30) | (w13 << 34) & 0x3fffffffff; out[0*32+22] = (w13 >> 4) & 0x3fffffffff; w14 = *(uint64_t *)(in+(0*19+14)*8/sizeof(in[0])); out[0*32+23] = (w13 >> 42) | (w14 << 22) & 0x3fffffffff; out[0*32+24] = (w14 >> 16) & 0x3fffffffff; w15 = *(uint64_t *)(in+(0*19+15)*8/sizeof(in[0])); out[0*32+25] = (w14 >> 54) | (w15 << 10) & 0x3fffffffff; w16 = *(uint64_t *)(in+(0*19+16)*8/sizeof(in[0])); out[0*32+26] = (w15 >> 28) | (w16 << 36) & 0x3fffffffff; out[0*32+27] = (w16 >> 2) & 0x3fffffffff; w17 = *(uint64_t *)(in+(0*19+17)*8/sizeof(in[0])); out[0*32+28] = (w16 >> 40) | (w17 << 24) & 0x3fffffffff; out[0*32+29] = (w17 >> 14) & 0x3fffffffff; w18 = *(uint64_t *)(in+(0*19+18)*8/sizeof(in[0])); out[0*32+30] = (w17 >> 52) | (w18 << 12) & 0x3fffffffff; out[0*32+31] = (w18 >> 26);;}; out += 32; in += 38*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_39(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*39)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(0*39+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7fffffffff; w1 = *(uint64_t *)(in+(0*39+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 39) | (w1 << 25) & 0x7fffffffff; out[0*64+ 2] = (w1 >> 14) & 0x7fffffffff; w2 = *(uint64_t *)(in+(0*39+2)*8/sizeof(in[0])); out[0*64+ 3] = (w1 >> 53) | (w2 << 11) & 0x7fffffffff; w3 = *(uint64_t *)(in+(0*39+3)*8/sizeof(in[0])); out[0*64+ 4] = (w2 >> 28) | (w3 << 36) & 0x7fffffffff; out[0*64+ 5] = (w3 >> 3) & 0x7fffffffff; w4 = *(uint64_t *)(in+(0*39+4)*8/sizeof(in[0])); out[0*64+ 6] = (w3 >> 42) | (w4 << 22) & 0x7fffffffff; out[0*64+ 7] = (w4 >> 17) & 0x7fffffffff; w5 = *(uint64_t *)(in+(0*39+5)*8/sizeof(in[0])); out[0*64+ 8] = (w4 >> 56) | (w5 << 8) & 0x7fffffffff; w6 = *(uint64_t *)(in+(0*39+6)*8/sizeof(in[0])); out[0*64+ 9] = (w5 >> 31) | (w6 << 33) & 0x7fffffffff; out[0*64+10] = (w6 >> 6) & 0x7fffffffff; w7 = *(uint64_t *)(in+(0*39+7)*8/sizeof(in[0])); out[0*64+11] = (w6 >> 45) | (w7 << 19) & 0x7fffffffff; out[0*64+12] = (w7 >> 20) & 0x7fffffffff; w8 = *(uint64_t *)(in+(0*39+8)*8/sizeof(in[0])); out[0*64+13] = (w7 >> 59) | (w8 << 5) & 0x7fffffffff; w9 = *(uint64_t *)(in+(0*39+9)*8/sizeof(in[0])); out[0*64+14] = (w8 >> 34) | (w9 << 30) & 0x7fffffffff; out[0*64+15] = (w9 >> 9) & 0x7fffffffff; w10 = *(uint64_t *)(in+(0*39+10)*8/sizeof(in[0])); out[0*64+16] = (w9 >> 48) | (w10 << 16) & 0x7fffffffff; out[0*64+17] = (w10 >> 23) & 0x7fffffffff; w11 = *(uint64_t *)(in+(0*39+11)*8/sizeof(in[0])); out[0*64+18] = (w10 >> 62) | (w11 << 2) & 0x7fffffffff; w12 = *(uint64_t *)(in+(0*39+12)*8/sizeof(in[0])); out[0*64+19] = (w11 >> 37) | (w12 << 27) & 0x7fffffffff; out[0*64+20] = (w12 >> 12) & 0x7fffffffff; w13 = *(uint64_t *)(in+(0*39+13)*8/sizeof(in[0])); out[0*64+21] = (w12 >> 51) | (w13 << 13) & 0x7fffffffff; w14 = *(uint64_t *)(in+(0*39+14)*8/sizeof(in[0])); out[0*64+22] = (w13 >> 26) | (w14 << 38) & 0x7fffffffff; out[0*64+23] = (w14 >> 1) & 0x7fffffffff; w15 = *(uint64_t *)(in+(0*39+15)*8/sizeof(in[0])); out[0*64+24] = (w14 >> 40) | (w15 << 24) & 0x7fffffffff; out[0*64+25] = (w15 >> 15) & 0x7fffffffff; w16 = *(uint64_t *)(in+(0*39+16)*8/sizeof(in[0])); out[0*64+26] = (w15 >> 54) | (w16 << 10) & 0x7fffffffff; w17 = *(uint64_t *)(in+(0*39+17)*8/sizeof(in[0])); out[0*64+27] = (w16 >> 29) | (w17 << 35) & 0x7fffffffff; out[0*64+28] = (w17 >> 4) & 0x7fffffffff; w18 = *(uint64_t *)(in+(0*39+18)*8/sizeof(in[0])); out[0*64+29] = (w17 >> 43) | (w18 << 21) & 0x7fffffffff; out[0*64+30] = (w18 >> 18) & 0x7fffffffff; w19 = *(uint32_t *)(in+(0*39+19)*8/sizeof(in[0])); out[0*64+31] = (w18 >> 57) | (w19 << 7) & 0x7fffffffff;;}; out += 32; in += 39*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_40(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*40)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*8+ 0] = (w0 ) & 0xffffffffff; w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*8+ 1] = (w0 >> 40) | (w1 << 24) & 0xffffffffff; out[0*8+ 2] = (w1 >> 16) & 0xffffffffff; w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*8+ 3] = (w1 >> 56) | (w2 << 8) & 0xffffffffff; w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*8+ 4] = (w2 >> 32) | (w3 << 32) & 0xffffffffff; out[0*8+ 5] = (w3 >> 8) & 0xffffffffff; w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*8+ 6] = (w3 >> 48) | (w4 << 16) & 0xffffffffff; out[0*8+ 7] = (w4 >> 24);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*8+ 0] = (w0 ) & 0xffffffffff; w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*8+ 1] = (w0 >> 40) | (w1 << 24) & 0xffffffffff; out[1*8+ 2] = (w1 >> 16) & 0xffffffffff; w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*8+ 3] = (w1 >> 56) | (w2 << 8) & 0xffffffffff; w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*8+ 4] = (w2 >> 32) | (w3 << 32) & 0xffffffffff; out[1*8+ 5] = (w3 >> 8) & 0xffffffffff; w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*8+ 6] = (w3 >> 48) | (w4 << 16) & 0xffffffffff; out[1*8+ 7] = (w4 >> 24);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(2*5+0)*8/sizeof(in[0])); out[2*8+ 0] = (w0 ) & 0xffffffffff; w1 = *(uint64_t *)(in+(2*5+1)*8/sizeof(in[0])); out[2*8+ 1] = (w0 >> 40) | (w1 << 24) & 0xffffffffff; out[2*8+ 2] = (w1 >> 16) & 0xffffffffff; w2 = *(uint64_t *)(in+(2*5+2)*8/sizeof(in[0])); out[2*8+ 3] = (w1 >> 56) | (w2 << 8) & 0xffffffffff; w3 = *(uint64_t *)(in+(2*5+3)*8/sizeof(in[0])); out[2*8+ 4] = (w2 >> 32) | (w3 << 32) & 0xffffffffff; out[2*8+ 5] = (w3 >> 8) & 0xffffffffff; w4 = *(uint64_t *)(in+(2*5+4)*8/sizeof(in[0])); out[2*8+ 6] = (w3 >> 48) | (w4 << 16) & 0xffffffffff; out[2*8+ 7] = (w4 >> 24);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(3*5+0)*8/sizeof(in[0])); out[3*8+ 0] = (w0 ) & 0xffffffffff; w1 = *(uint64_t *)(in+(3*5+1)*8/sizeof(in[0])); out[3*8+ 1] = (w0 >> 40) | (w1 << 24) & 0xffffffffff; out[3*8+ 2] = (w1 >> 16) & 0xffffffffff; w2 = *(uint64_t *)(in+(3*5+2)*8/sizeof(in[0])); out[3*8+ 3] = (w1 >> 56) | (w2 << 8) & 0xffffffffff; w3 = *(uint64_t *)(in+(3*5+3)*8/sizeof(in[0])); out[3*8+ 4] = (w2 >> 32) | (w3 << 32) & 0xffffffffff; out[3*8+ 5] = (w3 >> 8) & 0xffffffffff; w4 = *(uint64_t *)(in+(3*5+4)*8/sizeof(in[0])); out[3*8+ 6] = (w3 >> 48) | (w4 << 16) & 0xffffffffff; out[3*8+ 7] = (w4 >> 24);;}; out += 32; in += 40*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_41(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*41)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20; w0 = *(uint64_t *)(in+(0*41+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1ffffffffff; w1 = *(uint64_t *)(in+(0*41+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 41) | (w1 << 23) & 0x1ffffffffff; out[0*64+ 2] = (w1 >> 18) & 0x1ffffffffff; w2 = *(uint64_t *)(in+(0*41+2)*8/sizeof(in[0])); out[0*64+ 3] = (w1 >> 59) | (w2 << 5) & 0x1ffffffffff; w3 = *(uint64_t *)(in+(0*41+3)*8/sizeof(in[0])); out[0*64+ 4] = (w2 >> 36) | (w3 << 28) & 0x1ffffffffff; out[0*64+ 5] = (w3 >> 13) & 0x1ffffffffff; w4 = *(uint64_t *)(in+(0*41+4)*8/sizeof(in[0])); out[0*64+ 6] = (w3 >> 54) | (w4 << 10) & 0x1ffffffffff; w5 = *(uint64_t *)(in+(0*41+5)*8/sizeof(in[0])); out[0*64+ 7] = (w4 >> 31) | (w5 << 33) & 0x1ffffffffff; out[0*64+ 8] = (w5 >> 8) & 0x1ffffffffff; w6 = *(uint64_t *)(in+(0*41+6)*8/sizeof(in[0])); out[0*64+ 9] = (w5 >> 49) | (w6 << 15) & 0x1ffffffffff; w7 = *(uint64_t *)(in+(0*41+7)*8/sizeof(in[0])); out[0*64+10] = (w6 >> 26) | (w7 << 38) & 0x1ffffffffff; out[0*64+11] = (w7 >> 3) & 0x1ffffffffff; w8 = *(uint64_t *)(in+(0*41+8)*8/sizeof(in[0])); out[0*64+12] = (w7 >> 44) | (w8 << 20) & 0x1ffffffffff; out[0*64+13] = (w8 >> 21) & 0x1ffffffffff; w9 = *(uint64_t *)(in+(0*41+9)*8/sizeof(in[0])); out[0*64+14] = (w8 >> 62) | (w9 << 2) & 0x1ffffffffff; w10 = *(uint64_t *)(in+(0*41+10)*8/sizeof(in[0])); out[0*64+15] = (w9 >> 39) | (w10 << 25) & 0x1ffffffffff; out[0*64+16] = (w10 >> 16) & 0x1ffffffffff; w11 = *(uint64_t *)(in+(0*41+11)*8/sizeof(in[0])); out[0*64+17] = (w10 >> 57) | (w11 << 7) & 0x1ffffffffff; w12 = *(uint64_t *)(in+(0*41+12)*8/sizeof(in[0])); out[0*64+18] = (w11 >> 34) | (w12 << 30) & 0x1ffffffffff; out[0*64+19] = (w12 >> 11) & 0x1ffffffffff; w13 = *(uint64_t *)(in+(0*41+13)*8/sizeof(in[0])); out[0*64+20] = (w12 >> 52) | (w13 << 12) & 0x1ffffffffff; w14 = *(uint64_t *)(in+(0*41+14)*8/sizeof(in[0])); out[0*64+21] = (w13 >> 29) | (w14 << 35) & 0x1ffffffffff; out[0*64+22] = (w14 >> 6) & 0x1ffffffffff; w15 = *(uint64_t *)(in+(0*41+15)*8/sizeof(in[0])); out[0*64+23] = (w14 >> 47) | (w15 << 17) & 0x1ffffffffff; w16 = *(uint64_t *)(in+(0*41+16)*8/sizeof(in[0])); out[0*64+24] = (w15 >> 24) | (w16 << 40) & 0x1ffffffffff; out[0*64+25] = (w16 >> 1) & 0x1ffffffffff; w17 = *(uint64_t *)(in+(0*41+17)*8/sizeof(in[0])); out[0*64+26] = (w16 >> 42) | (w17 << 22) & 0x1ffffffffff; out[0*64+27] = (w17 >> 19) & 0x1ffffffffff; w18 = *(uint64_t *)(in+(0*41+18)*8/sizeof(in[0])); out[0*64+28] = (w17 >> 60) | (w18 << 4) & 0x1ffffffffff; w19 = *(uint64_t *)(in+(0*41+19)*8/sizeof(in[0])); out[0*64+29] = (w18 >> 37) | (w19 << 27) & 0x1ffffffffff; out[0*64+30] = (w19 >> 14) & 0x1ffffffffff; w20 = *(uint32_t *)(in+(0*41+20)*8/sizeof(in[0])); out[0*64+31] = (w19 >> 55) | (w20 << 9) & 0x1ffffffffff;;}; out += 32; in += 41*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_42(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*42)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3ffffffffff; w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*32+ 1] = (w0 >> 42) | (w1 << 22) & 0x3ffffffffff; out[0*32+ 2] = (w1 >> 20) & 0x3ffffffffff; w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*32+ 3] = (w1 >> 62) | (w2 << 2) & 0x3ffffffffff; w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*32+ 4] = (w2 >> 40) | (w3 << 24) & 0x3ffffffffff; out[0*32+ 5] = (w3 >> 18) & 0x3ffffffffff; w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*32+ 6] = (w3 >> 60) | (w4 << 4) & 0x3ffffffffff; w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*32+ 7] = (w4 >> 38) | (w5 << 26) & 0x3ffffffffff; out[0*32+ 8] = (w5 >> 16) & 0x3ffffffffff; w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*32+ 9] = (w5 >> 58) | (w6 << 6) & 0x3ffffffffff; w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*32+10] = (w6 >> 36) | (w7 << 28) & 0x3ffffffffff; out[0*32+11] = (w7 >> 14) & 0x3ffffffffff; w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*32+12] = (w7 >> 56) | (w8 << 8) & 0x3ffffffffff; w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*32+13] = (w8 >> 34) | (w9 << 30) & 0x3ffffffffff; out[0*32+14] = (w9 >> 12) & 0x3ffffffffff; w10 = *(uint64_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*32+15] = (w9 >> 54) | (w10 << 10) & 0x3ffffffffff; w11 = *(uint64_t *)(in+(0*21+11)*8/sizeof(in[0])); out[0*32+16] = (w10 >> 32) | (w11 << 32) & 0x3ffffffffff; out[0*32+17] = (w11 >> 10) & 0x3ffffffffff; w12 = *(uint64_t *)(in+(0*21+12)*8/sizeof(in[0])); out[0*32+18] = (w11 >> 52) | (w12 << 12) & 0x3ffffffffff; w13 = *(uint64_t *)(in+(0*21+13)*8/sizeof(in[0])); out[0*32+19] = (w12 >> 30) | (w13 << 34) & 0x3ffffffffff; out[0*32+20] = (w13 >> 8) & 0x3ffffffffff; w14 = *(uint64_t *)(in+(0*21+14)*8/sizeof(in[0])); out[0*32+21] = (w13 >> 50) | (w14 << 14) & 0x3ffffffffff; w15 = *(uint64_t *)(in+(0*21+15)*8/sizeof(in[0])); out[0*32+22] = (w14 >> 28) | (w15 << 36) & 0x3ffffffffff; out[0*32+23] = (w15 >> 6) & 0x3ffffffffff; w16 = *(uint64_t *)(in+(0*21+16)*8/sizeof(in[0])); out[0*32+24] = (w15 >> 48) | (w16 << 16) & 0x3ffffffffff; w17 = *(uint64_t *)(in+(0*21+17)*8/sizeof(in[0])); out[0*32+25] = (w16 >> 26) | (w17 << 38) & 0x3ffffffffff; out[0*32+26] = (w17 >> 4) & 0x3ffffffffff; w18 = *(uint64_t *)(in+(0*21+18)*8/sizeof(in[0])); out[0*32+27] = (w17 >> 46) | (w18 << 18) & 0x3ffffffffff; w19 = *(uint64_t *)(in+(0*21+19)*8/sizeof(in[0])); out[0*32+28] = (w18 >> 24) | (w19 << 40) & 0x3ffffffffff; out[0*32+29] = (w19 >> 2) & 0x3ffffffffff; w20 = *(uint64_t *)(in+(0*21+20)*8/sizeof(in[0])); out[0*32+30] = (w19 >> 44) | (w20 << 20) & 0x3ffffffffff; out[0*32+31] = (w20 >> 22);;}; out += 32; in += 42*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_43(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*43)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(0*43+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7ffffffffff; w1 = *(uint64_t *)(in+(0*43+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 43) | (w1 << 21) & 0x7ffffffffff; w2 = *(uint64_t *)(in+(0*43+2)*8/sizeof(in[0])); out[0*64+ 2] = (w1 >> 22) | (w2 << 42) & 0x7ffffffffff; out[0*64+ 3] = (w2 >> 1) & 0x7ffffffffff; w3 = *(uint64_t *)(in+(0*43+3)*8/sizeof(in[0])); out[0*64+ 4] = (w2 >> 44) | (w3 << 20) & 0x7ffffffffff; w4 = *(uint64_t *)(in+(0*43+4)*8/sizeof(in[0])); out[0*64+ 5] = (w3 >> 23) | (w4 << 41) & 0x7ffffffffff; out[0*64+ 6] = (w4 >> 2) & 0x7ffffffffff; w5 = *(uint64_t *)(in+(0*43+5)*8/sizeof(in[0])); out[0*64+ 7] = (w4 >> 45) | (w5 << 19) & 0x7ffffffffff; w6 = *(uint64_t *)(in+(0*43+6)*8/sizeof(in[0])); out[0*64+ 8] = (w5 >> 24) | (w6 << 40) & 0x7ffffffffff; out[0*64+ 9] = (w6 >> 3) & 0x7ffffffffff; w7 = *(uint64_t *)(in+(0*43+7)*8/sizeof(in[0])); out[0*64+10] = (w6 >> 46) | (w7 << 18) & 0x7ffffffffff; w8 = *(uint64_t *)(in+(0*43+8)*8/sizeof(in[0])); out[0*64+11] = (w7 >> 25) | (w8 << 39) & 0x7ffffffffff; out[0*64+12] = (w8 >> 4) & 0x7ffffffffff; w9 = *(uint64_t *)(in+(0*43+9)*8/sizeof(in[0])); out[0*64+13] = (w8 >> 47) | (w9 << 17) & 0x7ffffffffff; w10 = *(uint64_t *)(in+(0*43+10)*8/sizeof(in[0])); out[0*64+14] = (w9 >> 26) | (w10 << 38) & 0x7ffffffffff; out[0*64+15] = (w10 >> 5) & 0x7ffffffffff; w11 = *(uint64_t *)(in+(0*43+11)*8/sizeof(in[0])); out[0*64+16] = (w10 >> 48) | (w11 << 16) & 0x7ffffffffff; w12 = *(uint64_t *)(in+(0*43+12)*8/sizeof(in[0])); out[0*64+17] = (w11 >> 27) | (w12 << 37) & 0x7ffffffffff; out[0*64+18] = (w12 >> 6) & 0x7ffffffffff; w13 = *(uint64_t *)(in+(0*43+13)*8/sizeof(in[0])); out[0*64+19] = (w12 >> 49) | (w13 << 15) & 0x7ffffffffff; w14 = *(uint64_t *)(in+(0*43+14)*8/sizeof(in[0])); out[0*64+20] = (w13 >> 28) | (w14 << 36) & 0x7ffffffffff; out[0*64+21] = (w14 >> 7) & 0x7ffffffffff; w15 = *(uint64_t *)(in+(0*43+15)*8/sizeof(in[0])); out[0*64+22] = (w14 >> 50) | (w15 << 14) & 0x7ffffffffff; w16 = *(uint64_t *)(in+(0*43+16)*8/sizeof(in[0])); out[0*64+23] = (w15 >> 29) | (w16 << 35) & 0x7ffffffffff; out[0*64+24] = (w16 >> 8) & 0x7ffffffffff; w17 = *(uint64_t *)(in+(0*43+17)*8/sizeof(in[0])); out[0*64+25] = (w16 >> 51) | (w17 << 13) & 0x7ffffffffff; w18 = *(uint64_t *)(in+(0*43+18)*8/sizeof(in[0])); out[0*64+26] = (w17 >> 30) | (w18 << 34) & 0x7ffffffffff; out[0*64+27] = (w18 >> 9) & 0x7ffffffffff; w19 = *(uint64_t *)(in+(0*43+19)*8/sizeof(in[0])); out[0*64+28] = (w18 >> 52) | (w19 << 12) & 0x7ffffffffff; w20 = *(uint64_t *)(in+(0*43+20)*8/sizeof(in[0])); out[0*64+29] = (w19 >> 31) | (w20 << 33) & 0x7ffffffffff; out[0*64+30] = (w20 >> 10) & 0x7ffffffffff; w21 = *(uint32_t *)(in+(0*43+21)*8/sizeof(in[0])); out[0*64+31] = (w20 >> 53) | (w21 << 11) & 0x7ffffffffff;;}; out += 32; in += 43*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_44(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*44)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xfffffffffff; w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*16+ 1] = (w0 >> 44) | (w1 << 20) & 0xfffffffffff; w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*16+ 2] = (w1 >> 24) | (w2 << 40) & 0xfffffffffff; out[0*16+ 3] = (w2 >> 4) & 0xfffffffffff; w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*16+ 4] = (w2 >> 48) | (w3 << 16) & 0xfffffffffff; w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*16+ 5] = (w3 >> 28) | (w4 << 36) & 0xfffffffffff; out[0*16+ 6] = (w4 >> 8) & 0xfffffffffff; w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*16+ 7] = (w4 >> 52) | (w5 << 12) & 0xfffffffffff; w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*16+ 8] = (w5 >> 32) | (w6 << 32) & 0xfffffffffff; out[0*16+ 9] = (w6 >> 12) & 0xfffffffffff; w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*16+10] = (w6 >> 56) | (w7 << 8) & 0xfffffffffff; w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*16+11] = (w7 >> 36) | (w8 << 28) & 0xfffffffffff; out[0*16+12] = (w8 >> 16) & 0xfffffffffff; w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*16+13] = (w8 >> 60) | (w9 << 4) & 0xfffffffffff; w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*16+14] = (w9 >> 40) | (w10 << 24) & 0xfffffffffff; out[0*16+15] = (w10 >> 20);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(1*11+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xfffffffffff; w1 = *(uint64_t *)(in+(1*11+1)*8/sizeof(in[0])); out[1*16+ 1] = (w0 >> 44) | (w1 << 20) & 0xfffffffffff; w2 = *(uint64_t *)(in+(1*11+2)*8/sizeof(in[0])); out[1*16+ 2] = (w1 >> 24) | (w2 << 40) & 0xfffffffffff; out[1*16+ 3] = (w2 >> 4) & 0xfffffffffff; w3 = *(uint64_t *)(in+(1*11+3)*8/sizeof(in[0])); out[1*16+ 4] = (w2 >> 48) | (w3 << 16) & 0xfffffffffff; w4 = *(uint64_t *)(in+(1*11+4)*8/sizeof(in[0])); out[1*16+ 5] = (w3 >> 28) | (w4 << 36) & 0xfffffffffff; out[1*16+ 6] = (w4 >> 8) & 0xfffffffffff; w5 = *(uint64_t *)(in+(1*11+5)*8/sizeof(in[0])); out[1*16+ 7] = (w4 >> 52) | (w5 << 12) & 0xfffffffffff; w6 = *(uint64_t *)(in+(1*11+6)*8/sizeof(in[0])); out[1*16+ 8] = (w5 >> 32) | (w6 << 32) & 0xfffffffffff; out[1*16+ 9] = (w6 >> 12) & 0xfffffffffff; w7 = *(uint64_t *)(in+(1*11+7)*8/sizeof(in[0])); out[1*16+10] = (w6 >> 56) | (w7 << 8) & 0xfffffffffff; w8 = *(uint64_t *)(in+(1*11+8)*8/sizeof(in[0])); out[1*16+11] = (w7 >> 36) | (w8 << 28) & 0xfffffffffff; out[1*16+12] = (w8 >> 16) & 0xfffffffffff; w9 = *(uint64_t *)(in+(1*11+9)*8/sizeof(in[0])); out[1*16+13] = (w8 >> 60) | (w9 << 4) & 0xfffffffffff; w10 = *(uint64_t *)(in+(1*11+10)*8/sizeof(in[0])); out[1*16+14] = (w9 >> 40) | (w10 << 24) & 0xfffffffffff; out[1*16+15] = (w10 >> 20);;}; out += 32; in += 44*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_45(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*45)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22; w0 = *(uint64_t *)(in+(0*45+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1fffffffffff; w1 = *(uint64_t *)(in+(0*45+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 45) | (w1 << 19) & 0x1fffffffffff; w2 = *(uint64_t *)(in+(0*45+2)*8/sizeof(in[0])); out[0*64+ 2] = (w1 >> 26) | (w2 << 38) & 0x1fffffffffff; out[0*64+ 3] = (w2 >> 7) & 0x1fffffffffff; w3 = *(uint64_t *)(in+(0*45+3)*8/sizeof(in[0])); out[0*64+ 4] = (w2 >> 52) | (w3 << 12) & 0x1fffffffffff; w4 = *(uint64_t *)(in+(0*45+4)*8/sizeof(in[0])); out[0*64+ 5] = (w3 >> 33) | (w4 << 31) & 0x1fffffffffff; out[0*64+ 6] = (w4 >> 14) & 0x1fffffffffff; w5 = *(uint64_t *)(in+(0*45+5)*8/sizeof(in[0])); out[0*64+ 7] = (w4 >> 59) | (w5 << 5) & 0x1fffffffffff; w6 = *(uint64_t *)(in+(0*45+6)*8/sizeof(in[0])); out[0*64+ 8] = (w5 >> 40) | (w6 << 24) & 0x1fffffffffff; w7 = *(uint64_t *)(in+(0*45+7)*8/sizeof(in[0])); out[0*64+ 9] = (w6 >> 21) | (w7 << 43) & 0x1fffffffffff; out[0*64+10] = (w7 >> 2) & 0x1fffffffffff; w8 = *(uint64_t *)(in+(0*45+8)*8/sizeof(in[0])); out[0*64+11] = (w7 >> 47) | (w8 << 17) & 0x1fffffffffff; w9 = *(uint64_t *)(in+(0*45+9)*8/sizeof(in[0])); out[0*64+12] = (w8 >> 28) | (w9 << 36) & 0x1fffffffffff; out[0*64+13] = (w9 >> 9) & 0x1fffffffffff; w10 = *(uint64_t *)(in+(0*45+10)*8/sizeof(in[0])); out[0*64+14] = (w9 >> 54) | (w10 << 10) & 0x1fffffffffff; w11 = *(uint64_t *)(in+(0*45+11)*8/sizeof(in[0])); out[0*64+15] = (w10 >> 35) | (w11 << 29) & 0x1fffffffffff; out[0*64+16] = (w11 >> 16) & 0x1fffffffffff; w12 = *(uint64_t *)(in+(0*45+12)*8/sizeof(in[0])); out[0*64+17] = (w11 >> 61) | (w12 << 3) & 0x1fffffffffff; w13 = *(uint64_t *)(in+(0*45+13)*8/sizeof(in[0])); out[0*64+18] = (w12 >> 42) | (w13 << 22) & 0x1fffffffffff; w14 = *(uint64_t *)(in+(0*45+14)*8/sizeof(in[0])); out[0*64+19] = (w13 >> 23) | (w14 << 41) & 0x1fffffffffff; out[0*64+20] = (w14 >> 4) & 0x1fffffffffff; w15 = *(uint64_t *)(in+(0*45+15)*8/sizeof(in[0])); out[0*64+21] = (w14 >> 49) | (w15 << 15) & 0x1fffffffffff; w16 = *(uint64_t *)(in+(0*45+16)*8/sizeof(in[0])); out[0*64+22] = (w15 >> 30) | (w16 << 34) & 0x1fffffffffff; out[0*64+23] = (w16 >> 11) & 0x1fffffffffff; w17 = *(uint64_t *)(in+(0*45+17)*8/sizeof(in[0])); out[0*64+24] = (w16 >> 56) | (w17 << 8) & 0x1fffffffffff; w18 = *(uint64_t *)(in+(0*45+18)*8/sizeof(in[0])); out[0*64+25] = (w17 >> 37) | (w18 << 27) & 0x1fffffffffff; out[0*64+26] = (w18 >> 18) & 0x1fffffffffff; w19 = *(uint64_t *)(in+(0*45+19)*8/sizeof(in[0])); out[0*64+27] = (w18 >> 63) | (w19 << 1) & 0x1fffffffffff; w20 = *(uint64_t *)(in+(0*45+20)*8/sizeof(in[0])); out[0*64+28] = (w19 >> 44) | (w20 << 20) & 0x1fffffffffff; w21 = *(uint64_t *)(in+(0*45+21)*8/sizeof(in[0])); out[0*64+29] = (w20 >> 25) | (w21 << 39) & 0x1fffffffffff; out[0*64+30] = (w21 >> 6) & 0x1fffffffffff; w22 = *(uint32_t *)(in+(0*45+22)*8/sizeof(in[0])); out[0*64+31] = (w21 >> 51) | (w22 << 13) & 0x1fffffffffff;;}; out += 32; in += 45*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_46(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*46)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3fffffffffff; w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*32+ 1] = (w0 >> 46) | (w1 << 18) & 0x3fffffffffff; w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*32+ 2] = (w1 >> 28) | (w2 << 36) & 0x3fffffffffff; out[0*32+ 3] = (w2 >> 10) & 0x3fffffffffff; w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*32+ 4] = (w2 >> 56) | (w3 << 8) & 0x3fffffffffff; w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*32+ 5] = (w3 >> 38) | (w4 << 26) & 0x3fffffffffff; w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*32+ 6] = (w4 >> 20) | (w5 << 44) & 0x3fffffffffff; out[0*32+ 7] = (w5 >> 2) & 0x3fffffffffff; w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*32+ 8] = (w5 >> 48) | (w6 << 16) & 0x3fffffffffff; w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*32+ 9] = (w6 >> 30) | (w7 << 34) & 0x3fffffffffff; out[0*32+10] = (w7 >> 12) & 0x3fffffffffff; w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*32+11] = (w7 >> 58) | (w8 << 6) & 0x3fffffffffff; w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*32+12] = (w8 >> 40) | (w9 << 24) & 0x3fffffffffff; w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*32+13] = (w9 >> 22) | (w10 << 42) & 0x3fffffffffff; out[0*32+14] = (w10 >> 4) & 0x3fffffffffff; w11 = *(uint64_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*32+15] = (w10 >> 50) | (w11 << 14) & 0x3fffffffffff; w12 = *(uint64_t *)(in+(0*23+12)*8/sizeof(in[0])); out[0*32+16] = (w11 >> 32) | (w12 << 32) & 0x3fffffffffff; out[0*32+17] = (w12 >> 14) & 0x3fffffffffff; w13 = *(uint64_t *)(in+(0*23+13)*8/sizeof(in[0])); out[0*32+18] = (w12 >> 60) | (w13 << 4) & 0x3fffffffffff; w14 = *(uint64_t *)(in+(0*23+14)*8/sizeof(in[0])); out[0*32+19] = (w13 >> 42) | (w14 << 22) & 0x3fffffffffff; w15 = *(uint64_t *)(in+(0*23+15)*8/sizeof(in[0])); out[0*32+20] = (w14 >> 24) | (w15 << 40) & 0x3fffffffffff; out[0*32+21] = (w15 >> 6) & 0x3fffffffffff; w16 = *(uint64_t *)(in+(0*23+16)*8/sizeof(in[0])); out[0*32+22] = (w15 >> 52) | (w16 << 12) & 0x3fffffffffff; w17 = *(uint64_t *)(in+(0*23+17)*8/sizeof(in[0])); out[0*32+23] = (w16 >> 34) | (w17 << 30) & 0x3fffffffffff; out[0*32+24] = (w17 >> 16) & 0x3fffffffffff; w18 = *(uint64_t *)(in+(0*23+18)*8/sizeof(in[0])); out[0*32+25] = (w17 >> 62) | (w18 << 2) & 0x3fffffffffff; w19 = *(uint64_t *)(in+(0*23+19)*8/sizeof(in[0])); out[0*32+26] = (w18 >> 44) | (w19 << 20) & 0x3fffffffffff; w20 = *(uint64_t *)(in+(0*23+20)*8/sizeof(in[0])); out[0*32+27] = (w19 >> 26) | (w20 << 38) & 0x3fffffffffff; out[0*32+28] = (w20 >> 8) & 0x3fffffffffff; w21 = *(uint64_t *)(in+(0*23+21)*8/sizeof(in[0])); out[0*32+29] = (w20 >> 54) | (w21 << 10) & 0x3fffffffffff; w22 = *(uint64_t *)(in+(0*23+22)*8/sizeof(in[0])); out[0*32+30] = (w21 >> 36) | (w22 << 28) & 0x3fffffffffff; out[0*32+31] = (w22 >> 18);;}; out += 32; in += 46*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_47(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*47)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(0*47+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7fffffffffff; w1 = *(uint64_t *)(in+(0*47+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 47) | (w1 << 17) & 0x7fffffffffff; w2 = *(uint64_t *)(in+(0*47+2)*8/sizeof(in[0])); out[0*64+ 2] = (w1 >> 30) | (w2 << 34) & 0x7fffffffffff; out[0*64+ 3] = (w2 >> 13) & 0x7fffffffffff; w3 = *(uint64_t *)(in+(0*47+3)*8/sizeof(in[0])); out[0*64+ 4] = (w2 >> 60) | (w3 << 4) & 0x7fffffffffff; w4 = *(uint64_t *)(in+(0*47+4)*8/sizeof(in[0])); out[0*64+ 5] = (w3 >> 43) | (w4 << 21) & 0x7fffffffffff; w5 = *(uint64_t *)(in+(0*47+5)*8/sizeof(in[0])); out[0*64+ 6] = (w4 >> 26) | (w5 << 38) & 0x7fffffffffff; out[0*64+ 7] = (w5 >> 9) & 0x7fffffffffff; w6 = *(uint64_t *)(in+(0*47+6)*8/sizeof(in[0])); out[0*64+ 8] = (w5 >> 56) | (w6 << 8) & 0x7fffffffffff; w7 = *(uint64_t *)(in+(0*47+7)*8/sizeof(in[0])); out[0*64+ 9] = (w6 >> 39) | (w7 << 25) & 0x7fffffffffff; w8 = *(uint64_t *)(in+(0*47+8)*8/sizeof(in[0])); out[0*64+10] = (w7 >> 22) | (w8 << 42) & 0x7fffffffffff; out[0*64+11] = (w8 >> 5) & 0x7fffffffffff; w9 = *(uint64_t *)(in+(0*47+9)*8/sizeof(in[0])); out[0*64+12] = (w8 >> 52) | (w9 << 12) & 0x7fffffffffff; w10 = *(uint64_t *)(in+(0*47+10)*8/sizeof(in[0])); out[0*64+13] = (w9 >> 35) | (w10 << 29) & 0x7fffffffffff; w11 = *(uint64_t *)(in+(0*47+11)*8/sizeof(in[0])); out[0*64+14] = (w10 >> 18) | (w11 << 46) & 0x7fffffffffff; out[0*64+15] = (w11 >> 1) & 0x7fffffffffff; w12 = *(uint64_t *)(in+(0*47+12)*8/sizeof(in[0])); out[0*64+16] = (w11 >> 48) | (w12 << 16) & 0x7fffffffffff; w13 = *(uint64_t *)(in+(0*47+13)*8/sizeof(in[0])); out[0*64+17] = (w12 >> 31) | (w13 << 33) & 0x7fffffffffff; out[0*64+18] = (w13 >> 14) & 0x7fffffffffff; w14 = *(uint64_t *)(in+(0*47+14)*8/sizeof(in[0])); out[0*64+19] = (w13 >> 61) | (w14 << 3) & 0x7fffffffffff; w15 = *(uint64_t *)(in+(0*47+15)*8/sizeof(in[0])); out[0*64+20] = (w14 >> 44) | (w15 << 20) & 0x7fffffffffff; w16 = *(uint64_t *)(in+(0*47+16)*8/sizeof(in[0])); out[0*64+21] = (w15 >> 27) | (w16 << 37) & 0x7fffffffffff; out[0*64+22] = (w16 >> 10) & 0x7fffffffffff; w17 = *(uint64_t *)(in+(0*47+17)*8/sizeof(in[0])); out[0*64+23] = (w16 >> 57) | (w17 << 7) & 0x7fffffffffff; w18 = *(uint64_t *)(in+(0*47+18)*8/sizeof(in[0])); out[0*64+24] = (w17 >> 40) | (w18 << 24) & 0x7fffffffffff; w19 = *(uint64_t *)(in+(0*47+19)*8/sizeof(in[0])); out[0*64+25] = (w18 >> 23) | (w19 << 41) & 0x7fffffffffff; out[0*64+26] = (w19 >> 6) & 0x7fffffffffff; w20 = *(uint64_t *)(in+(0*47+20)*8/sizeof(in[0])); out[0*64+27] = (w19 >> 53) | (w20 << 11) & 0x7fffffffffff; w21 = *(uint64_t *)(in+(0*47+21)*8/sizeof(in[0])); out[0*64+28] = (w20 >> 36) | (w21 << 28) & 0x7fffffffffff; w22 = *(uint64_t *)(in+(0*47+22)*8/sizeof(in[0])); out[0*64+29] = (w21 >> 19) | (w22 << 45) & 0x7fffffffffff; out[0*64+30] = (w22 >> 2) & 0x7fffffffffff; w23 = *(uint32_t *)(in+(0*47+23)*8/sizeof(in[0])); out[0*64+31] = (w22 >> 49) | (w23 << 15) & 0x7fffffffffff;;}; out += 32; in += 47*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_48(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*48)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*4+ 0] = (w0 ) & 0xffffffffffff; w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*4+ 1] = (w0 >> 48) | (w1 << 16) & 0xffffffffffff; w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*4+ 2] = (w1 >> 32) | (w2 << 32) & 0xffffffffffff; out[0*4+ 3] = (w2 >> 16);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*4+ 0] = (w0 ) & 0xffffffffffff; w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*4+ 1] = (w0 >> 48) | (w1 << 16) & 0xffffffffffff; w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*4+ 2] = (w1 >> 32) | (w2 << 32) & 0xffffffffffff; out[1*4+ 3] = (w2 >> 16);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*4+ 0] = (w0 ) & 0xffffffffffff; w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*4+ 1] = (w0 >> 48) | (w1 << 16) & 0xffffffffffff; w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*4+ 2] = (w1 >> 32) | (w2 << 32) & 0xffffffffffff; out[2*4+ 3] = (w2 >> 16);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*4+ 0] = (w0 ) & 0xffffffffffff; w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*4+ 1] = (w0 >> 48) | (w1 << 16) & 0xffffffffffff; w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*4+ 2] = (w1 >> 32) | (w2 << 32) & 0xffffffffffff; out[3*4+ 3] = (w2 >> 16);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(4*3+0)*8/sizeof(in[0])); out[4*4+ 0] = (w0 ) & 0xffffffffffff; w1 = *(uint64_t *)(in+(4*3+1)*8/sizeof(in[0])); out[4*4+ 1] = (w0 >> 48) | (w1 << 16) & 0xffffffffffff; w2 = *(uint64_t *)(in+(4*3+2)*8/sizeof(in[0])); out[4*4+ 2] = (w1 >> 32) | (w2 << 32) & 0xffffffffffff; out[4*4+ 3] = (w2 >> 16);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(5*3+0)*8/sizeof(in[0])); out[5*4+ 0] = (w0 ) & 0xffffffffffff; w1 = *(uint64_t *)(in+(5*3+1)*8/sizeof(in[0])); out[5*4+ 1] = (w0 >> 48) | (w1 << 16) & 0xffffffffffff; w2 = *(uint64_t *)(in+(5*3+2)*8/sizeof(in[0])); out[5*4+ 2] = (w1 >> 32) | (w2 << 32) & 0xffffffffffff; out[5*4+ 3] = (w2 >> 16);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(6*3+0)*8/sizeof(in[0])); out[6*4+ 0] = (w0 ) & 0xffffffffffff; w1 = *(uint64_t *)(in+(6*3+1)*8/sizeof(in[0])); out[6*4+ 1] = (w0 >> 48) | (w1 << 16) & 0xffffffffffff; w2 = *(uint64_t *)(in+(6*3+2)*8/sizeof(in[0])); out[6*4+ 2] = (w1 >> 32) | (w2 << 32) & 0xffffffffffff; out[6*4+ 3] = (w2 >> 16);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(7*3+0)*8/sizeof(in[0])); out[7*4+ 0] = (w0 ) & 0xffffffffffff; w1 = *(uint64_t *)(in+(7*3+1)*8/sizeof(in[0])); out[7*4+ 1] = (w0 >> 48) | (w1 << 16) & 0xffffffffffff; w2 = *(uint64_t *)(in+(7*3+2)*8/sizeof(in[0])); out[7*4+ 2] = (w1 >> 32) | (w2 << 32) & 0xffffffffffff; out[7*4+ 3] = (w2 >> 16);;}; out += 32; in += 48*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_49(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*49)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24; w0 = *(uint64_t *)(in+(0*49+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1ffffffffffff; w1 = *(uint64_t *)(in+(0*49+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 49) | (w1 << 15) & 0x1ffffffffffff; w2 = *(uint64_t *)(in+(0*49+2)*8/sizeof(in[0])); out[0*64+ 2] = (w1 >> 34) | (w2 << 30) & 0x1ffffffffffff; w3 = *(uint64_t *)(in+(0*49+3)*8/sizeof(in[0])); out[0*64+ 3] = (w2 >> 19) | (w3 << 45) & 0x1ffffffffffff; out[0*64+ 4] = (w3 >> 4) & 0x1ffffffffffff; w4 = *(uint64_t *)(in+(0*49+4)*8/sizeof(in[0])); out[0*64+ 5] = (w3 >> 53) | (w4 << 11) & 0x1ffffffffffff; w5 = *(uint64_t *)(in+(0*49+5)*8/sizeof(in[0])); out[0*64+ 6] = (w4 >> 38) | (w5 << 26) & 0x1ffffffffffff; w6 = *(uint64_t *)(in+(0*49+6)*8/sizeof(in[0])); out[0*64+ 7] = (w5 >> 23) | (w6 << 41) & 0x1ffffffffffff; out[0*64+ 8] = (w6 >> 8) & 0x1ffffffffffff; w7 = *(uint64_t *)(in+(0*49+7)*8/sizeof(in[0])); out[0*64+ 9] = (w6 >> 57) | (w7 << 7) & 0x1ffffffffffff; w8 = *(uint64_t *)(in+(0*49+8)*8/sizeof(in[0])); out[0*64+10] = (w7 >> 42) | (w8 << 22) & 0x1ffffffffffff; w9 = *(uint64_t *)(in+(0*49+9)*8/sizeof(in[0])); out[0*64+11] = (w8 >> 27) | (w9 << 37) & 0x1ffffffffffff; out[0*64+12] = (w9 >> 12) & 0x1ffffffffffff; w10 = *(uint64_t *)(in+(0*49+10)*8/sizeof(in[0])); out[0*64+13] = (w9 >> 61) | (w10 << 3) & 0x1ffffffffffff; w11 = *(uint64_t *)(in+(0*49+11)*8/sizeof(in[0])); out[0*64+14] = (w10 >> 46) | (w11 << 18) & 0x1ffffffffffff; w12 = *(uint64_t *)(in+(0*49+12)*8/sizeof(in[0])); out[0*64+15] = (w11 >> 31) | (w12 << 33) & 0x1ffffffffffff; w13 = *(uint64_t *)(in+(0*49+13)*8/sizeof(in[0])); out[0*64+16] = (w12 >> 16) | (w13 << 48) & 0x1ffffffffffff; out[0*64+17] = (w13 >> 1) & 0x1ffffffffffff; w14 = *(uint64_t *)(in+(0*49+14)*8/sizeof(in[0])); out[0*64+18] = (w13 >> 50) | (w14 << 14) & 0x1ffffffffffff; w15 = *(uint64_t *)(in+(0*49+15)*8/sizeof(in[0])); out[0*64+19] = (w14 >> 35) | (w15 << 29) & 0x1ffffffffffff; w16 = *(uint64_t *)(in+(0*49+16)*8/sizeof(in[0])); out[0*64+20] = (w15 >> 20) | (w16 << 44) & 0x1ffffffffffff; out[0*64+21] = (w16 >> 5) & 0x1ffffffffffff; w17 = *(uint64_t *)(in+(0*49+17)*8/sizeof(in[0])); out[0*64+22] = (w16 >> 54) | (w17 << 10) & 0x1ffffffffffff; w18 = *(uint64_t *)(in+(0*49+18)*8/sizeof(in[0])); out[0*64+23] = (w17 >> 39) | (w18 << 25) & 0x1ffffffffffff; w19 = *(uint64_t *)(in+(0*49+19)*8/sizeof(in[0])); out[0*64+24] = (w18 >> 24) | (w19 << 40) & 0x1ffffffffffff; out[0*64+25] = (w19 >> 9) & 0x1ffffffffffff; w20 = *(uint64_t *)(in+(0*49+20)*8/sizeof(in[0])); out[0*64+26] = (w19 >> 58) | (w20 << 6) & 0x1ffffffffffff; w21 = *(uint64_t *)(in+(0*49+21)*8/sizeof(in[0])); out[0*64+27] = (w20 >> 43) | (w21 << 21) & 0x1ffffffffffff; w22 = *(uint64_t *)(in+(0*49+22)*8/sizeof(in[0])); out[0*64+28] = (w21 >> 28) | (w22 << 36) & 0x1ffffffffffff; out[0*64+29] = (w22 >> 13) & 0x1ffffffffffff; w23 = *(uint64_t *)(in+(0*49+23)*8/sizeof(in[0])); out[0*64+30] = (w22 >> 62) | (w23 << 2) & 0x1ffffffffffff; w24 = *(uint32_t *)(in+(0*49+24)*8/sizeof(in[0])); out[0*64+31] = (w23 >> 47) | (w24 << 17) & 0x1ffffffffffff;;}; out += 32; in += 49*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_50(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*50)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3ffffffffffff; w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*32+ 1] = (w0 >> 50) | (w1 << 14) & 0x3ffffffffffff; w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*32+ 2] = (w1 >> 36) | (w2 << 28) & 0x3ffffffffffff; w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*32+ 3] = (w2 >> 22) | (w3 << 42) & 0x3ffffffffffff; out[0*32+ 4] = (w3 >> 8) & 0x3ffffffffffff; w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*32+ 5] = (w3 >> 58) | (w4 << 6) & 0x3ffffffffffff; w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*32+ 6] = (w4 >> 44) | (w5 << 20) & 0x3ffffffffffff; w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*32+ 7] = (w5 >> 30) | (w6 << 34) & 0x3ffffffffffff; w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*32+ 8] = (w6 >> 16) | (w7 << 48) & 0x3ffffffffffff; out[0*32+ 9] = (w7 >> 2) & 0x3ffffffffffff; w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*32+10] = (w7 >> 52) | (w8 << 12) & 0x3ffffffffffff; w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*32+11] = (w8 >> 38) | (w9 << 26) & 0x3ffffffffffff; w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*32+12] = (w9 >> 24) | (w10 << 40) & 0x3ffffffffffff; out[0*32+13] = (w10 >> 10) & 0x3ffffffffffff; w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*32+14] = (w10 >> 60) | (w11 << 4) & 0x3ffffffffffff; w12 = *(uint64_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*32+15] = (w11 >> 46) | (w12 << 18) & 0x3ffffffffffff; w13 = *(uint64_t *)(in+(0*25+13)*8/sizeof(in[0])); out[0*32+16] = (w12 >> 32) | (w13 << 32) & 0x3ffffffffffff; w14 = *(uint64_t *)(in+(0*25+14)*8/sizeof(in[0])); out[0*32+17] = (w13 >> 18) | (w14 << 46) & 0x3ffffffffffff; out[0*32+18] = (w14 >> 4) & 0x3ffffffffffff; w15 = *(uint64_t *)(in+(0*25+15)*8/sizeof(in[0])); out[0*32+19] = (w14 >> 54) | (w15 << 10) & 0x3ffffffffffff; w16 = *(uint64_t *)(in+(0*25+16)*8/sizeof(in[0])); out[0*32+20] = (w15 >> 40) | (w16 << 24) & 0x3ffffffffffff; w17 = *(uint64_t *)(in+(0*25+17)*8/sizeof(in[0])); out[0*32+21] = (w16 >> 26) | (w17 << 38) & 0x3ffffffffffff; out[0*32+22] = (w17 >> 12) & 0x3ffffffffffff; w18 = *(uint64_t *)(in+(0*25+18)*8/sizeof(in[0])); out[0*32+23] = (w17 >> 62) | (w18 << 2) & 0x3ffffffffffff; w19 = *(uint64_t *)(in+(0*25+19)*8/sizeof(in[0])); out[0*32+24] = (w18 >> 48) | (w19 << 16) & 0x3ffffffffffff; w20 = *(uint64_t *)(in+(0*25+20)*8/sizeof(in[0])); out[0*32+25] = (w19 >> 34) | (w20 << 30) & 0x3ffffffffffff; w21 = *(uint64_t *)(in+(0*25+21)*8/sizeof(in[0])); out[0*32+26] = (w20 >> 20) | (w21 << 44) & 0x3ffffffffffff; out[0*32+27] = (w21 >> 6) & 0x3ffffffffffff; w22 = *(uint64_t *)(in+(0*25+22)*8/sizeof(in[0])); out[0*32+28] = (w21 >> 56) | (w22 << 8) & 0x3ffffffffffff; w23 = *(uint64_t *)(in+(0*25+23)*8/sizeof(in[0])); out[0*32+29] = (w22 >> 42) | (w23 << 22) & 0x3ffffffffffff; w24 = *(uint64_t *)(in+(0*25+24)*8/sizeof(in[0])); out[0*32+30] = (w23 >> 28) | (w24 << 36) & 0x3ffffffffffff; out[0*32+31] = (w24 >> 14);;}; out += 32; in += 50*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_51(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*51)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(0*51+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7ffffffffffff; w1 = *(uint64_t *)(in+(0*51+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 51) | (w1 << 13) & 0x7ffffffffffff; w2 = *(uint64_t *)(in+(0*51+2)*8/sizeof(in[0])); out[0*64+ 2] = (w1 >> 38) | (w2 << 26) & 0x7ffffffffffff; w3 = *(uint64_t *)(in+(0*51+3)*8/sizeof(in[0])); out[0*64+ 3] = (w2 >> 25) | (w3 << 39) & 0x7ffffffffffff; out[0*64+ 4] = (w3 >> 12) & 0x7ffffffffffff; w4 = *(uint64_t *)(in+(0*51+4)*8/sizeof(in[0])); out[0*64+ 5] = (w3 >> 63) | (w4 << 1) & 0x7ffffffffffff; w5 = *(uint64_t *)(in+(0*51+5)*8/sizeof(in[0])); out[0*64+ 6] = (w4 >> 50) | (w5 << 14) & 0x7ffffffffffff; w6 = *(uint64_t *)(in+(0*51+6)*8/sizeof(in[0])); out[0*64+ 7] = (w5 >> 37) | (w6 << 27) & 0x7ffffffffffff; w7 = *(uint64_t *)(in+(0*51+7)*8/sizeof(in[0])); out[0*64+ 8] = (w6 >> 24) | (w7 << 40) & 0x7ffffffffffff; out[0*64+ 9] = (w7 >> 11) & 0x7ffffffffffff; w8 = *(uint64_t *)(in+(0*51+8)*8/sizeof(in[0])); out[0*64+10] = (w7 >> 62) | (w8 << 2) & 0x7ffffffffffff; w9 = *(uint64_t *)(in+(0*51+9)*8/sizeof(in[0])); out[0*64+11] = (w8 >> 49) | (w9 << 15) & 0x7ffffffffffff; w10 = *(uint64_t *)(in+(0*51+10)*8/sizeof(in[0])); out[0*64+12] = (w9 >> 36) | (w10 << 28) & 0x7ffffffffffff; w11 = *(uint64_t *)(in+(0*51+11)*8/sizeof(in[0])); out[0*64+13] = (w10 >> 23) | (w11 << 41) & 0x7ffffffffffff; out[0*64+14] = (w11 >> 10) & 0x7ffffffffffff; w12 = *(uint64_t *)(in+(0*51+12)*8/sizeof(in[0])); out[0*64+15] = (w11 >> 61) | (w12 << 3) & 0x7ffffffffffff; w13 = *(uint64_t *)(in+(0*51+13)*8/sizeof(in[0])); out[0*64+16] = (w12 >> 48) | (w13 << 16) & 0x7ffffffffffff; w14 = *(uint64_t *)(in+(0*51+14)*8/sizeof(in[0])); out[0*64+17] = (w13 >> 35) | (w14 << 29) & 0x7ffffffffffff; w15 = *(uint64_t *)(in+(0*51+15)*8/sizeof(in[0])); out[0*64+18] = (w14 >> 22) | (w15 << 42) & 0x7ffffffffffff; out[0*64+19] = (w15 >> 9) & 0x7ffffffffffff; w16 = *(uint64_t *)(in+(0*51+16)*8/sizeof(in[0])); out[0*64+20] = (w15 >> 60) | (w16 << 4) & 0x7ffffffffffff; w17 = *(uint64_t *)(in+(0*51+17)*8/sizeof(in[0])); out[0*64+21] = (w16 >> 47) | (w17 << 17) & 0x7ffffffffffff; w18 = *(uint64_t *)(in+(0*51+18)*8/sizeof(in[0])); out[0*64+22] = (w17 >> 34) | (w18 << 30) & 0x7ffffffffffff; w19 = *(uint64_t *)(in+(0*51+19)*8/sizeof(in[0])); out[0*64+23] = (w18 >> 21) | (w19 << 43) & 0x7ffffffffffff; out[0*64+24] = (w19 >> 8) & 0x7ffffffffffff; w20 = *(uint64_t *)(in+(0*51+20)*8/sizeof(in[0])); out[0*64+25] = (w19 >> 59) | (w20 << 5) & 0x7ffffffffffff; w21 = *(uint64_t *)(in+(0*51+21)*8/sizeof(in[0])); out[0*64+26] = (w20 >> 46) | (w21 << 18) & 0x7ffffffffffff; w22 = *(uint64_t *)(in+(0*51+22)*8/sizeof(in[0])); out[0*64+27] = (w21 >> 33) | (w22 << 31) & 0x7ffffffffffff; w23 = *(uint64_t *)(in+(0*51+23)*8/sizeof(in[0])); out[0*64+28] = (w22 >> 20) | (w23 << 44) & 0x7ffffffffffff; out[0*64+29] = (w23 >> 7) & 0x7ffffffffffff; w24 = *(uint64_t *)(in+(0*51+24)*8/sizeof(in[0])); out[0*64+30] = (w23 >> 58) | (w24 << 6) & 0x7ffffffffffff; w25 = *(uint32_t *)(in+(0*51+25)*8/sizeof(in[0])); out[0*64+31] = (w24 >> 45) | (w25 << 19) & 0x7ffffffffffff;;}; out += 32; in += 51*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_52(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*52)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xfffffffffffff; w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*16+ 1] = (w0 >> 52) | (w1 << 12) & 0xfffffffffffff; w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*16+ 2] = (w1 >> 40) | (w2 << 24) & 0xfffffffffffff; w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*16+ 3] = (w2 >> 28) | (w3 << 36) & 0xfffffffffffff; w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*16+ 4] = (w3 >> 16) | (w4 << 48) & 0xfffffffffffff; out[0*16+ 5] = (w4 >> 4) & 0xfffffffffffff; w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*16+ 6] = (w4 >> 56) | (w5 << 8) & 0xfffffffffffff; w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*16+ 7] = (w5 >> 44) | (w6 << 20) & 0xfffffffffffff; w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*16+ 8] = (w6 >> 32) | (w7 << 32) & 0xfffffffffffff; w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*16+ 9] = (w7 >> 20) | (w8 << 44) & 0xfffffffffffff; out[0*16+10] = (w8 >> 8) & 0xfffffffffffff; w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*16+11] = (w8 >> 60) | (w9 << 4) & 0xfffffffffffff; w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*16+12] = (w9 >> 48) | (w10 << 16) & 0xfffffffffffff; w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*16+13] = (w10 >> 36) | (w11 << 28) & 0xfffffffffffff; w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*16+14] = (w11 >> 24) | (w12 << 40) & 0xfffffffffffff; out[0*16+15] = (w12 >> 12);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(1*13+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xfffffffffffff; w1 = *(uint64_t *)(in+(1*13+1)*8/sizeof(in[0])); out[1*16+ 1] = (w0 >> 52) | (w1 << 12) & 0xfffffffffffff; w2 = *(uint64_t *)(in+(1*13+2)*8/sizeof(in[0])); out[1*16+ 2] = (w1 >> 40) | (w2 << 24) & 0xfffffffffffff; w3 = *(uint64_t *)(in+(1*13+3)*8/sizeof(in[0])); out[1*16+ 3] = (w2 >> 28) | (w3 << 36) & 0xfffffffffffff; w4 = *(uint64_t *)(in+(1*13+4)*8/sizeof(in[0])); out[1*16+ 4] = (w3 >> 16) | (w4 << 48) & 0xfffffffffffff; out[1*16+ 5] = (w4 >> 4) & 0xfffffffffffff; w5 = *(uint64_t *)(in+(1*13+5)*8/sizeof(in[0])); out[1*16+ 6] = (w4 >> 56) | (w5 << 8) & 0xfffffffffffff; w6 = *(uint64_t *)(in+(1*13+6)*8/sizeof(in[0])); out[1*16+ 7] = (w5 >> 44) | (w6 << 20) & 0xfffffffffffff; w7 = *(uint64_t *)(in+(1*13+7)*8/sizeof(in[0])); out[1*16+ 8] = (w6 >> 32) | (w7 << 32) & 0xfffffffffffff; w8 = *(uint64_t *)(in+(1*13+8)*8/sizeof(in[0])); out[1*16+ 9] = (w7 >> 20) | (w8 << 44) & 0xfffffffffffff; out[1*16+10] = (w8 >> 8) & 0xfffffffffffff; w9 = *(uint64_t *)(in+(1*13+9)*8/sizeof(in[0])); out[1*16+11] = (w8 >> 60) | (w9 << 4) & 0xfffffffffffff; w10 = *(uint64_t *)(in+(1*13+10)*8/sizeof(in[0])); out[1*16+12] = (w9 >> 48) | (w10 << 16) & 0xfffffffffffff; w11 = *(uint64_t *)(in+(1*13+11)*8/sizeof(in[0])); out[1*16+13] = (w10 >> 36) | (w11 << 28) & 0xfffffffffffff; w12 = *(uint64_t *)(in+(1*13+12)*8/sizeof(in[0])); out[1*16+14] = (w11 >> 24) | (w12 << 40) & 0xfffffffffffff; out[1*16+15] = (w12 >> 12);;}; out += 32; in += 52*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_53(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*53)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26; w0 = *(uint64_t *)(in+(0*53+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1fffffffffffff; w1 = *(uint64_t *)(in+(0*53+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 53) | (w1 << 11) & 0x1fffffffffffff; w2 = *(uint64_t *)(in+(0*53+2)*8/sizeof(in[0])); out[0*64+ 2] = (w1 >> 42) | (w2 << 22) & 0x1fffffffffffff; w3 = *(uint64_t *)(in+(0*53+3)*8/sizeof(in[0])); out[0*64+ 3] = (w2 >> 31) | (w3 << 33) & 0x1fffffffffffff; w4 = *(uint64_t *)(in+(0*53+4)*8/sizeof(in[0])); out[0*64+ 4] = (w3 >> 20) | (w4 << 44) & 0x1fffffffffffff; out[0*64+ 5] = (w4 >> 9) & 0x1fffffffffffff; w5 = *(uint64_t *)(in+(0*53+5)*8/sizeof(in[0])); out[0*64+ 6] = (w4 >> 62) | (w5 << 2) & 0x1fffffffffffff; w6 = *(uint64_t *)(in+(0*53+6)*8/sizeof(in[0])); out[0*64+ 7] = (w5 >> 51) | (w6 << 13) & 0x1fffffffffffff; w7 = *(uint64_t *)(in+(0*53+7)*8/sizeof(in[0])); out[0*64+ 8] = (w6 >> 40) | (w7 << 24) & 0x1fffffffffffff; w8 = *(uint64_t *)(in+(0*53+8)*8/sizeof(in[0])); out[0*64+ 9] = (w7 >> 29) | (w8 << 35) & 0x1fffffffffffff; w9 = *(uint64_t *)(in+(0*53+9)*8/sizeof(in[0])); out[0*64+10] = (w8 >> 18) | (w9 << 46) & 0x1fffffffffffff; out[0*64+11] = (w9 >> 7) & 0x1fffffffffffff; w10 = *(uint64_t *)(in+(0*53+10)*8/sizeof(in[0])); out[0*64+12] = (w9 >> 60) | (w10 << 4) & 0x1fffffffffffff; w11 = *(uint64_t *)(in+(0*53+11)*8/sizeof(in[0])); out[0*64+13] = (w10 >> 49) | (w11 << 15) & 0x1fffffffffffff; w12 = *(uint64_t *)(in+(0*53+12)*8/sizeof(in[0])); out[0*64+14] = (w11 >> 38) | (w12 << 26) & 0x1fffffffffffff; w13 = *(uint64_t *)(in+(0*53+13)*8/sizeof(in[0])); out[0*64+15] = (w12 >> 27) | (w13 << 37) & 0x1fffffffffffff; w14 = *(uint64_t *)(in+(0*53+14)*8/sizeof(in[0])); out[0*64+16] = (w13 >> 16) | (w14 << 48) & 0x1fffffffffffff; out[0*64+17] = (w14 >> 5) & 0x1fffffffffffff; w15 = *(uint64_t *)(in+(0*53+15)*8/sizeof(in[0])); out[0*64+18] = (w14 >> 58) | (w15 << 6) & 0x1fffffffffffff; w16 = *(uint64_t *)(in+(0*53+16)*8/sizeof(in[0])); out[0*64+19] = (w15 >> 47) | (w16 << 17) & 0x1fffffffffffff; w17 = *(uint64_t *)(in+(0*53+17)*8/sizeof(in[0])); out[0*64+20] = (w16 >> 36) | (w17 << 28) & 0x1fffffffffffff; w18 = *(uint64_t *)(in+(0*53+18)*8/sizeof(in[0])); out[0*64+21] = (w17 >> 25) | (w18 << 39) & 0x1fffffffffffff; w19 = *(uint64_t *)(in+(0*53+19)*8/sizeof(in[0])); out[0*64+22] = (w18 >> 14) | (w19 << 50) & 0x1fffffffffffff; out[0*64+23] = (w19 >> 3) & 0x1fffffffffffff; w20 = *(uint64_t *)(in+(0*53+20)*8/sizeof(in[0])); out[0*64+24] = (w19 >> 56) | (w20 << 8) & 0x1fffffffffffff; w21 = *(uint64_t *)(in+(0*53+21)*8/sizeof(in[0])); out[0*64+25] = (w20 >> 45) | (w21 << 19) & 0x1fffffffffffff; w22 = *(uint64_t *)(in+(0*53+22)*8/sizeof(in[0])); out[0*64+26] = (w21 >> 34) | (w22 << 30) & 0x1fffffffffffff; w23 = *(uint64_t *)(in+(0*53+23)*8/sizeof(in[0])); out[0*64+27] = (w22 >> 23) | (w23 << 41) & 0x1fffffffffffff; w24 = *(uint64_t *)(in+(0*53+24)*8/sizeof(in[0])); out[0*64+28] = (w23 >> 12) | (w24 << 52) & 0x1fffffffffffff; out[0*64+29] = (w24 >> 1) & 0x1fffffffffffff; w25 = *(uint64_t *)(in+(0*53+25)*8/sizeof(in[0])); out[0*64+30] = (w24 >> 54) | (w25 << 10) & 0x1fffffffffffff; w26 = *(uint32_t *)(in+(0*53+26)*8/sizeof(in[0])); out[0*64+31] = (w25 >> 43) | (w26 << 21) & 0x1fffffffffffff;;}; out += 32; in += 53*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_54(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*54)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3fffffffffffff; w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*32+ 1] = (w0 >> 54) | (w1 << 10) & 0x3fffffffffffff; w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*32+ 2] = (w1 >> 44) | (w2 << 20) & 0x3fffffffffffff; w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*32+ 3] = (w2 >> 34) | (w3 << 30) & 0x3fffffffffffff; w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*32+ 4] = (w3 >> 24) | (w4 << 40) & 0x3fffffffffffff; w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*32+ 5] = (w4 >> 14) | (w5 << 50) & 0x3fffffffffffff; out[0*32+ 6] = (w5 >> 4) & 0x3fffffffffffff; w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*32+ 7] = (w5 >> 58) | (w6 << 6) & 0x3fffffffffffff; w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*32+ 8] = (w6 >> 48) | (w7 << 16) & 0x3fffffffffffff; w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*32+ 9] = (w7 >> 38) | (w8 << 26) & 0x3fffffffffffff; w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*32+10] = (w8 >> 28) | (w9 << 36) & 0x3fffffffffffff; w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*32+11] = (w9 >> 18) | (w10 << 46) & 0x3fffffffffffff; out[0*32+12] = (w10 >> 8) & 0x3fffffffffffff; w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*32+13] = (w10 >> 62) | (w11 << 2) & 0x3fffffffffffff; w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*32+14] = (w11 >> 52) | (w12 << 12) & 0x3fffffffffffff; w13 = *(uint64_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*32+15] = (w12 >> 42) | (w13 << 22) & 0x3fffffffffffff; w14 = *(uint64_t *)(in+(0*27+14)*8/sizeof(in[0])); out[0*32+16] = (w13 >> 32) | (w14 << 32) & 0x3fffffffffffff; w15 = *(uint64_t *)(in+(0*27+15)*8/sizeof(in[0])); out[0*32+17] = (w14 >> 22) | (w15 << 42) & 0x3fffffffffffff; w16 = *(uint64_t *)(in+(0*27+16)*8/sizeof(in[0])); out[0*32+18] = (w15 >> 12) | (w16 << 52) & 0x3fffffffffffff; out[0*32+19] = (w16 >> 2) & 0x3fffffffffffff; w17 = *(uint64_t *)(in+(0*27+17)*8/sizeof(in[0])); out[0*32+20] = (w16 >> 56) | (w17 << 8) & 0x3fffffffffffff; w18 = *(uint64_t *)(in+(0*27+18)*8/sizeof(in[0])); out[0*32+21] = (w17 >> 46) | (w18 << 18) & 0x3fffffffffffff; w19 = *(uint64_t *)(in+(0*27+19)*8/sizeof(in[0])); out[0*32+22] = (w18 >> 36) | (w19 << 28) & 0x3fffffffffffff; w20 = *(uint64_t *)(in+(0*27+20)*8/sizeof(in[0])); out[0*32+23] = (w19 >> 26) | (w20 << 38) & 0x3fffffffffffff; w21 = *(uint64_t *)(in+(0*27+21)*8/sizeof(in[0])); out[0*32+24] = (w20 >> 16) | (w21 << 48) & 0x3fffffffffffff; out[0*32+25] = (w21 >> 6) & 0x3fffffffffffff; w22 = *(uint64_t *)(in+(0*27+22)*8/sizeof(in[0])); out[0*32+26] = (w21 >> 60) | (w22 << 4) & 0x3fffffffffffff; w23 = *(uint64_t *)(in+(0*27+23)*8/sizeof(in[0])); out[0*32+27] = (w22 >> 50) | (w23 << 14) & 0x3fffffffffffff; w24 = *(uint64_t *)(in+(0*27+24)*8/sizeof(in[0])); out[0*32+28] = (w23 >> 40) | (w24 << 24) & 0x3fffffffffffff; w25 = *(uint64_t *)(in+(0*27+25)*8/sizeof(in[0])); out[0*32+29] = (w24 >> 30) | (w25 << 34) & 0x3fffffffffffff; w26 = *(uint64_t *)(in+(0*27+26)*8/sizeof(in[0])); out[0*32+30] = (w25 >> 20) | (w26 << 44) & 0x3fffffffffffff; out[0*32+31] = (w26 >> 10);;}; out += 32; in += 54*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_55(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*55)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(0*55+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7fffffffffffff; w1 = *(uint64_t *)(in+(0*55+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 55) | (w1 << 9) & 0x7fffffffffffff; w2 = *(uint64_t *)(in+(0*55+2)*8/sizeof(in[0])); out[0*64+ 2] = (w1 >> 46) | (w2 << 18) & 0x7fffffffffffff; w3 = *(uint64_t *)(in+(0*55+3)*8/sizeof(in[0])); out[0*64+ 3] = (w2 >> 37) | (w3 << 27) & 0x7fffffffffffff; w4 = *(uint64_t *)(in+(0*55+4)*8/sizeof(in[0])); out[0*64+ 4] = (w3 >> 28) | (w4 << 36) & 0x7fffffffffffff; w5 = *(uint64_t *)(in+(0*55+5)*8/sizeof(in[0])); out[0*64+ 5] = (w4 >> 19) | (w5 << 45) & 0x7fffffffffffff; w6 = *(uint64_t *)(in+(0*55+6)*8/sizeof(in[0])); out[0*64+ 6] = (w5 >> 10) | (w6 << 54) & 0x7fffffffffffff; out[0*64+ 7] = (w6 >> 1) & 0x7fffffffffffff; w7 = *(uint64_t *)(in+(0*55+7)*8/sizeof(in[0])); out[0*64+ 8] = (w6 >> 56) | (w7 << 8) & 0x7fffffffffffff; w8 = *(uint64_t *)(in+(0*55+8)*8/sizeof(in[0])); out[0*64+ 9] = (w7 >> 47) | (w8 << 17) & 0x7fffffffffffff; w9 = *(uint64_t *)(in+(0*55+9)*8/sizeof(in[0])); out[0*64+10] = (w8 >> 38) | (w9 << 26) & 0x7fffffffffffff; w10 = *(uint64_t *)(in+(0*55+10)*8/sizeof(in[0])); out[0*64+11] = (w9 >> 29) | (w10 << 35) & 0x7fffffffffffff; w11 = *(uint64_t *)(in+(0*55+11)*8/sizeof(in[0])); out[0*64+12] = (w10 >> 20) | (w11 << 44) & 0x7fffffffffffff; w12 = *(uint64_t *)(in+(0*55+12)*8/sizeof(in[0])); out[0*64+13] = (w11 >> 11) | (w12 << 53) & 0x7fffffffffffff; out[0*64+14] = (w12 >> 2) & 0x7fffffffffffff; w13 = *(uint64_t *)(in+(0*55+13)*8/sizeof(in[0])); out[0*64+15] = (w12 >> 57) | (w13 << 7) & 0x7fffffffffffff; w14 = *(uint64_t *)(in+(0*55+14)*8/sizeof(in[0])); out[0*64+16] = (w13 >> 48) | (w14 << 16) & 0x7fffffffffffff; w15 = *(uint64_t *)(in+(0*55+15)*8/sizeof(in[0])); out[0*64+17] = (w14 >> 39) | (w15 << 25) & 0x7fffffffffffff; w16 = *(uint64_t *)(in+(0*55+16)*8/sizeof(in[0])); out[0*64+18] = (w15 >> 30) | (w16 << 34) & 0x7fffffffffffff; w17 = *(uint64_t *)(in+(0*55+17)*8/sizeof(in[0])); out[0*64+19] = (w16 >> 21) | (w17 << 43) & 0x7fffffffffffff; w18 = *(uint64_t *)(in+(0*55+18)*8/sizeof(in[0])); out[0*64+20] = (w17 >> 12) | (w18 << 52) & 0x7fffffffffffff; out[0*64+21] = (w18 >> 3) & 0x7fffffffffffff; w19 = *(uint64_t *)(in+(0*55+19)*8/sizeof(in[0])); out[0*64+22] = (w18 >> 58) | (w19 << 6) & 0x7fffffffffffff; w20 = *(uint64_t *)(in+(0*55+20)*8/sizeof(in[0])); out[0*64+23] = (w19 >> 49) | (w20 << 15) & 0x7fffffffffffff; w21 = *(uint64_t *)(in+(0*55+21)*8/sizeof(in[0])); out[0*64+24] = (w20 >> 40) | (w21 << 24) & 0x7fffffffffffff; w22 = *(uint64_t *)(in+(0*55+22)*8/sizeof(in[0])); out[0*64+25] = (w21 >> 31) | (w22 << 33) & 0x7fffffffffffff; w23 = *(uint64_t *)(in+(0*55+23)*8/sizeof(in[0])); out[0*64+26] = (w22 >> 22) | (w23 << 42) & 0x7fffffffffffff; w24 = *(uint64_t *)(in+(0*55+24)*8/sizeof(in[0])); out[0*64+27] = (w23 >> 13) | (w24 << 51) & 0x7fffffffffffff; out[0*64+28] = (w24 >> 4) & 0x7fffffffffffff; w25 = *(uint64_t *)(in+(0*55+25)*8/sizeof(in[0])); out[0*64+29] = (w24 >> 59) | (w25 << 5) & 0x7fffffffffffff; w26 = *(uint64_t *)(in+(0*55+26)*8/sizeof(in[0])); out[0*64+30] = (w25 >> 50) | (w26 << 14) & 0x7fffffffffffff; w27 = *(uint32_t *)(in+(0*55+27)*8/sizeof(in[0])); out[0*64+31] = (w26 >> 41) | (w27 << 23) & 0x7fffffffffffff;;}; out += 32; in += 55*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_56(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*56)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*8+ 0] = (w0 ) & 0xffffffffffffff; w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*8+ 1] = (w0 >> 56) | (w1 << 8) & 0xffffffffffffff; w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*8+ 2] = (w1 >> 48) | (w2 << 16) & 0xffffffffffffff; w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*8+ 3] = (w2 >> 40) | (w3 << 24) & 0xffffffffffffff; w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*8+ 4] = (w3 >> 32) | (w4 << 32) & 0xffffffffffffff; w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*8+ 5] = (w4 >> 24) | (w5 << 40) & 0xffffffffffffff; w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*8+ 6] = (w5 >> 16) | (w6 << 48) & 0xffffffffffffff; out[0*8+ 7] = (w6 >> 8);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*8+ 0] = (w0 ) & 0xffffffffffffff; w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*8+ 1] = (w0 >> 56) | (w1 << 8) & 0xffffffffffffff; w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*8+ 2] = (w1 >> 48) | (w2 << 16) & 0xffffffffffffff; w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*8+ 3] = (w2 >> 40) | (w3 << 24) & 0xffffffffffffff; w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*8+ 4] = (w3 >> 32) | (w4 << 32) & 0xffffffffffffff; w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*8+ 5] = (w4 >> 24) | (w5 << 40) & 0xffffffffffffff; w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*8+ 6] = (w5 >> 16) | (w6 << 48) & 0xffffffffffffff; out[1*8+ 7] = (w6 >> 8);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(2*7+0)*8/sizeof(in[0])); out[2*8+ 0] = (w0 ) & 0xffffffffffffff; w1 = *(uint64_t *)(in+(2*7+1)*8/sizeof(in[0])); out[2*8+ 1] = (w0 >> 56) | (w1 << 8) & 0xffffffffffffff; w2 = *(uint64_t *)(in+(2*7+2)*8/sizeof(in[0])); out[2*8+ 2] = (w1 >> 48) | (w2 << 16) & 0xffffffffffffff; w3 = *(uint64_t *)(in+(2*7+3)*8/sizeof(in[0])); out[2*8+ 3] = (w2 >> 40) | (w3 << 24) & 0xffffffffffffff; w4 = *(uint64_t *)(in+(2*7+4)*8/sizeof(in[0])); out[2*8+ 4] = (w3 >> 32) | (w4 << 32) & 0xffffffffffffff; w5 = *(uint64_t *)(in+(2*7+5)*8/sizeof(in[0])); out[2*8+ 5] = (w4 >> 24) | (w5 << 40) & 0xffffffffffffff; w6 = *(uint64_t *)(in+(2*7+6)*8/sizeof(in[0])); out[2*8+ 6] = (w5 >> 16) | (w6 << 48) & 0xffffffffffffff; out[2*8+ 7] = (w6 >> 8);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(3*7+0)*8/sizeof(in[0])); out[3*8+ 0] = (w0 ) & 0xffffffffffffff; w1 = *(uint64_t *)(in+(3*7+1)*8/sizeof(in[0])); out[3*8+ 1] = (w0 >> 56) | (w1 << 8) & 0xffffffffffffff; w2 = *(uint64_t *)(in+(3*7+2)*8/sizeof(in[0])); out[3*8+ 2] = (w1 >> 48) | (w2 << 16) & 0xffffffffffffff; w3 = *(uint64_t *)(in+(3*7+3)*8/sizeof(in[0])); out[3*8+ 3] = (w2 >> 40) | (w3 << 24) & 0xffffffffffffff; w4 = *(uint64_t *)(in+(3*7+4)*8/sizeof(in[0])); out[3*8+ 4] = (w3 >> 32) | (w4 << 32) & 0xffffffffffffff; w5 = *(uint64_t *)(in+(3*7+5)*8/sizeof(in[0])); out[3*8+ 5] = (w4 >> 24) | (w5 << 40) & 0xffffffffffffff; w6 = *(uint64_t *)(in+(3*7+6)*8/sizeof(in[0])); out[3*8+ 6] = (w5 >> 16) | (w6 << 48) & 0xffffffffffffff; out[3*8+ 7] = (w6 >> 8);;}; out += 32; in += 56*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_57(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*57)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28; w0 = *(uint64_t *)(in+(0*57+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1ffffffffffffff; w1 = *(uint64_t *)(in+(0*57+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 57) | (w1 << 7) & 0x1ffffffffffffff; w2 = *(uint64_t *)(in+(0*57+2)*8/sizeof(in[0])); out[0*64+ 2] = (w1 >> 50) | (w2 << 14) & 0x1ffffffffffffff; w3 = *(uint64_t *)(in+(0*57+3)*8/sizeof(in[0])); out[0*64+ 3] = (w2 >> 43) | (w3 << 21) & 0x1ffffffffffffff; w4 = *(uint64_t *)(in+(0*57+4)*8/sizeof(in[0])); out[0*64+ 4] = (w3 >> 36) | (w4 << 28) & 0x1ffffffffffffff; w5 = *(uint64_t *)(in+(0*57+5)*8/sizeof(in[0])); out[0*64+ 5] = (w4 >> 29) | (w5 << 35) & 0x1ffffffffffffff; w6 = *(uint64_t *)(in+(0*57+6)*8/sizeof(in[0])); out[0*64+ 6] = (w5 >> 22) | (w6 << 42) & 0x1ffffffffffffff; w7 = *(uint64_t *)(in+(0*57+7)*8/sizeof(in[0])); out[0*64+ 7] = (w6 >> 15) | (w7 << 49) & 0x1ffffffffffffff; w8 = *(uint64_t *)(in+(0*57+8)*8/sizeof(in[0])); out[0*64+ 8] = (w7 >> 8) | (w8 << 56) & 0x1ffffffffffffff; out[0*64+ 9] = (w8 >> 1) & 0x1ffffffffffffff; w9 = *(uint64_t *)(in+(0*57+9)*8/sizeof(in[0])); out[0*64+10] = (w8 >> 58) | (w9 << 6) & 0x1ffffffffffffff; w10 = *(uint64_t *)(in+(0*57+10)*8/sizeof(in[0])); out[0*64+11] = (w9 >> 51) | (w10 << 13) & 0x1ffffffffffffff; w11 = *(uint64_t *)(in+(0*57+11)*8/sizeof(in[0])); out[0*64+12] = (w10 >> 44) | (w11 << 20) & 0x1ffffffffffffff; w12 = *(uint64_t *)(in+(0*57+12)*8/sizeof(in[0])); out[0*64+13] = (w11 >> 37) | (w12 << 27) & 0x1ffffffffffffff; w13 = *(uint64_t *)(in+(0*57+13)*8/sizeof(in[0])); out[0*64+14] = (w12 >> 30) | (w13 << 34) & 0x1ffffffffffffff; w14 = *(uint64_t *)(in+(0*57+14)*8/sizeof(in[0])); out[0*64+15] = (w13 >> 23) | (w14 << 41) & 0x1ffffffffffffff; w15 = *(uint64_t *)(in+(0*57+15)*8/sizeof(in[0])); out[0*64+16] = (w14 >> 16) | (w15 << 48) & 0x1ffffffffffffff; w16 = *(uint64_t *)(in+(0*57+16)*8/sizeof(in[0])); out[0*64+17] = (w15 >> 9) | (w16 << 55) & 0x1ffffffffffffff; out[0*64+18] = (w16 >> 2) & 0x1ffffffffffffff; w17 = *(uint64_t *)(in+(0*57+17)*8/sizeof(in[0])); out[0*64+19] = (w16 >> 59) | (w17 << 5) & 0x1ffffffffffffff; w18 = *(uint64_t *)(in+(0*57+18)*8/sizeof(in[0])); out[0*64+20] = (w17 >> 52) | (w18 << 12) & 0x1ffffffffffffff; w19 = *(uint64_t *)(in+(0*57+19)*8/sizeof(in[0])); out[0*64+21] = (w18 >> 45) | (w19 << 19) & 0x1ffffffffffffff; w20 = *(uint64_t *)(in+(0*57+20)*8/sizeof(in[0])); out[0*64+22] = (w19 >> 38) | (w20 << 26) & 0x1ffffffffffffff; w21 = *(uint64_t *)(in+(0*57+21)*8/sizeof(in[0])); out[0*64+23] = (w20 >> 31) | (w21 << 33) & 0x1ffffffffffffff; w22 = *(uint64_t *)(in+(0*57+22)*8/sizeof(in[0])); out[0*64+24] = (w21 >> 24) | (w22 << 40) & 0x1ffffffffffffff; w23 = *(uint64_t *)(in+(0*57+23)*8/sizeof(in[0])); out[0*64+25] = (w22 >> 17) | (w23 << 47) & 0x1ffffffffffffff; w24 = *(uint64_t *)(in+(0*57+24)*8/sizeof(in[0])); out[0*64+26] = (w23 >> 10) | (w24 << 54) & 0x1ffffffffffffff; out[0*64+27] = (w24 >> 3) & 0x1ffffffffffffff; w25 = *(uint64_t *)(in+(0*57+25)*8/sizeof(in[0])); out[0*64+28] = (w24 >> 60) | (w25 << 4) & 0x1ffffffffffffff; w26 = *(uint64_t *)(in+(0*57+26)*8/sizeof(in[0])); out[0*64+29] = (w25 >> 53) | (w26 << 11) & 0x1ffffffffffffff; w27 = *(uint64_t *)(in+(0*57+27)*8/sizeof(in[0])); out[0*64+30] = (w26 >> 46) | (w27 << 18) & 0x1ffffffffffffff; w28 = *(uint32_t *)(in+(0*57+28)*8/sizeof(in[0])); out[0*64+31] = (w27 >> 39) | (w28 << 25) & 0x1ffffffffffffff;;}; out += 32; in += 57*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_58(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*58)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3ffffffffffffff; w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*32+ 1] = (w0 >> 58) | (w1 << 6) & 0x3ffffffffffffff; w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*32+ 2] = (w1 >> 52) | (w2 << 12) & 0x3ffffffffffffff; w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*32+ 3] = (w2 >> 46) | (w3 << 18) & 0x3ffffffffffffff; w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*32+ 4] = (w3 >> 40) | (w4 << 24) & 0x3ffffffffffffff; w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*32+ 5] = (w4 >> 34) | (w5 << 30) & 0x3ffffffffffffff; w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*32+ 6] = (w5 >> 28) | (w6 << 36) & 0x3ffffffffffffff; w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*32+ 7] = (w6 >> 22) | (w7 << 42) & 0x3ffffffffffffff; w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*32+ 8] = (w7 >> 16) | (w8 << 48) & 0x3ffffffffffffff; w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*32+ 9] = (w8 >> 10) | (w9 << 54) & 0x3ffffffffffffff; out[0*32+10] = (w9 >> 4) & 0x3ffffffffffffff; w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*32+11] = (w9 >> 62) | (w10 << 2) & 0x3ffffffffffffff; w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*32+12] = (w10 >> 56) | (w11 << 8) & 0x3ffffffffffffff; w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*32+13] = (w11 >> 50) | (w12 << 14) & 0x3ffffffffffffff; w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*32+14] = (w12 >> 44) | (w13 << 20) & 0x3ffffffffffffff; w14 = *(uint64_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*32+15] = (w13 >> 38) | (w14 << 26) & 0x3ffffffffffffff; w15 = *(uint64_t *)(in+(0*29+15)*8/sizeof(in[0])); out[0*32+16] = (w14 >> 32) | (w15 << 32) & 0x3ffffffffffffff; w16 = *(uint64_t *)(in+(0*29+16)*8/sizeof(in[0])); out[0*32+17] = (w15 >> 26) | (w16 << 38) & 0x3ffffffffffffff; w17 = *(uint64_t *)(in+(0*29+17)*8/sizeof(in[0])); out[0*32+18] = (w16 >> 20) | (w17 << 44) & 0x3ffffffffffffff; w18 = *(uint64_t *)(in+(0*29+18)*8/sizeof(in[0])); out[0*32+19] = (w17 >> 14) | (w18 << 50) & 0x3ffffffffffffff; w19 = *(uint64_t *)(in+(0*29+19)*8/sizeof(in[0])); out[0*32+20] = (w18 >> 8) | (w19 << 56) & 0x3ffffffffffffff; out[0*32+21] = (w19 >> 2) & 0x3ffffffffffffff; w20 = *(uint64_t *)(in+(0*29+20)*8/sizeof(in[0])); out[0*32+22] = (w19 >> 60) | (w20 << 4) & 0x3ffffffffffffff; w21 = *(uint64_t *)(in+(0*29+21)*8/sizeof(in[0])); out[0*32+23] = (w20 >> 54) | (w21 << 10) & 0x3ffffffffffffff; w22 = *(uint64_t *)(in+(0*29+22)*8/sizeof(in[0])); out[0*32+24] = (w21 >> 48) | (w22 << 16) & 0x3ffffffffffffff; w23 = *(uint64_t *)(in+(0*29+23)*8/sizeof(in[0])); out[0*32+25] = (w22 >> 42) | (w23 << 22) & 0x3ffffffffffffff; w24 = *(uint64_t *)(in+(0*29+24)*8/sizeof(in[0])); out[0*32+26] = (w23 >> 36) | (w24 << 28) & 0x3ffffffffffffff; w25 = *(uint64_t *)(in+(0*29+25)*8/sizeof(in[0])); out[0*32+27] = (w24 >> 30) | (w25 << 34) & 0x3ffffffffffffff; w26 = *(uint64_t *)(in+(0*29+26)*8/sizeof(in[0])); out[0*32+28] = (w25 >> 24) | (w26 << 40) & 0x3ffffffffffffff; w27 = *(uint64_t *)(in+(0*29+27)*8/sizeof(in[0])); out[0*32+29] = (w26 >> 18) | (w27 << 46) & 0x3ffffffffffffff; w28 = *(uint64_t *)(in+(0*29+28)*8/sizeof(in[0])); out[0*32+30] = (w27 >> 12) | (w28 << 52) & 0x3ffffffffffffff; out[0*32+31] = (w28 >> 6);;}; out += 32; in += 58*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_59(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*59)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(0*59+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7ffffffffffffff; w1 = *(uint64_t *)(in+(0*59+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 59) | (w1 << 5) & 0x7ffffffffffffff; w2 = *(uint64_t *)(in+(0*59+2)*8/sizeof(in[0])); out[0*64+ 2] = (w1 >> 54) | (w2 << 10) & 0x7ffffffffffffff; w3 = *(uint64_t *)(in+(0*59+3)*8/sizeof(in[0])); out[0*64+ 3] = (w2 >> 49) | (w3 << 15) & 0x7ffffffffffffff; w4 = *(uint64_t *)(in+(0*59+4)*8/sizeof(in[0])); out[0*64+ 4] = (w3 >> 44) | (w4 << 20) & 0x7ffffffffffffff; w5 = *(uint64_t *)(in+(0*59+5)*8/sizeof(in[0])); out[0*64+ 5] = (w4 >> 39) | (w5 << 25) & 0x7ffffffffffffff; w6 = *(uint64_t *)(in+(0*59+6)*8/sizeof(in[0])); out[0*64+ 6] = (w5 >> 34) | (w6 << 30) & 0x7ffffffffffffff; w7 = *(uint64_t *)(in+(0*59+7)*8/sizeof(in[0])); out[0*64+ 7] = (w6 >> 29) | (w7 << 35) & 0x7ffffffffffffff; w8 = *(uint64_t *)(in+(0*59+8)*8/sizeof(in[0])); out[0*64+ 8] = (w7 >> 24) | (w8 << 40) & 0x7ffffffffffffff; w9 = *(uint64_t *)(in+(0*59+9)*8/sizeof(in[0])); out[0*64+ 9] = (w8 >> 19) | (w9 << 45) & 0x7ffffffffffffff; w10 = *(uint64_t *)(in+(0*59+10)*8/sizeof(in[0])); out[0*64+10] = (w9 >> 14) | (w10 << 50) & 0x7ffffffffffffff; w11 = *(uint64_t *)(in+(0*59+11)*8/sizeof(in[0])); out[0*64+11] = (w10 >> 9) | (w11 << 55) & 0x7ffffffffffffff; out[0*64+12] = (w11 >> 4) & 0x7ffffffffffffff; w12 = *(uint64_t *)(in+(0*59+12)*8/sizeof(in[0])); out[0*64+13] = (w11 >> 63) | (w12 << 1) & 0x7ffffffffffffff; w13 = *(uint64_t *)(in+(0*59+13)*8/sizeof(in[0])); out[0*64+14] = (w12 >> 58) | (w13 << 6) & 0x7ffffffffffffff; w14 = *(uint64_t *)(in+(0*59+14)*8/sizeof(in[0])); out[0*64+15] = (w13 >> 53) | (w14 << 11) & 0x7ffffffffffffff; w15 = *(uint64_t *)(in+(0*59+15)*8/sizeof(in[0])); out[0*64+16] = (w14 >> 48) | (w15 << 16) & 0x7ffffffffffffff; w16 = *(uint64_t *)(in+(0*59+16)*8/sizeof(in[0])); out[0*64+17] = (w15 >> 43) | (w16 << 21) & 0x7ffffffffffffff; w17 = *(uint64_t *)(in+(0*59+17)*8/sizeof(in[0])); out[0*64+18] = (w16 >> 38) | (w17 << 26) & 0x7ffffffffffffff; w18 = *(uint64_t *)(in+(0*59+18)*8/sizeof(in[0])); out[0*64+19] = (w17 >> 33) | (w18 << 31) & 0x7ffffffffffffff; w19 = *(uint64_t *)(in+(0*59+19)*8/sizeof(in[0])); out[0*64+20] = (w18 >> 28) | (w19 << 36) & 0x7ffffffffffffff; w20 = *(uint64_t *)(in+(0*59+20)*8/sizeof(in[0])); out[0*64+21] = (w19 >> 23) | (w20 << 41) & 0x7ffffffffffffff; w21 = *(uint64_t *)(in+(0*59+21)*8/sizeof(in[0])); out[0*64+22] = (w20 >> 18) | (w21 << 46) & 0x7ffffffffffffff; w22 = *(uint64_t *)(in+(0*59+22)*8/sizeof(in[0])); out[0*64+23] = (w21 >> 13) | (w22 << 51) & 0x7ffffffffffffff; w23 = *(uint64_t *)(in+(0*59+23)*8/sizeof(in[0])); out[0*64+24] = (w22 >> 8) | (w23 << 56) & 0x7ffffffffffffff; out[0*64+25] = (w23 >> 3) & 0x7ffffffffffffff; w24 = *(uint64_t *)(in+(0*59+24)*8/sizeof(in[0])); out[0*64+26] = (w23 >> 62) | (w24 << 2) & 0x7ffffffffffffff; w25 = *(uint64_t *)(in+(0*59+25)*8/sizeof(in[0])); out[0*64+27] = (w24 >> 57) | (w25 << 7) & 0x7ffffffffffffff; w26 = *(uint64_t *)(in+(0*59+26)*8/sizeof(in[0])); out[0*64+28] = (w25 >> 52) | (w26 << 12) & 0x7ffffffffffffff; w27 = *(uint64_t *)(in+(0*59+27)*8/sizeof(in[0])); out[0*64+29] = (w26 >> 47) | (w27 << 17) & 0x7ffffffffffffff; w28 = *(uint64_t *)(in+(0*59+28)*8/sizeof(in[0])); out[0*64+30] = (w27 >> 42) | (w28 << 22) & 0x7ffffffffffffff; w29 = *(uint32_t *)(in+(0*59+29)*8/sizeof(in[0])); out[0*64+31] = (w28 >> 37) | (w29 << 27) & 0x7ffffffffffffff;;}; out += 32; in += 59*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_60(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*60)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*16+ 0] = (w0 ) & 0xfffffffffffffff; w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*16+ 1] = (w0 >> 60) | (w1 << 4) & 0xfffffffffffffff; w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*16+ 2] = (w1 >> 56) | (w2 << 8) & 0xfffffffffffffff; w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*16+ 3] = (w2 >> 52) | (w3 << 12) & 0xfffffffffffffff; w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*16+ 4] = (w3 >> 48) | (w4 << 16) & 0xfffffffffffffff; w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*16+ 5] = (w4 >> 44) | (w5 << 20) & 0xfffffffffffffff; w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*16+ 6] = (w5 >> 40) | (w6 << 24) & 0xfffffffffffffff; w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*16+ 7] = (w6 >> 36) | (w7 << 28) & 0xfffffffffffffff; w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*16+ 8] = (w7 >> 32) | (w8 << 32) & 0xfffffffffffffff; w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*16+ 9] = (w8 >> 28) | (w9 << 36) & 0xfffffffffffffff; w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*16+10] = (w9 >> 24) | (w10 << 40) & 0xfffffffffffffff; w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*16+11] = (w10 >> 20) | (w11 << 44) & 0xfffffffffffffff; w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*16+12] = (w11 >> 16) | (w12 << 48) & 0xfffffffffffffff; w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*16+13] = (w12 >> 12) | (w13 << 52) & 0xfffffffffffffff; w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*16+14] = (w13 >> 8) | (w14 << 56) & 0xfffffffffffffff; out[0*16+15] = (w14 >> 4);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(1*15+0)*8/sizeof(in[0])); out[1*16+ 0] = (w0 ) & 0xfffffffffffffff; w1 = *(uint64_t *)(in+(1*15+1)*8/sizeof(in[0])); out[1*16+ 1] = (w0 >> 60) | (w1 << 4) & 0xfffffffffffffff; w2 = *(uint64_t *)(in+(1*15+2)*8/sizeof(in[0])); out[1*16+ 2] = (w1 >> 56) | (w2 << 8) & 0xfffffffffffffff; w3 = *(uint64_t *)(in+(1*15+3)*8/sizeof(in[0])); out[1*16+ 3] = (w2 >> 52) | (w3 << 12) & 0xfffffffffffffff; w4 = *(uint64_t *)(in+(1*15+4)*8/sizeof(in[0])); out[1*16+ 4] = (w3 >> 48) | (w4 << 16) & 0xfffffffffffffff; w5 = *(uint64_t *)(in+(1*15+5)*8/sizeof(in[0])); out[1*16+ 5] = (w4 >> 44) | (w5 << 20) & 0xfffffffffffffff; w6 = *(uint64_t *)(in+(1*15+6)*8/sizeof(in[0])); out[1*16+ 6] = (w5 >> 40) | (w6 << 24) & 0xfffffffffffffff; w7 = *(uint64_t *)(in+(1*15+7)*8/sizeof(in[0])); out[1*16+ 7] = (w6 >> 36) | (w7 << 28) & 0xfffffffffffffff; w8 = *(uint64_t *)(in+(1*15+8)*8/sizeof(in[0])); out[1*16+ 8] = (w7 >> 32) | (w8 << 32) & 0xfffffffffffffff; w9 = *(uint64_t *)(in+(1*15+9)*8/sizeof(in[0])); out[1*16+ 9] = (w8 >> 28) | (w9 << 36) & 0xfffffffffffffff; w10 = *(uint64_t *)(in+(1*15+10)*8/sizeof(in[0])); out[1*16+10] = (w9 >> 24) | (w10 << 40) & 0xfffffffffffffff; w11 = *(uint64_t *)(in+(1*15+11)*8/sizeof(in[0])); out[1*16+11] = (w10 >> 20) | (w11 << 44) & 0xfffffffffffffff; w12 = *(uint64_t *)(in+(1*15+12)*8/sizeof(in[0])); out[1*16+12] = (w11 >> 16) | (w12 << 48) & 0xfffffffffffffff; w13 = *(uint64_t *)(in+(1*15+13)*8/sizeof(in[0])); out[1*16+13] = (w12 >> 12) | (w13 << 52) & 0xfffffffffffffff; w14 = *(uint64_t *)(in+(1*15+14)*8/sizeof(in[0])); out[1*16+14] = (w13 >> 8) | (w14 << 56) & 0xfffffffffffffff; out[1*16+15] = (w14 >> 4);;}; out += 32; in += 60*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_61(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*61)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30; w0 = *(uint64_t *)(in+(0*61+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x1fffffffffffffff; w1 = *(uint64_t *)(in+(0*61+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 61) | (w1 << 3) & 0x1fffffffffffffff; w2 = *(uint64_t *)(in+(0*61+2)*8/sizeof(in[0])); out[0*64+ 2] = (w1 >> 58) | (w2 << 6) & 0x1fffffffffffffff; w3 = *(uint64_t *)(in+(0*61+3)*8/sizeof(in[0])); out[0*64+ 3] = (w2 >> 55) | (w3 << 9) & 0x1fffffffffffffff; w4 = *(uint64_t *)(in+(0*61+4)*8/sizeof(in[0])); out[0*64+ 4] = (w3 >> 52) | (w4 << 12) & 0x1fffffffffffffff; w5 = *(uint64_t *)(in+(0*61+5)*8/sizeof(in[0])); out[0*64+ 5] = (w4 >> 49) | (w5 << 15) & 0x1fffffffffffffff; w6 = *(uint64_t *)(in+(0*61+6)*8/sizeof(in[0])); out[0*64+ 6] = (w5 >> 46) | (w6 << 18) & 0x1fffffffffffffff; w7 = *(uint64_t *)(in+(0*61+7)*8/sizeof(in[0])); out[0*64+ 7] = (w6 >> 43) | (w7 << 21) & 0x1fffffffffffffff; w8 = *(uint64_t *)(in+(0*61+8)*8/sizeof(in[0])); out[0*64+ 8] = (w7 >> 40) | (w8 << 24) & 0x1fffffffffffffff; w9 = *(uint64_t *)(in+(0*61+9)*8/sizeof(in[0])); out[0*64+ 9] = (w8 >> 37) | (w9 << 27) & 0x1fffffffffffffff; w10 = *(uint64_t *)(in+(0*61+10)*8/sizeof(in[0])); out[0*64+10] = (w9 >> 34) | (w10 << 30) & 0x1fffffffffffffff; w11 = *(uint64_t *)(in+(0*61+11)*8/sizeof(in[0])); out[0*64+11] = (w10 >> 31) | (w11 << 33) & 0x1fffffffffffffff; w12 = *(uint64_t *)(in+(0*61+12)*8/sizeof(in[0])); out[0*64+12] = (w11 >> 28) | (w12 << 36) & 0x1fffffffffffffff; w13 = *(uint64_t *)(in+(0*61+13)*8/sizeof(in[0])); out[0*64+13] = (w12 >> 25) | (w13 << 39) & 0x1fffffffffffffff; w14 = *(uint64_t *)(in+(0*61+14)*8/sizeof(in[0])); out[0*64+14] = (w13 >> 22) | (w14 << 42) & 0x1fffffffffffffff; w15 = *(uint64_t *)(in+(0*61+15)*8/sizeof(in[0])); out[0*64+15] = (w14 >> 19) | (w15 << 45) & 0x1fffffffffffffff; w16 = *(uint64_t *)(in+(0*61+16)*8/sizeof(in[0])); out[0*64+16] = (w15 >> 16) | (w16 << 48) & 0x1fffffffffffffff; w17 = *(uint64_t *)(in+(0*61+17)*8/sizeof(in[0])); out[0*64+17] = (w16 >> 13) | (w17 << 51) & 0x1fffffffffffffff; w18 = *(uint64_t *)(in+(0*61+18)*8/sizeof(in[0])); out[0*64+18] = (w17 >> 10) | (w18 << 54) & 0x1fffffffffffffff; w19 = *(uint64_t *)(in+(0*61+19)*8/sizeof(in[0])); out[0*64+19] = (w18 >> 7) | (w19 << 57) & 0x1fffffffffffffff; w20 = *(uint64_t *)(in+(0*61+20)*8/sizeof(in[0])); out[0*64+20] = (w19 >> 4) | (w20 << 60) & 0x1fffffffffffffff; out[0*64+21] = (w20 >> 1) & 0x1fffffffffffffff; w21 = *(uint64_t *)(in+(0*61+21)*8/sizeof(in[0])); out[0*64+22] = (w20 >> 62) | (w21 << 2) & 0x1fffffffffffffff; w22 = *(uint64_t *)(in+(0*61+22)*8/sizeof(in[0])); out[0*64+23] = (w21 >> 59) | (w22 << 5) & 0x1fffffffffffffff; w23 = *(uint64_t *)(in+(0*61+23)*8/sizeof(in[0])); out[0*64+24] = (w22 >> 56) | (w23 << 8) & 0x1fffffffffffffff; w24 = *(uint64_t *)(in+(0*61+24)*8/sizeof(in[0])); out[0*64+25] = (w23 >> 53) | (w24 << 11) & 0x1fffffffffffffff; w25 = *(uint64_t *)(in+(0*61+25)*8/sizeof(in[0])); out[0*64+26] = (w24 >> 50) | (w25 << 14) & 0x1fffffffffffffff; w26 = *(uint64_t *)(in+(0*61+26)*8/sizeof(in[0])); out[0*64+27] = (w25 >> 47) | (w26 << 17) & 0x1fffffffffffffff; w27 = *(uint64_t *)(in+(0*61+27)*8/sizeof(in[0])); out[0*64+28] = (w26 >> 44) | (w27 << 20) & 0x1fffffffffffffff; w28 = *(uint64_t *)(in+(0*61+28)*8/sizeof(in[0])); out[0*64+29] = (w27 >> 41) | (w28 << 23) & 0x1fffffffffffffff; w29 = *(uint64_t *)(in+(0*61+29)*8/sizeof(in[0])); out[0*64+30] = (w28 >> 38) | (w29 << 26) & 0x1fffffffffffffff; w30 = *(uint32_t *)(in+(0*61+30)*8/sizeof(in[0])); out[0*64+31] = (w29 >> 35) | (w30 << 29) & 0x1fffffffffffffff;;}; out += 32; in += 61*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_62(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*62)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*32+ 0] = (w0 ) & 0x3fffffffffffffff; w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*32+ 1] = (w0 >> 62) | (w1 << 2) & 0x3fffffffffffffff; w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*32+ 2] = (w1 >> 60) | (w2 << 4) & 0x3fffffffffffffff; w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*32+ 3] = (w2 >> 58) | (w3 << 6) & 0x3fffffffffffffff; w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*32+ 4] = (w3 >> 56) | (w4 << 8) & 0x3fffffffffffffff; w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*32+ 5] = (w4 >> 54) | (w5 << 10) & 0x3fffffffffffffff; w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*32+ 6] = (w5 >> 52) | (w6 << 12) & 0x3fffffffffffffff; w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*32+ 7] = (w6 >> 50) | (w7 << 14) & 0x3fffffffffffffff; w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*32+ 8] = (w7 >> 48) | (w8 << 16) & 0x3fffffffffffffff; w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*32+ 9] = (w8 >> 46) | (w9 << 18) & 0x3fffffffffffffff; w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*32+10] = (w9 >> 44) | (w10 << 20) & 0x3fffffffffffffff; w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*32+11] = (w10 >> 42) | (w11 << 22) & 0x3fffffffffffffff; w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*32+12] = (w11 >> 40) | (w12 << 24) & 0x3fffffffffffffff; w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*32+13] = (w12 >> 38) | (w13 << 26) & 0x3fffffffffffffff; w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*32+14] = (w13 >> 36) | (w14 << 28) & 0x3fffffffffffffff; w15 = *(uint64_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*32+15] = (w14 >> 34) | (w15 << 30) & 0x3fffffffffffffff; w16 = *(uint64_t *)(in+(0*31+16)*8/sizeof(in[0])); out[0*32+16] = (w15 >> 32) | (w16 << 32) & 0x3fffffffffffffff; w17 = *(uint64_t *)(in+(0*31+17)*8/sizeof(in[0])); out[0*32+17] = (w16 >> 30) | (w17 << 34) & 0x3fffffffffffffff; w18 = *(uint64_t *)(in+(0*31+18)*8/sizeof(in[0])); out[0*32+18] = (w17 >> 28) | (w18 << 36) & 0x3fffffffffffffff; w19 = *(uint64_t *)(in+(0*31+19)*8/sizeof(in[0])); out[0*32+19] = (w18 >> 26) | (w19 << 38) & 0x3fffffffffffffff; w20 = *(uint64_t *)(in+(0*31+20)*8/sizeof(in[0])); out[0*32+20] = (w19 >> 24) | (w20 << 40) & 0x3fffffffffffffff; w21 = *(uint64_t *)(in+(0*31+21)*8/sizeof(in[0])); out[0*32+21] = (w20 >> 22) | (w21 << 42) & 0x3fffffffffffffff; w22 = *(uint64_t *)(in+(0*31+22)*8/sizeof(in[0])); out[0*32+22] = (w21 >> 20) | (w22 << 44) & 0x3fffffffffffffff; w23 = *(uint64_t *)(in+(0*31+23)*8/sizeof(in[0])); out[0*32+23] = (w22 >> 18) | (w23 << 46) & 0x3fffffffffffffff; w24 = *(uint64_t *)(in+(0*31+24)*8/sizeof(in[0])); out[0*32+24] = (w23 >> 16) | (w24 << 48) & 0x3fffffffffffffff; w25 = *(uint64_t *)(in+(0*31+25)*8/sizeof(in[0])); out[0*32+25] = (w24 >> 14) | (w25 << 50) & 0x3fffffffffffffff; w26 = *(uint64_t *)(in+(0*31+26)*8/sizeof(in[0])); out[0*32+26] = (w25 >> 12) | (w26 << 52) & 0x3fffffffffffffff; w27 = *(uint64_t *)(in+(0*31+27)*8/sizeof(in[0])); out[0*32+27] = (w26 >> 10) | (w27 << 54) & 0x3fffffffffffffff; w28 = *(uint64_t *)(in+(0*31+28)*8/sizeof(in[0])); out[0*32+28] = (w27 >> 8) | (w28 << 56) & 0x3fffffffffffffff; w29 = *(uint64_t *)(in+(0*31+29)*8/sizeof(in[0])); out[0*32+29] = (w28 >> 6) | (w29 << 58) & 0x3fffffffffffffff; w30 = *(uint64_t *)(in+(0*31+30)*8/sizeof(in[0])); out[0*32+30] = (w29 >> 4) | (w30 << 60) & 0x3fffffffffffffff; out[0*32+31] = (w30 >> 2);;}; out += 32; in += 62*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_63(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*63)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(0*63+0)*8/sizeof(in[0])); out[0*64+ 0] = (w0 ) & 0x7fffffffffffffff; w1 = *(uint64_t *)(in+(0*63+1)*8/sizeof(in[0])); out[0*64+ 1] = (w0 >> 63) | (w1 << 1) & 0x7fffffffffffffff; w2 = *(uint64_t *)(in+(0*63+2)*8/sizeof(in[0])); out[0*64+ 2] = (w1 >> 62) | (w2 << 2) & 0x7fffffffffffffff; w3 = *(uint64_t *)(in+(0*63+3)*8/sizeof(in[0])); out[0*64+ 3] = (w2 >> 61) | (w3 << 3) & 0x7fffffffffffffff; w4 = *(uint64_t *)(in+(0*63+4)*8/sizeof(in[0])); out[0*64+ 4] = (w3 >> 60) | (w4 << 4) & 0x7fffffffffffffff; w5 = *(uint64_t *)(in+(0*63+5)*8/sizeof(in[0])); out[0*64+ 5] = (w4 >> 59) | (w5 << 5) & 0x7fffffffffffffff; w6 = *(uint64_t *)(in+(0*63+6)*8/sizeof(in[0])); out[0*64+ 6] = (w5 >> 58) | (w6 << 6) & 0x7fffffffffffffff; w7 = *(uint64_t *)(in+(0*63+7)*8/sizeof(in[0])); out[0*64+ 7] = (w6 >> 57) | (w7 << 7) & 0x7fffffffffffffff; w8 = *(uint64_t *)(in+(0*63+8)*8/sizeof(in[0])); out[0*64+ 8] = (w7 >> 56) | (w8 << 8) & 0x7fffffffffffffff; w9 = *(uint64_t *)(in+(0*63+9)*8/sizeof(in[0])); out[0*64+ 9] = (w8 >> 55) | (w9 << 9) & 0x7fffffffffffffff; w10 = *(uint64_t *)(in+(0*63+10)*8/sizeof(in[0])); out[0*64+10] = (w9 >> 54) | (w10 << 10) & 0x7fffffffffffffff; w11 = *(uint64_t *)(in+(0*63+11)*8/sizeof(in[0])); out[0*64+11] = (w10 >> 53) | (w11 << 11) & 0x7fffffffffffffff; w12 = *(uint64_t *)(in+(0*63+12)*8/sizeof(in[0])); out[0*64+12] = (w11 >> 52) | (w12 << 12) & 0x7fffffffffffffff; w13 = *(uint64_t *)(in+(0*63+13)*8/sizeof(in[0])); out[0*64+13] = (w12 >> 51) | (w13 << 13) & 0x7fffffffffffffff; w14 = *(uint64_t *)(in+(0*63+14)*8/sizeof(in[0])); out[0*64+14] = (w13 >> 50) | (w14 << 14) & 0x7fffffffffffffff; w15 = *(uint64_t *)(in+(0*63+15)*8/sizeof(in[0])); out[0*64+15] = (w14 >> 49) | (w15 << 15) & 0x7fffffffffffffff; w16 = *(uint64_t *)(in+(0*63+16)*8/sizeof(in[0])); out[0*64+16] = (w15 >> 48) | (w16 << 16) & 0x7fffffffffffffff; w17 = *(uint64_t *)(in+(0*63+17)*8/sizeof(in[0])); out[0*64+17] = (w16 >> 47) | (w17 << 17) & 0x7fffffffffffffff; w18 = *(uint64_t *)(in+(0*63+18)*8/sizeof(in[0])); out[0*64+18] = (w17 >> 46) | (w18 << 18) & 0x7fffffffffffffff; w19 = *(uint64_t *)(in+(0*63+19)*8/sizeof(in[0])); out[0*64+19] = (w18 >> 45) | (w19 << 19) & 0x7fffffffffffffff; w20 = *(uint64_t *)(in+(0*63+20)*8/sizeof(in[0])); out[0*64+20] = (w19 >> 44) | (w20 << 20) & 0x7fffffffffffffff; w21 = *(uint64_t *)(in+(0*63+21)*8/sizeof(in[0])); out[0*64+21] = (w20 >> 43) | (w21 << 21) & 0x7fffffffffffffff; w22 = *(uint64_t *)(in+(0*63+22)*8/sizeof(in[0])); out[0*64+22] = (w21 >> 42) | (w22 << 22) & 0x7fffffffffffffff; w23 = *(uint64_t *)(in+(0*63+23)*8/sizeof(in[0])); out[0*64+23] = (w22 >> 41) | (w23 << 23) & 0x7fffffffffffffff; w24 = *(uint64_t *)(in+(0*63+24)*8/sizeof(in[0])); out[0*64+24] = (w23 >> 40) | (w24 << 24) & 0x7fffffffffffffff; w25 = *(uint64_t *)(in+(0*63+25)*8/sizeof(in[0])); out[0*64+25] = (w24 >> 39) | (w25 << 25) & 0x7fffffffffffffff; w26 = *(uint64_t *)(in+(0*63+26)*8/sizeof(in[0])); out[0*64+26] = (w25 >> 38) | (w26 << 26) & 0x7fffffffffffffff; w27 = *(uint64_t *)(in+(0*63+27)*8/sizeof(in[0])); out[0*64+27] = (w26 >> 37) | (w27 << 27) & 0x7fffffffffffffff; w28 = *(uint64_t *)(in+(0*63+28)*8/sizeof(in[0])); out[0*64+28] = (w27 >> 36) | (w28 << 28) & 0x7fffffffffffffff; w29 = *(uint64_t *)(in+(0*63+29)*8/sizeof(in[0])); out[0*64+29] = (w28 >> 35) | (w29 << 29) & 0x7fffffffffffffff; w30 = *(uint64_t *)(in+(0*63+30)*8/sizeof(in[0])); out[0*64+30] = (w29 >> 34) | (w30 << 30) & 0x7fffffffffffffff; w31 = *(uint32_t *)(in+(0*63+31)*8/sizeof(in[0])); out[0*64+31] = (w30 >> 33) | (w31 << 31) & 0x7fffffffffffffff;;}; out += 32; in += 63*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitunpack64_64(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out ) { unsigned char *in_=in+(((n*64)+7)/8); do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(4*1+0)*8/sizeof(in[0])); out[4*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(5*1+0)*8/sizeof(in[0])); out[5*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(6*1+0)*8/sizeof(in[0])); out[6*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(7*1+0)*8/sizeof(in[0])); out[7*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(8*1+0)*8/sizeof(in[0])); out[8*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(9*1+0)*8/sizeof(in[0])); out[9*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(10*1+0)*8/sizeof(in[0])); out[10*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(11*1+0)*8/sizeof(in[0])); out[11*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(12*1+0)*8/sizeof(in[0])); out[12*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(13*1+0)*8/sizeof(in[0])); out[13*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(14*1+0)*8/sizeof(in[0])); out[14*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(15*1+0)*8/sizeof(in[0])); out[15*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(16*1+0)*8/sizeof(in[0])); out[16*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(17*1+0)*8/sizeof(in[0])); out[17*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(18*1+0)*8/sizeof(in[0])); out[18*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(19*1+0)*8/sizeof(in[0])); out[19*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(20*1+0)*8/sizeof(in[0])); out[20*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(21*1+0)*8/sizeof(in[0])); out[21*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(22*1+0)*8/sizeof(in[0])); out[22*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(23*1+0)*8/sizeof(in[0])); out[23*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(24*1+0)*8/sizeof(in[0])); out[24*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(25*1+0)*8/sizeof(in[0])); out[25*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(26*1+0)*8/sizeof(in[0])); out[26*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(27*1+0)*8/sizeof(in[0])); out[27*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(28*1+0)*8/sizeof(in[0])); out[28*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(29*1+0)*8/sizeof(in[0])); out[29*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(30*1+0)*8/sizeof(in[0])); out[30*1+ 0] = (w0 );;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(31*1+0)*8/sizeof(in[0])); out[31*1+ 0] = (w0 );;}; out += 32; in += 64*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_F64 bitunpacka64[] = {
  &bitunpack64_0,
  &bitunpack64_1,
  &bitunpack64_2,
  &bitunpack64_3,
  &bitunpack64_4,
  &bitunpack64_5,
  &bitunpack64_6,
  &bitunpack64_7,
  &bitunpack64_8,
  &bitunpack64_9,
  &bitunpack64_10,
  &bitunpack64_11,
  &bitunpack64_12,
  &bitunpack64_13,
  &bitunpack64_14,
  &bitunpack64_15,
  &bitunpack64_16,
  &bitunpack64_17,
  &bitunpack64_18,
  &bitunpack64_19,
  &bitunpack64_20,
  &bitunpack64_21,
  &bitunpack64_22,
  &bitunpack64_23,
  &bitunpack64_24,
  &bitunpack64_25,
  &bitunpack64_26,
  &bitunpack64_27,
  &bitunpack64_28,
  &bitunpack64_29,
  &bitunpack64_30,
  &bitunpack64_31,
  &bitunpack64_32,
  &bitunpack64_33,
  &bitunpack64_34,
  &bitunpack64_35,
  &bitunpack64_36,
  &bitunpack64_37,
  &bitunpack64_38,
  &bitunpack64_39,
  &bitunpack64_40,
  &bitunpack64_41,
  &bitunpack64_42,
  &bitunpack64_43,
  &bitunpack64_44,
  &bitunpack64_45,
  &bitunpack64_46,
  &bitunpack64_47,
  &bitunpack64_48,
  &bitunpack64_49,
  &bitunpack64_50,
  &bitunpack64_51,
  &bitunpack64_52,
  &bitunpack64_53,
  &bitunpack64_54,
  &bitunpack64_55,
  &bitunpack64_56,
  &bitunpack64_57,
  &bitunpack64_58,
  &bitunpack64_59,
  &bitunpack64_60,
  &bitunpack64_61,
  &bitunpack64_62,
  &bitunpack64_63,
  &bitunpack64_64
};
unsigned char *bitunpack64( const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , unsigned b) { return bitunpacka64[ b](in, n, out); }
unsigned char *bitdunpack8_0(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint8_t *out_ = out+n; do { { { out[0*0+ 0] = (start += (0)); out[0*0+ 1] = (start += (0)); out[0*0+ 2] = (start += (0)); out[0*0+ 3] = (start += (0)); out[0*0+ 4] = (start += (0)); out[0*0+ 5] = (start += (0)); out[0*0+ 6] = (start += (0)); out[0*0+ 7] = (start += (0)); out[0*0+ 8] = (start += (0)); out[0*0+ 9] = (start += (0)); out[0*0+10] = (start += (0)); out[0*0+11] = (start += (0)); out[0*0+12] = (start += (0)); out[0*0+13] = (start += (0)); out[0*0+14] = (start += (0)); out[0*0+15] = (start += (0)); out[0*0+16] = (start += (0)); out[0*0+17] = (start += (0)); out[0*0+18] = (start += (0)); out[0*0+19] = (start += (0)); out[0*0+20] = (start += (0)); out[0*0+21] = (start += (0)); out[0*0+22] = (start += (0)); out[0*0+23] = (start += (0)); out[0*0+24] = (start += (0)); out[0*0+25] = (start += (0)); out[0*0+26] = (start += (0)); out[0*0+27] = (start += (0)); out[0*0+28] = (start += (0)); out[0*0+29] = (start += (0)); out[0*0+30] = (start += (0)); out[0*0+31] = (start += (0));;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitdunpack8_1(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x1)); out[0*32+ 1] = (start += ((w0 >> 1) & 0x1)); out[0*32+ 2] = (start += ((w0 >> 2) & 0x1)); out[0*32+ 3] = (start += ((w0 >> 3) & 0x1)); out[0*32+ 4] = (start += ((w0 >> 4) & 0x1)); out[0*32+ 5] = (start += ((w0 >> 5) & 0x1)); out[0*32+ 6] = (start += ((w0 >> 6) & 0x1)); out[0*32+ 7] = (start += ((w0 >> 7) & 0x1)); out[0*32+ 8] = (start += ((w0 >> 8) & 0x1)); out[0*32+ 9] = (start += ((w0 >> 9) & 0x1)); out[0*32+10] = (start += ((w0 >> 10) & 0x1)); out[0*32+11] = (start += ((w0 >> 11) & 0x1)); out[0*32+12] = (start += ((w0 >> 12) & 0x1)); out[0*32+13] = (start += ((w0 >> 13) & 0x1)); out[0*32+14] = (start += ((w0 >> 14) & 0x1)); out[0*32+15] = (start += ((w0 >> 15) & 0x1)); out[0*32+16] = (start += ((w0 >> 16) & 0x1)); out[0*32+17] = (start += ((w0 >> 17) & 0x1)); out[0*32+18] = (start += ((w0 >> 18) & 0x1)); out[0*32+19] = (start += ((w0 >> 19) & 0x1)); out[0*32+20] = (start += ((w0 >> 20) & 0x1)); out[0*32+21] = (start += ((w0 >> 21) & 0x1)); out[0*32+22] = (start += ((w0 >> 22) & 0x1)); out[0*32+23] = (start += ((w0 >> 23) & 0x1)); out[0*32+24] = (start += ((w0 >> 24) & 0x1)); out[0*32+25] = (start += ((w0 >> 25) & 0x1)); out[0*32+26] = (start += ((w0 >> 26) & 0x1)); out[0*32+27] = (start += ((w0 >> 27) & 0x1)); out[0*32+28] = (start += ((w0 >> 28) & 0x1)); out[0*32+29] = (start += ((w0 >> 29) & 0x1)); out[0*32+30] = (start += ((w0 >> 30) & 0x1)); out[0*32+31] = (start += ((w0 >> 31)));;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack8_2(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3)); out[0*32+ 1] = (start += ((w0 >> 2) & 0x3)); out[0*32+ 2] = (start += ((w0 >> 4) & 0x3)); out[0*32+ 3] = (start += ((w0 >> 6) & 0x3)); out[0*32+ 4] = (start += ((w0 >> 8) & 0x3)); out[0*32+ 5] = (start += ((w0 >> 10) & 0x3)); out[0*32+ 6] = (start += ((w0 >> 12) & 0x3)); out[0*32+ 7] = (start += ((w0 >> 14) & 0x3)); out[0*32+ 8] = (start += ((w0 >> 16) & 0x3)); out[0*32+ 9] = (start += ((w0 >> 18) & 0x3)); out[0*32+10] = (start += ((w0 >> 20) & 0x3)); out[0*32+11] = (start += ((w0 >> 22) & 0x3)); out[0*32+12] = (start += ((w0 >> 24) & 0x3)); out[0*32+13] = (start += ((w0 >> 26) & 0x3)); out[0*32+14] = (start += ((w0 >> 28) & 0x3)); out[0*32+15] = (start += ((w0 >> 30) & 0x3)); out[0*32+16] = (start += ((w0 >> 32) & 0x3)); out[0*32+17] = (start += ((w0 >> 34) & 0x3)); out[0*32+18] = (start += ((w0 >> 36) & 0x3)); out[0*32+19] = (start += ((w0 >> 38) & 0x3)); out[0*32+20] = (start += ((w0 >> 40) & 0x3)); out[0*32+21] = (start += ((w0 >> 42) & 0x3)); out[0*32+22] = (start += ((w0 >> 44) & 0x3)); out[0*32+23] = (start += ((w0 >> 46) & 0x3)); out[0*32+24] = (start += ((w0 >> 48) & 0x3)); out[0*32+25] = (start += ((w0 >> 50) & 0x3)); out[0*32+26] = (start += ((w0 >> 52) & 0x3)); out[0*32+27] = (start += ((w0 >> 54) & 0x3)); out[0*32+28] = (start += ((w0 >> 56) & 0x3)); out[0*32+29] = (start += ((w0 >> 58) & 0x3)); out[0*32+30] = (start += ((w0 >> 60) & 0x3)); out[0*32+31] = (start += ((w0 >> 62)));;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack8_3(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7)); out[0*64+ 1] = (start += ((w0 >> 3) & 0x7)); out[0*64+ 2] = (start += ((w0 >> 6) & 0x7)); out[0*64+ 3] = (start += ((w0 >> 9) & 0x7)); out[0*64+ 4] = (start += ((w0 >> 12) & 0x7)); out[0*64+ 5] = (start += ((w0 >> 15) & 0x7)); out[0*64+ 6] = (start += ((w0 >> 18) & 0x7)); out[0*64+ 7] = (start += ((w0 >> 21) & 0x7)); out[0*64+ 8] = (start += ((w0 >> 24) & 0x7)); out[0*64+ 9] = (start += ((w0 >> 27) & 0x7)); out[0*64+10] = (start += ((w0 >> 30) & 0x7)); out[0*64+11] = (start += ((w0 >> 33) & 0x7)); out[0*64+12] = (start += ((w0 >> 36) & 0x7)); out[0*64+13] = (start += ((w0 >> 39) & 0x7)); out[0*64+14] = (start += ((w0 >> 42) & 0x7)); out[0*64+15] = (start += ((w0 >> 45) & 0x7)); out[0*64+16] = (start += ((w0 >> 48) & 0x7)); out[0*64+17] = (start += ((w0 >> 51) & 0x7)); out[0*64+18] = (start += ((w0 >> 54) & 0x7)); out[0*64+19] = (start += ((w0 >> 57) & 0x7)); out[0*64+20] = (start += ((w0 >> 60) & 0x7)); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start += ((w0 >> 63) | (w1 << 1) & 0x7)); out[0*64+22] = (start += ((w1 >> 2) & 0x7)); out[0*64+23] = (start += ((w1 >> 5) & 0x7)); out[0*64+24] = (start += ((w1 >> 8) & 0x7)); out[0*64+25] = (start += ((w1 >> 11) & 0x7)); out[0*64+26] = (start += ((w1 >> 14) & 0x7)); out[0*64+27] = (start += ((w1 >> 17) & 0x7)); out[0*64+28] = (start += ((w1 >> 20) & 0x7)); out[0*64+29] = (start += ((w1 >> 23) & 0x7)); out[0*64+30] = (start += ((w1 >> 26) & 0x7)); out[0*64+31] = (start += ((w1 >> 29) & 0x7));;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack8_4(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xf)); out[0*16+ 1] = (start += ((w0 >> 4) & 0xf)); out[0*16+ 2] = (start += ((w0 >> 8) & 0xf)); out[0*16+ 3] = (start += ((w0 >> 12) & 0xf)); out[0*16+ 4] = (start += ((w0 >> 16) & 0xf)); out[0*16+ 5] = (start += ((w0 >> 20) & 0xf)); out[0*16+ 6] = (start += ((w0 >> 24) & 0xf)); out[0*16+ 7] = (start += ((w0 >> 28) & 0xf)); out[0*16+ 8] = (start += ((w0 >> 32) & 0xf)); out[0*16+ 9] = (start += ((w0 >> 36) & 0xf)); out[0*16+10] = (start += ((w0 >> 40) & 0xf)); out[0*16+11] = (start += ((w0 >> 44) & 0xf)); out[0*16+12] = (start += ((w0 >> 48) & 0xf)); out[0*16+13] = (start += ((w0 >> 52) & 0xf)); out[0*16+14] = (start += ((w0 >> 56) & 0xf)); out[0*16+15] = (start += ((w0 >> 60)));;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xf)); out[1*16+ 1] = (start += ((w0 >> 4) & 0xf)); out[1*16+ 2] = (start += ((w0 >> 8) & 0xf)); out[1*16+ 3] = (start += ((w0 >> 12) & 0xf)); out[1*16+ 4] = (start += ((w0 >> 16) & 0xf)); out[1*16+ 5] = (start += ((w0 >> 20) & 0xf)); out[1*16+ 6] = (start += ((w0 >> 24) & 0xf)); out[1*16+ 7] = (start += ((w0 >> 28) & 0xf)); out[1*16+ 8] = (start += ((w0 >> 32) & 0xf)); out[1*16+ 9] = (start += ((w0 >> 36) & 0xf)); out[1*16+10] = (start += ((w0 >> 40) & 0xf)); out[1*16+11] = (start += ((w0 >> 44) & 0xf)); out[1*16+12] = (start += ((w0 >> 48) & 0xf)); out[1*16+13] = (start += ((w0 >> 52) & 0xf)); out[1*16+14] = (start += ((w0 >> 56) & 0xf)); out[1*16+15] = (start += ((w0 >> 60)));;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack8_5(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1f)); out[0*64+ 1] = (start += ((w0 >> 5) & 0x1f)); out[0*64+ 2] = (start += ((w0 >> 10) & 0x1f)); out[0*64+ 3] = (start += ((w0 >> 15) & 0x1f)); out[0*64+ 4] = (start += ((w0 >> 20) & 0x1f)); out[0*64+ 5] = (start += ((w0 >> 25) & 0x1f)); out[0*64+ 6] = (start += ((w0 >> 30) & 0x1f)); out[0*64+ 7] = (start += ((w0 >> 35) & 0x1f)); out[0*64+ 8] = (start += ((w0 >> 40) & 0x1f)); out[0*64+ 9] = (start += ((w0 >> 45) & 0x1f)); out[0*64+10] = (start += ((w0 >> 50) & 0x1f)); out[0*64+11] = (start += ((w0 >> 55) & 0x1f)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start += ((w0 >> 60) | (w1 << 4) & 0x1f)); out[0*64+13] = (start += ((w1 >> 1) & 0x1f)); out[0*64+14] = (start += ((w1 >> 6) & 0x1f)); out[0*64+15] = (start += ((w1 >> 11) & 0x1f)); out[0*64+16] = (start += ((w1 >> 16) & 0x1f)); out[0*64+17] = (start += ((w1 >> 21) & 0x1f)); out[0*64+18] = (start += ((w1 >> 26) & 0x1f)); out[0*64+19] = (start += ((w1 >> 31) & 0x1f)); out[0*64+20] = (start += ((w1 >> 36) & 0x1f)); out[0*64+21] = (start += ((w1 >> 41) & 0x1f)); out[0*64+22] = (start += ((w1 >> 46) & 0x1f)); out[0*64+23] = (start += ((w1 >> 51) & 0x1f)); out[0*64+24] = (start += ((w1 >> 56) & 0x1f)); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start += ((w1 >> 61) | (w2 << 3) & 0x1f)); out[0*64+26] = (start += ((w2 >> 2) & 0x1f)); out[0*64+27] = (start += ((w2 >> 7) & 0x1f)); out[0*64+28] = (start += ((w2 >> 12) & 0x1f)); out[0*64+29] = (start += ((w2 >> 17) & 0x1f)); out[0*64+30] = (start += ((w2 >> 22) & 0x1f)); out[0*64+31] = (start += ((w2 >> 27) & 0x1f));;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack8_6(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3f)); out[0*32+ 1] = (start += ((w0 >> 6) & 0x3f)); out[0*32+ 2] = (start += ((w0 >> 12) & 0x3f)); out[0*32+ 3] = (start += ((w0 >> 18) & 0x3f)); out[0*32+ 4] = (start += ((w0 >> 24) & 0x3f)); out[0*32+ 5] = (start += ((w0 >> 30) & 0x3f)); out[0*32+ 6] = (start += ((w0 >> 36) & 0x3f)); out[0*32+ 7] = (start += ((w0 >> 42) & 0x3f)); out[0*32+ 8] = (start += ((w0 >> 48) & 0x3f)); out[0*32+ 9] = (start += ((w0 >> 54) & 0x3f)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start += ((w0 >> 60) | (w1 << 4) & 0x3f)); out[0*32+11] = (start += ((w1 >> 2) & 0x3f)); out[0*32+12] = (start += ((w1 >> 8) & 0x3f)); out[0*32+13] = (start += ((w1 >> 14) & 0x3f)); out[0*32+14] = (start += ((w1 >> 20) & 0x3f)); out[0*32+15] = (start += ((w1 >> 26) & 0x3f)); out[0*32+16] = (start += ((w1 >> 32) & 0x3f)); out[0*32+17] = (start += ((w1 >> 38) & 0x3f)); out[0*32+18] = (start += ((w1 >> 44) & 0x3f)); out[0*32+19] = (start += ((w1 >> 50) & 0x3f)); out[0*32+20] = (start += ((w1 >> 56) & 0x3f)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start += ((w1 >> 62) | (w2 << 2) & 0x3f)); out[0*32+22] = (start += ((w2 >> 4) & 0x3f)); out[0*32+23] = (start += ((w2 >> 10) & 0x3f)); out[0*32+24] = (start += ((w2 >> 16) & 0x3f)); out[0*32+25] = (start += ((w2 >> 22) & 0x3f)); out[0*32+26] = (start += ((w2 >> 28) & 0x3f)); out[0*32+27] = (start += ((w2 >> 34) & 0x3f)); out[0*32+28] = (start += ((w2 >> 40) & 0x3f)); out[0*32+29] = (start += ((w2 >> 46) & 0x3f)); out[0*32+30] = (start += ((w2 >> 52) & 0x3f)); out[0*32+31] = (start += ((w2 >> 58)));;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack8_7(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7f)); out[0*64+ 1] = (start += ((w0 >> 7) & 0x7f)); out[0*64+ 2] = (start += ((w0 >> 14) & 0x7f)); out[0*64+ 3] = (start += ((w0 >> 21) & 0x7f)); out[0*64+ 4] = (start += ((w0 >> 28) & 0x7f)); out[0*64+ 5] = (start += ((w0 >> 35) & 0x7f)); out[0*64+ 6] = (start += ((w0 >> 42) & 0x7f)); out[0*64+ 7] = (start += ((w0 >> 49) & 0x7f)); out[0*64+ 8] = (start += ((w0 >> 56) & 0x7f)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w0 >> 63) | (w1 << 1) & 0x7f)); out[0*64+10] = (start += ((w1 >> 6) & 0x7f)); out[0*64+11] = (start += ((w1 >> 13) & 0x7f)); out[0*64+12] = (start += ((w1 >> 20) & 0x7f)); out[0*64+13] = (start += ((w1 >> 27) & 0x7f)); out[0*64+14] = (start += ((w1 >> 34) & 0x7f)); out[0*64+15] = (start += ((w1 >> 41) & 0x7f)); out[0*64+16] = (start += ((w1 >> 48) & 0x7f)); out[0*64+17] = (start += ((w1 >> 55) & 0x7f)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start += ((w1 >> 62) | (w2 << 2) & 0x7f)); out[0*64+19] = (start += ((w2 >> 5) & 0x7f)); out[0*64+20] = (start += ((w2 >> 12) & 0x7f)); out[0*64+21] = (start += ((w2 >> 19) & 0x7f)); out[0*64+22] = (start += ((w2 >> 26) & 0x7f)); out[0*64+23] = (start += ((w2 >> 33) & 0x7f)); out[0*64+24] = (start += ((w2 >> 40) & 0x7f)); out[0*64+25] = (start += ((w2 >> 47) & 0x7f)); out[0*64+26] = (start += ((w2 >> 54) & 0x7f)); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start += ((w2 >> 61) | (w3 << 3) & 0x7f)); out[0*64+28] = (start += ((w3 >> 4) & 0x7f)); out[0*64+29] = (start += ((w3 >> 11) & 0x7f)); out[0*64+30] = (start += ((w3 >> 18) & 0x7f)); out[0*64+31] = (start += ((w3 >> 25) & 0x7f));;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack8_8(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xff)); out[0*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[0*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[0*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[0*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[0*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[0*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[0*8+ 7] = (start += ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xff)); out[1*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[1*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[1*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[1*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[1*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[1*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[1*8+ 7] = (start += ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xff)); out[2*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[2*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[2*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[2*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[2*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[2*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[2*8+ 7] = (start += ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xff)); out[3*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[3*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[3*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[3*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[3*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[3*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[3*8+ 7] = (start += ((w0 >> 56)));;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D8 bitdunpacka8[] = {
  &bitdunpack8_0,
  &bitdunpack8_1,
  &bitdunpack8_2,
  &bitdunpack8_3,
  &bitdunpack8_4,
  &bitdunpack8_5,
  &bitdunpack8_6,
  &bitdunpack8_7,
  &bitdunpack8_8
};
unsigned char *bitdunpack8( const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start, unsigned b) { return bitdunpacka8[ b](in, n, out, start); }
unsigned char *bitdunpack16_0(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint16_t *out_ = out+n; do { { { out[0*0+ 0] = (start += (0)); out[0*0+ 1] = (start += (0)); out[0*0+ 2] = (start += (0)); out[0*0+ 3] = (start += (0)); out[0*0+ 4] = (start += (0)); out[0*0+ 5] = (start += (0)); out[0*0+ 6] = (start += (0)); out[0*0+ 7] = (start += (0)); out[0*0+ 8] = (start += (0)); out[0*0+ 9] = (start += (0)); out[0*0+10] = (start += (0)); out[0*0+11] = (start += (0)); out[0*0+12] = (start += (0)); out[0*0+13] = (start += (0)); out[0*0+14] = (start += (0)); out[0*0+15] = (start += (0)); out[0*0+16] = (start += (0)); out[0*0+17] = (start += (0)); out[0*0+18] = (start += (0)); out[0*0+19] = (start += (0)); out[0*0+20] = (start += (0)); out[0*0+21] = (start += (0)); out[0*0+22] = (start += (0)); out[0*0+23] = (start += (0)); out[0*0+24] = (start += (0)); out[0*0+25] = (start += (0)); out[0*0+26] = (start += (0)); out[0*0+27] = (start += (0)); out[0*0+28] = (start += (0)); out[0*0+29] = (start += (0)); out[0*0+30] = (start += (0)); out[0*0+31] = (start += (0));;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitdunpack16_1(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x1)); out[0*32+ 1] = (start += ((w0 >> 1) & 0x1)); out[0*32+ 2] = (start += ((w0 >> 2) & 0x1)); out[0*32+ 3] = (start += ((w0 >> 3) & 0x1)); out[0*32+ 4] = (start += ((w0 >> 4) & 0x1)); out[0*32+ 5] = (start += ((w0 >> 5) & 0x1)); out[0*32+ 6] = (start += ((w0 >> 6) & 0x1)); out[0*32+ 7] = (start += ((w0 >> 7) & 0x1)); out[0*32+ 8] = (start += ((w0 >> 8) & 0x1)); out[0*32+ 9] = (start += ((w0 >> 9) & 0x1)); out[0*32+10] = (start += ((w0 >> 10) & 0x1)); out[0*32+11] = (start += ((w0 >> 11) & 0x1)); out[0*32+12] = (start += ((w0 >> 12) & 0x1)); out[0*32+13] = (start += ((w0 >> 13) & 0x1)); out[0*32+14] = (start += ((w0 >> 14) & 0x1)); out[0*32+15] = (start += ((w0 >> 15) & 0x1)); out[0*32+16] = (start += ((w0 >> 16) & 0x1)); out[0*32+17] = (start += ((w0 >> 17) & 0x1)); out[0*32+18] = (start += ((w0 >> 18) & 0x1)); out[0*32+19] = (start += ((w0 >> 19) & 0x1)); out[0*32+20] = (start += ((w0 >> 20) & 0x1)); out[0*32+21] = (start += ((w0 >> 21) & 0x1)); out[0*32+22] = (start += ((w0 >> 22) & 0x1)); out[0*32+23] = (start += ((w0 >> 23) & 0x1)); out[0*32+24] = (start += ((w0 >> 24) & 0x1)); out[0*32+25] = (start += ((w0 >> 25) & 0x1)); out[0*32+26] = (start += ((w0 >> 26) & 0x1)); out[0*32+27] = (start += ((w0 >> 27) & 0x1)); out[0*32+28] = (start += ((w0 >> 28) & 0x1)); out[0*32+29] = (start += ((w0 >> 29) & 0x1)); out[0*32+30] = (start += ((w0 >> 30) & 0x1)); out[0*32+31] = (start += ((w0 >> 31)));;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_2(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3)); out[0*32+ 1] = (start += ((w0 >> 2) & 0x3)); out[0*32+ 2] = (start += ((w0 >> 4) & 0x3)); out[0*32+ 3] = (start += ((w0 >> 6) & 0x3)); out[0*32+ 4] = (start += ((w0 >> 8) & 0x3)); out[0*32+ 5] = (start += ((w0 >> 10) & 0x3)); out[0*32+ 6] = (start += ((w0 >> 12) & 0x3)); out[0*32+ 7] = (start += ((w0 >> 14) & 0x3)); out[0*32+ 8] = (start += ((w0 >> 16) & 0x3)); out[0*32+ 9] = (start += ((w0 >> 18) & 0x3)); out[0*32+10] = (start += ((w0 >> 20) & 0x3)); out[0*32+11] = (start += ((w0 >> 22) & 0x3)); out[0*32+12] = (start += ((w0 >> 24) & 0x3)); out[0*32+13] = (start += ((w0 >> 26) & 0x3)); out[0*32+14] = (start += ((w0 >> 28) & 0x3)); out[0*32+15] = (start += ((w0 >> 30) & 0x3)); out[0*32+16] = (start += ((w0 >> 32) & 0x3)); out[0*32+17] = (start += ((w0 >> 34) & 0x3)); out[0*32+18] = (start += ((w0 >> 36) & 0x3)); out[0*32+19] = (start += ((w0 >> 38) & 0x3)); out[0*32+20] = (start += ((w0 >> 40) & 0x3)); out[0*32+21] = (start += ((w0 >> 42) & 0x3)); out[0*32+22] = (start += ((w0 >> 44) & 0x3)); out[0*32+23] = (start += ((w0 >> 46) & 0x3)); out[0*32+24] = (start += ((w0 >> 48) & 0x3)); out[0*32+25] = (start += ((w0 >> 50) & 0x3)); out[0*32+26] = (start += ((w0 >> 52) & 0x3)); out[0*32+27] = (start += ((w0 >> 54) & 0x3)); out[0*32+28] = (start += ((w0 >> 56) & 0x3)); out[0*32+29] = (start += ((w0 >> 58) & 0x3)); out[0*32+30] = (start += ((w0 >> 60) & 0x3)); out[0*32+31] = (start += ((w0 >> 62)));;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_3(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7)); out[0*64+ 1] = (start += ((w0 >> 3) & 0x7)); out[0*64+ 2] = (start += ((w0 >> 6) & 0x7)); out[0*64+ 3] = (start += ((w0 >> 9) & 0x7)); out[0*64+ 4] = (start += ((w0 >> 12) & 0x7)); out[0*64+ 5] = (start += ((w0 >> 15) & 0x7)); out[0*64+ 6] = (start += ((w0 >> 18) & 0x7)); out[0*64+ 7] = (start += ((w0 >> 21) & 0x7)); out[0*64+ 8] = (start += ((w0 >> 24) & 0x7)); out[0*64+ 9] = (start += ((w0 >> 27) & 0x7)); out[0*64+10] = (start += ((w0 >> 30) & 0x7)); out[0*64+11] = (start += ((w0 >> 33) & 0x7)); out[0*64+12] = (start += ((w0 >> 36) & 0x7)); out[0*64+13] = (start += ((w0 >> 39) & 0x7)); out[0*64+14] = (start += ((w0 >> 42) & 0x7)); out[0*64+15] = (start += ((w0 >> 45) & 0x7)); out[0*64+16] = (start += ((w0 >> 48) & 0x7)); out[0*64+17] = (start += ((w0 >> 51) & 0x7)); out[0*64+18] = (start += ((w0 >> 54) & 0x7)); out[0*64+19] = (start += ((w0 >> 57) & 0x7)); out[0*64+20] = (start += ((w0 >> 60) & 0x7)); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start += ((w0 >> 63) | (w1 << 1) & 0x7)); out[0*64+22] = (start += ((w1 >> 2) & 0x7)); out[0*64+23] = (start += ((w1 >> 5) & 0x7)); out[0*64+24] = (start += ((w1 >> 8) & 0x7)); out[0*64+25] = (start += ((w1 >> 11) & 0x7)); out[0*64+26] = (start += ((w1 >> 14) & 0x7)); out[0*64+27] = (start += ((w1 >> 17) & 0x7)); out[0*64+28] = (start += ((w1 >> 20) & 0x7)); out[0*64+29] = (start += ((w1 >> 23) & 0x7)); out[0*64+30] = (start += ((w1 >> 26) & 0x7)); out[0*64+31] = (start += ((w1 >> 29) & 0x7));;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_4(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xf)); out[0*16+ 1] = (start += ((w0 >> 4) & 0xf)); out[0*16+ 2] = (start += ((w0 >> 8) & 0xf)); out[0*16+ 3] = (start += ((w0 >> 12) & 0xf)); out[0*16+ 4] = (start += ((w0 >> 16) & 0xf)); out[0*16+ 5] = (start += ((w0 >> 20) & 0xf)); out[0*16+ 6] = (start += ((w0 >> 24) & 0xf)); out[0*16+ 7] = (start += ((w0 >> 28) & 0xf)); out[0*16+ 8] = (start += ((w0 >> 32) & 0xf)); out[0*16+ 9] = (start += ((w0 >> 36) & 0xf)); out[0*16+10] = (start += ((w0 >> 40) & 0xf)); out[0*16+11] = (start += ((w0 >> 44) & 0xf)); out[0*16+12] = (start += ((w0 >> 48) & 0xf)); out[0*16+13] = (start += ((w0 >> 52) & 0xf)); out[0*16+14] = (start += ((w0 >> 56) & 0xf)); out[0*16+15] = (start += ((w0 >> 60)));;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xf)); out[1*16+ 1] = (start += ((w0 >> 4) & 0xf)); out[1*16+ 2] = (start += ((w0 >> 8) & 0xf)); out[1*16+ 3] = (start += ((w0 >> 12) & 0xf)); out[1*16+ 4] = (start += ((w0 >> 16) & 0xf)); out[1*16+ 5] = (start += ((w0 >> 20) & 0xf)); out[1*16+ 6] = (start += ((w0 >> 24) & 0xf)); out[1*16+ 7] = (start += ((w0 >> 28) & 0xf)); out[1*16+ 8] = (start += ((w0 >> 32) & 0xf)); out[1*16+ 9] = (start += ((w0 >> 36) & 0xf)); out[1*16+10] = (start += ((w0 >> 40) & 0xf)); out[1*16+11] = (start += ((w0 >> 44) & 0xf)); out[1*16+12] = (start += ((w0 >> 48) & 0xf)); out[1*16+13] = (start += ((w0 >> 52) & 0xf)); out[1*16+14] = (start += ((w0 >> 56) & 0xf)); out[1*16+15] = (start += ((w0 >> 60)));;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_5(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1f)); out[0*64+ 1] = (start += ((w0 >> 5) & 0x1f)); out[0*64+ 2] = (start += ((w0 >> 10) & 0x1f)); out[0*64+ 3] = (start += ((w0 >> 15) & 0x1f)); out[0*64+ 4] = (start += ((w0 >> 20) & 0x1f)); out[0*64+ 5] = (start += ((w0 >> 25) & 0x1f)); out[0*64+ 6] = (start += ((w0 >> 30) & 0x1f)); out[0*64+ 7] = (start += ((w0 >> 35) & 0x1f)); out[0*64+ 8] = (start += ((w0 >> 40) & 0x1f)); out[0*64+ 9] = (start += ((w0 >> 45) & 0x1f)); out[0*64+10] = (start += ((w0 >> 50) & 0x1f)); out[0*64+11] = (start += ((w0 >> 55) & 0x1f)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start += ((w0 >> 60) | (w1 << 4) & 0x1f)); out[0*64+13] = (start += ((w1 >> 1) & 0x1f)); out[0*64+14] = (start += ((w1 >> 6) & 0x1f)); out[0*64+15] = (start += ((w1 >> 11) & 0x1f)); out[0*64+16] = (start += ((w1 >> 16) & 0x1f)); out[0*64+17] = (start += ((w1 >> 21) & 0x1f)); out[0*64+18] = (start += ((w1 >> 26) & 0x1f)); out[0*64+19] = (start += ((w1 >> 31) & 0x1f)); out[0*64+20] = (start += ((w1 >> 36) & 0x1f)); out[0*64+21] = (start += ((w1 >> 41) & 0x1f)); out[0*64+22] = (start += ((w1 >> 46) & 0x1f)); out[0*64+23] = (start += ((w1 >> 51) & 0x1f)); out[0*64+24] = (start += ((w1 >> 56) & 0x1f)); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start += ((w1 >> 61) | (w2 << 3) & 0x1f)); out[0*64+26] = (start += ((w2 >> 2) & 0x1f)); out[0*64+27] = (start += ((w2 >> 7) & 0x1f)); out[0*64+28] = (start += ((w2 >> 12) & 0x1f)); out[0*64+29] = (start += ((w2 >> 17) & 0x1f)); out[0*64+30] = (start += ((w2 >> 22) & 0x1f)); out[0*64+31] = (start += ((w2 >> 27) & 0x1f));;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_6(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3f)); out[0*32+ 1] = (start += ((w0 >> 6) & 0x3f)); out[0*32+ 2] = (start += ((w0 >> 12) & 0x3f)); out[0*32+ 3] = (start += ((w0 >> 18) & 0x3f)); out[0*32+ 4] = (start += ((w0 >> 24) & 0x3f)); out[0*32+ 5] = (start += ((w0 >> 30) & 0x3f)); out[0*32+ 6] = (start += ((w0 >> 36) & 0x3f)); out[0*32+ 7] = (start += ((w0 >> 42) & 0x3f)); out[0*32+ 8] = (start += ((w0 >> 48) & 0x3f)); out[0*32+ 9] = (start += ((w0 >> 54) & 0x3f)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start += ((w0 >> 60) | (w1 << 4) & 0x3f)); out[0*32+11] = (start += ((w1 >> 2) & 0x3f)); out[0*32+12] = (start += ((w1 >> 8) & 0x3f)); out[0*32+13] = (start += ((w1 >> 14) & 0x3f)); out[0*32+14] = (start += ((w1 >> 20) & 0x3f)); out[0*32+15] = (start += ((w1 >> 26) & 0x3f)); out[0*32+16] = (start += ((w1 >> 32) & 0x3f)); out[0*32+17] = (start += ((w1 >> 38) & 0x3f)); out[0*32+18] = (start += ((w1 >> 44) & 0x3f)); out[0*32+19] = (start += ((w1 >> 50) & 0x3f)); out[0*32+20] = (start += ((w1 >> 56) & 0x3f)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start += ((w1 >> 62) | (w2 << 2) & 0x3f)); out[0*32+22] = (start += ((w2 >> 4) & 0x3f)); out[0*32+23] = (start += ((w2 >> 10) & 0x3f)); out[0*32+24] = (start += ((w2 >> 16) & 0x3f)); out[0*32+25] = (start += ((w2 >> 22) & 0x3f)); out[0*32+26] = (start += ((w2 >> 28) & 0x3f)); out[0*32+27] = (start += ((w2 >> 34) & 0x3f)); out[0*32+28] = (start += ((w2 >> 40) & 0x3f)); out[0*32+29] = (start += ((w2 >> 46) & 0x3f)); out[0*32+30] = (start += ((w2 >> 52) & 0x3f)); out[0*32+31] = (start += ((w2 >> 58)));;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_7(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7f)); out[0*64+ 1] = (start += ((w0 >> 7) & 0x7f)); out[0*64+ 2] = (start += ((w0 >> 14) & 0x7f)); out[0*64+ 3] = (start += ((w0 >> 21) & 0x7f)); out[0*64+ 4] = (start += ((w0 >> 28) & 0x7f)); out[0*64+ 5] = (start += ((w0 >> 35) & 0x7f)); out[0*64+ 6] = (start += ((w0 >> 42) & 0x7f)); out[0*64+ 7] = (start += ((w0 >> 49) & 0x7f)); out[0*64+ 8] = (start += ((w0 >> 56) & 0x7f)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w0 >> 63) | (w1 << 1) & 0x7f)); out[0*64+10] = (start += ((w1 >> 6) & 0x7f)); out[0*64+11] = (start += ((w1 >> 13) & 0x7f)); out[0*64+12] = (start += ((w1 >> 20) & 0x7f)); out[0*64+13] = (start += ((w1 >> 27) & 0x7f)); out[0*64+14] = (start += ((w1 >> 34) & 0x7f)); out[0*64+15] = (start += ((w1 >> 41) & 0x7f)); out[0*64+16] = (start += ((w1 >> 48) & 0x7f)); out[0*64+17] = (start += ((w1 >> 55) & 0x7f)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start += ((w1 >> 62) | (w2 << 2) & 0x7f)); out[0*64+19] = (start += ((w2 >> 5) & 0x7f)); out[0*64+20] = (start += ((w2 >> 12) & 0x7f)); out[0*64+21] = (start += ((w2 >> 19) & 0x7f)); out[0*64+22] = (start += ((w2 >> 26) & 0x7f)); out[0*64+23] = (start += ((w2 >> 33) & 0x7f)); out[0*64+24] = (start += ((w2 >> 40) & 0x7f)); out[0*64+25] = (start += ((w2 >> 47) & 0x7f)); out[0*64+26] = (start += ((w2 >> 54) & 0x7f)); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start += ((w2 >> 61) | (w3 << 3) & 0x7f)); out[0*64+28] = (start += ((w3 >> 4) & 0x7f)); out[0*64+29] = (start += ((w3 >> 11) & 0x7f)); out[0*64+30] = (start += ((w3 >> 18) & 0x7f)); out[0*64+31] = (start += ((w3 >> 25) & 0x7f));;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_8(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xff)); out[0*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[0*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[0*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[0*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[0*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[0*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[0*8+ 7] = (start += ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xff)); out[1*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[1*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[1*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[1*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[1*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[1*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[1*8+ 7] = (start += ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xff)); out[2*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[2*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[2*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[2*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[2*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[2*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[2*8+ 7] = (start += ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xff)); out[3*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[3*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[3*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[3*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[3*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[3*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[3*8+ 7] = (start += ((w0 >> 56)));;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_9(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ff)); out[0*64+ 1] = (start += ((w0 >> 9) & 0x1ff)); out[0*64+ 2] = (start += ((w0 >> 18) & 0x1ff)); out[0*64+ 3] = (start += ((w0 >> 27) & 0x1ff)); out[0*64+ 4] = (start += ((w0 >> 36) & 0x1ff)); out[0*64+ 5] = (start += ((w0 >> 45) & 0x1ff)); out[0*64+ 6] = (start += ((w0 >> 54) & 0x1ff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w0 >> 63) | (w1 << 1) & 0x1ff)); out[0*64+ 8] = (start += ((w1 >> 8) & 0x1ff)); out[0*64+ 9] = (start += ((w1 >> 17) & 0x1ff)); out[0*64+10] = (start += ((w1 >> 26) & 0x1ff)); out[0*64+11] = (start += ((w1 >> 35) & 0x1ff)); out[0*64+12] = (start += ((w1 >> 44) & 0x1ff)); out[0*64+13] = (start += ((w1 >> 53) & 0x1ff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (start += ((w1 >> 62) | (w2 << 2) & 0x1ff)); out[0*64+15] = (start += ((w2 >> 7) & 0x1ff)); out[0*64+16] = (start += ((w2 >> 16) & 0x1ff)); out[0*64+17] = (start += ((w2 >> 25) & 0x1ff)); out[0*64+18] = (start += ((w2 >> 34) & 0x1ff)); out[0*64+19] = (start += ((w2 >> 43) & 0x1ff)); out[0*64+20] = (start += ((w2 >> 52) & 0x1ff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (start += ((w2 >> 61) | (w3 << 3) & 0x1ff)); out[0*64+22] = (start += ((w3 >> 6) & 0x1ff)); out[0*64+23] = (start += ((w3 >> 15) & 0x1ff)); out[0*64+24] = (start += ((w3 >> 24) & 0x1ff)); out[0*64+25] = (start += ((w3 >> 33) & 0x1ff)); out[0*64+26] = (start += ((w3 >> 42) & 0x1ff)); out[0*64+27] = (start += ((w3 >> 51) & 0x1ff)); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (start += ((w3 >> 60) | (w4 << 4) & 0x1ff)); out[0*64+29] = (start += ((w4 >> 5) & 0x1ff)); out[0*64+30] = (start += ((w4 >> 14) & 0x1ff)); out[0*64+31] = (start += ((w4 >> 23) & 0x1ff));;}; out += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_10(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ff)); out[0*32+ 1] = (start += ((w0 >> 10) & 0x3ff)); out[0*32+ 2] = (start += ((w0 >> 20) & 0x3ff)); out[0*32+ 3] = (start += ((w0 >> 30) & 0x3ff)); out[0*32+ 4] = (start += ((w0 >> 40) & 0x3ff)); out[0*32+ 5] = (start += ((w0 >> 50) & 0x3ff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w0 >> 60) | (w1 << 4) & 0x3ff)); out[0*32+ 7] = (start += ((w1 >> 6) & 0x3ff)); out[0*32+ 8] = (start += ((w1 >> 16) & 0x3ff)); out[0*32+ 9] = (start += ((w1 >> 26) & 0x3ff)); out[0*32+10] = (start += ((w1 >> 36) & 0x3ff)); out[0*32+11] = (start += ((w1 >> 46) & 0x3ff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (start += ((w1 >> 56) | (w2 << 8) & 0x3ff)); out[0*32+13] = (start += ((w2 >> 2) & 0x3ff)); out[0*32+14] = (start += ((w2 >> 12) & 0x3ff)); out[0*32+15] = (start += ((w2 >> 22) & 0x3ff)); out[0*32+16] = (start += ((w2 >> 32) & 0x3ff)); out[0*32+17] = (start += ((w2 >> 42) & 0x3ff)); out[0*32+18] = (start += ((w2 >> 52) & 0x3ff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (start += ((w2 >> 62) | (w3 << 2) & 0x3ff)); out[0*32+20] = (start += ((w3 >> 8) & 0x3ff)); out[0*32+21] = (start += ((w3 >> 18) & 0x3ff)); out[0*32+22] = (start += ((w3 >> 28) & 0x3ff)); out[0*32+23] = (start += ((w3 >> 38) & 0x3ff)); out[0*32+24] = (start += ((w3 >> 48) & 0x3ff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (start += ((w3 >> 58) | (w4 << 6) & 0x3ff)); out[0*32+26] = (start += ((w4 >> 4) & 0x3ff)); out[0*32+27] = (start += ((w4 >> 14) & 0x3ff)); out[0*32+28] = (start += ((w4 >> 24) & 0x3ff)); out[0*32+29] = (start += ((w4 >> 34) & 0x3ff)); out[0*32+30] = (start += ((w4 >> 44) & 0x3ff)); out[0*32+31] = (start += ((w4 >> 54)));;}; out += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_11(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ff)); out[0*64+ 1] = (start += ((w0 >> 11) & 0x7ff)); out[0*64+ 2] = (start += ((w0 >> 22) & 0x7ff)); out[0*64+ 3] = (start += ((w0 >> 33) & 0x7ff)); out[0*64+ 4] = (start += ((w0 >> 44) & 0x7ff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w0 >> 55) | (w1 << 9) & 0x7ff)); out[0*64+ 6] = (start += ((w1 >> 2) & 0x7ff)); out[0*64+ 7] = (start += ((w1 >> 13) & 0x7ff)); out[0*64+ 8] = (start += ((w1 >> 24) & 0x7ff)); out[0*64+ 9] = (start += ((w1 >> 35) & 0x7ff)); out[0*64+10] = (start += ((w1 >> 46) & 0x7ff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (start += ((w1 >> 57) | (w2 << 7) & 0x7ff)); out[0*64+12] = (start += ((w2 >> 4) & 0x7ff)); out[0*64+13] = (start += ((w2 >> 15) & 0x7ff)); out[0*64+14] = (start += ((w2 >> 26) & 0x7ff)); out[0*64+15] = (start += ((w2 >> 37) & 0x7ff)); out[0*64+16] = (start += ((w2 >> 48) & 0x7ff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (start += ((w2 >> 59) | (w3 << 5) & 0x7ff)); out[0*64+18] = (start += ((w3 >> 6) & 0x7ff)); out[0*64+19] = (start += ((w3 >> 17) & 0x7ff)); out[0*64+20] = (start += ((w3 >> 28) & 0x7ff)); out[0*64+21] = (start += ((w3 >> 39) & 0x7ff)); out[0*64+22] = (start += ((w3 >> 50) & 0x7ff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (start += ((w3 >> 61) | (w4 << 3) & 0x7ff)); out[0*64+24] = (start += ((w4 >> 8) & 0x7ff)); out[0*64+25] = (start += ((w4 >> 19) & 0x7ff)); out[0*64+26] = (start += ((w4 >> 30) & 0x7ff)); out[0*64+27] = (start += ((w4 >> 41) & 0x7ff)); out[0*64+28] = (start += ((w4 >> 52) & 0x7ff)); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (start += ((w4 >> 63) | (w5 << 1) & 0x7ff)); out[0*64+30] = (start += ((w5 >> 10) & 0x7ff)); out[0*64+31] = (start += ((w5 >> 21) & 0x7ff));;}; out += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_12(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfff)); out[0*16+ 1] = (start += ((w0 >> 12) & 0xfff)); out[0*16+ 2] = (start += ((w0 >> 24) & 0xfff)); out[0*16+ 3] = (start += ((w0 >> 36) & 0xfff)); out[0*16+ 4] = (start += ((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (start += ((w0 >> 60) | (w1 << 4) & 0xfff)); out[0*16+ 6] = (start += ((w1 >> 8) & 0xfff)); out[0*16+ 7] = (start += ((w1 >> 20) & 0xfff)); out[0*16+ 8] = (start += ((w1 >> 32) & 0xfff)); out[0*16+ 9] = (start += ((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (start += ((w1 >> 56) | (w2 << 8) & 0xfff)); out[0*16+11] = (start += ((w2 >> 4) & 0xfff)); out[0*16+12] = (start += ((w2 >> 16) & 0xfff)); out[0*16+13] = (start += ((w2 >> 28) & 0xfff)); out[0*16+14] = (start += ((w2 >> 40) & 0xfff)); out[0*16+15] = (start += ((w2 >> 52)));;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfff)); out[1*16+ 1] = (start += ((w0 >> 12) & 0xfff)); out[1*16+ 2] = (start += ((w0 >> 24) & 0xfff)); out[1*16+ 3] = (start += ((w0 >> 36) & 0xfff)); out[1*16+ 4] = (start += ((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (start += ((w0 >> 60) | (w1 << 4) & 0xfff)); out[1*16+ 6] = (start += ((w1 >> 8) & 0xfff)); out[1*16+ 7] = (start += ((w1 >> 20) & 0xfff)); out[1*16+ 8] = (start += ((w1 >> 32) & 0xfff)); out[1*16+ 9] = (start += ((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (start += ((w1 >> 56) | (w2 << 8) & 0xfff)); out[1*16+11] = (start += ((w2 >> 4) & 0xfff)); out[1*16+12] = (start += ((w2 >> 16) & 0xfff)); out[1*16+13] = (start += ((w2 >> 28) & 0xfff)); out[1*16+14] = (start += ((w2 >> 40) & 0xfff)); out[1*16+15] = (start += ((w2 >> 52)));;}; out += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_13(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fff)); out[0*64+ 1] = (start += ((w0 >> 13) & 0x1fff)); out[0*64+ 2] = (start += ((w0 >> 26) & 0x1fff)); out[0*64+ 3] = (start += ((w0 >> 39) & 0x1fff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w0 >> 52) | (w1 << 12) & 0x1fff)); out[0*64+ 5] = (start += ((w1 >> 1) & 0x1fff)); out[0*64+ 6] = (start += ((w1 >> 14) & 0x1fff)); out[0*64+ 7] = (start += ((w1 >> 27) & 0x1fff)); out[0*64+ 8] = (start += ((w1 >> 40) & 0x1fff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w1 >> 53) | (w2 << 11) & 0x1fff)); out[0*64+10] = (start += ((w2 >> 2) & 0x1fff)); out[0*64+11] = (start += ((w2 >> 15) & 0x1fff)); out[0*64+12] = (start += ((w2 >> 28) & 0x1fff)); out[0*64+13] = (start += ((w2 >> 41) & 0x1fff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (start += ((w2 >> 54) | (w3 << 10) & 0x1fff)); out[0*64+15] = (start += ((w3 >> 3) & 0x1fff)); out[0*64+16] = (start += ((w3 >> 16) & 0x1fff)); out[0*64+17] = (start += ((w3 >> 29) & 0x1fff)); out[0*64+18] = (start += ((w3 >> 42) & 0x1fff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (start += ((w3 >> 55) | (w4 << 9) & 0x1fff)); out[0*64+20] = (start += ((w4 >> 4) & 0x1fff)); out[0*64+21] = (start += ((w4 >> 17) & 0x1fff)); out[0*64+22] = (start += ((w4 >> 30) & 0x1fff)); out[0*64+23] = (start += ((w4 >> 43) & 0x1fff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (start += ((w4 >> 56) | (w5 << 8) & 0x1fff)); out[0*64+25] = (start += ((w5 >> 5) & 0x1fff)); out[0*64+26] = (start += ((w5 >> 18) & 0x1fff)); out[0*64+27] = (start += ((w5 >> 31) & 0x1fff)); out[0*64+28] = (start += ((w5 >> 44) & 0x1fff)); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (start += ((w5 >> 57) | (w6 << 7) & 0x1fff)); out[0*64+30] = (start += ((w6 >> 6) & 0x1fff)); out[0*64+31] = (start += ((w6 >> 19) & 0x1fff));;}; out += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_14(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fff)); out[0*32+ 1] = (start += ((w0 >> 14) & 0x3fff)); out[0*32+ 2] = (start += ((w0 >> 28) & 0x3fff)); out[0*32+ 3] = (start += ((w0 >> 42) & 0x3fff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w0 >> 56) | (w1 << 8) & 0x3fff)); out[0*32+ 5] = (start += ((w1 >> 6) & 0x3fff)); out[0*32+ 6] = (start += ((w1 >> 20) & 0x3fff)); out[0*32+ 7] = (start += ((w1 >> 34) & 0x3fff)); out[0*32+ 8] = (start += ((w1 >> 48) & 0x3fff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w1 >> 62) | (w2 << 2) & 0x3fff)); out[0*32+10] = (start += ((w2 >> 12) & 0x3fff)); out[0*32+11] = (start += ((w2 >> 26) & 0x3fff)); out[0*32+12] = (start += ((w2 >> 40) & 0x3fff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (start += ((w2 >> 54) | (w3 << 10) & 0x3fff)); out[0*32+14] = (start += ((w3 >> 4) & 0x3fff)); out[0*32+15] = (start += ((w3 >> 18) & 0x3fff)); out[0*32+16] = (start += ((w3 >> 32) & 0x3fff)); out[0*32+17] = (start += ((w3 >> 46) & 0x3fff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (start += ((w3 >> 60) | (w4 << 4) & 0x3fff)); out[0*32+19] = (start += ((w4 >> 10) & 0x3fff)); out[0*32+20] = (start += ((w4 >> 24) & 0x3fff)); out[0*32+21] = (start += ((w4 >> 38) & 0x3fff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (start += ((w4 >> 52) | (w5 << 12) & 0x3fff)); out[0*32+23] = (start += ((w5 >> 2) & 0x3fff)); out[0*32+24] = (start += ((w5 >> 16) & 0x3fff)); out[0*32+25] = (start += ((w5 >> 30) & 0x3fff)); out[0*32+26] = (start += ((w5 >> 44) & 0x3fff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (start += ((w5 >> 58) | (w6 << 6) & 0x3fff)); out[0*32+28] = (start += ((w6 >> 8) & 0x3fff)); out[0*32+29] = (start += ((w6 >> 22) & 0x3fff)); out[0*32+30] = (start += ((w6 >> 36) & 0x3fff)); out[0*32+31] = (start += ((w6 >> 50)));;}; out += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_15(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fff)); out[0*64+ 1] = (start += ((w0 >> 15) & 0x7fff)); out[0*64+ 2] = (start += ((w0 >> 30) & 0x7fff)); out[0*64+ 3] = (start += ((w0 >> 45) & 0x7fff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w0 >> 60) | (w1 << 4) & 0x7fff)); out[0*64+ 5] = (start += ((w1 >> 11) & 0x7fff)); out[0*64+ 6] = (start += ((w1 >> 26) & 0x7fff)); out[0*64+ 7] = (start += ((w1 >> 41) & 0x7fff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w1 >> 56) | (w2 << 8) & 0x7fff)); out[0*64+ 9] = (start += ((w2 >> 7) & 0x7fff)); out[0*64+10] = (start += ((w2 >> 22) & 0x7fff)); out[0*64+11] = (start += ((w2 >> 37) & 0x7fff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (start += ((w2 >> 52) | (w3 << 12) & 0x7fff)); out[0*64+13] = (start += ((w3 >> 3) & 0x7fff)); out[0*64+14] = (start += ((w3 >> 18) & 0x7fff)); out[0*64+15] = (start += ((w3 >> 33) & 0x7fff)); out[0*64+16] = (start += ((w3 >> 48) & 0x7fff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (start += ((w3 >> 63) | (w4 << 1) & 0x7fff)); out[0*64+18] = (start += ((w4 >> 14) & 0x7fff)); out[0*64+19] = (start += ((w4 >> 29) & 0x7fff)); out[0*64+20] = (start += ((w4 >> 44) & 0x7fff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (start += ((w4 >> 59) | (w5 << 5) & 0x7fff)); out[0*64+22] = (start += ((w5 >> 10) & 0x7fff)); out[0*64+23] = (start += ((w5 >> 25) & 0x7fff)); out[0*64+24] = (start += ((w5 >> 40) & 0x7fff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (start += ((w5 >> 55) | (w6 << 9) & 0x7fff)); out[0*64+26] = (start += ((w6 >> 6) & 0x7fff)); out[0*64+27] = (start += ((w6 >> 21) & 0x7fff)); out[0*64+28] = (start += ((w6 >> 36) & 0x7fff)); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (start += ((w6 >> 51) | (w7 << 13) & 0x7fff)); out[0*64+30] = (start += ((w7 >> 2) & 0x7fff)); out[0*64+31] = (start += ((w7 >> 17) & 0x7fff));;}; out += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack16_16(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = (start += (*(uint16_t *)(in+0*8+ 0))); out[0*4+ 1] = (start += (*(uint16_t *)(in+0*8+ 2))); out[0*4+ 2] = (start += (*(uint16_t *)(in+0*8+ 4))); out[0*4+ 3] = (start += (*(uint16_t *)(in+0*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = (start += (*(uint16_t *)(in+1*8+ 0))); out[1*4+ 1] = (start += (*(uint16_t *)(in+1*8+ 2))); out[1*4+ 2] = (start += (*(uint16_t *)(in+1*8+ 4))); out[1*4+ 3] = (start += (*(uint16_t *)(in+1*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = (start += (*(uint16_t *)(in+2*8+ 0))); out[2*4+ 1] = (start += (*(uint16_t *)(in+2*8+ 2))); out[2*4+ 2] = (start += (*(uint16_t *)(in+2*8+ 4))); out[2*4+ 3] = (start += (*(uint16_t *)(in+2*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = (start += (*(uint16_t *)(in+3*8+ 0))); out[3*4+ 1] = (start += (*(uint16_t *)(in+3*8+ 2))); out[3*4+ 2] = (start += (*(uint16_t *)(in+3*8+ 4))); out[3*4+ 3] = (start += (*(uint16_t *)(in+3*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = (start += (*(uint16_t *)(in+4*8+ 0))); out[4*4+ 1] = (start += (*(uint16_t *)(in+4*8+ 2))); out[4*4+ 2] = (start += (*(uint16_t *)(in+4*8+ 4))); out[4*4+ 3] = (start += (*(uint16_t *)(in+4*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = (start += (*(uint16_t *)(in+5*8+ 0))); out[5*4+ 1] = (start += (*(uint16_t *)(in+5*8+ 2))); out[5*4+ 2] = (start += (*(uint16_t *)(in+5*8+ 4))); out[5*4+ 3] = (start += (*(uint16_t *)(in+5*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = (start += (*(uint16_t *)(in+6*8+ 0))); out[6*4+ 1] = (start += (*(uint16_t *)(in+6*8+ 2))); out[6*4+ 2] = (start += (*(uint16_t *)(in+6*8+ 4))); out[6*4+ 3] = (start += (*(uint16_t *)(in+6*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = (start += (*(uint16_t *)(in+7*8+ 0))); out[7*4+ 1] = (start += (*(uint16_t *)(in+7*8+ 2))); out[7*4+ 2] = (start += (*(uint16_t *)(in+7*8+ 4))); out[7*4+ 3] = (start += (*(uint16_t *)(in+7*8+ 6)));;}; out += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D16 bitdunpacka16[] = {
  &bitdunpack16_0,
  &bitdunpack16_1,
  &bitdunpack16_2,
  &bitdunpack16_3,
  &bitdunpack16_4,
  &bitdunpack16_5,
  &bitdunpack16_6,
  &bitdunpack16_7,
  &bitdunpack16_8,
  &bitdunpack16_9,
  &bitdunpack16_10,
  &bitdunpack16_11,
  &bitdunpack16_12,
  &bitdunpack16_13,
  &bitdunpack16_14,
  &bitdunpack16_15,
  &bitdunpack16_16
};
unsigned char *bitdunpack16( const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start, unsigned b) { return bitdunpacka16[ b](in, n, out, start); }
unsigned char *bitdunpack32_0(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint32_t *out_ = out+n; do { { { out[0*0+ 0] = (start += (0)); out[0*0+ 1] = (start += (0)); out[0*0+ 2] = (start += (0)); out[0*0+ 3] = (start += (0)); out[0*0+ 4] = (start += (0)); out[0*0+ 5] = (start += (0)); out[0*0+ 6] = (start += (0)); out[0*0+ 7] = (start += (0)); out[0*0+ 8] = (start += (0)); out[0*0+ 9] = (start += (0)); out[0*0+10] = (start += (0)); out[0*0+11] = (start += (0)); out[0*0+12] = (start += (0)); out[0*0+13] = (start += (0)); out[0*0+14] = (start += (0)); out[0*0+15] = (start += (0)); out[0*0+16] = (start += (0)); out[0*0+17] = (start += (0)); out[0*0+18] = (start += (0)); out[0*0+19] = (start += (0)); out[0*0+20] = (start += (0)); out[0*0+21] = (start += (0)); out[0*0+22] = (start += (0)); out[0*0+23] = (start += (0)); out[0*0+24] = (start += (0)); out[0*0+25] = (start += (0)); out[0*0+26] = (start += (0)); out[0*0+27] = (start += (0)); out[0*0+28] = (start += (0)); out[0*0+29] = (start += (0)); out[0*0+30] = (start += (0)); out[0*0+31] = (start += (0));;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitdunpack32_1(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x1)); out[0*32+ 1] = (start += ((w0 >> 1) & 0x1)); out[0*32+ 2] = (start += ((w0 >> 2) & 0x1)); out[0*32+ 3] = (start += ((w0 >> 3) & 0x1)); out[0*32+ 4] = (start += ((w0 >> 4) & 0x1)); out[0*32+ 5] = (start += ((w0 >> 5) & 0x1)); out[0*32+ 6] = (start += ((w0 >> 6) & 0x1)); out[0*32+ 7] = (start += ((w0 >> 7) & 0x1)); out[0*32+ 8] = (start += ((w0 >> 8) & 0x1)); out[0*32+ 9] = (start += ((w0 >> 9) & 0x1)); out[0*32+10] = (start += ((w0 >> 10) & 0x1)); out[0*32+11] = (start += ((w0 >> 11) & 0x1)); out[0*32+12] = (start += ((w0 >> 12) & 0x1)); out[0*32+13] = (start += ((w0 >> 13) & 0x1)); out[0*32+14] = (start += ((w0 >> 14) & 0x1)); out[0*32+15] = (start += ((w0 >> 15) & 0x1)); out[0*32+16] = (start += ((w0 >> 16) & 0x1)); out[0*32+17] = (start += ((w0 >> 17) & 0x1)); out[0*32+18] = (start += ((w0 >> 18) & 0x1)); out[0*32+19] = (start += ((w0 >> 19) & 0x1)); out[0*32+20] = (start += ((w0 >> 20) & 0x1)); out[0*32+21] = (start += ((w0 >> 21) & 0x1)); out[0*32+22] = (start += ((w0 >> 22) & 0x1)); out[0*32+23] = (start += ((w0 >> 23) & 0x1)); out[0*32+24] = (start += ((w0 >> 24) & 0x1)); out[0*32+25] = (start += ((w0 >> 25) & 0x1)); out[0*32+26] = (start += ((w0 >> 26) & 0x1)); out[0*32+27] = (start += ((w0 >> 27) & 0x1)); out[0*32+28] = (start += ((w0 >> 28) & 0x1)); out[0*32+29] = (start += ((w0 >> 29) & 0x1)); out[0*32+30] = (start += ((w0 >> 30) & 0x1)); out[0*32+31] = (start += ((w0 >> 31)));;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_2(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3)); out[0*32+ 1] = (start += ((w0 >> 2) & 0x3)); out[0*32+ 2] = (start += ((w0 >> 4) & 0x3)); out[0*32+ 3] = (start += ((w0 >> 6) & 0x3)); out[0*32+ 4] = (start += ((w0 >> 8) & 0x3)); out[0*32+ 5] = (start += ((w0 >> 10) & 0x3)); out[0*32+ 6] = (start += ((w0 >> 12) & 0x3)); out[0*32+ 7] = (start += ((w0 >> 14) & 0x3)); out[0*32+ 8] = (start += ((w0 >> 16) & 0x3)); out[0*32+ 9] = (start += ((w0 >> 18) & 0x3)); out[0*32+10] = (start += ((w0 >> 20) & 0x3)); out[0*32+11] = (start += ((w0 >> 22) & 0x3)); out[0*32+12] = (start += ((w0 >> 24) & 0x3)); out[0*32+13] = (start += ((w0 >> 26) & 0x3)); out[0*32+14] = (start += ((w0 >> 28) & 0x3)); out[0*32+15] = (start += ((w0 >> 30) & 0x3)); out[0*32+16] = (start += ((w0 >> 32) & 0x3)); out[0*32+17] = (start += ((w0 >> 34) & 0x3)); out[0*32+18] = (start += ((w0 >> 36) & 0x3)); out[0*32+19] = (start += ((w0 >> 38) & 0x3)); out[0*32+20] = (start += ((w0 >> 40) & 0x3)); out[0*32+21] = (start += ((w0 >> 42) & 0x3)); out[0*32+22] = (start += ((w0 >> 44) & 0x3)); out[0*32+23] = (start += ((w0 >> 46) & 0x3)); out[0*32+24] = (start += ((w0 >> 48) & 0x3)); out[0*32+25] = (start += ((w0 >> 50) & 0x3)); out[0*32+26] = (start += ((w0 >> 52) & 0x3)); out[0*32+27] = (start += ((w0 >> 54) & 0x3)); out[0*32+28] = (start += ((w0 >> 56) & 0x3)); out[0*32+29] = (start += ((w0 >> 58) & 0x3)); out[0*32+30] = (start += ((w0 >> 60) & 0x3)); out[0*32+31] = (start += ((w0 >> 62)));;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_3(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7)); out[0*64+ 1] = (start += ((w0 >> 3) & 0x7)); out[0*64+ 2] = (start += ((w0 >> 6) & 0x7)); out[0*64+ 3] = (start += ((w0 >> 9) & 0x7)); out[0*64+ 4] = (start += ((w0 >> 12) & 0x7)); out[0*64+ 5] = (start += ((w0 >> 15) & 0x7)); out[0*64+ 6] = (start += ((w0 >> 18) & 0x7)); out[0*64+ 7] = (start += ((w0 >> 21) & 0x7)); out[0*64+ 8] = (start += ((w0 >> 24) & 0x7)); out[0*64+ 9] = (start += ((w0 >> 27) & 0x7)); out[0*64+10] = (start += ((w0 >> 30) & 0x7)); out[0*64+11] = (start += ((w0 >> 33) & 0x7)); out[0*64+12] = (start += ((w0 >> 36) & 0x7)); out[0*64+13] = (start += ((w0 >> 39) & 0x7)); out[0*64+14] = (start += ((w0 >> 42) & 0x7)); out[0*64+15] = (start += ((w0 >> 45) & 0x7)); out[0*64+16] = (start += ((w0 >> 48) & 0x7)); out[0*64+17] = (start += ((w0 >> 51) & 0x7)); out[0*64+18] = (start += ((w0 >> 54) & 0x7)); out[0*64+19] = (start += ((w0 >> 57) & 0x7)); out[0*64+20] = (start += ((w0 >> 60) & 0x7)); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start += ((w0 >> 63) | (w1 << 1) & 0x7)); out[0*64+22] = (start += ((w1 >> 2) & 0x7)); out[0*64+23] = (start += ((w1 >> 5) & 0x7)); out[0*64+24] = (start += ((w1 >> 8) & 0x7)); out[0*64+25] = (start += ((w1 >> 11) & 0x7)); out[0*64+26] = (start += ((w1 >> 14) & 0x7)); out[0*64+27] = (start += ((w1 >> 17) & 0x7)); out[0*64+28] = (start += ((w1 >> 20) & 0x7)); out[0*64+29] = (start += ((w1 >> 23) & 0x7)); out[0*64+30] = (start += ((w1 >> 26) & 0x7)); out[0*64+31] = (start += ((w1 >> 29) & 0x7));;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_4(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xf)); out[0*16+ 1] = (start += ((w0 >> 4) & 0xf)); out[0*16+ 2] = (start += ((w0 >> 8) & 0xf)); out[0*16+ 3] = (start += ((w0 >> 12) & 0xf)); out[0*16+ 4] = (start += ((w0 >> 16) & 0xf)); out[0*16+ 5] = (start += ((w0 >> 20) & 0xf)); out[0*16+ 6] = (start += ((w0 >> 24) & 0xf)); out[0*16+ 7] = (start += ((w0 >> 28) & 0xf)); out[0*16+ 8] = (start += ((w0 >> 32) & 0xf)); out[0*16+ 9] = (start += ((w0 >> 36) & 0xf)); out[0*16+10] = (start += ((w0 >> 40) & 0xf)); out[0*16+11] = (start += ((w0 >> 44) & 0xf)); out[0*16+12] = (start += ((w0 >> 48) & 0xf)); out[0*16+13] = (start += ((w0 >> 52) & 0xf)); out[0*16+14] = (start += ((w0 >> 56) & 0xf)); out[0*16+15] = (start += ((w0 >> 60)));;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xf)); out[1*16+ 1] = (start += ((w0 >> 4) & 0xf)); out[1*16+ 2] = (start += ((w0 >> 8) & 0xf)); out[1*16+ 3] = (start += ((w0 >> 12) & 0xf)); out[1*16+ 4] = (start += ((w0 >> 16) & 0xf)); out[1*16+ 5] = (start += ((w0 >> 20) & 0xf)); out[1*16+ 6] = (start += ((w0 >> 24) & 0xf)); out[1*16+ 7] = (start += ((w0 >> 28) & 0xf)); out[1*16+ 8] = (start += ((w0 >> 32) & 0xf)); out[1*16+ 9] = (start += ((w0 >> 36) & 0xf)); out[1*16+10] = (start += ((w0 >> 40) & 0xf)); out[1*16+11] = (start += ((w0 >> 44) & 0xf)); out[1*16+12] = (start += ((w0 >> 48) & 0xf)); out[1*16+13] = (start += ((w0 >> 52) & 0xf)); out[1*16+14] = (start += ((w0 >> 56) & 0xf)); out[1*16+15] = (start += ((w0 >> 60)));;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_5(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1f)); out[0*64+ 1] = (start += ((w0 >> 5) & 0x1f)); out[0*64+ 2] = (start += ((w0 >> 10) & 0x1f)); out[0*64+ 3] = (start += ((w0 >> 15) & 0x1f)); out[0*64+ 4] = (start += ((w0 >> 20) & 0x1f)); out[0*64+ 5] = (start += ((w0 >> 25) & 0x1f)); out[0*64+ 6] = (start += ((w0 >> 30) & 0x1f)); out[0*64+ 7] = (start += ((w0 >> 35) & 0x1f)); out[0*64+ 8] = (start += ((w0 >> 40) & 0x1f)); out[0*64+ 9] = (start += ((w0 >> 45) & 0x1f)); out[0*64+10] = (start += ((w0 >> 50) & 0x1f)); out[0*64+11] = (start += ((w0 >> 55) & 0x1f)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start += ((w0 >> 60) | (w1 << 4) & 0x1f)); out[0*64+13] = (start += ((w1 >> 1) & 0x1f)); out[0*64+14] = (start += ((w1 >> 6) & 0x1f)); out[0*64+15] = (start += ((w1 >> 11) & 0x1f)); out[0*64+16] = (start += ((w1 >> 16) & 0x1f)); out[0*64+17] = (start += ((w1 >> 21) & 0x1f)); out[0*64+18] = (start += ((w1 >> 26) & 0x1f)); out[0*64+19] = (start += ((w1 >> 31) & 0x1f)); out[0*64+20] = (start += ((w1 >> 36) & 0x1f)); out[0*64+21] = (start += ((w1 >> 41) & 0x1f)); out[0*64+22] = (start += ((w1 >> 46) & 0x1f)); out[0*64+23] = (start += ((w1 >> 51) & 0x1f)); out[0*64+24] = (start += ((w1 >> 56) & 0x1f)); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start += ((w1 >> 61) | (w2 << 3) & 0x1f)); out[0*64+26] = (start += ((w2 >> 2) & 0x1f)); out[0*64+27] = (start += ((w2 >> 7) & 0x1f)); out[0*64+28] = (start += ((w2 >> 12) & 0x1f)); out[0*64+29] = (start += ((w2 >> 17) & 0x1f)); out[0*64+30] = (start += ((w2 >> 22) & 0x1f)); out[0*64+31] = (start += ((w2 >> 27) & 0x1f));;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_6(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3f)); out[0*32+ 1] = (start += ((w0 >> 6) & 0x3f)); out[0*32+ 2] = (start += ((w0 >> 12) & 0x3f)); out[0*32+ 3] = (start += ((w0 >> 18) & 0x3f)); out[0*32+ 4] = (start += ((w0 >> 24) & 0x3f)); out[0*32+ 5] = (start += ((w0 >> 30) & 0x3f)); out[0*32+ 6] = (start += ((w0 >> 36) & 0x3f)); out[0*32+ 7] = (start += ((w0 >> 42) & 0x3f)); out[0*32+ 8] = (start += ((w0 >> 48) & 0x3f)); out[0*32+ 9] = (start += ((w0 >> 54) & 0x3f)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start += ((w0 >> 60) | (w1 << 4) & 0x3f)); out[0*32+11] = (start += ((w1 >> 2) & 0x3f)); out[0*32+12] = (start += ((w1 >> 8) & 0x3f)); out[0*32+13] = (start += ((w1 >> 14) & 0x3f)); out[0*32+14] = (start += ((w1 >> 20) & 0x3f)); out[0*32+15] = (start += ((w1 >> 26) & 0x3f)); out[0*32+16] = (start += ((w1 >> 32) & 0x3f)); out[0*32+17] = (start += ((w1 >> 38) & 0x3f)); out[0*32+18] = (start += ((w1 >> 44) & 0x3f)); out[0*32+19] = (start += ((w1 >> 50) & 0x3f)); out[0*32+20] = (start += ((w1 >> 56) & 0x3f)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start += ((w1 >> 62) | (w2 << 2) & 0x3f)); out[0*32+22] = (start += ((w2 >> 4) & 0x3f)); out[0*32+23] = (start += ((w2 >> 10) & 0x3f)); out[0*32+24] = (start += ((w2 >> 16) & 0x3f)); out[0*32+25] = (start += ((w2 >> 22) & 0x3f)); out[0*32+26] = (start += ((w2 >> 28) & 0x3f)); out[0*32+27] = (start += ((w2 >> 34) & 0x3f)); out[0*32+28] = (start += ((w2 >> 40) & 0x3f)); out[0*32+29] = (start += ((w2 >> 46) & 0x3f)); out[0*32+30] = (start += ((w2 >> 52) & 0x3f)); out[0*32+31] = (start += ((w2 >> 58)));;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_7(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7f)); out[0*64+ 1] = (start += ((w0 >> 7) & 0x7f)); out[0*64+ 2] = (start += ((w0 >> 14) & 0x7f)); out[0*64+ 3] = (start += ((w0 >> 21) & 0x7f)); out[0*64+ 4] = (start += ((w0 >> 28) & 0x7f)); out[0*64+ 5] = (start += ((w0 >> 35) & 0x7f)); out[0*64+ 6] = (start += ((w0 >> 42) & 0x7f)); out[0*64+ 7] = (start += ((w0 >> 49) & 0x7f)); out[0*64+ 8] = (start += ((w0 >> 56) & 0x7f)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w0 >> 63) | (w1 << 1) & 0x7f)); out[0*64+10] = (start += ((w1 >> 6) & 0x7f)); out[0*64+11] = (start += ((w1 >> 13) & 0x7f)); out[0*64+12] = (start += ((w1 >> 20) & 0x7f)); out[0*64+13] = (start += ((w1 >> 27) & 0x7f)); out[0*64+14] = (start += ((w1 >> 34) & 0x7f)); out[0*64+15] = (start += ((w1 >> 41) & 0x7f)); out[0*64+16] = (start += ((w1 >> 48) & 0x7f)); out[0*64+17] = (start += ((w1 >> 55) & 0x7f)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start += ((w1 >> 62) | (w2 << 2) & 0x7f)); out[0*64+19] = (start += ((w2 >> 5) & 0x7f)); out[0*64+20] = (start += ((w2 >> 12) & 0x7f)); out[0*64+21] = (start += ((w2 >> 19) & 0x7f)); out[0*64+22] = (start += ((w2 >> 26) & 0x7f)); out[0*64+23] = (start += ((w2 >> 33) & 0x7f)); out[0*64+24] = (start += ((w2 >> 40) & 0x7f)); out[0*64+25] = (start += ((w2 >> 47) & 0x7f)); out[0*64+26] = (start += ((w2 >> 54) & 0x7f)); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start += ((w2 >> 61) | (w3 << 3) & 0x7f)); out[0*64+28] = (start += ((w3 >> 4) & 0x7f)); out[0*64+29] = (start += ((w3 >> 11) & 0x7f)); out[0*64+30] = (start += ((w3 >> 18) & 0x7f)); out[0*64+31] = (start += ((w3 >> 25) & 0x7f));;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_8(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xff)); out[0*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[0*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[0*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[0*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[0*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[0*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[0*8+ 7] = (start += ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xff)); out[1*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[1*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[1*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[1*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[1*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[1*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[1*8+ 7] = (start += ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xff)); out[2*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[2*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[2*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[2*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[2*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[2*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[2*8+ 7] = (start += ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xff)); out[3*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[3*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[3*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[3*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[3*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[3*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[3*8+ 7] = (start += ((w0 >> 56)));;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_9(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ff)); out[0*64+ 1] = (start += ((w0 >> 9) & 0x1ff)); out[0*64+ 2] = (start += ((w0 >> 18) & 0x1ff)); out[0*64+ 3] = (start += ((w0 >> 27) & 0x1ff)); out[0*64+ 4] = (start += ((w0 >> 36) & 0x1ff)); out[0*64+ 5] = (start += ((w0 >> 45) & 0x1ff)); out[0*64+ 6] = (start += ((w0 >> 54) & 0x1ff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w0 >> 63) | (w1 << 1) & 0x1ff)); out[0*64+ 8] = (start += ((w1 >> 8) & 0x1ff)); out[0*64+ 9] = (start += ((w1 >> 17) & 0x1ff)); out[0*64+10] = (start += ((w1 >> 26) & 0x1ff)); out[0*64+11] = (start += ((w1 >> 35) & 0x1ff)); out[0*64+12] = (start += ((w1 >> 44) & 0x1ff)); out[0*64+13] = (start += ((w1 >> 53) & 0x1ff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (start += ((w1 >> 62) | (w2 << 2) & 0x1ff)); out[0*64+15] = (start += ((w2 >> 7) & 0x1ff)); out[0*64+16] = (start += ((w2 >> 16) & 0x1ff)); out[0*64+17] = (start += ((w2 >> 25) & 0x1ff)); out[0*64+18] = (start += ((w2 >> 34) & 0x1ff)); out[0*64+19] = (start += ((w2 >> 43) & 0x1ff)); out[0*64+20] = (start += ((w2 >> 52) & 0x1ff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (start += ((w2 >> 61) | (w3 << 3) & 0x1ff)); out[0*64+22] = (start += ((w3 >> 6) & 0x1ff)); out[0*64+23] = (start += ((w3 >> 15) & 0x1ff)); out[0*64+24] = (start += ((w3 >> 24) & 0x1ff)); out[0*64+25] = (start += ((w3 >> 33) & 0x1ff)); out[0*64+26] = (start += ((w3 >> 42) & 0x1ff)); out[0*64+27] = (start += ((w3 >> 51) & 0x1ff)); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (start += ((w3 >> 60) | (w4 << 4) & 0x1ff)); out[0*64+29] = (start += ((w4 >> 5) & 0x1ff)); out[0*64+30] = (start += ((w4 >> 14) & 0x1ff)); out[0*64+31] = (start += ((w4 >> 23) & 0x1ff));;}; out += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_10(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ff)); out[0*32+ 1] = (start += ((w0 >> 10) & 0x3ff)); out[0*32+ 2] = (start += ((w0 >> 20) & 0x3ff)); out[0*32+ 3] = (start += ((w0 >> 30) & 0x3ff)); out[0*32+ 4] = (start += ((w0 >> 40) & 0x3ff)); out[0*32+ 5] = (start += ((w0 >> 50) & 0x3ff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w0 >> 60) | (w1 << 4) & 0x3ff)); out[0*32+ 7] = (start += ((w1 >> 6) & 0x3ff)); out[0*32+ 8] = (start += ((w1 >> 16) & 0x3ff)); out[0*32+ 9] = (start += ((w1 >> 26) & 0x3ff)); out[0*32+10] = (start += ((w1 >> 36) & 0x3ff)); out[0*32+11] = (start += ((w1 >> 46) & 0x3ff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (start += ((w1 >> 56) | (w2 << 8) & 0x3ff)); out[0*32+13] = (start += ((w2 >> 2) & 0x3ff)); out[0*32+14] = (start += ((w2 >> 12) & 0x3ff)); out[0*32+15] = (start += ((w2 >> 22) & 0x3ff)); out[0*32+16] = (start += ((w2 >> 32) & 0x3ff)); out[0*32+17] = (start += ((w2 >> 42) & 0x3ff)); out[0*32+18] = (start += ((w2 >> 52) & 0x3ff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (start += ((w2 >> 62) | (w3 << 2) & 0x3ff)); out[0*32+20] = (start += ((w3 >> 8) & 0x3ff)); out[0*32+21] = (start += ((w3 >> 18) & 0x3ff)); out[0*32+22] = (start += ((w3 >> 28) & 0x3ff)); out[0*32+23] = (start += ((w3 >> 38) & 0x3ff)); out[0*32+24] = (start += ((w3 >> 48) & 0x3ff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (start += ((w3 >> 58) | (w4 << 6) & 0x3ff)); out[0*32+26] = (start += ((w4 >> 4) & 0x3ff)); out[0*32+27] = (start += ((w4 >> 14) & 0x3ff)); out[0*32+28] = (start += ((w4 >> 24) & 0x3ff)); out[0*32+29] = (start += ((w4 >> 34) & 0x3ff)); out[0*32+30] = (start += ((w4 >> 44) & 0x3ff)); out[0*32+31] = (start += ((w4 >> 54)));;}; out += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_11(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ff)); out[0*64+ 1] = (start += ((w0 >> 11) & 0x7ff)); out[0*64+ 2] = (start += ((w0 >> 22) & 0x7ff)); out[0*64+ 3] = (start += ((w0 >> 33) & 0x7ff)); out[0*64+ 4] = (start += ((w0 >> 44) & 0x7ff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w0 >> 55) | (w1 << 9) & 0x7ff)); out[0*64+ 6] = (start += ((w1 >> 2) & 0x7ff)); out[0*64+ 7] = (start += ((w1 >> 13) & 0x7ff)); out[0*64+ 8] = (start += ((w1 >> 24) & 0x7ff)); out[0*64+ 9] = (start += ((w1 >> 35) & 0x7ff)); out[0*64+10] = (start += ((w1 >> 46) & 0x7ff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (start += ((w1 >> 57) | (w2 << 7) & 0x7ff)); out[0*64+12] = (start += ((w2 >> 4) & 0x7ff)); out[0*64+13] = (start += ((w2 >> 15) & 0x7ff)); out[0*64+14] = (start += ((w2 >> 26) & 0x7ff)); out[0*64+15] = (start += ((w2 >> 37) & 0x7ff)); out[0*64+16] = (start += ((w2 >> 48) & 0x7ff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (start += ((w2 >> 59) | (w3 << 5) & 0x7ff)); out[0*64+18] = (start += ((w3 >> 6) & 0x7ff)); out[0*64+19] = (start += ((w3 >> 17) & 0x7ff)); out[0*64+20] = (start += ((w3 >> 28) & 0x7ff)); out[0*64+21] = (start += ((w3 >> 39) & 0x7ff)); out[0*64+22] = (start += ((w3 >> 50) & 0x7ff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (start += ((w3 >> 61) | (w4 << 3) & 0x7ff)); out[0*64+24] = (start += ((w4 >> 8) & 0x7ff)); out[0*64+25] = (start += ((w4 >> 19) & 0x7ff)); out[0*64+26] = (start += ((w4 >> 30) & 0x7ff)); out[0*64+27] = (start += ((w4 >> 41) & 0x7ff)); out[0*64+28] = (start += ((w4 >> 52) & 0x7ff)); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (start += ((w4 >> 63) | (w5 << 1) & 0x7ff)); out[0*64+30] = (start += ((w5 >> 10) & 0x7ff)); out[0*64+31] = (start += ((w5 >> 21) & 0x7ff));;}; out += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_12(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfff)); out[0*16+ 1] = (start += ((w0 >> 12) & 0xfff)); out[0*16+ 2] = (start += ((w0 >> 24) & 0xfff)); out[0*16+ 3] = (start += ((w0 >> 36) & 0xfff)); out[0*16+ 4] = (start += ((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (start += ((w0 >> 60) | (w1 << 4) & 0xfff)); out[0*16+ 6] = (start += ((w1 >> 8) & 0xfff)); out[0*16+ 7] = (start += ((w1 >> 20) & 0xfff)); out[0*16+ 8] = (start += ((w1 >> 32) & 0xfff)); out[0*16+ 9] = (start += ((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (start += ((w1 >> 56) | (w2 << 8) & 0xfff)); out[0*16+11] = (start += ((w2 >> 4) & 0xfff)); out[0*16+12] = (start += ((w2 >> 16) & 0xfff)); out[0*16+13] = (start += ((w2 >> 28) & 0xfff)); out[0*16+14] = (start += ((w2 >> 40) & 0xfff)); out[0*16+15] = (start += ((w2 >> 52)));;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfff)); out[1*16+ 1] = (start += ((w0 >> 12) & 0xfff)); out[1*16+ 2] = (start += ((w0 >> 24) & 0xfff)); out[1*16+ 3] = (start += ((w0 >> 36) & 0xfff)); out[1*16+ 4] = (start += ((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (start += ((w0 >> 60) | (w1 << 4) & 0xfff)); out[1*16+ 6] = (start += ((w1 >> 8) & 0xfff)); out[1*16+ 7] = (start += ((w1 >> 20) & 0xfff)); out[1*16+ 8] = (start += ((w1 >> 32) & 0xfff)); out[1*16+ 9] = (start += ((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (start += ((w1 >> 56) | (w2 << 8) & 0xfff)); out[1*16+11] = (start += ((w2 >> 4) & 0xfff)); out[1*16+12] = (start += ((w2 >> 16) & 0xfff)); out[1*16+13] = (start += ((w2 >> 28) & 0xfff)); out[1*16+14] = (start += ((w2 >> 40) & 0xfff)); out[1*16+15] = (start += ((w2 >> 52)));;}; out += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_13(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fff)); out[0*64+ 1] = (start += ((w0 >> 13) & 0x1fff)); out[0*64+ 2] = (start += ((w0 >> 26) & 0x1fff)); out[0*64+ 3] = (start += ((w0 >> 39) & 0x1fff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w0 >> 52) | (w1 << 12) & 0x1fff)); out[0*64+ 5] = (start += ((w1 >> 1) & 0x1fff)); out[0*64+ 6] = (start += ((w1 >> 14) & 0x1fff)); out[0*64+ 7] = (start += ((w1 >> 27) & 0x1fff)); out[0*64+ 8] = (start += ((w1 >> 40) & 0x1fff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w1 >> 53) | (w2 << 11) & 0x1fff)); out[0*64+10] = (start += ((w2 >> 2) & 0x1fff)); out[0*64+11] = (start += ((w2 >> 15) & 0x1fff)); out[0*64+12] = (start += ((w2 >> 28) & 0x1fff)); out[0*64+13] = (start += ((w2 >> 41) & 0x1fff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (start += ((w2 >> 54) | (w3 << 10) & 0x1fff)); out[0*64+15] = (start += ((w3 >> 3) & 0x1fff)); out[0*64+16] = (start += ((w3 >> 16) & 0x1fff)); out[0*64+17] = (start += ((w3 >> 29) & 0x1fff)); out[0*64+18] = (start += ((w3 >> 42) & 0x1fff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (start += ((w3 >> 55) | (w4 << 9) & 0x1fff)); out[0*64+20] = (start += ((w4 >> 4) & 0x1fff)); out[0*64+21] = (start += ((w4 >> 17) & 0x1fff)); out[0*64+22] = (start += ((w4 >> 30) & 0x1fff)); out[0*64+23] = (start += ((w4 >> 43) & 0x1fff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (start += ((w4 >> 56) | (w5 << 8) & 0x1fff)); out[0*64+25] = (start += ((w5 >> 5) & 0x1fff)); out[0*64+26] = (start += ((w5 >> 18) & 0x1fff)); out[0*64+27] = (start += ((w5 >> 31) & 0x1fff)); out[0*64+28] = (start += ((w5 >> 44) & 0x1fff)); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (start += ((w5 >> 57) | (w6 << 7) & 0x1fff)); out[0*64+30] = (start += ((w6 >> 6) & 0x1fff)); out[0*64+31] = (start += ((w6 >> 19) & 0x1fff));;}; out += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_14(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fff)); out[0*32+ 1] = (start += ((w0 >> 14) & 0x3fff)); out[0*32+ 2] = (start += ((w0 >> 28) & 0x3fff)); out[0*32+ 3] = (start += ((w0 >> 42) & 0x3fff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w0 >> 56) | (w1 << 8) & 0x3fff)); out[0*32+ 5] = (start += ((w1 >> 6) & 0x3fff)); out[0*32+ 6] = (start += ((w1 >> 20) & 0x3fff)); out[0*32+ 7] = (start += ((w1 >> 34) & 0x3fff)); out[0*32+ 8] = (start += ((w1 >> 48) & 0x3fff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w1 >> 62) | (w2 << 2) & 0x3fff)); out[0*32+10] = (start += ((w2 >> 12) & 0x3fff)); out[0*32+11] = (start += ((w2 >> 26) & 0x3fff)); out[0*32+12] = (start += ((w2 >> 40) & 0x3fff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (start += ((w2 >> 54) | (w3 << 10) & 0x3fff)); out[0*32+14] = (start += ((w3 >> 4) & 0x3fff)); out[0*32+15] = (start += ((w3 >> 18) & 0x3fff)); out[0*32+16] = (start += ((w3 >> 32) & 0x3fff)); out[0*32+17] = (start += ((w3 >> 46) & 0x3fff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (start += ((w3 >> 60) | (w4 << 4) & 0x3fff)); out[0*32+19] = (start += ((w4 >> 10) & 0x3fff)); out[0*32+20] = (start += ((w4 >> 24) & 0x3fff)); out[0*32+21] = (start += ((w4 >> 38) & 0x3fff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (start += ((w4 >> 52) | (w5 << 12) & 0x3fff)); out[0*32+23] = (start += ((w5 >> 2) & 0x3fff)); out[0*32+24] = (start += ((w5 >> 16) & 0x3fff)); out[0*32+25] = (start += ((w5 >> 30) & 0x3fff)); out[0*32+26] = (start += ((w5 >> 44) & 0x3fff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (start += ((w5 >> 58) | (w6 << 6) & 0x3fff)); out[0*32+28] = (start += ((w6 >> 8) & 0x3fff)); out[0*32+29] = (start += ((w6 >> 22) & 0x3fff)); out[0*32+30] = (start += ((w6 >> 36) & 0x3fff)); out[0*32+31] = (start += ((w6 >> 50)));;}; out += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_15(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fff)); out[0*64+ 1] = (start += ((w0 >> 15) & 0x7fff)); out[0*64+ 2] = (start += ((w0 >> 30) & 0x7fff)); out[0*64+ 3] = (start += ((w0 >> 45) & 0x7fff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w0 >> 60) | (w1 << 4) & 0x7fff)); out[0*64+ 5] = (start += ((w1 >> 11) & 0x7fff)); out[0*64+ 6] = (start += ((w1 >> 26) & 0x7fff)); out[0*64+ 7] = (start += ((w1 >> 41) & 0x7fff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w1 >> 56) | (w2 << 8) & 0x7fff)); out[0*64+ 9] = (start += ((w2 >> 7) & 0x7fff)); out[0*64+10] = (start += ((w2 >> 22) & 0x7fff)); out[0*64+11] = (start += ((w2 >> 37) & 0x7fff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (start += ((w2 >> 52) | (w3 << 12) & 0x7fff)); out[0*64+13] = (start += ((w3 >> 3) & 0x7fff)); out[0*64+14] = (start += ((w3 >> 18) & 0x7fff)); out[0*64+15] = (start += ((w3 >> 33) & 0x7fff)); out[0*64+16] = (start += ((w3 >> 48) & 0x7fff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (start += ((w3 >> 63) | (w4 << 1) & 0x7fff)); out[0*64+18] = (start += ((w4 >> 14) & 0x7fff)); out[0*64+19] = (start += ((w4 >> 29) & 0x7fff)); out[0*64+20] = (start += ((w4 >> 44) & 0x7fff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (start += ((w4 >> 59) | (w5 << 5) & 0x7fff)); out[0*64+22] = (start += ((w5 >> 10) & 0x7fff)); out[0*64+23] = (start += ((w5 >> 25) & 0x7fff)); out[0*64+24] = (start += ((w5 >> 40) & 0x7fff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (start += ((w5 >> 55) | (w6 << 9) & 0x7fff)); out[0*64+26] = (start += ((w6 >> 6) & 0x7fff)); out[0*64+27] = (start += ((w6 >> 21) & 0x7fff)); out[0*64+28] = (start += ((w6 >> 36) & 0x7fff)); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (start += ((w6 >> 51) | (w7 << 13) & 0x7fff)); out[0*64+30] = (start += ((w7 >> 2) & 0x7fff)); out[0*64+31] = (start += ((w7 >> 17) & 0x7fff));;}; out += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_16(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = (start += (*(uint16_t *)(in+0*8+ 0))); out[0*4+ 1] = (start += (*(uint16_t *)(in+0*8+ 2))); out[0*4+ 2] = (start += (*(uint16_t *)(in+0*8+ 4))); out[0*4+ 3] = (start += (*(uint16_t *)(in+0*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = (start += (*(uint16_t *)(in+1*8+ 0))); out[1*4+ 1] = (start += (*(uint16_t *)(in+1*8+ 2))); out[1*4+ 2] = (start += (*(uint16_t *)(in+1*8+ 4))); out[1*4+ 3] = (start += (*(uint16_t *)(in+1*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = (start += (*(uint16_t *)(in+2*8+ 0))); out[2*4+ 1] = (start += (*(uint16_t *)(in+2*8+ 2))); out[2*4+ 2] = (start += (*(uint16_t *)(in+2*8+ 4))); out[2*4+ 3] = (start += (*(uint16_t *)(in+2*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = (start += (*(uint16_t *)(in+3*8+ 0))); out[3*4+ 1] = (start += (*(uint16_t *)(in+3*8+ 2))); out[3*4+ 2] = (start += (*(uint16_t *)(in+3*8+ 4))); out[3*4+ 3] = (start += (*(uint16_t *)(in+3*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = (start += (*(uint16_t *)(in+4*8+ 0))); out[4*4+ 1] = (start += (*(uint16_t *)(in+4*8+ 2))); out[4*4+ 2] = (start += (*(uint16_t *)(in+4*8+ 4))); out[4*4+ 3] = (start += (*(uint16_t *)(in+4*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = (start += (*(uint16_t *)(in+5*8+ 0))); out[5*4+ 1] = (start += (*(uint16_t *)(in+5*8+ 2))); out[5*4+ 2] = (start += (*(uint16_t *)(in+5*8+ 4))); out[5*4+ 3] = (start += (*(uint16_t *)(in+5*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = (start += (*(uint16_t *)(in+6*8+ 0))); out[6*4+ 1] = (start += (*(uint16_t *)(in+6*8+ 2))); out[6*4+ 2] = (start += (*(uint16_t *)(in+6*8+ 4))); out[6*4+ 3] = (start += (*(uint16_t *)(in+6*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = (start += (*(uint16_t *)(in+7*8+ 0))); out[7*4+ 1] = (start += (*(uint16_t *)(in+7*8+ 2))); out[7*4+ 2] = (start += (*(uint16_t *)(in+7*8+ 4))); out[7*4+ 3] = (start += (*(uint16_t *)(in+7*8+ 6)));;}; out += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_17(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*17)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffff)); out[0*64+ 1] = (start += ((w0 >> 17) & 0x1ffff)); out[0*64+ 2] = (start += ((w0 >> 34) & 0x1ffff)); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w0 >> 51) | (w1 << 13) & 0x1ffff)); out[0*64+ 4] = (start += ((w1 >> 4) & 0x1ffff)); out[0*64+ 5] = (start += ((w1 >> 21) & 0x1ffff)); out[0*64+ 6] = (start += ((w1 >> 38) & 0x1ffff)); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w1 >> 55) | (w2 << 9) & 0x1ffff)); out[0*64+ 8] = (start += ((w2 >> 8) & 0x1ffff)); out[0*64+ 9] = (start += ((w2 >> 25) & 0x1ffff)); out[0*64+10] = (start += ((w2 >> 42) & 0x1ffff)); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*64+11] = (start += ((w2 >> 59) | (w3 << 5) & 0x1ffff)); out[0*64+12] = (start += ((w3 >> 12) & 0x1ffff)); out[0*64+13] = (start += ((w3 >> 29) & 0x1ffff)); out[0*64+14] = (start += ((w3 >> 46) & 0x1ffff)); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*64+15] = (start += ((w3 >> 63) | (w4 << 1) & 0x1ffff)); out[0*64+16] = (start += ((w4 >> 16) & 0x1ffff)); out[0*64+17] = (start += ((w4 >> 33) & 0x1ffff)); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*64+18] = (start += ((w4 >> 50) | (w5 << 14) & 0x1ffff)); out[0*64+19] = (start += ((w5 >> 3) & 0x1ffff)); out[0*64+20] = (start += ((w5 >> 20) & 0x1ffff)); out[0*64+21] = (start += ((w5 >> 37) & 0x1ffff)); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*64+22] = (start += ((w5 >> 54) | (w6 << 10) & 0x1ffff)); out[0*64+23] = (start += ((w6 >> 7) & 0x1ffff)); out[0*64+24] = (start += ((w6 >> 24) & 0x1ffff)); out[0*64+25] = (start += ((w6 >> 41) & 0x1ffff)); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*64+26] = (start += ((w6 >> 58) | (w7 << 6) & 0x1ffff)); out[0*64+27] = (start += ((w7 >> 11) & 0x1ffff)); out[0*64+28] = (start += ((w7 >> 28) & 0x1ffff)); out[0*64+29] = (start += ((w7 >> 45) & 0x1ffff)); w8 = *(uint32_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*64+30] = (start += ((w7 >> 62) | (w8 << 2) & 0x1ffff)); out[0*64+31] = (start += ((w8 >> 15) & 0x1ffff));;}; out += 32; in += 17*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_18(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*18)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffff)); out[0*32+ 1] = (start += ((w0 >> 18) & 0x3ffff)); out[0*32+ 2] = (start += ((w0 >> 36) & 0x3ffff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w0 >> 54) | (w1 << 10) & 0x3ffff)); out[0*32+ 4] = (start += ((w1 >> 8) & 0x3ffff)); out[0*32+ 5] = (start += ((w1 >> 26) & 0x3ffff)); out[0*32+ 6] = (start += ((w1 >> 44) & 0x3ffff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w1 >> 62) | (w2 << 2) & 0x3ffff)); out[0*32+ 8] = (start += ((w2 >> 16) & 0x3ffff)); out[0*32+ 9] = (start += ((w2 >> 34) & 0x3ffff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*32+10] = (start += ((w2 >> 52) | (w3 << 12) & 0x3ffff)); out[0*32+11] = (start += ((w3 >> 6) & 0x3ffff)); out[0*32+12] = (start += ((w3 >> 24) & 0x3ffff)); out[0*32+13] = (start += ((w3 >> 42) & 0x3ffff)); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*32+14] = (start += ((w3 >> 60) | (w4 << 4) & 0x3ffff)); out[0*32+15] = (start += ((w4 >> 14) & 0x3ffff)); out[0*32+16] = (start += ((w4 >> 32) & 0x3ffff)); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*32+17] = (start += ((w4 >> 50) | (w5 << 14) & 0x3ffff)); out[0*32+18] = (start += ((w5 >> 4) & 0x3ffff)); out[0*32+19] = (start += ((w5 >> 22) & 0x3ffff)); out[0*32+20] = (start += ((w5 >> 40) & 0x3ffff)); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*32+21] = (start += ((w5 >> 58) | (w6 << 6) & 0x3ffff)); out[0*32+22] = (start += ((w6 >> 12) & 0x3ffff)); out[0*32+23] = (start += ((w6 >> 30) & 0x3ffff)); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*32+24] = (start += ((w6 >> 48) | (w7 << 16) & 0x3ffff)); out[0*32+25] = (start += ((w7 >> 2) & 0x3ffff)); out[0*32+26] = (start += ((w7 >> 20) & 0x3ffff)); out[0*32+27] = (start += ((w7 >> 38) & 0x3ffff)); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*32+28] = (start += ((w7 >> 56) | (w8 << 8) & 0x3ffff)); out[0*32+29] = (start += ((w8 >> 10) & 0x3ffff)); out[0*32+30] = (start += ((w8 >> 28) & 0x3ffff)); out[0*32+31] = (start += ((w8 >> 46)));;}; out += 32; in += 18*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_19(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*19)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffff)); out[0*64+ 1] = (start += ((w0 >> 19) & 0x7ffff)); out[0*64+ 2] = (start += ((w0 >> 38) & 0x7ffff)); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w0 >> 57) | (w1 << 7) & 0x7ffff)); out[0*64+ 4] = (start += ((w1 >> 12) & 0x7ffff)); out[0*64+ 5] = (start += ((w1 >> 31) & 0x7ffff)); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w1 >> 50) | (w2 << 14) & 0x7ffff)); out[0*64+ 7] = (start += ((w2 >> 5) & 0x7ffff)); out[0*64+ 8] = (start += ((w2 >> 24) & 0x7ffff)); out[0*64+ 9] = (start += ((w2 >> 43) & 0x7ffff)); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*64+10] = (start += ((w2 >> 62) | (w3 << 2) & 0x7ffff)); out[0*64+11] = (start += ((w3 >> 17) & 0x7ffff)); out[0*64+12] = (start += ((w3 >> 36) & 0x7ffff)); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*64+13] = (start += ((w3 >> 55) | (w4 << 9) & 0x7ffff)); out[0*64+14] = (start += ((w4 >> 10) & 0x7ffff)); out[0*64+15] = (start += ((w4 >> 29) & 0x7ffff)); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*64+16] = (start += ((w4 >> 48) | (w5 << 16) & 0x7ffff)); out[0*64+17] = (start += ((w5 >> 3) & 0x7ffff)); out[0*64+18] = (start += ((w5 >> 22) & 0x7ffff)); out[0*64+19] = (start += ((w5 >> 41) & 0x7ffff)); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*64+20] = (start += ((w5 >> 60) | (w6 << 4) & 0x7ffff)); out[0*64+21] = (start += ((w6 >> 15) & 0x7ffff)); out[0*64+22] = (start += ((w6 >> 34) & 0x7ffff)); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*64+23] = (start += ((w6 >> 53) | (w7 << 11) & 0x7ffff)); out[0*64+24] = (start += ((w7 >> 8) & 0x7ffff)); out[0*64+25] = (start += ((w7 >> 27) & 0x7ffff)); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*64+26] = (start += ((w7 >> 46) | (w8 << 18) & 0x7ffff)); out[0*64+27] = (start += ((w8 >> 1) & 0x7ffff)); out[0*64+28] = (start += ((w8 >> 20) & 0x7ffff)); out[0*64+29] = (start += ((w8 >> 39) & 0x7ffff)); w9 = *(uint32_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*64+30] = (start += ((w8 >> 58) | (w9 << 6) & 0x7ffff)); out[0*64+31] = (start += ((w9 >> 13) & 0x7ffff));;}; out += 32; in += 19*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_20(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*20)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffff)); out[0*16+ 1] = (start += ((w0 >> 20) & 0xfffff)); out[0*16+ 2] = (start += ((w0 >> 40) & 0xfffff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*16+ 3] = (start += ((w0 >> 60) | (w1 << 4) & 0xfffff)); out[0*16+ 4] = (start += ((w1 >> 16) & 0xfffff)); out[0*16+ 5] = (start += ((w1 >> 36) & 0xfffff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*16+ 6] = (start += ((w1 >> 56) | (w2 << 8) & 0xfffff)); out[0*16+ 7] = (start += ((w2 >> 12) & 0xfffff)); out[0*16+ 8] = (start += ((w2 >> 32) & 0xfffff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*16+ 9] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffff)); out[0*16+10] = (start += ((w3 >> 8) & 0xfffff)); out[0*16+11] = (start += ((w3 >> 28) & 0xfffff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*16+12] = (start += ((w3 >> 48) | (w4 << 16) & 0xfffff)); out[0*16+13] = (start += ((w4 >> 4) & 0xfffff)); out[0*16+14] = (start += ((w4 >> 24) & 0xfffff)); out[0*16+15] = (start += ((w4 >> 44)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffff)); out[1*16+ 1] = (start += ((w0 >> 20) & 0xfffff)); out[1*16+ 2] = (start += ((w0 >> 40) & 0xfffff)); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*16+ 3] = (start += ((w0 >> 60) | (w1 << 4) & 0xfffff)); out[1*16+ 4] = (start += ((w1 >> 16) & 0xfffff)); out[1*16+ 5] = (start += ((w1 >> 36) & 0xfffff)); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*16+ 6] = (start += ((w1 >> 56) | (w2 << 8) & 0xfffff)); out[1*16+ 7] = (start += ((w2 >> 12) & 0xfffff)); out[1*16+ 8] = (start += ((w2 >> 32) & 0xfffff)); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*16+ 9] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffff)); out[1*16+10] = (start += ((w3 >> 8) & 0xfffff)); out[1*16+11] = (start += ((w3 >> 28) & 0xfffff)); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*16+12] = (start += ((w3 >> 48) | (w4 << 16) & 0xfffff)); out[1*16+13] = (start += ((w4 >> 4) & 0xfffff)); out[1*16+14] = (start += ((w4 >> 24) & 0xfffff)); out[1*16+15] = (start += ((w4 >> 44)));;}; out += 32; in += 20*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_21(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*21)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffff)); out[0*64+ 1] = (start += ((w0 >> 21) & 0x1fffff)); out[0*64+ 2] = (start += ((w0 >> 42) & 0x1fffff)); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w0 >> 63) | (w1 << 1) & 0x1fffff)); out[0*64+ 4] = (start += ((w1 >> 20) & 0x1fffff)); out[0*64+ 5] = (start += ((w1 >> 41) & 0x1fffff)); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w1 >> 62) | (w2 << 2) & 0x1fffff)); out[0*64+ 7] = (start += ((w2 >> 19) & 0x1fffff)); out[0*64+ 8] = (start += ((w2 >> 40) & 0x1fffff)); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w2 >> 61) | (w3 << 3) & 0x1fffff)); out[0*64+10] = (start += ((w3 >> 18) & 0x1fffff)); out[0*64+11] = (start += ((w3 >> 39) & 0x1fffff)); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*64+12] = (start += ((w3 >> 60) | (w4 << 4) & 0x1fffff)); out[0*64+13] = (start += ((w4 >> 17) & 0x1fffff)); out[0*64+14] = (start += ((w4 >> 38) & 0x1fffff)); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*64+15] = (start += ((w4 >> 59) | (w5 << 5) & 0x1fffff)); out[0*64+16] = (start += ((w5 >> 16) & 0x1fffff)); out[0*64+17] = (start += ((w5 >> 37) & 0x1fffff)); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*64+18] = (start += ((w5 >> 58) | (w6 << 6) & 0x1fffff)); out[0*64+19] = (start += ((w6 >> 15) & 0x1fffff)); out[0*64+20] = (start += ((w6 >> 36) & 0x1fffff)); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*64+21] = (start += ((w6 >> 57) | (w7 << 7) & 0x1fffff)); out[0*64+22] = (start += ((w7 >> 14) & 0x1fffff)); out[0*64+23] = (start += ((w7 >> 35) & 0x1fffff)); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*64+24] = (start += ((w7 >> 56) | (w8 << 8) & 0x1fffff)); out[0*64+25] = (start += ((w8 >> 13) & 0x1fffff)); out[0*64+26] = (start += ((w8 >> 34) & 0x1fffff)); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*64+27] = (start += ((w8 >> 55) | (w9 << 9) & 0x1fffff)); out[0*64+28] = (start += ((w9 >> 12) & 0x1fffff)); out[0*64+29] = (start += ((w9 >> 33) & 0x1fffff)); w10 = *(uint32_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*64+30] = (start += ((w9 >> 54) | (w10 << 10) & 0x1fffff)); out[0*64+31] = (start += ((w10 >> 11) & 0x1fffff));;}; out += 32; in += 21*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_22(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*22)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffff)); out[0*32+ 1] = (start += ((w0 >> 22) & 0x3fffff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w0 >> 44) | (w1 << 20) & 0x3fffff)); out[0*32+ 3] = (start += ((w1 >> 2) & 0x3fffff)); out[0*32+ 4] = (start += ((w1 >> 24) & 0x3fffff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w1 >> 46) | (w2 << 18) & 0x3fffff)); out[0*32+ 6] = (start += ((w2 >> 4) & 0x3fffff)); out[0*32+ 7] = (start += ((w2 >> 26) & 0x3fffff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w2 >> 48) | (w3 << 16) & 0x3fffff)); out[0*32+ 9] = (start += ((w3 >> 6) & 0x3fffff)); out[0*32+10] = (start += ((w3 >> 28) & 0x3fffff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*32+11] = (start += ((w3 >> 50) | (w4 << 14) & 0x3fffff)); out[0*32+12] = (start += ((w4 >> 8) & 0x3fffff)); out[0*32+13] = (start += ((w4 >> 30) & 0x3fffff)); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*32+14] = (start += ((w4 >> 52) | (w5 << 12) & 0x3fffff)); out[0*32+15] = (start += ((w5 >> 10) & 0x3fffff)); out[0*32+16] = (start += ((w5 >> 32) & 0x3fffff)); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*32+17] = (start += ((w5 >> 54) | (w6 << 10) & 0x3fffff)); out[0*32+18] = (start += ((w6 >> 12) & 0x3fffff)); out[0*32+19] = (start += ((w6 >> 34) & 0x3fffff)); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*32+20] = (start += ((w6 >> 56) | (w7 << 8) & 0x3fffff)); out[0*32+21] = (start += ((w7 >> 14) & 0x3fffff)); out[0*32+22] = (start += ((w7 >> 36) & 0x3fffff)); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*32+23] = (start += ((w7 >> 58) | (w8 << 6) & 0x3fffff)); out[0*32+24] = (start += ((w8 >> 16) & 0x3fffff)); out[0*32+25] = (start += ((w8 >> 38) & 0x3fffff)); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*32+26] = (start += ((w8 >> 60) | (w9 << 4) & 0x3fffff)); out[0*32+27] = (start += ((w9 >> 18) & 0x3fffff)); out[0*32+28] = (start += ((w9 >> 40) & 0x3fffff)); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*32+29] = (start += ((w9 >> 62) | (w10 << 2) & 0x3fffff)); out[0*32+30] = (start += ((w10 >> 20) & 0x3fffff)); out[0*32+31] = (start += ((w10 >> 42)));;}; out += 32; in += 22*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_23(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*23)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffff)); out[0*64+ 1] = (start += ((w0 >> 23) & 0x7fffff)); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 46) | (w1 << 18) & 0x7fffff)); out[0*64+ 3] = (start += ((w1 >> 5) & 0x7fffff)); out[0*64+ 4] = (start += ((w1 >> 28) & 0x7fffff)); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w1 >> 51) | (w2 << 13) & 0x7fffff)); out[0*64+ 6] = (start += ((w2 >> 10) & 0x7fffff)); out[0*64+ 7] = (start += ((w2 >> 33) & 0x7fffff)); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w2 >> 56) | (w3 << 8) & 0x7fffff)); out[0*64+ 9] = (start += ((w3 >> 15) & 0x7fffff)); out[0*64+10] = (start += ((w3 >> 38) & 0x7fffff)); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*64+11] = (start += ((w3 >> 61) | (w4 << 3) & 0x7fffff)); out[0*64+12] = (start += ((w4 >> 20) & 0x7fffff)); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*64+13] = (start += ((w4 >> 43) | (w5 << 21) & 0x7fffff)); out[0*64+14] = (start += ((w5 >> 2) & 0x7fffff)); out[0*64+15] = (start += ((w5 >> 25) & 0x7fffff)); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*64+16] = (start += ((w5 >> 48) | (w6 << 16) & 0x7fffff)); out[0*64+17] = (start += ((w6 >> 7) & 0x7fffff)); out[0*64+18] = (start += ((w6 >> 30) & 0x7fffff)); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*64+19] = (start += ((w6 >> 53) | (w7 << 11) & 0x7fffff)); out[0*64+20] = (start += ((w7 >> 12) & 0x7fffff)); out[0*64+21] = (start += ((w7 >> 35) & 0x7fffff)); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*64+22] = (start += ((w7 >> 58) | (w8 << 6) & 0x7fffff)); out[0*64+23] = (start += ((w8 >> 17) & 0x7fffff)); out[0*64+24] = (start += ((w8 >> 40) & 0x7fffff)); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*64+25] = (start += ((w8 >> 63) | (w9 << 1) & 0x7fffff)); out[0*64+26] = (start += ((w9 >> 22) & 0x7fffff)); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*64+27] = (start += ((w9 >> 45) | (w10 << 19) & 0x7fffff)); out[0*64+28] = (start += ((w10 >> 4) & 0x7fffff)); out[0*64+29] = (start += ((w10 >> 27) & 0x7fffff)); w11 = *(uint32_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*64+30] = (start += ((w10 >> 50) | (w11 << 14) & 0x7fffff)); out[0*64+31] = (start += ((w11 >> 9) & 0x7fffff));;}; out += 32; in += 23*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_24(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*24)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xffffff)); out[0*8+ 1] = (start += ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[0*8+ 3] = (start += ((w1 >> 8) & 0xffffff)); out[0*8+ 4] = (start += ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[0*8+ 6] = (start += ((w2 >> 16) & 0xffffff)); out[0*8+ 7] = (start += ((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xffffff)); out[1*8+ 1] = (start += ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[1*8+ 3] = (start += ((w1 >> 8) & 0xffffff)); out[1*8+ 4] = (start += ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[1*8+ 6] = (start += ((w2 >> 16) & 0xffffff)); out[1*8+ 7] = (start += ((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xffffff)); out[2*8+ 1] = (start += ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[2*8+ 3] = (start += ((w1 >> 8) & 0xffffff)); out[2*8+ 4] = (start += ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[2*8+ 6] = (start += ((w2 >> 16) & 0xffffff)); out[2*8+ 7] = (start += ((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xffffff)); out[3*8+ 1] = (start += ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[3*8+ 3] = (start += ((w1 >> 8) & 0xffffff)); out[3*8+ 4] = (start += ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[3*8+ 6] = (start += ((w2 >> 16) & 0xffffff)); out[3*8+ 7] = (start += ((w2 >> 40)));;}; out += 32; in += 24*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_25(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*25)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffffff)); out[0*64+ 1] = (start += ((w0 >> 25) & 0x1ffffff)); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 50) | (w1 << 14) & 0x1ffffff)); out[0*64+ 3] = (start += ((w1 >> 11) & 0x1ffffff)); out[0*64+ 4] = (start += ((w1 >> 36) & 0x1ffffff)); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w1 >> 61) | (w2 << 3) & 0x1ffffff)); out[0*64+ 6] = (start += ((w2 >> 22) & 0x1ffffff)); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w2 >> 47) | (w3 << 17) & 0x1ffffff)); out[0*64+ 8] = (start += ((w3 >> 8) & 0x1ffffff)); out[0*64+ 9] = (start += ((w3 >> 33) & 0x1ffffff)); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*64+10] = (start += ((w3 >> 58) | (w4 << 6) & 0x1ffffff)); out[0*64+11] = (start += ((w4 >> 19) & 0x1ffffff)); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*64+12] = (start += ((w4 >> 44) | (w5 << 20) & 0x1ffffff)); out[0*64+13] = (start += ((w5 >> 5) & 0x1ffffff)); out[0*64+14] = (start += ((w5 >> 30) & 0x1ffffff)); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*64+15] = (start += ((w5 >> 55) | (w6 << 9) & 0x1ffffff)); out[0*64+16] = (start += ((w6 >> 16) & 0x1ffffff)); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*64+17] = (start += ((w6 >> 41) | (w7 << 23) & 0x1ffffff)); out[0*64+18] = (start += ((w7 >> 2) & 0x1ffffff)); out[0*64+19] = (start += ((w7 >> 27) & 0x1ffffff)); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*64+20] = (start += ((w7 >> 52) | (w8 << 12) & 0x1ffffff)); out[0*64+21] = (start += ((w8 >> 13) & 0x1ffffff)); out[0*64+22] = (start += ((w8 >> 38) & 0x1ffffff)); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*64+23] = (start += ((w8 >> 63) | (w9 << 1) & 0x1ffffff)); out[0*64+24] = (start += ((w9 >> 24) & 0x1ffffff)); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*64+25] = (start += ((w9 >> 49) | (w10 << 15) & 0x1ffffff)); out[0*64+26] = (start += ((w10 >> 10) & 0x1ffffff)); out[0*64+27] = (start += ((w10 >> 35) & 0x1ffffff)); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*64+28] = (start += ((w10 >> 60) | (w11 << 4) & 0x1ffffff)); out[0*64+29] = (start += ((w11 >> 21) & 0x1ffffff)); w12 = *(uint32_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*64+30] = (start += ((w11 >> 46) | (w12 << 18) & 0x1ffffff)); out[0*64+31] = (start += ((w12 >> 7) & 0x1ffffff));;}; out += 32; in += 25*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_26(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*26)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffffff)); out[0*32+ 1] = (start += ((w0 >> 26) & 0x3ffffff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w0 >> 52) | (w1 << 12) & 0x3ffffff)); out[0*32+ 3] = (start += ((w1 >> 14) & 0x3ffffff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w1 >> 40) | (w2 << 24) & 0x3ffffff)); out[0*32+ 5] = (start += ((w2 >> 2) & 0x3ffffff)); out[0*32+ 6] = (start += ((w2 >> 28) & 0x3ffffff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w2 >> 54) | (w3 << 10) & 0x3ffffff)); out[0*32+ 8] = (start += ((w3 >> 16) & 0x3ffffff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w3 >> 42) | (w4 << 22) & 0x3ffffff)); out[0*32+10] = (start += ((w4 >> 4) & 0x3ffffff)); out[0*32+11] = (start += ((w4 >> 30) & 0x3ffffff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*32+12] = (start += ((w4 >> 56) | (w5 << 8) & 0x3ffffff)); out[0*32+13] = (start += ((w5 >> 18) & 0x3ffffff)); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*32+14] = (start += ((w5 >> 44) | (w6 << 20) & 0x3ffffff)); out[0*32+15] = (start += ((w6 >> 6) & 0x3ffffff)); out[0*32+16] = (start += ((w6 >> 32) & 0x3ffffff)); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*32+17] = (start += ((w6 >> 58) | (w7 << 6) & 0x3ffffff)); out[0*32+18] = (start += ((w7 >> 20) & 0x3ffffff)); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*32+19] = (start += ((w7 >> 46) | (w8 << 18) & 0x3ffffff)); out[0*32+20] = (start += ((w8 >> 8) & 0x3ffffff)); out[0*32+21] = (start += ((w8 >> 34) & 0x3ffffff)); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*32+22] = (start += ((w8 >> 60) | (w9 << 4) & 0x3ffffff)); out[0*32+23] = (start += ((w9 >> 22) & 0x3ffffff)); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*32+24] = (start += ((w9 >> 48) | (w10 << 16) & 0x3ffffff)); out[0*32+25] = (start += ((w10 >> 10) & 0x3ffffff)); out[0*32+26] = (start += ((w10 >> 36) & 0x3ffffff)); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*32+27] = (start += ((w10 >> 62) | (w11 << 2) & 0x3ffffff)); out[0*32+28] = (start += ((w11 >> 24) & 0x3ffffff)); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*32+29] = (start += ((w11 >> 50) | (w12 << 14) & 0x3ffffff)); out[0*32+30] = (start += ((w12 >> 12) & 0x3ffffff)); out[0*32+31] = (start += ((w12 >> 38)));;}; out += 32; in += 26*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_27(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*27)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffffff)); out[0*64+ 1] = (start += ((w0 >> 27) & 0x7ffffff)); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 54) | (w1 << 10) & 0x7ffffff)); out[0*64+ 3] = (start += ((w1 >> 17) & 0x7ffffff)); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w1 >> 44) | (w2 << 20) & 0x7ffffff)); out[0*64+ 5] = (start += ((w2 >> 7) & 0x7ffffff)); out[0*64+ 6] = (start += ((w2 >> 34) & 0x7ffffff)); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w2 >> 61) | (w3 << 3) & 0x7ffffff)); out[0*64+ 8] = (start += ((w3 >> 24) & 0x7ffffff)); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w3 >> 51) | (w4 << 13) & 0x7ffffff)); out[0*64+10] = (start += ((w4 >> 14) & 0x7ffffff)); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*64+11] = (start += ((w4 >> 41) | (w5 << 23) & 0x7ffffff)); out[0*64+12] = (start += ((w5 >> 4) & 0x7ffffff)); out[0*64+13] = (start += ((w5 >> 31) & 0x7ffffff)); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*64+14] = (start += ((w5 >> 58) | (w6 << 6) & 0x7ffffff)); out[0*64+15] = (start += ((w6 >> 21) & 0x7ffffff)); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*64+16] = (start += ((w6 >> 48) | (w7 << 16) & 0x7ffffff)); out[0*64+17] = (start += ((w7 >> 11) & 0x7ffffff)); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*64+18] = (start += ((w7 >> 38) | (w8 << 26) & 0x7ffffff)); out[0*64+19] = (start += ((w8 >> 1) & 0x7ffffff)); out[0*64+20] = (start += ((w8 >> 28) & 0x7ffffff)); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*64+21] = (start += ((w8 >> 55) | (w9 << 9) & 0x7ffffff)); out[0*64+22] = (start += ((w9 >> 18) & 0x7ffffff)); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*64+23] = (start += ((w9 >> 45) | (w10 << 19) & 0x7ffffff)); out[0*64+24] = (start += ((w10 >> 8) & 0x7ffffff)); out[0*64+25] = (start += ((w10 >> 35) & 0x7ffffff)); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*64+26] = (start += ((w10 >> 62) | (w11 << 2) & 0x7ffffff)); out[0*64+27] = (start += ((w11 >> 25) & 0x7ffffff)); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*64+28] = (start += ((w11 >> 52) | (w12 << 12) & 0x7ffffff)); out[0*64+29] = (start += ((w12 >> 15) & 0x7ffffff)); w13 = *(uint32_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*64+30] = (start += ((w12 >> 42) | (w13 << 22) & 0x7ffffff)); out[0*64+31] = (start += ((w13 >> 5) & 0x7ffffff));;}; out += 32; in += 27*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_28(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*28)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffffff)); out[0*16+ 1] = (start += ((w0 >> 28) & 0xfffffff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*16+ 2] = (start += ((w0 >> 56) | (w1 << 8) & 0xfffffff)); out[0*16+ 3] = (start += ((w1 >> 20) & 0xfffffff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*16+ 4] = (start += ((w1 >> 48) | (w2 << 16) & 0xfffffff)); out[0*16+ 5] = (start += ((w2 >> 12) & 0xfffffff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*16+ 6] = (start += ((w2 >> 40) | (w3 << 24) & 0xfffffff)); out[0*16+ 7] = (start += ((w3 >> 4) & 0xfffffff)); out[0*16+ 8] = (start += ((w3 >> 32) & 0xfffffff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*16+ 9] = (start += ((w3 >> 60) | (w4 << 4) & 0xfffffff)); out[0*16+10] = (start += ((w4 >> 24) & 0xfffffff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*16+11] = (start += ((w4 >> 52) | (w5 << 12) & 0xfffffff)); out[0*16+12] = (start += ((w5 >> 16) & 0xfffffff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*16+13] = (start += ((w5 >> 44) | (w6 << 20) & 0xfffffff)); out[0*16+14] = (start += ((w6 >> 8) & 0xfffffff)); out[0*16+15] = (start += ((w6 >> 36)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffffff)); out[1*16+ 1] = (start += ((w0 >> 28) & 0xfffffff)); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*16+ 2] = (start += ((w0 >> 56) | (w1 << 8) & 0xfffffff)); out[1*16+ 3] = (start += ((w1 >> 20) & 0xfffffff)); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*16+ 4] = (start += ((w1 >> 48) | (w2 << 16) & 0xfffffff)); out[1*16+ 5] = (start += ((w2 >> 12) & 0xfffffff)); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*16+ 6] = (start += ((w2 >> 40) | (w3 << 24) & 0xfffffff)); out[1*16+ 7] = (start += ((w3 >> 4) & 0xfffffff)); out[1*16+ 8] = (start += ((w3 >> 32) & 0xfffffff)); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*16+ 9] = (start += ((w3 >> 60) | (w4 << 4) & 0xfffffff)); out[1*16+10] = (start += ((w4 >> 24) & 0xfffffff)); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*16+11] = (start += ((w4 >> 52) | (w5 << 12) & 0xfffffff)); out[1*16+12] = (start += ((w5 >> 16) & 0xfffffff)); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*16+13] = (start += ((w5 >> 44) | (w6 << 20) & 0xfffffff)); out[1*16+14] = (start += ((w6 >> 8) & 0xfffffff)); out[1*16+15] = (start += ((w6 >> 36)));;}; out += 32; in += 28*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_29(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*29)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffffff)); out[0*64+ 1] = (start += ((w0 >> 29) & 0x1fffffff)); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 58) | (w1 << 6) & 0x1fffffff)); out[0*64+ 3] = (start += ((w1 >> 23) & 0x1fffffff)); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w1 >> 52) | (w2 << 12) & 0x1fffffff)); out[0*64+ 5] = (start += ((w2 >> 17) & 0x1fffffff)); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w2 >> 46) | (w3 << 18) & 0x1fffffff)); out[0*64+ 7] = (start += ((w3 >> 11) & 0x1fffffff)); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w3 >> 40) | (w4 << 24) & 0x1fffffff)); out[0*64+ 9] = (start += ((w4 >> 5) & 0x1fffffff)); out[0*64+10] = (start += ((w4 >> 34) & 0x1fffffff)); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*64+11] = (start += ((w4 >> 63) | (w5 << 1) & 0x1fffffff)); out[0*64+12] = (start += ((w5 >> 28) & 0x1fffffff)); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*64+13] = (start += ((w5 >> 57) | (w6 << 7) & 0x1fffffff)); out[0*64+14] = (start += ((w6 >> 22) & 0x1fffffff)); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*64+15] = (start += ((w6 >> 51) | (w7 << 13) & 0x1fffffff)); out[0*64+16] = (start += ((w7 >> 16) & 0x1fffffff)); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*64+17] = (start += ((w7 >> 45) | (w8 << 19) & 0x1fffffff)); out[0*64+18] = (start += ((w8 >> 10) & 0x1fffffff)); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*64+19] = (start += ((w8 >> 39) | (w9 << 25) & 0x1fffffff)); out[0*64+20] = (start += ((w9 >> 4) & 0x1fffffff)); out[0*64+21] = (start += ((w9 >> 33) & 0x1fffffff)); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*64+22] = (start += ((w9 >> 62) | (w10 << 2) & 0x1fffffff)); out[0*64+23] = (start += ((w10 >> 27) & 0x1fffffff)); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*64+24] = (start += ((w10 >> 56) | (w11 << 8) & 0x1fffffff)); out[0*64+25] = (start += ((w11 >> 21) & 0x1fffffff)); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*64+26] = (start += ((w11 >> 50) | (w12 << 14) & 0x1fffffff)); out[0*64+27] = (start += ((w12 >> 15) & 0x1fffffff)); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*64+28] = (start += ((w12 >> 44) | (w13 << 20) & 0x1fffffff)); out[0*64+29] = (start += ((w13 >> 9) & 0x1fffffff)); w14 = *(uint32_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*64+30] = (start += ((w13 >> 38) | (w14 << 26) & 0x1fffffff)); out[0*64+31] = (start += ((w14 >> 3) & 0x1fffffff));;}; out += 32; in += 29*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_30(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*30)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffffff)); out[0*32+ 1] = (start += ((w0 >> 30) & 0x3fffffff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w0 >> 60) | (w1 << 4) & 0x3fffffff)); out[0*32+ 3] = (start += ((w1 >> 26) & 0x3fffffff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w1 >> 56) | (w2 << 8) & 0x3fffffff)); out[0*32+ 5] = (start += ((w2 >> 22) & 0x3fffffff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w2 >> 52) | (w3 << 12) & 0x3fffffff)); out[0*32+ 7] = (start += ((w3 >> 18) & 0x3fffffff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w3 >> 48) | (w4 << 16) & 0x3fffffff)); out[0*32+ 9] = (start += ((w4 >> 14) & 0x3fffffff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*32+10] = (start += ((w4 >> 44) | (w5 << 20) & 0x3fffffff)); out[0*32+11] = (start += ((w5 >> 10) & 0x3fffffff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*32+12] = (start += ((w5 >> 40) | (w6 << 24) & 0x3fffffff)); out[0*32+13] = (start += ((w6 >> 6) & 0x3fffffff)); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*32+14] = (start += ((w6 >> 36) | (w7 << 28) & 0x3fffffff)); out[0*32+15] = (start += ((w7 >> 2) & 0x3fffffff)); out[0*32+16] = (start += ((w7 >> 32) & 0x3fffffff)); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*32+17] = (start += ((w7 >> 62) | (w8 << 2) & 0x3fffffff)); out[0*32+18] = (start += ((w8 >> 28) & 0x3fffffff)); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*32+19] = (start += ((w8 >> 58) | (w9 << 6) & 0x3fffffff)); out[0*32+20] = (start += ((w9 >> 24) & 0x3fffffff)); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*32+21] = (start += ((w9 >> 54) | (w10 << 10) & 0x3fffffff)); out[0*32+22] = (start += ((w10 >> 20) & 0x3fffffff)); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*32+23] = (start += ((w10 >> 50) | (w11 << 14) & 0x3fffffff)); out[0*32+24] = (start += ((w11 >> 16) & 0x3fffffff)); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*32+25] = (start += ((w11 >> 46) | (w12 << 18) & 0x3fffffff)); out[0*32+26] = (start += ((w12 >> 12) & 0x3fffffff)); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*32+27] = (start += ((w12 >> 42) | (w13 << 22) & 0x3fffffff)); out[0*32+28] = (start += ((w13 >> 8) & 0x3fffffff)); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*32+29] = (start += ((w13 >> 38) | (w14 << 26) & 0x3fffffff)); out[0*32+30] = (start += ((w14 >> 4) & 0x3fffffff)); out[0*32+31] = (start += ((w14 >> 34)));;}; out += 32; in += 30*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_31(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*31)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffffff)); out[0*64+ 1] = (start += ((w0 >> 31) & 0x7fffffff)); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 62) | (w1 << 2) & 0x7fffffff)); out[0*64+ 3] = (start += ((w1 >> 29) & 0x7fffffff)); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w1 >> 60) | (w2 << 4) & 0x7fffffff)); out[0*64+ 5] = (start += ((w2 >> 27) & 0x7fffffff)); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w2 >> 58) | (w3 << 6) & 0x7fffffff)); out[0*64+ 7] = (start += ((w3 >> 25) & 0x7fffffff)); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w3 >> 56) | (w4 << 8) & 0x7fffffff)); out[0*64+ 9] = (start += ((w4 >> 23) & 0x7fffffff)); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*64+10] = (start += ((w4 >> 54) | (w5 << 10) & 0x7fffffff)); out[0*64+11] = (start += ((w5 >> 21) & 0x7fffffff)); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*64+12] = (start += ((w5 >> 52) | (w6 << 12) & 0x7fffffff)); out[0*64+13] = (start += ((w6 >> 19) & 0x7fffffff)); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*64+14] = (start += ((w6 >> 50) | (w7 << 14) & 0x7fffffff)); out[0*64+15] = (start += ((w7 >> 17) & 0x7fffffff)); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*64+16] = (start += ((w7 >> 48) | (w8 << 16) & 0x7fffffff)); out[0*64+17] = (start += ((w8 >> 15) & 0x7fffffff)); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*64+18] = (start += ((w8 >> 46) | (w9 << 18) & 0x7fffffff)); out[0*64+19] = (start += ((w9 >> 13) & 0x7fffffff)); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*64+20] = (start += ((w9 >> 44) | (w10 << 20) & 0x7fffffff)); out[0*64+21] = (start += ((w10 >> 11) & 0x7fffffff)); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*64+22] = (start += ((w10 >> 42) | (w11 << 22) & 0x7fffffff)); out[0*64+23] = (start += ((w11 >> 9) & 0x7fffffff)); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*64+24] = (start += ((w11 >> 40) | (w12 << 24) & 0x7fffffff)); out[0*64+25] = (start += ((w12 >> 7) & 0x7fffffff)); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*64+26] = (start += ((w12 >> 38) | (w13 << 26) & 0x7fffffff)); out[0*64+27] = (start += ((w13 >> 5) & 0x7fffffff)); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*64+28] = (start += ((w13 >> 36) | (w14 << 28) & 0x7fffffff)); out[0*64+29] = (start += ((w14 >> 3) & 0x7fffffff)); w15 = *(uint32_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*64+30] = (start += ((w14 >> 34) | (w15 << 30) & 0x7fffffff)); out[0*64+31] = (start += ((w15 >> 1) & 0x7fffffff));;}; out += 32; in += 31*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack32_32(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*32)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[0*2+ 0] = (start += (*(uint32_t *)(in+0*8+ 0))); out[0*2+ 1] = (start += (*(uint32_t *)(in+0*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[1*2+ 0] = (start += (*(uint32_t *)(in+1*8+ 0))); out[1*2+ 1] = (start += (*(uint32_t *)(in+1*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[2*2+ 0] = (start += (*(uint32_t *)(in+2*8+ 0))); out[2*2+ 1] = (start += (*(uint32_t *)(in+2*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[3*2+ 0] = (start += (*(uint32_t *)(in+3*8+ 0))); out[3*2+ 1] = (start += (*(uint32_t *)(in+3*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[4*2+ 0] = (start += (*(uint32_t *)(in+4*8+ 0))); out[4*2+ 1] = (start += (*(uint32_t *)(in+4*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[5*2+ 0] = (start += (*(uint32_t *)(in+5*8+ 0))); out[5*2+ 1] = (start += (*(uint32_t *)(in+5*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[6*2+ 0] = (start += (*(uint32_t *)(in+6*8+ 0))); out[6*2+ 1] = (start += (*(uint32_t *)(in+6*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[7*2+ 0] = (start += (*(uint32_t *)(in+7*8+ 0))); out[7*2+ 1] = (start += (*(uint32_t *)(in+7*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[8*2+ 0] = (start += (*(uint32_t *)(in+8*8+ 0))); out[8*2+ 1] = (start += (*(uint32_t *)(in+8*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[9*2+ 0] = (start += (*(uint32_t *)(in+9*8+ 0))); out[9*2+ 1] = (start += (*(uint32_t *)(in+9*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[10*2+ 0] = (start += (*(uint32_t *)(in+10*8+ 0))); out[10*2+ 1] = (start += (*(uint32_t *)(in+10*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[11*2+ 0] = (start += (*(uint32_t *)(in+11*8+ 0))); out[11*2+ 1] = (start += (*(uint32_t *)(in+11*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[12*2+ 0] = (start += (*(uint32_t *)(in+12*8+ 0))); out[12*2+ 1] = (start += (*(uint32_t *)(in+12*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[13*2+ 0] = (start += (*(uint32_t *)(in+13*8+ 0))); out[13*2+ 1] = (start += (*(uint32_t *)(in+13*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[14*2+ 0] = (start += (*(uint32_t *)(in+14*8+ 0))); out[14*2+ 1] = (start += (*(uint32_t *)(in+14*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[15*2+ 0] = (start += (*(uint32_t *)(in+15*8+ 0))); out[15*2+ 1] = (start += (*(uint32_t *)(in+15*8+ 4)));;}; out += 32; in += 32*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D32 bitdunpacka32[] = {
  &bitdunpack32_0,
  &bitdunpack32_1,
  &bitdunpack32_2,
  &bitdunpack32_3,
  &bitdunpack32_4,
  &bitdunpack32_5,
  &bitdunpack32_6,
  &bitdunpack32_7,
  &bitdunpack32_8,
  &bitdunpack32_9,
  &bitdunpack32_10,
  &bitdunpack32_11,
  &bitdunpack32_12,
  &bitdunpack32_13,
  &bitdunpack32_14,
  &bitdunpack32_15,
  &bitdunpack32_16,
  &bitdunpack32_17,
  &bitdunpack32_18,
  &bitdunpack32_19,
  &bitdunpack32_20,
  &bitdunpack32_21,
  &bitdunpack32_22,
  &bitdunpack32_23,
  &bitdunpack32_24,
  &bitdunpack32_25,
  &bitdunpack32_26,
  &bitdunpack32_27,
  &bitdunpack32_28,
  &bitdunpack32_29,
  &bitdunpack32_30,
  &bitdunpack32_31,
  &bitdunpack32_32
};
unsigned char *bitdunpack32( const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start, unsigned b) { return bitdunpacka32[ b](in, n, out, start); }
unsigned char *bitdunpack64_0(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint64_t *out_ = out+n; do { { { out[0*0+ 0] = (start += (0)); out[0*0+ 1] = (start += (0)); out[0*0+ 2] = (start += (0)); out[0*0+ 3] = (start += (0)); out[0*0+ 4] = (start += (0)); out[0*0+ 5] = (start += (0)); out[0*0+ 6] = (start += (0)); out[0*0+ 7] = (start += (0)); out[0*0+ 8] = (start += (0)); out[0*0+ 9] = (start += (0)); out[0*0+10] = (start += (0)); out[0*0+11] = (start += (0)); out[0*0+12] = (start += (0)); out[0*0+13] = (start += (0)); out[0*0+14] = (start += (0)); out[0*0+15] = (start += (0)); out[0*0+16] = (start += (0)); out[0*0+17] = (start += (0)); out[0*0+18] = (start += (0)); out[0*0+19] = (start += (0)); out[0*0+20] = (start += (0)); out[0*0+21] = (start += (0)); out[0*0+22] = (start += (0)); out[0*0+23] = (start += (0)); out[0*0+24] = (start += (0)); out[0*0+25] = (start += (0)); out[0*0+26] = (start += (0)); out[0*0+27] = (start += (0)); out[0*0+28] = (start += (0)); out[0*0+29] = (start += (0)); out[0*0+30] = (start += (0)); out[0*0+31] = (start += (0));;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitdunpack64_1(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x1)); out[0*32+ 1] = (start += ((w0 >> 1) & 0x1)); out[0*32+ 2] = (start += ((w0 >> 2) & 0x1)); out[0*32+ 3] = (start += ((w0 >> 3) & 0x1)); out[0*32+ 4] = (start += ((w0 >> 4) & 0x1)); out[0*32+ 5] = (start += ((w0 >> 5) & 0x1)); out[0*32+ 6] = (start += ((w0 >> 6) & 0x1)); out[0*32+ 7] = (start += ((w0 >> 7) & 0x1)); out[0*32+ 8] = (start += ((w0 >> 8) & 0x1)); out[0*32+ 9] = (start += ((w0 >> 9) & 0x1)); out[0*32+10] = (start += ((w0 >> 10) & 0x1)); out[0*32+11] = (start += ((w0 >> 11) & 0x1)); out[0*32+12] = (start += ((w0 >> 12) & 0x1)); out[0*32+13] = (start += ((w0 >> 13) & 0x1)); out[0*32+14] = (start += ((w0 >> 14) & 0x1)); out[0*32+15] = (start += ((w0 >> 15) & 0x1)); out[0*32+16] = (start += ((w0 >> 16) & 0x1)); out[0*32+17] = (start += ((w0 >> 17) & 0x1)); out[0*32+18] = (start += ((w0 >> 18) & 0x1)); out[0*32+19] = (start += ((w0 >> 19) & 0x1)); out[0*32+20] = (start += ((w0 >> 20) & 0x1)); out[0*32+21] = (start += ((w0 >> 21) & 0x1)); out[0*32+22] = (start += ((w0 >> 22) & 0x1)); out[0*32+23] = (start += ((w0 >> 23) & 0x1)); out[0*32+24] = (start += ((w0 >> 24) & 0x1)); out[0*32+25] = (start += ((w0 >> 25) & 0x1)); out[0*32+26] = (start += ((w0 >> 26) & 0x1)); out[0*32+27] = (start += ((w0 >> 27) & 0x1)); out[0*32+28] = (start += ((w0 >> 28) & 0x1)); out[0*32+29] = (start += ((w0 >> 29) & 0x1)); out[0*32+30] = (start += ((w0 >> 30) & 0x1)); out[0*32+31] = (start += ((w0 >> 31)));;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_2(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3)); out[0*32+ 1] = (start += ((w0 >> 2) & 0x3)); out[0*32+ 2] = (start += ((w0 >> 4) & 0x3)); out[0*32+ 3] = (start += ((w0 >> 6) & 0x3)); out[0*32+ 4] = (start += ((w0 >> 8) & 0x3)); out[0*32+ 5] = (start += ((w0 >> 10) & 0x3)); out[0*32+ 6] = (start += ((w0 >> 12) & 0x3)); out[0*32+ 7] = (start += ((w0 >> 14) & 0x3)); out[0*32+ 8] = (start += ((w0 >> 16) & 0x3)); out[0*32+ 9] = (start += ((w0 >> 18) & 0x3)); out[0*32+10] = (start += ((w0 >> 20) & 0x3)); out[0*32+11] = (start += ((w0 >> 22) & 0x3)); out[0*32+12] = (start += ((w0 >> 24) & 0x3)); out[0*32+13] = (start += ((w0 >> 26) & 0x3)); out[0*32+14] = (start += ((w0 >> 28) & 0x3)); out[0*32+15] = (start += ((w0 >> 30) & 0x3)); out[0*32+16] = (start += ((w0 >> 32) & 0x3)); out[0*32+17] = (start += ((w0 >> 34) & 0x3)); out[0*32+18] = (start += ((w0 >> 36) & 0x3)); out[0*32+19] = (start += ((w0 >> 38) & 0x3)); out[0*32+20] = (start += ((w0 >> 40) & 0x3)); out[0*32+21] = (start += ((w0 >> 42) & 0x3)); out[0*32+22] = (start += ((w0 >> 44) & 0x3)); out[0*32+23] = (start += ((w0 >> 46) & 0x3)); out[0*32+24] = (start += ((w0 >> 48) & 0x3)); out[0*32+25] = (start += ((w0 >> 50) & 0x3)); out[0*32+26] = (start += ((w0 >> 52) & 0x3)); out[0*32+27] = (start += ((w0 >> 54) & 0x3)); out[0*32+28] = (start += ((w0 >> 56) & 0x3)); out[0*32+29] = (start += ((w0 >> 58) & 0x3)); out[0*32+30] = (start += ((w0 >> 60) & 0x3)); out[0*32+31] = (start += ((w0 >> 62)));;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_3(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7)); out[0*64+ 1] = (start += ((w0 >> 3) & 0x7)); out[0*64+ 2] = (start += ((w0 >> 6) & 0x7)); out[0*64+ 3] = (start += ((w0 >> 9) & 0x7)); out[0*64+ 4] = (start += ((w0 >> 12) & 0x7)); out[0*64+ 5] = (start += ((w0 >> 15) & 0x7)); out[0*64+ 6] = (start += ((w0 >> 18) & 0x7)); out[0*64+ 7] = (start += ((w0 >> 21) & 0x7)); out[0*64+ 8] = (start += ((w0 >> 24) & 0x7)); out[0*64+ 9] = (start += ((w0 >> 27) & 0x7)); out[0*64+10] = (start += ((w0 >> 30) & 0x7)); out[0*64+11] = (start += ((w0 >> 33) & 0x7)); out[0*64+12] = (start += ((w0 >> 36) & 0x7)); out[0*64+13] = (start += ((w0 >> 39) & 0x7)); out[0*64+14] = (start += ((w0 >> 42) & 0x7)); out[0*64+15] = (start += ((w0 >> 45) & 0x7)); out[0*64+16] = (start += ((w0 >> 48) & 0x7)); out[0*64+17] = (start += ((w0 >> 51) & 0x7)); out[0*64+18] = (start += ((w0 >> 54) & 0x7)); out[0*64+19] = (start += ((w0 >> 57) & 0x7)); out[0*64+20] = (start += ((w0 >> 60) & 0x7)); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start += ((w0 >> 63) | (w1 << 1) & 0x7)); out[0*64+22] = (start += ((w1 >> 2) & 0x7)); out[0*64+23] = (start += ((w1 >> 5) & 0x7)); out[0*64+24] = (start += ((w1 >> 8) & 0x7)); out[0*64+25] = (start += ((w1 >> 11) & 0x7)); out[0*64+26] = (start += ((w1 >> 14) & 0x7)); out[0*64+27] = (start += ((w1 >> 17) & 0x7)); out[0*64+28] = (start += ((w1 >> 20) & 0x7)); out[0*64+29] = (start += ((w1 >> 23) & 0x7)); out[0*64+30] = (start += ((w1 >> 26) & 0x7)); out[0*64+31] = (start += ((w1 >> 29) & 0x7));;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_4(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xf)); out[0*16+ 1] = (start += ((w0 >> 4) & 0xf)); out[0*16+ 2] = (start += ((w0 >> 8) & 0xf)); out[0*16+ 3] = (start += ((w0 >> 12) & 0xf)); out[0*16+ 4] = (start += ((w0 >> 16) & 0xf)); out[0*16+ 5] = (start += ((w0 >> 20) & 0xf)); out[0*16+ 6] = (start += ((w0 >> 24) & 0xf)); out[0*16+ 7] = (start += ((w0 >> 28) & 0xf)); out[0*16+ 8] = (start += ((w0 >> 32) & 0xf)); out[0*16+ 9] = (start += ((w0 >> 36) & 0xf)); out[0*16+10] = (start += ((w0 >> 40) & 0xf)); out[0*16+11] = (start += ((w0 >> 44) & 0xf)); out[0*16+12] = (start += ((w0 >> 48) & 0xf)); out[0*16+13] = (start += ((w0 >> 52) & 0xf)); out[0*16+14] = (start += ((w0 >> 56) & 0xf)); out[0*16+15] = (start += ((w0 >> 60)));;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xf)); out[1*16+ 1] = (start += ((w0 >> 4) & 0xf)); out[1*16+ 2] = (start += ((w0 >> 8) & 0xf)); out[1*16+ 3] = (start += ((w0 >> 12) & 0xf)); out[1*16+ 4] = (start += ((w0 >> 16) & 0xf)); out[1*16+ 5] = (start += ((w0 >> 20) & 0xf)); out[1*16+ 6] = (start += ((w0 >> 24) & 0xf)); out[1*16+ 7] = (start += ((w0 >> 28) & 0xf)); out[1*16+ 8] = (start += ((w0 >> 32) & 0xf)); out[1*16+ 9] = (start += ((w0 >> 36) & 0xf)); out[1*16+10] = (start += ((w0 >> 40) & 0xf)); out[1*16+11] = (start += ((w0 >> 44) & 0xf)); out[1*16+12] = (start += ((w0 >> 48) & 0xf)); out[1*16+13] = (start += ((w0 >> 52) & 0xf)); out[1*16+14] = (start += ((w0 >> 56) & 0xf)); out[1*16+15] = (start += ((w0 >> 60)));;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_5(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1f)); out[0*64+ 1] = (start += ((w0 >> 5) & 0x1f)); out[0*64+ 2] = (start += ((w0 >> 10) & 0x1f)); out[0*64+ 3] = (start += ((w0 >> 15) & 0x1f)); out[0*64+ 4] = (start += ((w0 >> 20) & 0x1f)); out[0*64+ 5] = (start += ((w0 >> 25) & 0x1f)); out[0*64+ 6] = (start += ((w0 >> 30) & 0x1f)); out[0*64+ 7] = (start += ((w0 >> 35) & 0x1f)); out[0*64+ 8] = (start += ((w0 >> 40) & 0x1f)); out[0*64+ 9] = (start += ((w0 >> 45) & 0x1f)); out[0*64+10] = (start += ((w0 >> 50) & 0x1f)); out[0*64+11] = (start += ((w0 >> 55) & 0x1f)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start += ((w0 >> 60) | (w1 << 4) & 0x1f)); out[0*64+13] = (start += ((w1 >> 1) & 0x1f)); out[0*64+14] = (start += ((w1 >> 6) & 0x1f)); out[0*64+15] = (start += ((w1 >> 11) & 0x1f)); out[0*64+16] = (start += ((w1 >> 16) & 0x1f)); out[0*64+17] = (start += ((w1 >> 21) & 0x1f)); out[0*64+18] = (start += ((w1 >> 26) & 0x1f)); out[0*64+19] = (start += ((w1 >> 31) & 0x1f)); out[0*64+20] = (start += ((w1 >> 36) & 0x1f)); out[0*64+21] = (start += ((w1 >> 41) & 0x1f)); out[0*64+22] = (start += ((w1 >> 46) & 0x1f)); out[0*64+23] = (start += ((w1 >> 51) & 0x1f)); out[0*64+24] = (start += ((w1 >> 56) & 0x1f)); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start += ((w1 >> 61) | (w2 << 3) & 0x1f)); out[0*64+26] = (start += ((w2 >> 2) & 0x1f)); out[0*64+27] = (start += ((w2 >> 7) & 0x1f)); out[0*64+28] = (start += ((w2 >> 12) & 0x1f)); out[0*64+29] = (start += ((w2 >> 17) & 0x1f)); out[0*64+30] = (start += ((w2 >> 22) & 0x1f)); out[0*64+31] = (start += ((w2 >> 27) & 0x1f));;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_6(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3f)); out[0*32+ 1] = (start += ((w0 >> 6) & 0x3f)); out[0*32+ 2] = (start += ((w0 >> 12) & 0x3f)); out[0*32+ 3] = (start += ((w0 >> 18) & 0x3f)); out[0*32+ 4] = (start += ((w0 >> 24) & 0x3f)); out[0*32+ 5] = (start += ((w0 >> 30) & 0x3f)); out[0*32+ 6] = (start += ((w0 >> 36) & 0x3f)); out[0*32+ 7] = (start += ((w0 >> 42) & 0x3f)); out[0*32+ 8] = (start += ((w0 >> 48) & 0x3f)); out[0*32+ 9] = (start += ((w0 >> 54) & 0x3f)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start += ((w0 >> 60) | (w1 << 4) & 0x3f)); out[0*32+11] = (start += ((w1 >> 2) & 0x3f)); out[0*32+12] = (start += ((w1 >> 8) & 0x3f)); out[0*32+13] = (start += ((w1 >> 14) & 0x3f)); out[0*32+14] = (start += ((w1 >> 20) & 0x3f)); out[0*32+15] = (start += ((w1 >> 26) & 0x3f)); out[0*32+16] = (start += ((w1 >> 32) & 0x3f)); out[0*32+17] = (start += ((w1 >> 38) & 0x3f)); out[0*32+18] = (start += ((w1 >> 44) & 0x3f)); out[0*32+19] = (start += ((w1 >> 50) & 0x3f)); out[0*32+20] = (start += ((w1 >> 56) & 0x3f)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start += ((w1 >> 62) | (w2 << 2) & 0x3f)); out[0*32+22] = (start += ((w2 >> 4) & 0x3f)); out[0*32+23] = (start += ((w2 >> 10) & 0x3f)); out[0*32+24] = (start += ((w2 >> 16) & 0x3f)); out[0*32+25] = (start += ((w2 >> 22) & 0x3f)); out[0*32+26] = (start += ((w2 >> 28) & 0x3f)); out[0*32+27] = (start += ((w2 >> 34) & 0x3f)); out[0*32+28] = (start += ((w2 >> 40) & 0x3f)); out[0*32+29] = (start += ((w2 >> 46) & 0x3f)); out[0*32+30] = (start += ((w2 >> 52) & 0x3f)); out[0*32+31] = (start += ((w2 >> 58)));;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_7(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7f)); out[0*64+ 1] = (start += ((w0 >> 7) & 0x7f)); out[0*64+ 2] = (start += ((w0 >> 14) & 0x7f)); out[0*64+ 3] = (start += ((w0 >> 21) & 0x7f)); out[0*64+ 4] = (start += ((w0 >> 28) & 0x7f)); out[0*64+ 5] = (start += ((w0 >> 35) & 0x7f)); out[0*64+ 6] = (start += ((w0 >> 42) & 0x7f)); out[0*64+ 7] = (start += ((w0 >> 49) & 0x7f)); out[0*64+ 8] = (start += ((w0 >> 56) & 0x7f)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w0 >> 63) | (w1 << 1) & 0x7f)); out[0*64+10] = (start += ((w1 >> 6) & 0x7f)); out[0*64+11] = (start += ((w1 >> 13) & 0x7f)); out[0*64+12] = (start += ((w1 >> 20) & 0x7f)); out[0*64+13] = (start += ((w1 >> 27) & 0x7f)); out[0*64+14] = (start += ((w1 >> 34) & 0x7f)); out[0*64+15] = (start += ((w1 >> 41) & 0x7f)); out[0*64+16] = (start += ((w1 >> 48) & 0x7f)); out[0*64+17] = (start += ((w1 >> 55) & 0x7f)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start += ((w1 >> 62) | (w2 << 2) & 0x7f)); out[0*64+19] = (start += ((w2 >> 5) & 0x7f)); out[0*64+20] = (start += ((w2 >> 12) & 0x7f)); out[0*64+21] = (start += ((w2 >> 19) & 0x7f)); out[0*64+22] = (start += ((w2 >> 26) & 0x7f)); out[0*64+23] = (start += ((w2 >> 33) & 0x7f)); out[0*64+24] = (start += ((w2 >> 40) & 0x7f)); out[0*64+25] = (start += ((w2 >> 47) & 0x7f)); out[0*64+26] = (start += ((w2 >> 54) & 0x7f)); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start += ((w2 >> 61) | (w3 << 3) & 0x7f)); out[0*64+28] = (start += ((w3 >> 4) & 0x7f)); out[0*64+29] = (start += ((w3 >> 11) & 0x7f)); out[0*64+30] = (start += ((w3 >> 18) & 0x7f)); out[0*64+31] = (start += ((w3 >> 25) & 0x7f));;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_8(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xff)); out[0*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[0*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[0*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[0*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[0*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[0*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[0*8+ 7] = (start += ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xff)); out[1*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[1*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[1*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[1*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[1*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[1*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[1*8+ 7] = (start += ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xff)); out[2*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[2*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[2*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[2*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[2*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[2*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[2*8+ 7] = (start += ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xff)); out[3*8+ 1] = (start += ((w0 >> 8) & 0xff)); out[3*8+ 2] = (start += ((w0 >> 16) & 0xff)); out[3*8+ 3] = (start += ((w0 >> 24) & 0xff)); out[3*8+ 4] = (start += ((w0 >> 32) & 0xff)); out[3*8+ 5] = (start += ((w0 >> 40) & 0xff)); out[3*8+ 6] = (start += ((w0 >> 48) & 0xff)); out[3*8+ 7] = (start += ((w0 >> 56)));;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_9(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ff)); out[0*64+ 1] = (start += ((w0 >> 9) & 0x1ff)); out[0*64+ 2] = (start += ((w0 >> 18) & 0x1ff)); out[0*64+ 3] = (start += ((w0 >> 27) & 0x1ff)); out[0*64+ 4] = (start += ((w0 >> 36) & 0x1ff)); out[0*64+ 5] = (start += ((w0 >> 45) & 0x1ff)); out[0*64+ 6] = (start += ((w0 >> 54) & 0x1ff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w0 >> 63) | (w1 << 1) & 0x1ff)); out[0*64+ 8] = (start += ((w1 >> 8) & 0x1ff)); out[0*64+ 9] = (start += ((w1 >> 17) & 0x1ff)); out[0*64+10] = (start += ((w1 >> 26) & 0x1ff)); out[0*64+11] = (start += ((w1 >> 35) & 0x1ff)); out[0*64+12] = (start += ((w1 >> 44) & 0x1ff)); out[0*64+13] = (start += ((w1 >> 53) & 0x1ff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (start += ((w1 >> 62) | (w2 << 2) & 0x1ff)); out[0*64+15] = (start += ((w2 >> 7) & 0x1ff)); out[0*64+16] = (start += ((w2 >> 16) & 0x1ff)); out[0*64+17] = (start += ((w2 >> 25) & 0x1ff)); out[0*64+18] = (start += ((w2 >> 34) & 0x1ff)); out[0*64+19] = (start += ((w2 >> 43) & 0x1ff)); out[0*64+20] = (start += ((w2 >> 52) & 0x1ff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (start += ((w2 >> 61) | (w3 << 3) & 0x1ff)); out[0*64+22] = (start += ((w3 >> 6) & 0x1ff)); out[0*64+23] = (start += ((w3 >> 15) & 0x1ff)); out[0*64+24] = (start += ((w3 >> 24) & 0x1ff)); out[0*64+25] = (start += ((w3 >> 33) & 0x1ff)); out[0*64+26] = (start += ((w3 >> 42) & 0x1ff)); out[0*64+27] = (start += ((w3 >> 51) & 0x1ff)); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (start += ((w3 >> 60) | (w4 << 4) & 0x1ff)); out[0*64+29] = (start += ((w4 >> 5) & 0x1ff)); out[0*64+30] = (start += ((w4 >> 14) & 0x1ff)); out[0*64+31] = (start += ((w4 >> 23) & 0x1ff));;}; out += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_10(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ff)); out[0*32+ 1] = (start += ((w0 >> 10) & 0x3ff)); out[0*32+ 2] = (start += ((w0 >> 20) & 0x3ff)); out[0*32+ 3] = (start += ((w0 >> 30) & 0x3ff)); out[0*32+ 4] = (start += ((w0 >> 40) & 0x3ff)); out[0*32+ 5] = (start += ((w0 >> 50) & 0x3ff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w0 >> 60) | (w1 << 4) & 0x3ff)); out[0*32+ 7] = (start += ((w1 >> 6) & 0x3ff)); out[0*32+ 8] = (start += ((w1 >> 16) & 0x3ff)); out[0*32+ 9] = (start += ((w1 >> 26) & 0x3ff)); out[0*32+10] = (start += ((w1 >> 36) & 0x3ff)); out[0*32+11] = (start += ((w1 >> 46) & 0x3ff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (start += ((w1 >> 56) | (w2 << 8) & 0x3ff)); out[0*32+13] = (start += ((w2 >> 2) & 0x3ff)); out[0*32+14] = (start += ((w2 >> 12) & 0x3ff)); out[0*32+15] = (start += ((w2 >> 22) & 0x3ff)); out[0*32+16] = (start += ((w2 >> 32) & 0x3ff)); out[0*32+17] = (start += ((w2 >> 42) & 0x3ff)); out[0*32+18] = (start += ((w2 >> 52) & 0x3ff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (start += ((w2 >> 62) | (w3 << 2) & 0x3ff)); out[0*32+20] = (start += ((w3 >> 8) & 0x3ff)); out[0*32+21] = (start += ((w3 >> 18) & 0x3ff)); out[0*32+22] = (start += ((w3 >> 28) & 0x3ff)); out[0*32+23] = (start += ((w3 >> 38) & 0x3ff)); out[0*32+24] = (start += ((w3 >> 48) & 0x3ff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (start += ((w3 >> 58) | (w4 << 6) & 0x3ff)); out[0*32+26] = (start += ((w4 >> 4) & 0x3ff)); out[0*32+27] = (start += ((w4 >> 14) & 0x3ff)); out[0*32+28] = (start += ((w4 >> 24) & 0x3ff)); out[0*32+29] = (start += ((w4 >> 34) & 0x3ff)); out[0*32+30] = (start += ((w4 >> 44) & 0x3ff)); out[0*32+31] = (start += ((w4 >> 54)));;}; out += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_11(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ff)); out[0*64+ 1] = (start += ((w0 >> 11) & 0x7ff)); out[0*64+ 2] = (start += ((w0 >> 22) & 0x7ff)); out[0*64+ 3] = (start += ((w0 >> 33) & 0x7ff)); out[0*64+ 4] = (start += ((w0 >> 44) & 0x7ff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w0 >> 55) | (w1 << 9) & 0x7ff)); out[0*64+ 6] = (start += ((w1 >> 2) & 0x7ff)); out[0*64+ 7] = (start += ((w1 >> 13) & 0x7ff)); out[0*64+ 8] = (start += ((w1 >> 24) & 0x7ff)); out[0*64+ 9] = (start += ((w1 >> 35) & 0x7ff)); out[0*64+10] = (start += ((w1 >> 46) & 0x7ff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (start += ((w1 >> 57) | (w2 << 7) & 0x7ff)); out[0*64+12] = (start += ((w2 >> 4) & 0x7ff)); out[0*64+13] = (start += ((w2 >> 15) & 0x7ff)); out[0*64+14] = (start += ((w2 >> 26) & 0x7ff)); out[0*64+15] = (start += ((w2 >> 37) & 0x7ff)); out[0*64+16] = (start += ((w2 >> 48) & 0x7ff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (start += ((w2 >> 59) | (w3 << 5) & 0x7ff)); out[0*64+18] = (start += ((w3 >> 6) & 0x7ff)); out[0*64+19] = (start += ((w3 >> 17) & 0x7ff)); out[0*64+20] = (start += ((w3 >> 28) & 0x7ff)); out[0*64+21] = (start += ((w3 >> 39) & 0x7ff)); out[0*64+22] = (start += ((w3 >> 50) & 0x7ff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (start += ((w3 >> 61) | (w4 << 3) & 0x7ff)); out[0*64+24] = (start += ((w4 >> 8) & 0x7ff)); out[0*64+25] = (start += ((w4 >> 19) & 0x7ff)); out[0*64+26] = (start += ((w4 >> 30) & 0x7ff)); out[0*64+27] = (start += ((w4 >> 41) & 0x7ff)); out[0*64+28] = (start += ((w4 >> 52) & 0x7ff)); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (start += ((w4 >> 63) | (w5 << 1) & 0x7ff)); out[0*64+30] = (start += ((w5 >> 10) & 0x7ff)); out[0*64+31] = (start += ((w5 >> 21) & 0x7ff));;}; out += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_12(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfff)); out[0*16+ 1] = (start += ((w0 >> 12) & 0xfff)); out[0*16+ 2] = (start += ((w0 >> 24) & 0xfff)); out[0*16+ 3] = (start += ((w0 >> 36) & 0xfff)); out[0*16+ 4] = (start += ((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (start += ((w0 >> 60) | (w1 << 4) & 0xfff)); out[0*16+ 6] = (start += ((w1 >> 8) & 0xfff)); out[0*16+ 7] = (start += ((w1 >> 20) & 0xfff)); out[0*16+ 8] = (start += ((w1 >> 32) & 0xfff)); out[0*16+ 9] = (start += ((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (start += ((w1 >> 56) | (w2 << 8) & 0xfff)); out[0*16+11] = (start += ((w2 >> 4) & 0xfff)); out[0*16+12] = (start += ((w2 >> 16) & 0xfff)); out[0*16+13] = (start += ((w2 >> 28) & 0xfff)); out[0*16+14] = (start += ((w2 >> 40) & 0xfff)); out[0*16+15] = (start += ((w2 >> 52)));;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfff)); out[1*16+ 1] = (start += ((w0 >> 12) & 0xfff)); out[1*16+ 2] = (start += ((w0 >> 24) & 0xfff)); out[1*16+ 3] = (start += ((w0 >> 36) & 0xfff)); out[1*16+ 4] = (start += ((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (start += ((w0 >> 60) | (w1 << 4) & 0xfff)); out[1*16+ 6] = (start += ((w1 >> 8) & 0xfff)); out[1*16+ 7] = (start += ((w1 >> 20) & 0xfff)); out[1*16+ 8] = (start += ((w1 >> 32) & 0xfff)); out[1*16+ 9] = (start += ((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (start += ((w1 >> 56) | (w2 << 8) & 0xfff)); out[1*16+11] = (start += ((w2 >> 4) & 0xfff)); out[1*16+12] = (start += ((w2 >> 16) & 0xfff)); out[1*16+13] = (start += ((w2 >> 28) & 0xfff)); out[1*16+14] = (start += ((w2 >> 40) & 0xfff)); out[1*16+15] = (start += ((w2 >> 52)));;}; out += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_13(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fff)); out[0*64+ 1] = (start += ((w0 >> 13) & 0x1fff)); out[0*64+ 2] = (start += ((w0 >> 26) & 0x1fff)); out[0*64+ 3] = (start += ((w0 >> 39) & 0x1fff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w0 >> 52) | (w1 << 12) & 0x1fff)); out[0*64+ 5] = (start += ((w1 >> 1) & 0x1fff)); out[0*64+ 6] = (start += ((w1 >> 14) & 0x1fff)); out[0*64+ 7] = (start += ((w1 >> 27) & 0x1fff)); out[0*64+ 8] = (start += ((w1 >> 40) & 0x1fff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w1 >> 53) | (w2 << 11) & 0x1fff)); out[0*64+10] = (start += ((w2 >> 2) & 0x1fff)); out[0*64+11] = (start += ((w2 >> 15) & 0x1fff)); out[0*64+12] = (start += ((w2 >> 28) & 0x1fff)); out[0*64+13] = (start += ((w2 >> 41) & 0x1fff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (start += ((w2 >> 54) | (w3 << 10) & 0x1fff)); out[0*64+15] = (start += ((w3 >> 3) & 0x1fff)); out[0*64+16] = (start += ((w3 >> 16) & 0x1fff)); out[0*64+17] = (start += ((w3 >> 29) & 0x1fff)); out[0*64+18] = (start += ((w3 >> 42) & 0x1fff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (start += ((w3 >> 55) | (w4 << 9) & 0x1fff)); out[0*64+20] = (start += ((w4 >> 4) & 0x1fff)); out[0*64+21] = (start += ((w4 >> 17) & 0x1fff)); out[0*64+22] = (start += ((w4 >> 30) & 0x1fff)); out[0*64+23] = (start += ((w4 >> 43) & 0x1fff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (start += ((w4 >> 56) | (w5 << 8) & 0x1fff)); out[0*64+25] = (start += ((w5 >> 5) & 0x1fff)); out[0*64+26] = (start += ((w5 >> 18) & 0x1fff)); out[0*64+27] = (start += ((w5 >> 31) & 0x1fff)); out[0*64+28] = (start += ((w5 >> 44) & 0x1fff)); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (start += ((w5 >> 57) | (w6 << 7) & 0x1fff)); out[0*64+30] = (start += ((w6 >> 6) & 0x1fff)); out[0*64+31] = (start += ((w6 >> 19) & 0x1fff));;}; out += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_14(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fff)); out[0*32+ 1] = (start += ((w0 >> 14) & 0x3fff)); out[0*32+ 2] = (start += ((w0 >> 28) & 0x3fff)); out[0*32+ 3] = (start += ((w0 >> 42) & 0x3fff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w0 >> 56) | (w1 << 8) & 0x3fff)); out[0*32+ 5] = (start += ((w1 >> 6) & 0x3fff)); out[0*32+ 6] = (start += ((w1 >> 20) & 0x3fff)); out[0*32+ 7] = (start += ((w1 >> 34) & 0x3fff)); out[0*32+ 8] = (start += ((w1 >> 48) & 0x3fff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w1 >> 62) | (w2 << 2) & 0x3fff)); out[0*32+10] = (start += ((w2 >> 12) & 0x3fff)); out[0*32+11] = (start += ((w2 >> 26) & 0x3fff)); out[0*32+12] = (start += ((w2 >> 40) & 0x3fff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (start += ((w2 >> 54) | (w3 << 10) & 0x3fff)); out[0*32+14] = (start += ((w3 >> 4) & 0x3fff)); out[0*32+15] = (start += ((w3 >> 18) & 0x3fff)); out[0*32+16] = (start += ((w3 >> 32) & 0x3fff)); out[0*32+17] = (start += ((w3 >> 46) & 0x3fff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (start += ((w3 >> 60) | (w4 << 4) & 0x3fff)); out[0*32+19] = (start += ((w4 >> 10) & 0x3fff)); out[0*32+20] = (start += ((w4 >> 24) & 0x3fff)); out[0*32+21] = (start += ((w4 >> 38) & 0x3fff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (start += ((w4 >> 52) | (w5 << 12) & 0x3fff)); out[0*32+23] = (start += ((w5 >> 2) & 0x3fff)); out[0*32+24] = (start += ((w5 >> 16) & 0x3fff)); out[0*32+25] = (start += ((w5 >> 30) & 0x3fff)); out[0*32+26] = (start += ((w5 >> 44) & 0x3fff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (start += ((w5 >> 58) | (w6 << 6) & 0x3fff)); out[0*32+28] = (start += ((w6 >> 8) & 0x3fff)); out[0*32+29] = (start += ((w6 >> 22) & 0x3fff)); out[0*32+30] = (start += ((w6 >> 36) & 0x3fff)); out[0*32+31] = (start += ((w6 >> 50)));;}; out += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_15(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fff)); out[0*64+ 1] = (start += ((w0 >> 15) & 0x7fff)); out[0*64+ 2] = (start += ((w0 >> 30) & 0x7fff)); out[0*64+ 3] = (start += ((w0 >> 45) & 0x7fff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w0 >> 60) | (w1 << 4) & 0x7fff)); out[0*64+ 5] = (start += ((w1 >> 11) & 0x7fff)); out[0*64+ 6] = (start += ((w1 >> 26) & 0x7fff)); out[0*64+ 7] = (start += ((w1 >> 41) & 0x7fff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w1 >> 56) | (w2 << 8) & 0x7fff)); out[0*64+ 9] = (start += ((w2 >> 7) & 0x7fff)); out[0*64+10] = (start += ((w2 >> 22) & 0x7fff)); out[0*64+11] = (start += ((w2 >> 37) & 0x7fff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (start += ((w2 >> 52) | (w3 << 12) & 0x7fff)); out[0*64+13] = (start += ((w3 >> 3) & 0x7fff)); out[0*64+14] = (start += ((w3 >> 18) & 0x7fff)); out[0*64+15] = (start += ((w3 >> 33) & 0x7fff)); out[0*64+16] = (start += ((w3 >> 48) & 0x7fff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (start += ((w3 >> 63) | (w4 << 1) & 0x7fff)); out[0*64+18] = (start += ((w4 >> 14) & 0x7fff)); out[0*64+19] = (start += ((w4 >> 29) & 0x7fff)); out[0*64+20] = (start += ((w4 >> 44) & 0x7fff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (start += ((w4 >> 59) | (w5 << 5) & 0x7fff)); out[0*64+22] = (start += ((w5 >> 10) & 0x7fff)); out[0*64+23] = (start += ((w5 >> 25) & 0x7fff)); out[0*64+24] = (start += ((w5 >> 40) & 0x7fff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (start += ((w5 >> 55) | (w6 << 9) & 0x7fff)); out[0*64+26] = (start += ((w6 >> 6) & 0x7fff)); out[0*64+27] = (start += ((w6 >> 21) & 0x7fff)); out[0*64+28] = (start += ((w6 >> 36) & 0x7fff)); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (start += ((w6 >> 51) | (w7 << 13) & 0x7fff)); out[0*64+30] = (start += ((w7 >> 2) & 0x7fff)); out[0*64+31] = (start += ((w7 >> 17) & 0x7fff));;}; out += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_16(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = (start += (*(uint16_t *)(in+0*8+ 0))); out[0*4+ 1] = (start += (*(uint16_t *)(in+0*8+ 2))); out[0*4+ 2] = (start += (*(uint16_t *)(in+0*8+ 4))); out[0*4+ 3] = (start += (*(uint16_t *)(in+0*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = (start += (*(uint16_t *)(in+1*8+ 0))); out[1*4+ 1] = (start += (*(uint16_t *)(in+1*8+ 2))); out[1*4+ 2] = (start += (*(uint16_t *)(in+1*8+ 4))); out[1*4+ 3] = (start += (*(uint16_t *)(in+1*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = (start += (*(uint16_t *)(in+2*8+ 0))); out[2*4+ 1] = (start += (*(uint16_t *)(in+2*8+ 2))); out[2*4+ 2] = (start += (*(uint16_t *)(in+2*8+ 4))); out[2*4+ 3] = (start += (*(uint16_t *)(in+2*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = (start += (*(uint16_t *)(in+3*8+ 0))); out[3*4+ 1] = (start += (*(uint16_t *)(in+3*8+ 2))); out[3*4+ 2] = (start += (*(uint16_t *)(in+3*8+ 4))); out[3*4+ 3] = (start += (*(uint16_t *)(in+3*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = (start += (*(uint16_t *)(in+4*8+ 0))); out[4*4+ 1] = (start += (*(uint16_t *)(in+4*8+ 2))); out[4*4+ 2] = (start += (*(uint16_t *)(in+4*8+ 4))); out[4*4+ 3] = (start += (*(uint16_t *)(in+4*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = (start += (*(uint16_t *)(in+5*8+ 0))); out[5*4+ 1] = (start += (*(uint16_t *)(in+5*8+ 2))); out[5*4+ 2] = (start += (*(uint16_t *)(in+5*8+ 4))); out[5*4+ 3] = (start += (*(uint16_t *)(in+5*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = (start += (*(uint16_t *)(in+6*8+ 0))); out[6*4+ 1] = (start += (*(uint16_t *)(in+6*8+ 2))); out[6*4+ 2] = (start += (*(uint16_t *)(in+6*8+ 4))); out[6*4+ 3] = (start += (*(uint16_t *)(in+6*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = (start += (*(uint16_t *)(in+7*8+ 0))); out[7*4+ 1] = (start += (*(uint16_t *)(in+7*8+ 2))); out[7*4+ 2] = (start += (*(uint16_t *)(in+7*8+ 4))); out[7*4+ 3] = (start += (*(uint16_t *)(in+7*8+ 6)));;}; out += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_17(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*17)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffff)); out[0*64+ 1] = (start += ((w0 >> 17) & 0x1ffff)); out[0*64+ 2] = (start += ((w0 >> 34) & 0x1ffff)); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w0 >> 51) | (w1 << 13) & 0x1ffff)); out[0*64+ 4] = (start += ((w1 >> 4) & 0x1ffff)); out[0*64+ 5] = (start += ((w1 >> 21) & 0x1ffff)); out[0*64+ 6] = (start += ((w1 >> 38) & 0x1ffff)); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w1 >> 55) | (w2 << 9) & 0x1ffff)); out[0*64+ 8] = (start += ((w2 >> 8) & 0x1ffff)); out[0*64+ 9] = (start += ((w2 >> 25) & 0x1ffff)); out[0*64+10] = (start += ((w2 >> 42) & 0x1ffff)); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*64+11] = (start += ((w2 >> 59) | (w3 << 5) & 0x1ffff)); out[0*64+12] = (start += ((w3 >> 12) & 0x1ffff)); out[0*64+13] = (start += ((w3 >> 29) & 0x1ffff)); out[0*64+14] = (start += ((w3 >> 46) & 0x1ffff)); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*64+15] = (start += ((w3 >> 63) | (w4 << 1) & 0x1ffff)); out[0*64+16] = (start += ((w4 >> 16) & 0x1ffff)); out[0*64+17] = (start += ((w4 >> 33) & 0x1ffff)); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*64+18] = (start += ((w4 >> 50) | (w5 << 14) & 0x1ffff)); out[0*64+19] = (start += ((w5 >> 3) & 0x1ffff)); out[0*64+20] = (start += ((w5 >> 20) & 0x1ffff)); out[0*64+21] = (start += ((w5 >> 37) & 0x1ffff)); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*64+22] = (start += ((w5 >> 54) | (w6 << 10) & 0x1ffff)); out[0*64+23] = (start += ((w6 >> 7) & 0x1ffff)); out[0*64+24] = (start += ((w6 >> 24) & 0x1ffff)); out[0*64+25] = (start += ((w6 >> 41) & 0x1ffff)); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*64+26] = (start += ((w6 >> 58) | (w7 << 6) & 0x1ffff)); out[0*64+27] = (start += ((w7 >> 11) & 0x1ffff)); out[0*64+28] = (start += ((w7 >> 28) & 0x1ffff)); out[0*64+29] = (start += ((w7 >> 45) & 0x1ffff)); w8 = *(uint32_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*64+30] = (start += ((w7 >> 62) | (w8 << 2) & 0x1ffff)); out[0*64+31] = (start += ((w8 >> 15) & 0x1ffff));;}; out += 32; in += 17*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_18(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*18)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffff)); out[0*32+ 1] = (start += ((w0 >> 18) & 0x3ffff)); out[0*32+ 2] = (start += ((w0 >> 36) & 0x3ffff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w0 >> 54) | (w1 << 10) & 0x3ffff)); out[0*32+ 4] = (start += ((w1 >> 8) & 0x3ffff)); out[0*32+ 5] = (start += ((w1 >> 26) & 0x3ffff)); out[0*32+ 6] = (start += ((w1 >> 44) & 0x3ffff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w1 >> 62) | (w2 << 2) & 0x3ffff)); out[0*32+ 8] = (start += ((w2 >> 16) & 0x3ffff)); out[0*32+ 9] = (start += ((w2 >> 34) & 0x3ffff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*32+10] = (start += ((w2 >> 52) | (w3 << 12) & 0x3ffff)); out[0*32+11] = (start += ((w3 >> 6) & 0x3ffff)); out[0*32+12] = (start += ((w3 >> 24) & 0x3ffff)); out[0*32+13] = (start += ((w3 >> 42) & 0x3ffff)); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*32+14] = (start += ((w3 >> 60) | (w4 << 4) & 0x3ffff)); out[0*32+15] = (start += ((w4 >> 14) & 0x3ffff)); out[0*32+16] = (start += ((w4 >> 32) & 0x3ffff)); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*32+17] = (start += ((w4 >> 50) | (w5 << 14) & 0x3ffff)); out[0*32+18] = (start += ((w5 >> 4) & 0x3ffff)); out[0*32+19] = (start += ((w5 >> 22) & 0x3ffff)); out[0*32+20] = (start += ((w5 >> 40) & 0x3ffff)); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*32+21] = (start += ((w5 >> 58) | (w6 << 6) & 0x3ffff)); out[0*32+22] = (start += ((w6 >> 12) & 0x3ffff)); out[0*32+23] = (start += ((w6 >> 30) & 0x3ffff)); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*32+24] = (start += ((w6 >> 48) | (w7 << 16) & 0x3ffff)); out[0*32+25] = (start += ((w7 >> 2) & 0x3ffff)); out[0*32+26] = (start += ((w7 >> 20) & 0x3ffff)); out[0*32+27] = (start += ((w7 >> 38) & 0x3ffff)); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*32+28] = (start += ((w7 >> 56) | (w8 << 8) & 0x3ffff)); out[0*32+29] = (start += ((w8 >> 10) & 0x3ffff)); out[0*32+30] = (start += ((w8 >> 28) & 0x3ffff)); out[0*32+31] = (start += ((w8 >> 46)));;}; out += 32; in += 18*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_19(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*19)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffff)); out[0*64+ 1] = (start += ((w0 >> 19) & 0x7ffff)); out[0*64+ 2] = (start += ((w0 >> 38) & 0x7ffff)); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w0 >> 57) | (w1 << 7) & 0x7ffff)); out[0*64+ 4] = (start += ((w1 >> 12) & 0x7ffff)); out[0*64+ 5] = (start += ((w1 >> 31) & 0x7ffff)); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w1 >> 50) | (w2 << 14) & 0x7ffff)); out[0*64+ 7] = (start += ((w2 >> 5) & 0x7ffff)); out[0*64+ 8] = (start += ((w2 >> 24) & 0x7ffff)); out[0*64+ 9] = (start += ((w2 >> 43) & 0x7ffff)); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*64+10] = (start += ((w2 >> 62) | (w3 << 2) & 0x7ffff)); out[0*64+11] = (start += ((w3 >> 17) & 0x7ffff)); out[0*64+12] = (start += ((w3 >> 36) & 0x7ffff)); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*64+13] = (start += ((w3 >> 55) | (w4 << 9) & 0x7ffff)); out[0*64+14] = (start += ((w4 >> 10) & 0x7ffff)); out[0*64+15] = (start += ((w4 >> 29) & 0x7ffff)); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*64+16] = (start += ((w4 >> 48) | (w5 << 16) & 0x7ffff)); out[0*64+17] = (start += ((w5 >> 3) & 0x7ffff)); out[0*64+18] = (start += ((w5 >> 22) & 0x7ffff)); out[0*64+19] = (start += ((w5 >> 41) & 0x7ffff)); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*64+20] = (start += ((w5 >> 60) | (w6 << 4) & 0x7ffff)); out[0*64+21] = (start += ((w6 >> 15) & 0x7ffff)); out[0*64+22] = (start += ((w6 >> 34) & 0x7ffff)); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*64+23] = (start += ((w6 >> 53) | (w7 << 11) & 0x7ffff)); out[0*64+24] = (start += ((w7 >> 8) & 0x7ffff)); out[0*64+25] = (start += ((w7 >> 27) & 0x7ffff)); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*64+26] = (start += ((w7 >> 46) | (w8 << 18) & 0x7ffff)); out[0*64+27] = (start += ((w8 >> 1) & 0x7ffff)); out[0*64+28] = (start += ((w8 >> 20) & 0x7ffff)); out[0*64+29] = (start += ((w8 >> 39) & 0x7ffff)); w9 = *(uint32_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*64+30] = (start += ((w8 >> 58) | (w9 << 6) & 0x7ffff)); out[0*64+31] = (start += ((w9 >> 13) & 0x7ffff));;}; out += 32; in += 19*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_20(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*20)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffff)); out[0*16+ 1] = (start += ((w0 >> 20) & 0xfffff)); out[0*16+ 2] = (start += ((w0 >> 40) & 0xfffff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*16+ 3] = (start += ((w0 >> 60) | (w1 << 4) & 0xfffff)); out[0*16+ 4] = (start += ((w1 >> 16) & 0xfffff)); out[0*16+ 5] = (start += ((w1 >> 36) & 0xfffff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*16+ 6] = (start += ((w1 >> 56) | (w2 << 8) & 0xfffff)); out[0*16+ 7] = (start += ((w2 >> 12) & 0xfffff)); out[0*16+ 8] = (start += ((w2 >> 32) & 0xfffff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*16+ 9] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffff)); out[0*16+10] = (start += ((w3 >> 8) & 0xfffff)); out[0*16+11] = (start += ((w3 >> 28) & 0xfffff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*16+12] = (start += ((w3 >> 48) | (w4 << 16) & 0xfffff)); out[0*16+13] = (start += ((w4 >> 4) & 0xfffff)); out[0*16+14] = (start += ((w4 >> 24) & 0xfffff)); out[0*16+15] = (start += ((w4 >> 44)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffff)); out[1*16+ 1] = (start += ((w0 >> 20) & 0xfffff)); out[1*16+ 2] = (start += ((w0 >> 40) & 0xfffff)); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*16+ 3] = (start += ((w0 >> 60) | (w1 << 4) & 0xfffff)); out[1*16+ 4] = (start += ((w1 >> 16) & 0xfffff)); out[1*16+ 5] = (start += ((w1 >> 36) & 0xfffff)); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*16+ 6] = (start += ((w1 >> 56) | (w2 << 8) & 0xfffff)); out[1*16+ 7] = (start += ((w2 >> 12) & 0xfffff)); out[1*16+ 8] = (start += ((w2 >> 32) & 0xfffff)); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*16+ 9] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffff)); out[1*16+10] = (start += ((w3 >> 8) & 0xfffff)); out[1*16+11] = (start += ((w3 >> 28) & 0xfffff)); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*16+12] = (start += ((w3 >> 48) | (w4 << 16) & 0xfffff)); out[1*16+13] = (start += ((w4 >> 4) & 0xfffff)); out[1*16+14] = (start += ((w4 >> 24) & 0xfffff)); out[1*16+15] = (start += ((w4 >> 44)));;}; out += 32; in += 20*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_21(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*21)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffff)); out[0*64+ 1] = (start += ((w0 >> 21) & 0x1fffff)); out[0*64+ 2] = (start += ((w0 >> 42) & 0x1fffff)); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w0 >> 63) | (w1 << 1) & 0x1fffff)); out[0*64+ 4] = (start += ((w1 >> 20) & 0x1fffff)); out[0*64+ 5] = (start += ((w1 >> 41) & 0x1fffff)); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w1 >> 62) | (w2 << 2) & 0x1fffff)); out[0*64+ 7] = (start += ((w2 >> 19) & 0x1fffff)); out[0*64+ 8] = (start += ((w2 >> 40) & 0x1fffff)); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w2 >> 61) | (w3 << 3) & 0x1fffff)); out[0*64+10] = (start += ((w3 >> 18) & 0x1fffff)); out[0*64+11] = (start += ((w3 >> 39) & 0x1fffff)); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*64+12] = (start += ((w3 >> 60) | (w4 << 4) & 0x1fffff)); out[0*64+13] = (start += ((w4 >> 17) & 0x1fffff)); out[0*64+14] = (start += ((w4 >> 38) & 0x1fffff)); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*64+15] = (start += ((w4 >> 59) | (w5 << 5) & 0x1fffff)); out[0*64+16] = (start += ((w5 >> 16) & 0x1fffff)); out[0*64+17] = (start += ((w5 >> 37) & 0x1fffff)); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*64+18] = (start += ((w5 >> 58) | (w6 << 6) & 0x1fffff)); out[0*64+19] = (start += ((w6 >> 15) & 0x1fffff)); out[0*64+20] = (start += ((w6 >> 36) & 0x1fffff)); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*64+21] = (start += ((w6 >> 57) | (w7 << 7) & 0x1fffff)); out[0*64+22] = (start += ((w7 >> 14) & 0x1fffff)); out[0*64+23] = (start += ((w7 >> 35) & 0x1fffff)); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*64+24] = (start += ((w7 >> 56) | (w8 << 8) & 0x1fffff)); out[0*64+25] = (start += ((w8 >> 13) & 0x1fffff)); out[0*64+26] = (start += ((w8 >> 34) & 0x1fffff)); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*64+27] = (start += ((w8 >> 55) | (w9 << 9) & 0x1fffff)); out[0*64+28] = (start += ((w9 >> 12) & 0x1fffff)); out[0*64+29] = (start += ((w9 >> 33) & 0x1fffff)); w10 = *(uint32_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*64+30] = (start += ((w9 >> 54) | (w10 << 10) & 0x1fffff)); out[0*64+31] = (start += ((w10 >> 11) & 0x1fffff));;}; out += 32; in += 21*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_22(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*22)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffff)); out[0*32+ 1] = (start += ((w0 >> 22) & 0x3fffff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w0 >> 44) | (w1 << 20) & 0x3fffff)); out[0*32+ 3] = (start += ((w1 >> 2) & 0x3fffff)); out[0*32+ 4] = (start += ((w1 >> 24) & 0x3fffff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w1 >> 46) | (w2 << 18) & 0x3fffff)); out[0*32+ 6] = (start += ((w2 >> 4) & 0x3fffff)); out[0*32+ 7] = (start += ((w2 >> 26) & 0x3fffff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w2 >> 48) | (w3 << 16) & 0x3fffff)); out[0*32+ 9] = (start += ((w3 >> 6) & 0x3fffff)); out[0*32+10] = (start += ((w3 >> 28) & 0x3fffff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*32+11] = (start += ((w3 >> 50) | (w4 << 14) & 0x3fffff)); out[0*32+12] = (start += ((w4 >> 8) & 0x3fffff)); out[0*32+13] = (start += ((w4 >> 30) & 0x3fffff)); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*32+14] = (start += ((w4 >> 52) | (w5 << 12) & 0x3fffff)); out[0*32+15] = (start += ((w5 >> 10) & 0x3fffff)); out[0*32+16] = (start += ((w5 >> 32) & 0x3fffff)); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*32+17] = (start += ((w5 >> 54) | (w6 << 10) & 0x3fffff)); out[0*32+18] = (start += ((w6 >> 12) & 0x3fffff)); out[0*32+19] = (start += ((w6 >> 34) & 0x3fffff)); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*32+20] = (start += ((w6 >> 56) | (w7 << 8) & 0x3fffff)); out[0*32+21] = (start += ((w7 >> 14) & 0x3fffff)); out[0*32+22] = (start += ((w7 >> 36) & 0x3fffff)); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*32+23] = (start += ((w7 >> 58) | (w8 << 6) & 0x3fffff)); out[0*32+24] = (start += ((w8 >> 16) & 0x3fffff)); out[0*32+25] = (start += ((w8 >> 38) & 0x3fffff)); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*32+26] = (start += ((w8 >> 60) | (w9 << 4) & 0x3fffff)); out[0*32+27] = (start += ((w9 >> 18) & 0x3fffff)); out[0*32+28] = (start += ((w9 >> 40) & 0x3fffff)); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*32+29] = (start += ((w9 >> 62) | (w10 << 2) & 0x3fffff)); out[0*32+30] = (start += ((w10 >> 20) & 0x3fffff)); out[0*32+31] = (start += ((w10 >> 42)));;}; out += 32; in += 22*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_23(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*23)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffff)); out[0*64+ 1] = (start += ((w0 >> 23) & 0x7fffff)); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 46) | (w1 << 18) & 0x7fffff)); out[0*64+ 3] = (start += ((w1 >> 5) & 0x7fffff)); out[0*64+ 4] = (start += ((w1 >> 28) & 0x7fffff)); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w1 >> 51) | (w2 << 13) & 0x7fffff)); out[0*64+ 6] = (start += ((w2 >> 10) & 0x7fffff)); out[0*64+ 7] = (start += ((w2 >> 33) & 0x7fffff)); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w2 >> 56) | (w3 << 8) & 0x7fffff)); out[0*64+ 9] = (start += ((w3 >> 15) & 0x7fffff)); out[0*64+10] = (start += ((w3 >> 38) & 0x7fffff)); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*64+11] = (start += ((w3 >> 61) | (w4 << 3) & 0x7fffff)); out[0*64+12] = (start += ((w4 >> 20) & 0x7fffff)); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*64+13] = (start += ((w4 >> 43) | (w5 << 21) & 0x7fffff)); out[0*64+14] = (start += ((w5 >> 2) & 0x7fffff)); out[0*64+15] = (start += ((w5 >> 25) & 0x7fffff)); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*64+16] = (start += ((w5 >> 48) | (w6 << 16) & 0x7fffff)); out[0*64+17] = (start += ((w6 >> 7) & 0x7fffff)); out[0*64+18] = (start += ((w6 >> 30) & 0x7fffff)); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*64+19] = (start += ((w6 >> 53) | (w7 << 11) & 0x7fffff)); out[0*64+20] = (start += ((w7 >> 12) & 0x7fffff)); out[0*64+21] = (start += ((w7 >> 35) & 0x7fffff)); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*64+22] = (start += ((w7 >> 58) | (w8 << 6) & 0x7fffff)); out[0*64+23] = (start += ((w8 >> 17) & 0x7fffff)); out[0*64+24] = (start += ((w8 >> 40) & 0x7fffff)); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*64+25] = (start += ((w8 >> 63) | (w9 << 1) & 0x7fffff)); out[0*64+26] = (start += ((w9 >> 22) & 0x7fffff)); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*64+27] = (start += ((w9 >> 45) | (w10 << 19) & 0x7fffff)); out[0*64+28] = (start += ((w10 >> 4) & 0x7fffff)); out[0*64+29] = (start += ((w10 >> 27) & 0x7fffff)); w11 = *(uint32_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*64+30] = (start += ((w10 >> 50) | (w11 << 14) & 0x7fffff)); out[0*64+31] = (start += ((w11 >> 9) & 0x7fffff));;}; out += 32; in += 23*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_24(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*24)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xffffff)); out[0*8+ 1] = (start += ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[0*8+ 3] = (start += ((w1 >> 8) & 0xffffff)); out[0*8+ 4] = (start += ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[0*8+ 6] = (start += ((w2 >> 16) & 0xffffff)); out[0*8+ 7] = (start += ((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xffffff)); out[1*8+ 1] = (start += ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[1*8+ 3] = (start += ((w1 >> 8) & 0xffffff)); out[1*8+ 4] = (start += ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[1*8+ 6] = (start += ((w2 >> 16) & 0xffffff)); out[1*8+ 7] = (start += ((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xffffff)); out[2*8+ 1] = (start += ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[2*8+ 3] = (start += ((w1 >> 8) & 0xffffff)); out[2*8+ 4] = (start += ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[2*8+ 6] = (start += ((w2 >> 16) & 0xffffff)); out[2*8+ 7] = (start += ((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xffffff)); out[3*8+ 1] = (start += ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[3*8+ 3] = (start += ((w1 >> 8) & 0xffffff)); out[3*8+ 4] = (start += ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[3*8+ 6] = (start += ((w2 >> 16) & 0xffffff)); out[3*8+ 7] = (start += ((w2 >> 40)));;}; out += 32; in += 24*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_25(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*25)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffffff)); out[0*64+ 1] = (start += ((w0 >> 25) & 0x1ffffff)); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 50) | (w1 << 14) & 0x1ffffff)); out[0*64+ 3] = (start += ((w1 >> 11) & 0x1ffffff)); out[0*64+ 4] = (start += ((w1 >> 36) & 0x1ffffff)); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w1 >> 61) | (w2 << 3) & 0x1ffffff)); out[0*64+ 6] = (start += ((w2 >> 22) & 0x1ffffff)); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w2 >> 47) | (w3 << 17) & 0x1ffffff)); out[0*64+ 8] = (start += ((w3 >> 8) & 0x1ffffff)); out[0*64+ 9] = (start += ((w3 >> 33) & 0x1ffffff)); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*64+10] = (start += ((w3 >> 58) | (w4 << 6) & 0x1ffffff)); out[0*64+11] = (start += ((w4 >> 19) & 0x1ffffff)); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*64+12] = (start += ((w4 >> 44) | (w5 << 20) & 0x1ffffff)); out[0*64+13] = (start += ((w5 >> 5) & 0x1ffffff)); out[0*64+14] = (start += ((w5 >> 30) & 0x1ffffff)); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*64+15] = (start += ((w5 >> 55) | (w6 << 9) & 0x1ffffff)); out[0*64+16] = (start += ((w6 >> 16) & 0x1ffffff)); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*64+17] = (start += ((w6 >> 41) | (w7 << 23) & 0x1ffffff)); out[0*64+18] = (start += ((w7 >> 2) & 0x1ffffff)); out[0*64+19] = (start += ((w7 >> 27) & 0x1ffffff)); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*64+20] = (start += ((w7 >> 52) | (w8 << 12) & 0x1ffffff)); out[0*64+21] = (start += ((w8 >> 13) & 0x1ffffff)); out[0*64+22] = (start += ((w8 >> 38) & 0x1ffffff)); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*64+23] = (start += ((w8 >> 63) | (w9 << 1) & 0x1ffffff)); out[0*64+24] = (start += ((w9 >> 24) & 0x1ffffff)); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*64+25] = (start += ((w9 >> 49) | (w10 << 15) & 0x1ffffff)); out[0*64+26] = (start += ((w10 >> 10) & 0x1ffffff)); out[0*64+27] = (start += ((w10 >> 35) & 0x1ffffff)); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*64+28] = (start += ((w10 >> 60) | (w11 << 4) & 0x1ffffff)); out[0*64+29] = (start += ((w11 >> 21) & 0x1ffffff)); w12 = *(uint32_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*64+30] = (start += ((w11 >> 46) | (w12 << 18) & 0x1ffffff)); out[0*64+31] = (start += ((w12 >> 7) & 0x1ffffff));;}; out += 32; in += 25*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_26(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*26)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffffff)); out[0*32+ 1] = (start += ((w0 >> 26) & 0x3ffffff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w0 >> 52) | (w1 << 12) & 0x3ffffff)); out[0*32+ 3] = (start += ((w1 >> 14) & 0x3ffffff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w1 >> 40) | (w2 << 24) & 0x3ffffff)); out[0*32+ 5] = (start += ((w2 >> 2) & 0x3ffffff)); out[0*32+ 6] = (start += ((w2 >> 28) & 0x3ffffff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w2 >> 54) | (w3 << 10) & 0x3ffffff)); out[0*32+ 8] = (start += ((w3 >> 16) & 0x3ffffff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w3 >> 42) | (w4 << 22) & 0x3ffffff)); out[0*32+10] = (start += ((w4 >> 4) & 0x3ffffff)); out[0*32+11] = (start += ((w4 >> 30) & 0x3ffffff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*32+12] = (start += ((w4 >> 56) | (w5 << 8) & 0x3ffffff)); out[0*32+13] = (start += ((w5 >> 18) & 0x3ffffff)); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*32+14] = (start += ((w5 >> 44) | (w6 << 20) & 0x3ffffff)); out[0*32+15] = (start += ((w6 >> 6) & 0x3ffffff)); out[0*32+16] = (start += ((w6 >> 32) & 0x3ffffff)); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*32+17] = (start += ((w6 >> 58) | (w7 << 6) & 0x3ffffff)); out[0*32+18] = (start += ((w7 >> 20) & 0x3ffffff)); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*32+19] = (start += ((w7 >> 46) | (w8 << 18) & 0x3ffffff)); out[0*32+20] = (start += ((w8 >> 8) & 0x3ffffff)); out[0*32+21] = (start += ((w8 >> 34) & 0x3ffffff)); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*32+22] = (start += ((w8 >> 60) | (w9 << 4) & 0x3ffffff)); out[0*32+23] = (start += ((w9 >> 22) & 0x3ffffff)); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*32+24] = (start += ((w9 >> 48) | (w10 << 16) & 0x3ffffff)); out[0*32+25] = (start += ((w10 >> 10) & 0x3ffffff)); out[0*32+26] = (start += ((w10 >> 36) & 0x3ffffff)); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*32+27] = (start += ((w10 >> 62) | (w11 << 2) & 0x3ffffff)); out[0*32+28] = (start += ((w11 >> 24) & 0x3ffffff)); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*32+29] = (start += ((w11 >> 50) | (w12 << 14) & 0x3ffffff)); out[0*32+30] = (start += ((w12 >> 12) & 0x3ffffff)); out[0*32+31] = (start += ((w12 >> 38)));;}; out += 32; in += 26*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_27(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*27)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffffff)); out[0*64+ 1] = (start += ((w0 >> 27) & 0x7ffffff)); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 54) | (w1 << 10) & 0x7ffffff)); out[0*64+ 3] = (start += ((w1 >> 17) & 0x7ffffff)); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w1 >> 44) | (w2 << 20) & 0x7ffffff)); out[0*64+ 5] = (start += ((w2 >> 7) & 0x7ffffff)); out[0*64+ 6] = (start += ((w2 >> 34) & 0x7ffffff)); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w2 >> 61) | (w3 << 3) & 0x7ffffff)); out[0*64+ 8] = (start += ((w3 >> 24) & 0x7ffffff)); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w3 >> 51) | (w4 << 13) & 0x7ffffff)); out[0*64+10] = (start += ((w4 >> 14) & 0x7ffffff)); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*64+11] = (start += ((w4 >> 41) | (w5 << 23) & 0x7ffffff)); out[0*64+12] = (start += ((w5 >> 4) & 0x7ffffff)); out[0*64+13] = (start += ((w5 >> 31) & 0x7ffffff)); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*64+14] = (start += ((w5 >> 58) | (w6 << 6) & 0x7ffffff)); out[0*64+15] = (start += ((w6 >> 21) & 0x7ffffff)); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*64+16] = (start += ((w6 >> 48) | (w7 << 16) & 0x7ffffff)); out[0*64+17] = (start += ((w7 >> 11) & 0x7ffffff)); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*64+18] = (start += ((w7 >> 38) | (w8 << 26) & 0x7ffffff)); out[0*64+19] = (start += ((w8 >> 1) & 0x7ffffff)); out[0*64+20] = (start += ((w8 >> 28) & 0x7ffffff)); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*64+21] = (start += ((w8 >> 55) | (w9 << 9) & 0x7ffffff)); out[0*64+22] = (start += ((w9 >> 18) & 0x7ffffff)); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*64+23] = (start += ((w9 >> 45) | (w10 << 19) & 0x7ffffff)); out[0*64+24] = (start += ((w10 >> 8) & 0x7ffffff)); out[0*64+25] = (start += ((w10 >> 35) & 0x7ffffff)); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*64+26] = (start += ((w10 >> 62) | (w11 << 2) & 0x7ffffff)); out[0*64+27] = (start += ((w11 >> 25) & 0x7ffffff)); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*64+28] = (start += ((w11 >> 52) | (w12 << 12) & 0x7ffffff)); out[0*64+29] = (start += ((w12 >> 15) & 0x7ffffff)); w13 = *(uint32_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*64+30] = (start += ((w12 >> 42) | (w13 << 22) & 0x7ffffff)); out[0*64+31] = (start += ((w13 >> 5) & 0x7ffffff));;}; out += 32; in += 27*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_28(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*28)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffffff)); out[0*16+ 1] = (start += ((w0 >> 28) & 0xfffffff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*16+ 2] = (start += ((w0 >> 56) | (w1 << 8) & 0xfffffff)); out[0*16+ 3] = (start += ((w1 >> 20) & 0xfffffff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*16+ 4] = (start += ((w1 >> 48) | (w2 << 16) & 0xfffffff)); out[0*16+ 5] = (start += ((w2 >> 12) & 0xfffffff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*16+ 6] = (start += ((w2 >> 40) | (w3 << 24) & 0xfffffff)); out[0*16+ 7] = (start += ((w3 >> 4) & 0xfffffff)); out[0*16+ 8] = (start += ((w3 >> 32) & 0xfffffff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*16+ 9] = (start += ((w3 >> 60) | (w4 << 4) & 0xfffffff)); out[0*16+10] = (start += ((w4 >> 24) & 0xfffffff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*16+11] = (start += ((w4 >> 52) | (w5 << 12) & 0xfffffff)); out[0*16+12] = (start += ((w5 >> 16) & 0xfffffff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*16+13] = (start += ((w5 >> 44) | (w6 << 20) & 0xfffffff)); out[0*16+14] = (start += ((w6 >> 8) & 0xfffffff)); out[0*16+15] = (start += ((w6 >> 36)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffffff)); out[1*16+ 1] = (start += ((w0 >> 28) & 0xfffffff)); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*16+ 2] = (start += ((w0 >> 56) | (w1 << 8) & 0xfffffff)); out[1*16+ 3] = (start += ((w1 >> 20) & 0xfffffff)); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*16+ 4] = (start += ((w1 >> 48) | (w2 << 16) & 0xfffffff)); out[1*16+ 5] = (start += ((w2 >> 12) & 0xfffffff)); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*16+ 6] = (start += ((w2 >> 40) | (w3 << 24) & 0xfffffff)); out[1*16+ 7] = (start += ((w3 >> 4) & 0xfffffff)); out[1*16+ 8] = (start += ((w3 >> 32) & 0xfffffff)); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*16+ 9] = (start += ((w3 >> 60) | (w4 << 4) & 0xfffffff)); out[1*16+10] = (start += ((w4 >> 24) & 0xfffffff)); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*16+11] = (start += ((w4 >> 52) | (w5 << 12) & 0xfffffff)); out[1*16+12] = (start += ((w5 >> 16) & 0xfffffff)); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*16+13] = (start += ((w5 >> 44) | (w6 << 20) & 0xfffffff)); out[1*16+14] = (start += ((w6 >> 8) & 0xfffffff)); out[1*16+15] = (start += ((w6 >> 36)));;}; out += 32; in += 28*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_29(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*29)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffffff)); out[0*64+ 1] = (start += ((w0 >> 29) & 0x1fffffff)); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 58) | (w1 << 6) & 0x1fffffff)); out[0*64+ 3] = (start += ((w1 >> 23) & 0x1fffffff)); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w1 >> 52) | (w2 << 12) & 0x1fffffff)); out[0*64+ 5] = (start += ((w2 >> 17) & 0x1fffffff)); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w2 >> 46) | (w3 << 18) & 0x1fffffff)); out[0*64+ 7] = (start += ((w3 >> 11) & 0x1fffffff)); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w3 >> 40) | (w4 << 24) & 0x1fffffff)); out[0*64+ 9] = (start += ((w4 >> 5) & 0x1fffffff)); out[0*64+10] = (start += ((w4 >> 34) & 0x1fffffff)); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*64+11] = (start += ((w4 >> 63) | (w5 << 1) & 0x1fffffff)); out[0*64+12] = (start += ((w5 >> 28) & 0x1fffffff)); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*64+13] = (start += ((w5 >> 57) | (w6 << 7) & 0x1fffffff)); out[0*64+14] = (start += ((w6 >> 22) & 0x1fffffff)); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*64+15] = (start += ((w6 >> 51) | (w7 << 13) & 0x1fffffff)); out[0*64+16] = (start += ((w7 >> 16) & 0x1fffffff)); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*64+17] = (start += ((w7 >> 45) | (w8 << 19) & 0x1fffffff)); out[0*64+18] = (start += ((w8 >> 10) & 0x1fffffff)); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*64+19] = (start += ((w8 >> 39) | (w9 << 25) & 0x1fffffff)); out[0*64+20] = (start += ((w9 >> 4) & 0x1fffffff)); out[0*64+21] = (start += ((w9 >> 33) & 0x1fffffff)); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*64+22] = (start += ((w9 >> 62) | (w10 << 2) & 0x1fffffff)); out[0*64+23] = (start += ((w10 >> 27) & 0x1fffffff)); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*64+24] = (start += ((w10 >> 56) | (w11 << 8) & 0x1fffffff)); out[0*64+25] = (start += ((w11 >> 21) & 0x1fffffff)); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*64+26] = (start += ((w11 >> 50) | (w12 << 14) & 0x1fffffff)); out[0*64+27] = (start += ((w12 >> 15) & 0x1fffffff)); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*64+28] = (start += ((w12 >> 44) | (w13 << 20) & 0x1fffffff)); out[0*64+29] = (start += ((w13 >> 9) & 0x1fffffff)); w14 = *(uint32_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*64+30] = (start += ((w13 >> 38) | (w14 << 26) & 0x1fffffff)); out[0*64+31] = (start += ((w14 >> 3) & 0x1fffffff));;}; out += 32; in += 29*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_30(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*30)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffffff)); out[0*32+ 1] = (start += ((w0 >> 30) & 0x3fffffff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w0 >> 60) | (w1 << 4) & 0x3fffffff)); out[0*32+ 3] = (start += ((w1 >> 26) & 0x3fffffff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w1 >> 56) | (w2 << 8) & 0x3fffffff)); out[0*32+ 5] = (start += ((w2 >> 22) & 0x3fffffff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w2 >> 52) | (w3 << 12) & 0x3fffffff)); out[0*32+ 7] = (start += ((w3 >> 18) & 0x3fffffff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w3 >> 48) | (w4 << 16) & 0x3fffffff)); out[0*32+ 9] = (start += ((w4 >> 14) & 0x3fffffff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*32+10] = (start += ((w4 >> 44) | (w5 << 20) & 0x3fffffff)); out[0*32+11] = (start += ((w5 >> 10) & 0x3fffffff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*32+12] = (start += ((w5 >> 40) | (w6 << 24) & 0x3fffffff)); out[0*32+13] = (start += ((w6 >> 6) & 0x3fffffff)); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*32+14] = (start += ((w6 >> 36) | (w7 << 28) & 0x3fffffff)); out[0*32+15] = (start += ((w7 >> 2) & 0x3fffffff)); out[0*32+16] = (start += ((w7 >> 32) & 0x3fffffff)); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*32+17] = (start += ((w7 >> 62) | (w8 << 2) & 0x3fffffff)); out[0*32+18] = (start += ((w8 >> 28) & 0x3fffffff)); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*32+19] = (start += ((w8 >> 58) | (w9 << 6) & 0x3fffffff)); out[0*32+20] = (start += ((w9 >> 24) & 0x3fffffff)); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*32+21] = (start += ((w9 >> 54) | (w10 << 10) & 0x3fffffff)); out[0*32+22] = (start += ((w10 >> 20) & 0x3fffffff)); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*32+23] = (start += ((w10 >> 50) | (w11 << 14) & 0x3fffffff)); out[0*32+24] = (start += ((w11 >> 16) & 0x3fffffff)); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*32+25] = (start += ((w11 >> 46) | (w12 << 18) & 0x3fffffff)); out[0*32+26] = (start += ((w12 >> 12) & 0x3fffffff)); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*32+27] = (start += ((w12 >> 42) | (w13 << 22) & 0x3fffffff)); out[0*32+28] = (start += ((w13 >> 8) & 0x3fffffff)); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*32+29] = (start += ((w13 >> 38) | (w14 << 26) & 0x3fffffff)); out[0*32+30] = (start += ((w14 >> 4) & 0x3fffffff)); out[0*32+31] = (start += ((w14 >> 34)));;}; out += 32; in += 30*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_31(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*31)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffffff)); out[0*64+ 1] = (start += ((w0 >> 31) & 0x7fffffff)); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 62) | (w1 << 2) & 0x7fffffff)); out[0*64+ 3] = (start += ((w1 >> 29) & 0x7fffffff)); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w1 >> 60) | (w2 << 4) & 0x7fffffff)); out[0*64+ 5] = (start += ((w2 >> 27) & 0x7fffffff)); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w2 >> 58) | (w3 << 6) & 0x7fffffff)); out[0*64+ 7] = (start += ((w3 >> 25) & 0x7fffffff)); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w3 >> 56) | (w4 << 8) & 0x7fffffff)); out[0*64+ 9] = (start += ((w4 >> 23) & 0x7fffffff)); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*64+10] = (start += ((w4 >> 54) | (w5 << 10) & 0x7fffffff)); out[0*64+11] = (start += ((w5 >> 21) & 0x7fffffff)); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*64+12] = (start += ((w5 >> 52) | (w6 << 12) & 0x7fffffff)); out[0*64+13] = (start += ((w6 >> 19) & 0x7fffffff)); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*64+14] = (start += ((w6 >> 50) | (w7 << 14) & 0x7fffffff)); out[0*64+15] = (start += ((w7 >> 17) & 0x7fffffff)); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*64+16] = (start += ((w7 >> 48) | (w8 << 16) & 0x7fffffff)); out[0*64+17] = (start += ((w8 >> 15) & 0x7fffffff)); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*64+18] = (start += ((w8 >> 46) | (w9 << 18) & 0x7fffffff)); out[0*64+19] = (start += ((w9 >> 13) & 0x7fffffff)); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*64+20] = (start += ((w9 >> 44) | (w10 << 20) & 0x7fffffff)); out[0*64+21] = (start += ((w10 >> 11) & 0x7fffffff)); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*64+22] = (start += ((w10 >> 42) | (w11 << 22) & 0x7fffffff)); out[0*64+23] = (start += ((w11 >> 9) & 0x7fffffff)); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*64+24] = (start += ((w11 >> 40) | (w12 << 24) & 0x7fffffff)); out[0*64+25] = (start += ((w12 >> 7) & 0x7fffffff)); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*64+26] = (start += ((w12 >> 38) | (w13 << 26) & 0x7fffffff)); out[0*64+27] = (start += ((w13 >> 5) & 0x7fffffff)); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*64+28] = (start += ((w13 >> 36) | (w14 << 28) & 0x7fffffff)); out[0*64+29] = (start += ((w14 >> 3) & 0x7fffffff)); w15 = *(uint32_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*64+30] = (start += ((w14 >> 34) | (w15 << 30) & 0x7fffffff)); out[0*64+31] = (start += ((w15 >> 1) & 0x7fffffff));;}; out += 32; in += 31*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_32(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*32)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[0*2+ 0] = (start += (*(uint32_t *)(in+0*8+ 0))); out[0*2+ 1] = (start += (*(uint32_t *)(in+0*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[1*2+ 0] = (start += (*(uint32_t *)(in+1*8+ 0))); out[1*2+ 1] = (start += (*(uint32_t *)(in+1*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[2*2+ 0] = (start += (*(uint32_t *)(in+2*8+ 0))); out[2*2+ 1] = (start += (*(uint32_t *)(in+2*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[3*2+ 0] = (start += (*(uint32_t *)(in+3*8+ 0))); out[3*2+ 1] = (start += (*(uint32_t *)(in+3*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[4*2+ 0] = (start += (*(uint32_t *)(in+4*8+ 0))); out[4*2+ 1] = (start += (*(uint32_t *)(in+4*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[5*2+ 0] = (start += (*(uint32_t *)(in+5*8+ 0))); out[5*2+ 1] = (start += (*(uint32_t *)(in+5*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[6*2+ 0] = (start += (*(uint32_t *)(in+6*8+ 0))); out[6*2+ 1] = (start += (*(uint32_t *)(in+6*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[7*2+ 0] = (start += (*(uint32_t *)(in+7*8+ 0))); out[7*2+ 1] = (start += (*(uint32_t *)(in+7*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[8*2+ 0] = (start += (*(uint32_t *)(in+8*8+ 0))); out[8*2+ 1] = (start += (*(uint32_t *)(in+8*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[9*2+ 0] = (start += (*(uint32_t *)(in+9*8+ 0))); out[9*2+ 1] = (start += (*(uint32_t *)(in+9*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[10*2+ 0] = (start += (*(uint32_t *)(in+10*8+ 0))); out[10*2+ 1] = (start += (*(uint32_t *)(in+10*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[11*2+ 0] = (start += (*(uint32_t *)(in+11*8+ 0))); out[11*2+ 1] = (start += (*(uint32_t *)(in+11*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[12*2+ 0] = (start += (*(uint32_t *)(in+12*8+ 0))); out[12*2+ 1] = (start += (*(uint32_t *)(in+12*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[13*2+ 0] = (start += (*(uint32_t *)(in+13*8+ 0))); out[13*2+ 1] = (start += (*(uint32_t *)(in+13*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[14*2+ 0] = (start += (*(uint32_t *)(in+14*8+ 0))); out[14*2+ 1] = (start += (*(uint32_t *)(in+14*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[15*2+ 0] = (start += (*(uint32_t *)(in+15*8+ 0))); out[15*2+ 1] = (start += (*(uint32_t *)(in+15*8+ 4)));;}; out += 32; in += 32*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_33(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*33)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16; w0 = *(uint64_t *)(in+(0*33+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffffffff)); w1 = *(uint64_t *)(in+(0*33+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 33) | (w1 << 31) & 0x1ffffffff)); out[0*64+ 2] = (start += ((w1 >> 2) & 0x1ffffffff)); w2 = *(uint64_t *)(in+(0*33+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w1 >> 35) | (w2 << 29) & 0x1ffffffff)); out[0*64+ 4] = (start += ((w2 >> 4) & 0x1ffffffff)); w3 = *(uint64_t *)(in+(0*33+3)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w2 >> 37) | (w3 << 27) & 0x1ffffffff)); out[0*64+ 6] = (start += ((w3 >> 6) & 0x1ffffffff)); w4 = *(uint64_t *)(in+(0*33+4)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w3 >> 39) | (w4 << 25) & 0x1ffffffff)); out[0*64+ 8] = (start += ((w4 >> 8) & 0x1ffffffff)); w5 = *(uint64_t *)(in+(0*33+5)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w4 >> 41) | (w5 << 23) & 0x1ffffffff)); out[0*64+10] = (start += ((w5 >> 10) & 0x1ffffffff)); w6 = *(uint64_t *)(in+(0*33+6)*8/sizeof(in[0])); out[0*64+11] = (start += ((w5 >> 43) | (w6 << 21) & 0x1ffffffff)); out[0*64+12] = (start += ((w6 >> 12) & 0x1ffffffff)); w7 = *(uint64_t *)(in+(0*33+7)*8/sizeof(in[0])); out[0*64+13] = (start += ((w6 >> 45) | (w7 << 19) & 0x1ffffffff)); out[0*64+14] = (start += ((w7 >> 14) & 0x1ffffffff)); w8 = *(uint64_t *)(in+(0*33+8)*8/sizeof(in[0])); out[0*64+15] = (start += ((w7 >> 47) | (w8 << 17) & 0x1ffffffff)); out[0*64+16] = (start += ((w8 >> 16) & 0x1ffffffff)); w9 = *(uint64_t *)(in+(0*33+9)*8/sizeof(in[0])); out[0*64+17] = (start += ((w8 >> 49) | (w9 << 15) & 0x1ffffffff)); out[0*64+18] = (start += ((w9 >> 18) & 0x1ffffffff)); w10 = *(uint64_t *)(in+(0*33+10)*8/sizeof(in[0])); out[0*64+19] = (start += ((w9 >> 51) | (w10 << 13) & 0x1ffffffff)); out[0*64+20] = (start += ((w10 >> 20) & 0x1ffffffff)); w11 = *(uint64_t *)(in+(0*33+11)*8/sizeof(in[0])); out[0*64+21] = (start += ((w10 >> 53) | (w11 << 11) & 0x1ffffffff)); out[0*64+22] = (start += ((w11 >> 22) & 0x1ffffffff)); w12 = *(uint64_t *)(in+(0*33+12)*8/sizeof(in[0])); out[0*64+23] = (start += ((w11 >> 55) | (w12 << 9) & 0x1ffffffff)); out[0*64+24] = (start += ((w12 >> 24) & 0x1ffffffff)); w13 = *(uint64_t *)(in+(0*33+13)*8/sizeof(in[0])); out[0*64+25] = (start += ((w12 >> 57) | (w13 << 7) & 0x1ffffffff)); out[0*64+26] = (start += ((w13 >> 26) & 0x1ffffffff)); w14 = *(uint64_t *)(in+(0*33+14)*8/sizeof(in[0])); out[0*64+27] = (start += ((w13 >> 59) | (w14 << 5) & 0x1ffffffff)); out[0*64+28] = (start += ((w14 >> 28) & 0x1ffffffff)); w15 = *(uint64_t *)(in+(0*33+15)*8/sizeof(in[0])); out[0*64+29] = (start += ((w14 >> 61) | (w15 << 3) & 0x1ffffffff)); out[0*64+30] = (start += ((w15 >> 30) & 0x1ffffffff)); w16 = *(uint32_t *)(in+(0*33+16)*8/sizeof(in[0])); out[0*64+31] = (start += ((w15 >> 63) | (w16 << 1) & 0x1ffffffff));;}; out += 32; in += 33*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_34(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*34)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffffffff)); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 34) | (w1 << 30) & 0x3ffffffff)); out[0*32+ 2] = (start += ((w1 >> 4) & 0x3ffffffff)); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w1 >> 38) | (w2 << 26) & 0x3ffffffff)); out[0*32+ 4] = (start += ((w2 >> 8) & 0x3ffffffff)); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w2 >> 42) | (w3 << 22) & 0x3ffffffff)); out[0*32+ 6] = (start += ((w3 >> 12) & 0x3ffffffff)); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w3 >> 46) | (w4 << 18) & 0x3ffffffff)); out[0*32+ 8] = (start += ((w4 >> 16) & 0x3ffffffff)); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w4 >> 50) | (w5 << 14) & 0x3ffffffff)); out[0*32+10] = (start += ((w5 >> 20) & 0x3ffffffff)); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*32+11] = (start += ((w5 >> 54) | (w6 << 10) & 0x3ffffffff)); out[0*32+12] = (start += ((w6 >> 24) & 0x3ffffffff)); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*32+13] = (start += ((w6 >> 58) | (w7 << 6) & 0x3ffffffff)); out[0*32+14] = (start += ((w7 >> 28) & 0x3ffffffff)); w8 = *(uint64_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*32+15] = (start += ((w7 >> 62) | (w8 << 2) & 0x3ffffffff)); w9 = *(uint64_t *)(in+(0*17+9)*8/sizeof(in[0])); out[0*32+16] = (start += ((w8 >> 32) | (w9 << 32) & 0x3ffffffff)); out[0*32+17] = (start += ((w9 >> 2) & 0x3ffffffff)); w10 = *(uint64_t *)(in+(0*17+10)*8/sizeof(in[0])); out[0*32+18] = (start += ((w9 >> 36) | (w10 << 28) & 0x3ffffffff)); out[0*32+19] = (start += ((w10 >> 6) & 0x3ffffffff)); w11 = *(uint64_t *)(in+(0*17+11)*8/sizeof(in[0])); out[0*32+20] = (start += ((w10 >> 40) | (w11 << 24) & 0x3ffffffff)); out[0*32+21] = (start += ((w11 >> 10) & 0x3ffffffff)); w12 = *(uint64_t *)(in+(0*17+12)*8/sizeof(in[0])); out[0*32+22] = (start += ((w11 >> 44) | (w12 << 20) & 0x3ffffffff)); out[0*32+23] = (start += ((w12 >> 14) & 0x3ffffffff)); w13 = *(uint64_t *)(in+(0*17+13)*8/sizeof(in[0])); out[0*32+24] = (start += ((w12 >> 48) | (w13 << 16) & 0x3ffffffff)); out[0*32+25] = (start += ((w13 >> 18) & 0x3ffffffff)); w14 = *(uint64_t *)(in+(0*17+14)*8/sizeof(in[0])); out[0*32+26] = (start += ((w13 >> 52) | (w14 << 12) & 0x3ffffffff)); out[0*32+27] = (start += ((w14 >> 22) & 0x3ffffffff)); w15 = *(uint64_t *)(in+(0*17+15)*8/sizeof(in[0])); out[0*32+28] = (start += ((w14 >> 56) | (w15 << 8) & 0x3ffffffff)); out[0*32+29] = (start += ((w15 >> 26) & 0x3ffffffff)); w16 = *(uint64_t *)(in+(0*17+16)*8/sizeof(in[0])); out[0*32+30] = (start += ((w15 >> 60) | (w16 << 4) & 0x3ffffffff)); out[0*32+31] = (start += ((w16 >> 30)));;}; out += 32; in += 34*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_35(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*35)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(0*35+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffffffff)); w1 = *(uint64_t *)(in+(0*35+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 35) | (w1 << 29) & 0x7ffffffff)); out[0*64+ 2] = (start += ((w1 >> 6) & 0x7ffffffff)); w2 = *(uint64_t *)(in+(0*35+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w1 >> 41) | (w2 << 23) & 0x7ffffffff)); out[0*64+ 4] = (start += ((w2 >> 12) & 0x7ffffffff)); w3 = *(uint64_t *)(in+(0*35+3)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w2 >> 47) | (w3 << 17) & 0x7ffffffff)); out[0*64+ 6] = (start += ((w3 >> 18) & 0x7ffffffff)); w4 = *(uint64_t *)(in+(0*35+4)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w3 >> 53) | (w4 << 11) & 0x7ffffffff)); out[0*64+ 8] = (start += ((w4 >> 24) & 0x7ffffffff)); w5 = *(uint64_t *)(in+(0*35+5)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w4 >> 59) | (w5 << 5) & 0x7ffffffff)); w6 = *(uint64_t *)(in+(0*35+6)*8/sizeof(in[0])); out[0*64+10] = (start += ((w5 >> 30) | (w6 << 34) & 0x7ffffffff)); out[0*64+11] = (start += ((w6 >> 1) & 0x7ffffffff)); w7 = *(uint64_t *)(in+(0*35+7)*8/sizeof(in[0])); out[0*64+12] = (start += ((w6 >> 36) | (w7 << 28) & 0x7ffffffff)); out[0*64+13] = (start += ((w7 >> 7) & 0x7ffffffff)); w8 = *(uint64_t *)(in+(0*35+8)*8/sizeof(in[0])); out[0*64+14] = (start += ((w7 >> 42) | (w8 << 22) & 0x7ffffffff)); out[0*64+15] = (start += ((w8 >> 13) & 0x7ffffffff)); w9 = *(uint64_t *)(in+(0*35+9)*8/sizeof(in[0])); out[0*64+16] = (start += ((w8 >> 48) | (w9 << 16) & 0x7ffffffff)); out[0*64+17] = (start += ((w9 >> 19) & 0x7ffffffff)); w10 = *(uint64_t *)(in+(0*35+10)*8/sizeof(in[0])); out[0*64+18] = (start += ((w9 >> 54) | (w10 << 10) & 0x7ffffffff)); out[0*64+19] = (start += ((w10 >> 25) & 0x7ffffffff)); w11 = *(uint64_t *)(in+(0*35+11)*8/sizeof(in[0])); out[0*64+20] = (start += ((w10 >> 60) | (w11 << 4) & 0x7ffffffff)); w12 = *(uint64_t *)(in+(0*35+12)*8/sizeof(in[0])); out[0*64+21] = (start += ((w11 >> 31) | (w12 << 33) & 0x7ffffffff)); out[0*64+22] = (start += ((w12 >> 2) & 0x7ffffffff)); w13 = *(uint64_t *)(in+(0*35+13)*8/sizeof(in[0])); out[0*64+23] = (start += ((w12 >> 37) | (w13 << 27) & 0x7ffffffff)); out[0*64+24] = (start += ((w13 >> 8) & 0x7ffffffff)); w14 = *(uint64_t *)(in+(0*35+14)*8/sizeof(in[0])); out[0*64+25] = (start += ((w13 >> 43) | (w14 << 21) & 0x7ffffffff)); out[0*64+26] = (start += ((w14 >> 14) & 0x7ffffffff)); w15 = *(uint64_t *)(in+(0*35+15)*8/sizeof(in[0])); out[0*64+27] = (start += ((w14 >> 49) | (w15 << 15) & 0x7ffffffff)); out[0*64+28] = (start += ((w15 >> 20) & 0x7ffffffff)); w16 = *(uint64_t *)(in+(0*35+16)*8/sizeof(in[0])); out[0*64+29] = (start += ((w15 >> 55) | (w16 << 9) & 0x7ffffffff)); out[0*64+30] = (start += ((w16 >> 26) & 0x7ffffffff)); w17 = *(uint32_t *)(in+(0*35+17)*8/sizeof(in[0])); out[0*64+31] = (start += ((w16 >> 61) | (w17 << 3) & 0x7ffffffff));;}; out += 32; in += 35*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_36(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*36)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffffffff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*16+ 1] = (start += ((w0 >> 36) | (w1 << 28) & 0xfffffffff)); out[0*16+ 2] = (start += ((w1 >> 8) & 0xfffffffff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*16+ 3] = (start += ((w1 >> 44) | (w2 << 20) & 0xfffffffff)); out[0*16+ 4] = (start += ((w2 >> 16) & 0xfffffffff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*16+ 5] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffffffff)); out[0*16+ 6] = (start += ((w3 >> 24) & 0xfffffffff)); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*16+ 7] = (start += ((w3 >> 60) | (w4 << 4) & 0xfffffffff)); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*16+ 8] = (start += ((w4 >> 32) | (w5 << 32) & 0xfffffffff)); out[0*16+ 9] = (start += ((w5 >> 4) & 0xfffffffff)); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*16+10] = (start += ((w5 >> 40) | (w6 << 24) & 0xfffffffff)); out[0*16+11] = (start += ((w6 >> 12) & 0xfffffffff)); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*16+12] = (start += ((w6 >> 48) | (w7 << 16) & 0xfffffffff)); out[0*16+13] = (start += ((w7 >> 20) & 0xfffffffff)); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*16+14] = (start += ((w7 >> 56) | (w8 << 8) & 0xfffffffff)); out[0*16+15] = (start += ((w8 >> 28)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(1*9+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffffffff)); w1 = *(uint64_t *)(in+(1*9+1)*8/sizeof(in[0])); out[1*16+ 1] = (start += ((w0 >> 36) | (w1 << 28) & 0xfffffffff)); out[1*16+ 2] = (start += ((w1 >> 8) & 0xfffffffff)); w2 = *(uint64_t *)(in+(1*9+2)*8/sizeof(in[0])); out[1*16+ 3] = (start += ((w1 >> 44) | (w2 << 20) & 0xfffffffff)); out[1*16+ 4] = (start += ((w2 >> 16) & 0xfffffffff)); w3 = *(uint64_t *)(in+(1*9+3)*8/sizeof(in[0])); out[1*16+ 5] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffffffff)); out[1*16+ 6] = (start += ((w3 >> 24) & 0xfffffffff)); w4 = *(uint64_t *)(in+(1*9+4)*8/sizeof(in[0])); out[1*16+ 7] = (start += ((w3 >> 60) | (w4 << 4) & 0xfffffffff)); w5 = *(uint64_t *)(in+(1*9+5)*8/sizeof(in[0])); out[1*16+ 8] = (start += ((w4 >> 32) | (w5 << 32) & 0xfffffffff)); out[1*16+ 9] = (start += ((w5 >> 4) & 0xfffffffff)); w6 = *(uint64_t *)(in+(1*9+6)*8/sizeof(in[0])); out[1*16+10] = (start += ((w5 >> 40) | (w6 << 24) & 0xfffffffff)); out[1*16+11] = (start += ((w6 >> 12) & 0xfffffffff)); w7 = *(uint64_t *)(in+(1*9+7)*8/sizeof(in[0])); out[1*16+12] = (start += ((w6 >> 48) | (w7 << 16) & 0xfffffffff)); out[1*16+13] = (start += ((w7 >> 20) & 0xfffffffff)); w8 = *(uint64_t *)(in+(1*9+8)*8/sizeof(in[0])); out[1*16+14] = (start += ((w7 >> 56) | (w8 << 8) & 0xfffffffff)); out[1*16+15] = (start += ((w8 >> 28)));;}; out += 32; in += 36*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_37(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*37)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18; w0 = *(uint64_t *)(in+(0*37+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffffffff)); w1 = *(uint64_t *)(in+(0*37+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 37) | (w1 << 27) & 0x1fffffffff)); out[0*64+ 2] = (start += ((w1 >> 10) & 0x1fffffffff)); w2 = *(uint64_t *)(in+(0*37+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w1 >> 47) | (w2 << 17) & 0x1fffffffff)); out[0*64+ 4] = (start += ((w2 >> 20) & 0x1fffffffff)); w3 = *(uint64_t *)(in+(0*37+3)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w2 >> 57) | (w3 << 7) & 0x1fffffffff)); w4 = *(uint64_t *)(in+(0*37+4)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w3 >> 30) | (w4 << 34) & 0x1fffffffff)); out[0*64+ 7] = (start += ((w4 >> 3) & 0x1fffffffff)); w5 = *(uint64_t *)(in+(0*37+5)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w4 >> 40) | (w5 << 24) & 0x1fffffffff)); out[0*64+ 9] = (start += ((w5 >> 13) & 0x1fffffffff)); w6 = *(uint64_t *)(in+(0*37+6)*8/sizeof(in[0])); out[0*64+10] = (start += ((w5 >> 50) | (w6 << 14) & 0x1fffffffff)); out[0*64+11] = (start += ((w6 >> 23) & 0x1fffffffff)); w7 = *(uint64_t *)(in+(0*37+7)*8/sizeof(in[0])); out[0*64+12] = (start += ((w6 >> 60) | (w7 << 4) & 0x1fffffffff)); w8 = *(uint64_t *)(in+(0*37+8)*8/sizeof(in[0])); out[0*64+13] = (start += ((w7 >> 33) | (w8 << 31) & 0x1fffffffff)); out[0*64+14] = (start += ((w8 >> 6) & 0x1fffffffff)); w9 = *(uint64_t *)(in+(0*37+9)*8/sizeof(in[0])); out[0*64+15] = (start += ((w8 >> 43) | (w9 << 21) & 0x1fffffffff)); out[0*64+16] = (start += ((w9 >> 16) & 0x1fffffffff)); w10 = *(uint64_t *)(in+(0*37+10)*8/sizeof(in[0])); out[0*64+17] = (start += ((w9 >> 53) | (w10 << 11) & 0x1fffffffff)); out[0*64+18] = (start += ((w10 >> 26) & 0x1fffffffff)); w11 = *(uint64_t *)(in+(0*37+11)*8/sizeof(in[0])); out[0*64+19] = (start += ((w10 >> 63) | (w11 << 1) & 0x1fffffffff)); w12 = *(uint64_t *)(in+(0*37+12)*8/sizeof(in[0])); out[0*64+20] = (start += ((w11 >> 36) | (w12 << 28) & 0x1fffffffff)); out[0*64+21] = (start += ((w12 >> 9) & 0x1fffffffff)); w13 = *(uint64_t *)(in+(0*37+13)*8/sizeof(in[0])); out[0*64+22] = (start += ((w12 >> 46) | (w13 << 18) & 0x1fffffffff)); out[0*64+23] = (start += ((w13 >> 19) & 0x1fffffffff)); w14 = *(uint64_t *)(in+(0*37+14)*8/sizeof(in[0])); out[0*64+24] = (start += ((w13 >> 56) | (w14 << 8) & 0x1fffffffff)); w15 = *(uint64_t *)(in+(0*37+15)*8/sizeof(in[0])); out[0*64+25] = (start += ((w14 >> 29) | (w15 << 35) & 0x1fffffffff)); out[0*64+26] = (start += ((w15 >> 2) & 0x1fffffffff)); w16 = *(uint64_t *)(in+(0*37+16)*8/sizeof(in[0])); out[0*64+27] = (start += ((w15 >> 39) | (w16 << 25) & 0x1fffffffff)); out[0*64+28] = (start += ((w16 >> 12) & 0x1fffffffff)); w17 = *(uint64_t *)(in+(0*37+17)*8/sizeof(in[0])); out[0*64+29] = (start += ((w16 >> 49) | (w17 << 15) & 0x1fffffffff)); out[0*64+30] = (start += ((w17 >> 22) & 0x1fffffffff)); w18 = *(uint32_t *)(in+(0*37+18)*8/sizeof(in[0])); out[0*64+31] = (start += ((w17 >> 59) | (w18 << 5) & 0x1fffffffff));;}; out += 32; in += 37*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_38(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*38)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffffffff)); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 38) | (w1 << 26) & 0x3fffffffff)); out[0*32+ 2] = (start += ((w1 >> 12) & 0x3fffffffff)); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w1 >> 50) | (w2 << 14) & 0x3fffffffff)); out[0*32+ 4] = (start += ((w2 >> 24) & 0x3fffffffff)); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w2 >> 62) | (w3 << 2) & 0x3fffffffff)); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w3 >> 36) | (w4 << 28) & 0x3fffffffff)); out[0*32+ 7] = (start += ((w4 >> 10) & 0x3fffffffff)); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w4 >> 48) | (w5 << 16) & 0x3fffffffff)); out[0*32+ 9] = (start += ((w5 >> 22) & 0x3fffffffff)); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*32+10] = (start += ((w5 >> 60) | (w6 << 4) & 0x3fffffffff)); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*32+11] = (start += ((w6 >> 34) | (w7 << 30) & 0x3fffffffff)); out[0*32+12] = (start += ((w7 >> 8) & 0x3fffffffff)); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*32+13] = (start += ((w7 >> 46) | (w8 << 18) & 0x3fffffffff)); out[0*32+14] = (start += ((w8 >> 20) & 0x3fffffffff)); w9 = *(uint64_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*32+15] = (start += ((w8 >> 58) | (w9 << 6) & 0x3fffffffff)); w10 = *(uint64_t *)(in+(0*19+10)*8/sizeof(in[0])); out[0*32+16] = (start += ((w9 >> 32) | (w10 << 32) & 0x3fffffffff)); out[0*32+17] = (start += ((w10 >> 6) & 0x3fffffffff)); w11 = *(uint64_t *)(in+(0*19+11)*8/sizeof(in[0])); out[0*32+18] = (start += ((w10 >> 44) | (w11 << 20) & 0x3fffffffff)); out[0*32+19] = (start += ((w11 >> 18) & 0x3fffffffff)); w12 = *(uint64_t *)(in+(0*19+12)*8/sizeof(in[0])); out[0*32+20] = (start += ((w11 >> 56) | (w12 << 8) & 0x3fffffffff)); w13 = *(uint64_t *)(in+(0*19+13)*8/sizeof(in[0])); out[0*32+21] = (start += ((w12 >> 30) | (w13 << 34) & 0x3fffffffff)); out[0*32+22] = (start += ((w13 >> 4) & 0x3fffffffff)); w14 = *(uint64_t *)(in+(0*19+14)*8/sizeof(in[0])); out[0*32+23] = (start += ((w13 >> 42) | (w14 << 22) & 0x3fffffffff)); out[0*32+24] = (start += ((w14 >> 16) & 0x3fffffffff)); w15 = *(uint64_t *)(in+(0*19+15)*8/sizeof(in[0])); out[0*32+25] = (start += ((w14 >> 54) | (w15 << 10) & 0x3fffffffff)); w16 = *(uint64_t *)(in+(0*19+16)*8/sizeof(in[0])); out[0*32+26] = (start += ((w15 >> 28) | (w16 << 36) & 0x3fffffffff)); out[0*32+27] = (start += ((w16 >> 2) & 0x3fffffffff)); w17 = *(uint64_t *)(in+(0*19+17)*8/sizeof(in[0])); out[0*32+28] = (start += ((w16 >> 40) | (w17 << 24) & 0x3fffffffff)); out[0*32+29] = (start += ((w17 >> 14) & 0x3fffffffff)); w18 = *(uint64_t *)(in+(0*19+18)*8/sizeof(in[0])); out[0*32+30] = (start += ((w17 >> 52) | (w18 << 12) & 0x3fffffffff)); out[0*32+31] = (start += ((w18 >> 26)));;}; out += 32; in += 38*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_39(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*39)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(0*39+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffffffff)); w1 = *(uint64_t *)(in+(0*39+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 39) | (w1 << 25) & 0x7fffffffff)); out[0*64+ 2] = (start += ((w1 >> 14) & 0x7fffffffff)); w2 = *(uint64_t *)(in+(0*39+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w1 >> 53) | (w2 << 11) & 0x7fffffffff)); w3 = *(uint64_t *)(in+(0*39+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w2 >> 28) | (w3 << 36) & 0x7fffffffff)); out[0*64+ 5] = (start += ((w3 >> 3) & 0x7fffffffff)); w4 = *(uint64_t *)(in+(0*39+4)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w3 >> 42) | (w4 << 22) & 0x7fffffffff)); out[0*64+ 7] = (start += ((w4 >> 17) & 0x7fffffffff)); w5 = *(uint64_t *)(in+(0*39+5)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w4 >> 56) | (w5 << 8) & 0x7fffffffff)); w6 = *(uint64_t *)(in+(0*39+6)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w5 >> 31) | (w6 << 33) & 0x7fffffffff)); out[0*64+10] = (start += ((w6 >> 6) & 0x7fffffffff)); w7 = *(uint64_t *)(in+(0*39+7)*8/sizeof(in[0])); out[0*64+11] = (start += ((w6 >> 45) | (w7 << 19) & 0x7fffffffff)); out[0*64+12] = (start += ((w7 >> 20) & 0x7fffffffff)); w8 = *(uint64_t *)(in+(0*39+8)*8/sizeof(in[0])); out[0*64+13] = (start += ((w7 >> 59) | (w8 << 5) & 0x7fffffffff)); w9 = *(uint64_t *)(in+(0*39+9)*8/sizeof(in[0])); out[0*64+14] = (start += ((w8 >> 34) | (w9 << 30) & 0x7fffffffff)); out[0*64+15] = (start += ((w9 >> 9) & 0x7fffffffff)); w10 = *(uint64_t *)(in+(0*39+10)*8/sizeof(in[0])); out[0*64+16] = (start += ((w9 >> 48) | (w10 << 16) & 0x7fffffffff)); out[0*64+17] = (start += ((w10 >> 23) & 0x7fffffffff)); w11 = *(uint64_t *)(in+(0*39+11)*8/sizeof(in[0])); out[0*64+18] = (start += ((w10 >> 62) | (w11 << 2) & 0x7fffffffff)); w12 = *(uint64_t *)(in+(0*39+12)*8/sizeof(in[0])); out[0*64+19] = (start += ((w11 >> 37) | (w12 << 27) & 0x7fffffffff)); out[0*64+20] = (start += ((w12 >> 12) & 0x7fffffffff)); w13 = *(uint64_t *)(in+(0*39+13)*8/sizeof(in[0])); out[0*64+21] = (start += ((w12 >> 51) | (w13 << 13) & 0x7fffffffff)); w14 = *(uint64_t *)(in+(0*39+14)*8/sizeof(in[0])); out[0*64+22] = (start += ((w13 >> 26) | (w14 << 38) & 0x7fffffffff)); out[0*64+23] = (start += ((w14 >> 1) & 0x7fffffffff)); w15 = *(uint64_t *)(in+(0*39+15)*8/sizeof(in[0])); out[0*64+24] = (start += ((w14 >> 40) | (w15 << 24) & 0x7fffffffff)); out[0*64+25] = (start += ((w15 >> 15) & 0x7fffffffff)); w16 = *(uint64_t *)(in+(0*39+16)*8/sizeof(in[0])); out[0*64+26] = (start += ((w15 >> 54) | (w16 << 10) & 0x7fffffffff)); w17 = *(uint64_t *)(in+(0*39+17)*8/sizeof(in[0])); out[0*64+27] = (start += ((w16 >> 29) | (w17 << 35) & 0x7fffffffff)); out[0*64+28] = (start += ((w17 >> 4) & 0x7fffffffff)); w18 = *(uint64_t *)(in+(0*39+18)*8/sizeof(in[0])); out[0*64+29] = (start += ((w17 >> 43) | (w18 << 21) & 0x7fffffffff)); out[0*64+30] = (start += ((w18 >> 18) & 0x7fffffffff)); w19 = *(uint32_t *)(in+(0*39+19)*8/sizeof(in[0])); out[0*64+31] = (start += ((w18 >> 57) | (w19 << 7) & 0x7fffffffff));;}; out += 32; in += 39*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_40(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*40)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xffffffffff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*8+ 1] = (start += ((w0 >> 40) | (w1 << 24) & 0xffffffffff)); out[0*8+ 2] = (start += ((w1 >> 16) & 0xffffffffff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*8+ 3] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffffffff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*8+ 4] = (start += ((w2 >> 32) | (w3 << 32) & 0xffffffffff)); out[0*8+ 5] = (start += ((w3 >> 8) & 0xffffffffff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*8+ 6] = (start += ((w3 >> 48) | (w4 << 16) & 0xffffffffff)); out[0*8+ 7] = (start += ((w4 >> 24)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xffffffffff)); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*8+ 1] = (start += ((w0 >> 40) | (w1 << 24) & 0xffffffffff)); out[1*8+ 2] = (start += ((w1 >> 16) & 0xffffffffff)); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*8+ 3] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffffffff)); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*8+ 4] = (start += ((w2 >> 32) | (w3 << 32) & 0xffffffffff)); out[1*8+ 5] = (start += ((w3 >> 8) & 0xffffffffff)); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*8+ 6] = (start += ((w3 >> 48) | (w4 << 16) & 0xffffffffff)); out[1*8+ 7] = (start += ((w4 >> 24)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(2*5+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xffffffffff)); w1 = *(uint64_t *)(in+(2*5+1)*8/sizeof(in[0])); out[2*8+ 1] = (start += ((w0 >> 40) | (w1 << 24) & 0xffffffffff)); out[2*8+ 2] = (start += ((w1 >> 16) & 0xffffffffff)); w2 = *(uint64_t *)(in+(2*5+2)*8/sizeof(in[0])); out[2*8+ 3] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffffffff)); w3 = *(uint64_t *)(in+(2*5+3)*8/sizeof(in[0])); out[2*8+ 4] = (start += ((w2 >> 32) | (w3 << 32) & 0xffffffffff)); out[2*8+ 5] = (start += ((w3 >> 8) & 0xffffffffff)); w4 = *(uint64_t *)(in+(2*5+4)*8/sizeof(in[0])); out[2*8+ 6] = (start += ((w3 >> 48) | (w4 << 16) & 0xffffffffff)); out[2*8+ 7] = (start += ((w4 >> 24)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(3*5+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xffffffffff)); w1 = *(uint64_t *)(in+(3*5+1)*8/sizeof(in[0])); out[3*8+ 1] = (start += ((w0 >> 40) | (w1 << 24) & 0xffffffffff)); out[3*8+ 2] = (start += ((w1 >> 16) & 0xffffffffff)); w2 = *(uint64_t *)(in+(3*5+2)*8/sizeof(in[0])); out[3*8+ 3] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffffffff)); w3 = *(uint64_t *)(in+(3*5+3)*8/sizeof(in[0])); out[3*8+ 4] = (start += ((w2 >> 32) | (w3 << 32) & 0xffffffffff)); out[3*8+ 5] = (start += ((w3 >> 8) & 0xffffffffff)); w4 = *(uint64_t *)(in+(3*5+4)*8/sizeof(in[0])); out[3*8+ 6] = (start += ((w3 >> 48) | (w4 << 16) & 0xffffffffff)); out[3*8+ 7] = (start += ((w4 >> 24)));;}; out += 32; in += 40*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_41(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*41)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20; w0 = *(uint64_t *)(in+(0*41+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffffffffff)); w1 = *(uint64_t *)(in+(0*41+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 41) | (w1 << 23) & 0x1ffffffffff)); out[0*64+ 2] = (start += ((w1 >> 18) & 0x1ffffffffff)); w2 = *(uint64_t *)(in+(0*41+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w1 >> 59) | (w2 << 5) & 0x1ffffffffff)); w3 = *(uint64_t *)(in+(0*41+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w2 >> 36) | (w3 << 28) & 0x1ffffffffff)); out[0*64+ 5] = (start += ((w3 >> 13) & 0x1ffffffffff)); w4 = *(uint64_t *)(in+(0*41+4)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w3 >> 54) | (w4 << 10) & 0x1ffffffffff)); w5 = *(uint64_t *)(in+(0*41+5)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w4 >> 31) | (w5 << 33) & 0x1ffffffffff)); out[0*64+ 8] = (start += ((w5 >> 8) & 0x1ffffffffff)); w6 = *(uint64_t *)(in+(0*41+6)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w5 >> 49) | (w6 << 15) & 0x1ffffffffff)); w7 = *(uint64_t *)(in+(0*41+7)*8/sizeof(in[0])); out[0*64+10] = (start += ((w6 >> 26) | (w7 << 38) & 0x1ffffffffff)); out[0*64+11] = (start += ((w7 >> 3) & 0x1ffffffffff)); w8 = *(uint64_t *)(in+(0*41+8)*8/sizeof(in[0])); out[0*64+12] = (start += ((w7 >> 44) | (w8 << 20) & 0x1ffffffffff)); out[0*64+13] = (start += ((w8 >> 21) & 0x1ffffffffff)); w9 = *(uint64_t *)(in+(0*41+9)*8/sizeof(in[0])); out[0*64+14] = (start += ((w8 >> 62) | (w9 << 2) & 0x1ffffffffff)); w10 = *(uint64_t *)(in+(0*41+10)*8/sizeof(in[0])); out[0*64+15] = (start += ((w9 >> 39) | (w10 << 25) & 0x1ffffffffff)); out[0*64+16] = (start += ((w10 >> 16) & 0x1ffffffffff)); w11 = *(uint64_t *)(in+(0*41+11)*8/sizeof(in[0])); out[0*64+17] = (start += ((w10 >> 57) | (w11 << 7) & 0x1ffffffffff)); w12 = *(uint64_t *)(in+(0*41+12)*8/sizeof(in[0])); out[0*64+18] = (start += ((w11 >> 34) | (w12 << 30) & 0x1ffffffffff)); out[0*64+19] = (start += ((w12 >> 11) & 0x1ffffffffff)); w13 = *(uint64_t *)(in+(0*41+13)*8/sizeof(in[0])); out[0*64+20] = (start += ((w12 >> 52) | (w13 << 12) & 0x1ffffffffff)); w14 = *(uint64_t *)(in+(0*41+14)*8/sizeof(in[0])); out[0*64+21] = (start += ((w13 >> 29) | (w14 << 35) & 0x1ffffffffff)); out[0*64+22] = (start += ((w14 >> 6) & 0x1ffffffffff)); w15 = *(uint64_t *)(in+(0*41+15)*8/sizeof(in[0])); out[0*64+23] = (start += ((w14 >> 47) | (w15 << 17) & 0x1ffffffffff)); w16 = *(uint64_t *)(in+(0*41+16)*8/sizeof(in[0])); out[0*64+24] = (start += ((w15 >> 24) | (w16 << 40) & 0x1ffffffffff)); out[0*64+25] = (start += ((w16 >> 1) & 0x1ffffffffff)); w17 = *(uint64_t *)(in+(0*41+17)*8/sizeof(in[0])); out[0*64+26] = (start += ((w16 >> 42) | (w17 << 22) & 0x1ffffffffff)); out[0*64+27] = (start += ((w17 >> 19) & 0x1ffffffffff)); w18 = *(uint64_t *)(in+(0*41+18)*8/sizeof(in[0])); out[0*64+28] = (start += ((w17 >> 60) | (w18 << 4) & 0x1ffffffffff)); w19 = *(uint64_t *)(in+(0*41+19)*8/sizeof(in[0])); out[0*64+29] = (start += ((w18 >> 37) | (w19 << 27) & 0x1ffffffffff)); out[0*64+30] = (start += ((w19 >> 14) & 0x1ffffffffff)); w20 = *(uint32_t *)(in+(0*41+20)*8/sizeof(in[0])); out[0*64+31] = (start += ((w19 >> 55) | (w20 << 9) & 0x1ffffffffff));;}; out += 32; in += 41*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_42(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*42)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffffffffff)); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 42) | (w1 << 22) & 0x3ffffffffff)); out[0*32+ 2] = (start += ((w1 >> 20) & 0x3ffffffffff)); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w1 >> 62) | (w2 << 2) & 0x3ffffffffff)); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w2 >> 40) | (w3 << 24) & 0x3ffffffffff)); out[0*32+ 5] = (start += ((w3 >> 18) & 0x3ffffffffff)); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w3 >> 60) | (w4 << 4) & 0x3ffffffffff)); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w4 >> 38) | (w5 << 26) & 0x3ffffffffff)); out[0*32+ 8] = (start += ((w5 >> 16) & 0x3ffffffffff)); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w5 >> 58) | (w6 << 6) & 0x3ffffffffff)); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*32+10] = (start += ((w6 >> 36) | (w7 << 28) & 0x3ffffffffff)); out[0*32+11] = (start += ((w7 >> 14) & 0x3ffffffffff)); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*32+12] = (start += ((w7 >> 56) | (w8 << 8) & 0x3ffffffffff)); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*32+13] = (start += ((w8 >> 34) | (w9 << 30) & 0x3ffffffffff)); out[0*32+14] = (start += ((w9 >> 12) & 0x3ffffffffff)); w10 = *(uint64_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*32+15] = (start += ((w9 >> 54) | (w10 << 10) & 0x3ffffffffff)); w11 = *(uint64_t *)(in+(0*21+11)*8/sizeof(in[0])); out[0*32+16] = (start += ((w10 >> 32) | (w11 << 32) & 0x3ffffffffff)); out[0*32+17] = (start += ((w11 >> 10) & 0x3ffffffffff)); w12 = *(uint64_t *)(in+(0*21+12)*8/sizeof(in[0])); out[0*32+18] = (start += ((w11 >> 52) | (w12 << 12) & 0x3ffffffffff)); w13 = *(uint64_t *)(in+(0*21+13)*8/sizeof(in[0])); out[0*32+19] = (start += ((w12 >> 30) | (w13 << 34) & 0x3ffffffffff)); out[0*32+20] = (start += ((w13 >> 8) & 0x3ffffffffff)); w14 = *(uint64_t *)(in+(0*21+14)*8/sizeof(in[0])); out[0*32+21] = (start += ((w13 >> 50) | (w14 << 14) & 0x3ffffffffff)); w15 = *(uint64_t *)(in+(0*21+15)*8/sizeof(in[0])); out[0*32+22] = (start += ((w14 >> 28) | (w15 << 36) & 0x3ffffffffff)); out[0*32+23] = (start += ((w15 >> 6) & 0x3ffffffffff)); w16 = *(uint64_t *)(in+(0*21+16)*8/sizeof(in[0])); out[0*32+24] = (start += ((w15 >> 48) | (w16 << 16) & 0x3ffffffffff)); w17 = *(uint64_t *)(in+(0*21+17)*8/sizeof(in[0])); out[0*32+25] = (start += ((w16 >> 26) | (w17 << 38) & 0x3ffffffffff)); out[0*32+26] = (start += ((w17 >> 4) & 0x3ffffffffff)); w18 = *(uint64_t *)(in+(0*21+18)*8/sizeof(in[0])); out[0*32+27] = (start += ((w17 >> 46) | (w18 << 18) & 0x3ffffffffff)); w19 = *(uint64_t *)(in+(0*21+19)*8/sizeof(in[0])); out[0*32+28] = (start += ((w18 >> 24) | (w19 << 40) & 0x3ffffffffff)); out[0*32+29] = (start += ((w19 >> 2) & 0x3ffffffffff)); w20 = *(uint64_t *)(in+(0*21+20)*8/sizeof(in[0])); out[0*32+30] = (start += ((w19 >> 44) | (w20 << 20) & 0x3ffffffffff)); out[0*32+31] = (start += ((w20 >> 22)));;}; out += 32; in += 42*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_43(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*43)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(0*43+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffffffffff)); w1 = *(uint64_t *)(in+(0*43+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 43) | (w1 << 21) & 0x7ffffffffff)); w2 = *(uint64_t *)(in+(0*43+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 22) | (w2 << 42) & 0x7ffffffffff)); out[0*64+ 3] = (start += ((w2 >> 1) & 0x7ffffffffff)); w3 = *(uint64_t *)(in+(0*43+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w2 >> 44) | (w3 << 20) & 0x7ffffffffff)); w4 = *(uint64_t *)(in+(0*43+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w3 >> 23) | (w4 << 41) & 0x7ffffffffff)); out[0*64+ 6] = (start += ((w4 >> 2) & 0x7ffffffffff)); w5 = *(uint64_t *)(in+(0*43+5)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w4 >> 45) | (w5 << 19) & 0x7ffffffffff)); w6 = *(uint64_t *)(in+(0*43+6)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w5 >> 24) | (w6 << 40) & 0x7ffffffffff)); out[0*64+ 9] = (start += ((w6 >> 3) & 0x7ffffffffff)); w7 = *(uint64_t *)(in+(0*43+7)*8/sizeof(in[0])); out[0*64+10] = (start += ((w6 >> 46) | (w7 << 18) & 0x7ffffffffff)); w8 = *(uint64_t *)(in+(0*43+8)*8/sizeof(in[0])); out[0*64+11] = (start += ((w7 >> 25) | (w8 << 39) & 0x7ffffffffff)); out[0*64+12] = (start += ((w8 >> 4) & 0x7ffffffffff)); w9 = *(uint64_t *)(in+(0*43+9)*8/sizeof(in[0])); out[0*64+13] = (start += ((w8 >> 47) | (w9 << 17) & 0x7ffffffffff)); w10 = *(uint64_t *)(in+(0*43+10)*8/sizeof(in[0])); out[0*64+14] = (start += ((w9 >> 26) | (w10 << 38) & 0x7ffffffffff)); out[0*64+15] = (start += ((w10 >> 5) & 0x7ffffffffff)); w11 = *(uint64_t *)(in+(0*43+11)*8/sizeof(in[0])); out[0*64+16] = (start += ((w10 >> 48) | (w11 << 16) & 0x7ffffffffff)); w12 = *(uint64_t *)(in+(0*43+12)*8/sizeof(in[0])); out[0*64+17] = (start += ((w11 >> 27) | (w12 << 37) & 0x7ffffffffff)); out[0*64+18] = (start += ((w12 >> 6) & 0x7ffffffffff)); w13 = *(uint64_t *)(in+(0*43+13)*8/sizeof(in[0])); out[0*64+19] = (start += ((w12 >> 49) | (w13 << 15) & 0x7ffffffffff)); w14 = *(uint64_t *)(in+(0*43+14)*8/sizeof(in[0])); out[0*64+20] = (start += ((w13 >> 28) | (w14 << 36) & 0x7ffffffffff)); out[0*64+21] = (start += ((w14 >> 7) & 0x7ffffffffff)); w15 = *(uint64_t *)(in+(0*43+15)*8/sizeof(in[0])); out[0*64+22] = (start += ((w14 >> 50) | (w15 << 14) & 0x7ffffffffff)); w16 = *(uint64_t *)(in+(0*43+16)*8/sizeof(in[0])); out[0*64+23] = (start += ((w15 >> 29) | (w16 << 35) & 0x7ffffffffff)); out[0*64+24] = (start += ((w16 >> 8) & 0x7ffffffffff)); w17 = *(uint64_t *)(in+(0*43+17)*8/sizeof(in[0])); out[0*64+25] = (start += ((w16 >> 51) | (w17 << 13) & 0x7ffffffffff)); w18 = *(uint64_t *)(in+(0*43+18)*8/sizeof(in[0])); out[0*64+26] = (start += ((w17 >> 30) | (w18 << 34) & 0x7ffffffffff)); out[0*64+27] = (start += ((w18 >> 9) & 0x7ffffffffff)); w19 = *(uint64_t *)(in+(0*43+19)*8/sizeof(in[0])); out[0*64+28] = (start += ((w18 >> 52) | (w19 << 12) & 0x7ffffffffff)); w20 = *(uint64_t *)(in+(0*43+20)*8/sizeof(in[0])); out[0*64+29] = (start += ((w19 >> 31) | (w20 << 33) & 0x7ffffffffff)); out[0*64+30] = (start += ((w20 >> 10) & 0x7ffffffffff)); w21 = *(uint32_t *)(in+(0*43+21)*8/sizeof(in[0])); out[0*64+31] = (start += ((w20 >> 53) | (w21 << 11) & 0x7ffffffffff));;}; out += 32; in += 43*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_44(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*44)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffffffffff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*16+ 1] = (start += ((w0 >> 44) | (w1 << 20) & 0xfffffffffff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*16+ 2] = (start += ((w1 >> 24) | (w2 << 40) & 0xfffffffffff)); out[0*16+ 3] = (start += ((w2 >> 4) & 0xfffffffffff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*16+ 4] = (start += ((w2 >> 48) | (w3 << 16) & 0xfffffffffff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*16+ 5] = (start += ((w3 >> 28) | (w4 << 36) & 0xfffffffffff)); out[0*16+ 6] = (start += ((w4 >> 8) & 0xfffffffffff)); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*16+ 7] = (start += ((w4 >> 52) | (w5 << 12) & 0xfffffffffff)); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*16+ 8] = (start += ((w5 >> 32) | (w6 << 32) & 0xfffffffffff)); out[0*16+ 9] = (start += ((w6 >> 12) & 0xfffffffffff)); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*16+10] = (start += ((w6 >> 56) | (w7 << 8) & 0xfffffffffff)); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*16+11] = (start += ((w7 >> 36) | (w8 << 28) & 0xfffffffffff)); out[0*16+12] = (start += ((w8 >> 16) & 0xfffffffffff)); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*16+13] = (start += ((w8 >> 60) | (w9 << 4) & 0xfffffffffff)); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*16+14] = (start += ((w9 >> 40) | (w10 << 24) & 0xfffffffffff)); out[0*16+15] = (start += ((w10 >> 20)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(1*11+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffffffffff)); w1 = *(uint64_t *)(in+(1*11+1)*8/sizeof(in[0])); out[1*16+ 1] = (start += ((w0 >> 44) | (w1 << 20) & 0xfffffffffff)); w2 = *(uint64_t *)(in+(1*11+2)*8/sizeof(in[0])); out[1*16+ 2] = (start += ((w1 >> 24) | (w2 << 40) & 0xfffffffffff)); out[1*16+ 3] = (start += ((w2 >> 4) & 0xfffffffffff)); w3 = *(uint64_t *)(in+(1*11+3)*8/sizeof(in[0])); out[1*16+ 4] = (start += ((w2 >> 48) | (w3 << 16) & 0xfffffffffff)); w4 = *(uint64_t *)(in+(1*11+4)*8/sizeof(in[0])); out[1*16+ 5] = (start += ((w3 >> 28) | (w4 << 36) & 0xfffffffffff)); out[1*16+ 6] = (start += ((w4 >> 8) & 0xfffffffffff)); w5 = *(uint64_t *)(in+(1*11+5)*8/sizeof(in[0])); out[1*16+ 7] = (start += ((w4 >> 52) | (w5 << 12) & 0xfffffffffff)); w6 = *(uint64_t *)(in+(1*11+6)*8/sizeof(in[0])); out[1*16+ 8] = (start += ((w5 >> 32) | (w6 << 32) & 0xfffffffffff)); out[1*16+ 9] = (start += ((w6 >> 12) & 0xfffffffffff)); w7 = *(uint64_t *)(in+(1*11+7)*8/sizeof(in[0])); out[1*16+10] = (start += ((w6 >> 56) | (w7 << 8) & 0xfffffffffff)); w8 = *(uint64_t *)(in+(1*11+8)*8/sizeof(in[0])); out[1*16+11] = (start += ((w7 >> 36) | (w8 << 28) & 0xfffffffffff)); out[1*16+12] = (start += ((w8 >> 16) & 0xfffffffffff)); w9 = *(uint64_t *)(in+(1*11+9)*8/sizeof(in[0])); out[1*16+13] = (start += ((w8 >> 60) | (w9 << 4) & 0xfffffffffff)); w10 = *(uint64_t *)(in+(1*11+10)*8/sizeof(in[0])); out[1*16+14] = (start += ((w9 >> 40) | (w10 << 24) & 0xfffffffffff)); out[1*16+15] = (start += ((w10 >> 20)));;}; out += 32; in += 44*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_45(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*45)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22; w0 = *(uint64_t *)(in+(0*45+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffffffffff)); w1 = *(uint64_t *)(in+(0*45+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 45) | (w1 << 19) & 0x1fffffffffff)); w2 = *(uint64_t *)(in+(0*45+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 26) | (w2 << 38) & 0x1fffffffffff)); out[0*64+ 3] = (start += ((w2 >> 7) & 0x1fffffffffff)); w3 = *(uint64_t *)(in+(0*45+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w2 >> 52) | (w3 << 12) & 0x1fffffffffff)); w4 = *(uint64_t *)(in+(0*45+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w3 >> 33) | (w4 << 31) & 0x1fffffffffff)); out[0*64+ 6] = (start += ((w4 >> 14) & 0x1fffffffffff)); w5 = *(uint64_t *)(in+(0*45+5)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w4 >> 59) | (w5 << 5) & 0x1fffffffffff)); w6 = *(uint64_t *)(in+(0*45+6)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w5 >> 40) | (w6 << 24) & 0x1fffffffffff)); w7 = *(uint64_t *)(in+(0*45+7)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w6 >> 21) | (w7 << 43) & 0x1fffffffffff)); out[0*64+10] = (start += ((w7 >> 2) & 0x1fffffffffff)); w8 = *(uint64_t *)(in+(0*45+8)*8/sizeof(in[0])); out[0*64+11] = (start += ((w7 >> 47) | (w8 << 17) & 0x1fffffffffff)); w9 = *(uint64_t *)(in+(0*45+9)*8/sizeof(in[0])); out[0*64+12] = (start += ((w8 >> 28) | (w9 << 36) & 0x1fffffffffff)); out[0*64+13] = (start += ((w9 >> 9) & 0x1fffffffffff)); w10 = *(uint64_t *)(in+(0*45+10)*8/sizeof(in[0])); out[0*64+14] = (start += ((w9 >> 54) | (w10 << 10) & 0x1fffffffffff)); w11 = *(uint64_t *)(in+(0*45+11)*8/sizeof(in[0])); out[0*64+15] = (start += ((w10 >> 35) | (w11 << 29) & 0x1fffffffffff)); out[0*64+16] = (start += ((w11 >> 16) & 0x1fffffffffff)); w12 = *(uint64_t *)(in+(0*45+12)*8/sizeof(in[0])); out[0*64+17] = (start += ((w11 >> 61) | (w12 << 3) & 0x1fffffffffff)); w13 = *(uint64_t *)(in+(0*45+13)*8/sizeof(in[0])); out[0*64+18] = (start += ((w12 >> 42) | (w13 << 22) & 0x1fffffffffff)); w14 = *(uint64_t *)(in+(0*45+14)*8/sizeof(in[0])); out[0*64+19] = (start += ((w13 >> 23) | (w14 << 41) & 0x1fffffffffff)); out[0*64+20] = (start += ((w14 >> 4) & 0x1fffffffffff)); w15 = *(uint64_t *)(in+(0*45+15)*8/sizeof(in[0])); out[0*64+21] = (start += ((w14 >> 49) | (w15 << 15) & 0x1fffffffffff)); w16 = *(uint64_t *)(in+(0*45+16)*8/sizeof(in[0])); out[0*64+22] = (start += ((w15 >> 30) | (w16 << 34) & 0x1fffffffffff)); out[0*64+23] = (start += ((w16 >> 11) & 0x1fffffffffff)); w17 = *(uint64_t *)(in+(0*45+17)*8/sizeof(in[0])); out[0*64+24] = (start += ((w16 >> 56) | (w17 << 8) & 0x1fffffffffff)); w18 = *(uint64_t *)(in+(0*45+18)*8/sizeof(in[0])); out[0*64+25] = (start += ((w17 >> 37) | (w18 << 27) & 0x1fffffffffff)); out[0*64+26] = (start += ((w18 >> 18) & 0x1fffffffffff)); w19 = *(uint64_t *)(in+(0*45+19)*8/sizeof(in[0])); out[0*64+27] = (start += ((w18 >> 63) | (w19 << 1) & 0x1fffffffffff)); w20 = *(uint64_t *)(in+(0*45+20)*8/sizeof(in[0])); out[0*64+28] = (start += ((w19 >> 44) | (w20 << 20) & 0x1fffffffffff)); w21 = *(uint64_t *)(in+(0*45+21)*8/sizeof(in[0])); out[0*64+29] = (start += ((w20 >> 25) | (w21 << 39) & 0x1fffffffffff)); out[0*64+30] = (start += ((w21 >> 6) & 0x1fffffffffff)); w22 = *(uint32_t *)(in+(0*45+22)*8/sizeof(in[0])); out[0*64+31] = (start += ((w21 >> 51) | (w22 << 13) & 0x1fffffffffff));;}; out += 32; in += 45*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_46(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*46)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffffffffff)); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 46) | (w1 << 18) & 0x3fffffffffff)); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w1 >> 28) | (w2 << 36) & 0x3fffffffffff)); out[0*32+ 3] = (start += ((w2 >> 10) & 0x3fffffffffff)); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w2 >> 56) | (w3 << 8) & 0x3fffffffffff)); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w3 >> 38) | (w4 << 26) & 0x3fffffffffff)); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w4 >> 20) | (w5 << 44) & 0x3fffffffffff)); out[0*32+ 7] = (start += ((w5 >> 2) & 0x3fffffffffff)); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w5 >> 48) | (w6 << 16) & 0x3fffffffffff)); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w6 >> 30) | (w7 << 34) & 0x3fffffffffff)); out[0*32+10] = (start += ((w7 >> 12) & 0x3fffffffffff)); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*32+11] = (start += ((w7 >> 58) | (w8 << 6) & 0x3fffffffffff)); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*32+12] = (start += ((w8 >> 40) | (w9 << 24) & 0x3fffffffffff)); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*32+13] = (start += ((w9 >> 22) | (w10 << 42) & 0x3fffffffffff)); out[0*32+14] = (start += ((w10 >> 4) & 0x3fffffffffff)); w11 = *(uint64_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*32+15] = (start += ((w10 >> 50) | (w11 << 14) & 0x3fffffffffff)); w12 = *(uint64_t *)(in+(0*23+12)*8/sizeof(in[0])); out[0*32+16] = (start += ((w11 >> 32) | (w12 << 32) & 0x3fffffffffff)); out[0*32+17] = (start += ((w12 >> 14) & 0x3fffffffffff)); w13 = *(uint64_t *)(in+(0*23+13)*8/sizeof(in[0])); out[0*32+18] = (start += ((w12 >> 60) | (w13 << 4) & 0x3fffffffffff)); w14 = *(uint64_t *)(in+(0*23+14)*8/sizeof(in[0])); out[0*32+19] = (start += ((w13 >> 42) | (w14 << 22) & 0x3fffffffffff)); w15 = *(uint64_t *)(in+(0*23+15)*8/sizeof(in[0])); out[0*32+20] = (start += ((w14 >> 24) | (w15 << 40) & 0x3fffffffffff)); out[0*32+21] = (start += ((w15 >> 6) & 0x3fffffffffff)); w16 = *(uint64_t *)(in+(0*23+16)*8/sizeof(in[0])); out[0*32+22] = (start += ((w15 >> 52) | (w16 << 12) & 0x3fffffffffff)); w17 = *(uint64_t *)(in+(0*23+17)*8/sizeof(in[0])); out[0*32+23] = (start += ((w16 >> 34) | (w17 << 30) & 0x3fffffffffff)); out[0*32+24] = (start += ((w17 >> 16) & 0x3fffffffffff)); w18 = *(uint64_t *)(in+(0*23+18)*8/sizeof(in[0])); out[0*32+25] = (start += ((w17 >> 62) | (w18 << 2) & 0x3fffffffffff)); w19 = *(uint64_t *)(in+(0*23+19)*8/sizeof(in[0])); out[0*32+26] = (start += ((w18 >> 44) | (w19 << 20) & 0x3fffffffffff)); w20 = *(uint64_t *)(in+(0*23+20)*8/sizeof(in[0])); out[0*32+27] = (start += ((w19 >> 26) | (w20 << 38) & 0x3fffffffffff)); out[0*32+28] = (start += ((w20 >> 8) & 0x3fffffffffff)); w21 = *(uint64_t *)(in+(0*23+21)*8/sizeof(in[0])); out[0*32+29] = (start += ((w20 >> 54) | (w21 << 10) & 0x3fffffffffff)); w22 = *(uint64_t *)(in+(0*23+22)*8/sizeof(in[0])); out[0*32+30] = (start += ((w21 >> 36) | (w22 << 28) & 0x3fffffffffff)); out[0*32+31] = (start += ((w22 >> 18)));;}; out += 32; in += 46*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_47(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*47)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(0*47+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffffffffff)); w1 = *(uint64_t *)(in+(0*47+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 47) | (w1 << 17) & 0x7fffffffffff)); w2 = *(uint64_t *)(in+(0*47+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 30) | (w2 << 34) & 0x7fffffffffff)); out[0*64+ 3] = (start += ((w2 >> 13) & 0x7fffffffffff)); w3 = *(uint64_t *)(in+(0*47+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w2 >> 60) | (w3 << 4) & 0x7fffffffffff)); w4 = *(uint64_t *)(in+(0*47+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w3 >> 43) | (w4 << 21) & 0x7fffffffffff)); w5 = *(uint64_t *)(in+(0*47+5)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w4 >> 26) | (w5 << 38) & 0x7fffffffffff)); out[0*64+ 7] = (start += ((w5 >> 9) & 0x7fffffffffff)); w6 = *(uint64_t *)(in+(0*47+6)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w5 >> 56) | (w6 << 8) & 0x7fffffffffff)); w7 = *(uint64_t *)(in+(0*47+7)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w6 >> 39) | (w7 << 25) & 0x7fffffffffff)); w8 = *(uint64_t *)(in+(0*47+8)*8/sizeof(in[0])); out[0*64+10] = (start += ((w7 >> 22) | (w8 << 42) & 0x7fffffffffff)); out[0*64+11] = (start += ((w8 >> 5) & 0x7fffffffffff)); w9 = *(uint64_t *)(in+(0*47+9)*8/sizeof(in[0])); out[0*64+12] = (start += ((w8 >> 52) | (w9 << 12) & 0x7fffffffffff)); w10 = *(uint64_t *)(in+(0*47+10)*8/sizeof(in[0])); out[0*64+13] = (start += ((w9 >> 35) | (w10 << 29) & 0x7fffffffffff)); w11 = *(uint64_t *)(in+(0*47+11)*8/sizeof(in[0])); out[0*64+14] = (start += ((w10 >> 18) | (w11 << 46) & 0x7fffffffffff)); out[0*64+15] = (start += ((w11 >> 1) & 0x7fffffffffff)); w12 = *(uint64_t *)(in+(0*47+12)*8/sizeof(in[0])); out[0*64+16] = (start += ((w11 >> 48) | (w12 << 16) & 0x7fffffffffff)); w13 = *(uint64_t *)(in+(0*47+13)*8/sizeof(in[0])); out[0*64+17] = (start += ((w12 >> 31) | (w13 << 33) & 0x7fffffffffff)); out[0*64+18] = (start += ((w13 >> 14) & 0x7fffffffffff)); w14 = *(uint64_t *)(in+(0*47+14)*8/sizeof(in[0])); out[0*64+19] = (start += ((w13 >> 61) | (w14 << 3) & 0x7fffffffffff)); w15 = *(uint64_t *)(in+(0*47+15)*8/sizeof(in[0])); out[0*64+20] = (start += ((w14 >> 44) | (w15 << 20) & 0x7fffffffffff)); w16 = *(uint64_t *)(in+(0*47+16)*8/sizeof(in[0])); out[0*64+21] = (start += ((w15 >> 27) | (w16 << 37) & 0x7fffffffffff)); out[0*64+22] = (start += ((w16 >> 10) & 0x7fffffffffff)); w17 = *(uint64_t *)(in+(0*47+17)*8/sizeof(in[0])); out[0*64+23] = (start += ((w16 >> 57) | (w17 << 7) & 0x7fffffffffff)); w18 = *(uint64_t *)(in+(0*47+18)*8/sizeof(in[0])); out[0*64+24] = (start += ((w17 >> 40) | (w18 << 24) & 0x7fffffffffff)); w19 = *(uint64_t *)(in+(0*47+19)*8/sizeof(in[0])); out[0*64+25] = (start += ((w18 >> 23) | (w19 << 41) & 0x7fffffffffff)); out[0*64+26] = (start += ((w19 >> 6) & 0x7fffffffffff)); w20 = *(uint64_t *)(in+(0*47+20)*8/sizeof(in[0])); out[0*64+27] = (start += ((w19 >> 53) | (w20 << 11) & 0x7fffffffffff)); w21 = *(uint64_t *)(in+(0*47+21)*8/sizeof(in[0])); out[0*64+28] = (start += ((w20 >> 36) | (w21 << 28) & 0x7fffffffffff)); w22 = *(uint64_t *)(in+(0*47+22)*8/sizeof(in[0])); out[0*64+29] = (start += ((w21 >> 19) | (w22 << 45) & 0x7fffffffffff)); out[0*64+30] = (start += ((w22 >> 2) & 0x7fffffffffff)); w23 = *(uint32_t *)(in+(0*47+23)*8/sizeof(in[0])); out[0*64+31] = (start += ((w22 >> 49) | (w23 << 15) & 0x7fffffffffff));;}; out += 32; in += 47*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_48(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*48)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*4+ 0] = (start += ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[0*4+ 3] = (start += ((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*4+ 0] = (start += ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[1*4+ 3] = (start += ((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*4+ 0] = (start += ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[2*4+ 3] = (start += ((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*4+ 0] = (start += ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[3*4+ 3] = (start += ((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(4*3+0)*8/sizeof(in[0])); out[4*4+ 0] = (start += ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(4*3+1)*8/sizeof(in[0])); out[4*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(4*3+2)*8/sizeof(in[0])); out[4*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[4*4+ 3] = (start += ((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(5*3+0)*8/sizeof(in[0])); out[5*4+ 0] = (start += ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(5*3+1)*8/sizeof(in[0])); out[5*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(5*3+2)*8/sizeof(in[0])); out[5*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[5*4+ 3] = (start += ((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(6*3+0)*8/sizeof(in[0])); out[6*4+ 0] = (start += ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(6*3+1)*8/sizeof(in[0])); out[6*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(6*3+2)*8/sizeof(in[0])); out[6*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[6*4+ 3] = (start += ((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(7*3+0)*8/sizeof(in[0])); out[7*4+ 0] = (start += ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(7*3+1)*8/sizeof(in[0])); out[7*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(7*3+2)*8/sizeof(in[0])); out[7*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[7*4+ 3] = (start += ((w2 >> 16)));;}; out += 32; in += 48*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_49(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*49)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24; w0 = *(uint64_t *)(in+(0*49+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffffffffffff)); w1 = *(uint64_t *)(in+(0*49+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 49) | (w1 << 15) & 0x1ffffffffffff)); w2 = *(uint64_t *)(in+(0*49+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 34) | (w2 << 30) & 0x1ffffffffffff)); w3 = *(uint64_t *)(in+(0*49+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 19) | (w3 << 45) & 0x1ffffffffffff)); out[0*64+ 4] = (start += ((w3 >> 4) & 0x1ffffffffffff)); w4 = *(uint64_t *)(in+(0*49+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w3 >> 53) | (w4 << 11) & 0x1ffffffffffff)); w5 = *(uint64_t *)(in+(0*49+5)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w4 >> 38) | (w5 << 26) & 0x1ffffffffffff)); w6 = *(uint64_t *)(in+(0*49+6)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w5 >> 23) | (w6 << 41) & 0x1ffffffffffff)); out[0*64+ 8] = (start += ((w6 >> 8) & 0x1ffffffffffff)); w7 = *(uint64_t *)(in+(0*49+7)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w6 >> 57) | (w7 << 7) & 0x1ffffffffffff)); w8 = *(uint64_t *)(in+(0*49+8)*8/sizeof(in[0])); out[0*64+10] = (start += ((w7 >> 42) | (w8 << 22) & 0x1ffffffffffff)); w9 = *(uint64_t *)(in+(0*49+9)*8/sizeof(in[0])); out[0*64+11] = (start += ((w8 >> 27) | (w9 << 37) & 0x1ffffffffffff)); out[0*64+12] = (start += ((w9 >> 12) & 0x1ffffffffffff)); w10 = *(uint64_t *)(in+(0*49+10)*8/sizeof(in[0])); out[0*64+13] = (start += ((w9 >> 61) | (w10 << 3) & 0x1ffffffffffff)); w11 = *(uint64_t *)(in+(0*49+11)*8/sizeof(in[0])); out[0*64+14] = (start += ((w10 >> 46) | (w11 << 18) & 0x1ffffffffffff)); w12 = *(uint64_t *)(in+(0*49+12)*8/sizeof(in[0])); out[0*64+15] = (start += ((w11 >> 31) | (w12 << 33) & 0x1ffffffffffff)); w13 = *(uint64_t *)(in+(0*49+13)*8/sizeof(in[0])); out[0*64+16] = (start += ((w12 >> 16) | (w13 << 48) & 0x1ffffffffffff)); out[0*64+17] = (start += ((w13 >> 1) & 0x1ffffffffffff)); w14 = *(uint64_t *)(in+(0*49+14)*8/sizeof(in[0])); out[0*64+18] = (start += ((w13 >> 50) | (w14 << 14) & 0x1ffffffffffff)); w15 = *(uint64_t *)(in+(0*49+15)*8/sizeof(in[0])); out[0*64+19] = (start += ((w14 >> 35) | (w15 << 29) & 0x1ffffffffffff)); w16 = *(uint64_t *)(in+(0*49+16)*8/sizeof(in[0])); out[0*64+20] = (start += ((w15 >> 20) | (w16 << 44) & 0x1ffffffffffff)); out[0*64+21] = (start += ((w16 >> 5) & 0x1ffffffffffff)); w17 = *(uint64_t *)(in+(0*49+17)*8/sizeof(in[0])); out[0*64+22] = (start += ((w16 >> 54) | (w17 << 10) & 0x1ffffffffffff)); w18 = *(uint64_t *)(in+(0*49+18)*8/sizeof(in[0])); out[0*64+23] = (start += ((w17 >> 39) | (w18 << 25) & 0x1ffffffffffff)); w19 = *(uint64_t *)(in+(0*49+19)*8/sizeof(in[0])); out[0*64+24] = (start += ((w18 >> 24) | (w19 << 40) & 0x1ffffffffffff)); out[0*64+25] = (start += ((w19 >> 9) & 0x1ffffffffffff)); w20 = *(uint64_t *)(in+(0*49+20)*8/sizeof(in[0])); out[0*64+26] = (start += ((w19 >> 58) | (w20 << 6) & 0x1ffffffffffff)); w21 = *(uint64_t *)(in+(0*49+21)*8/sizeof(in[0])); out[0*64+27] = (start += ((w20 >> 43) | (w21 << 21) & 0x1ffffffffffff)); w22 = *(uint64_t *)(in+(0*49+22)*8/sizeof(in[0])); out[0*64+28] = (start += ((w21 >> 28) | (w22 << 36) & 0x1ffffffffffff)); out[0*64+29] = (start += ((w22 >> 13) & 0x1ffffffffffff)); w23 = *(uint64_t *)(in+(0*49+23)*8/sizeof(in[0])); out[0*64+30] = (start += ((w22 >> 62) | (w23 << 2) & 0x1ffffffffffff)); w24 = *(uint32_t *)(in+(0*49+24)*8/sizeof(in[0])); out[0*64+31] = (start += ((w23 >> 47) | (w24 << 17) & 0x1ffffffffffff));;}; out += 32; in += 49*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_50(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*50)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffffffffffff)); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 50) | (w1 << 14) & 0x3ffffffffffff)); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w1 >> 36) | (w2 << 28) & 0x3ffffffffffff)); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w2 >> 22) | (w3 << 42) & 0x3ffffffffffff)); out[0*32+ 4] = (start += ((w3 >> 8) & 0x3ffffffffffff)); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w3 >> 58) | (w4 << 6) & 0x3ffffffffffff)); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w4 >> 44) | (w5 << 20) & 0x3ffffffffffff)); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w5 >> 30) | (w6 << 34) & 0x3ffffffffffff)); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w6 >> 16) | (w7 << 48) & 0x3ffffffffffff)); out[0*32+ 9] = (start += ((w7 >> 2) & 0x3ffffffffffff)); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*32+10] = (start += ((w7 >> 52) | (w8 << 12) & 0x3ffffffffffff)); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*32+11] = (start += ((w8 >> 38) | (w9 << 26) & 0x3ffffffffffff)); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*32+12] = (start += ((w9 >> 24) | (w10 << 40) & 0x3ffffffffffff)); out[0*32+13] = (start += ((w10 >> 10) & 0x3ffffffffffff)); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*32+14] = (start += ((w10 >> 60) | (w11 << 4) & 0x3ffffffffffff)); w12 = *(uint64_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*32+15] = (start += ((w11 >> 46) | (w12 << 18) & 0x3ffffffffffff)); w13 = *(uint64_t *)(in+(0*25+13)*8/sizeof(in[0])); out[0*32+16] = (start += ((w12 >> 32) | (w13 << 32) & 0x3ffffffffffff)); w14 = *(uint64_t *)(in+(0*25+14)*8/sizeof(in[0])); out[0*32+17] = (start += ((w13 >> 18) | (w14 << 46) & 0x3ffffffffffff)); out[0*32+18] = (start += ((w14 >> 4) & 0x3ffffffffffff)); w15 = *(uint64_t *)(in+(0*25+15)*8/sizeof(in[0])); out[0*32+19] = (start += ((w14 >> 54) | (w15 << 10) & 0x3ffffffffffff)); w16 = *(uint64_t *)(in+(0*25+16)*8/sizeof(in[0])); out[0*32+20] = (start += ((w15 >> 40) | (w16 << 24) & 0x3ffffffffffff)); w17 = *(uint64_t *)(in+(0*25+17)*8/sizeof(in[0])); out[0*32+21] = (start += ((w16 >> 26) | (w17 << 38) & 0x3ffffffffffff)); out[0*32+22] = (start += ((w17 >> 12) & 0x3ffffffffffff)); w18 = *(uint64_t *)(in+(0*25+18)*8/sizeof(in[0])); out[0*32+23] = (start += ((w17 >> 62) | (w18 << 2) & 0x3ffffffffffff)); w19 = *(uint64_t *)(in+(0*25+19)*8/sizeof(in[0])); out[0*32+24] = (start += ((w18 >> 48) | (w19 << 16) & 0x3ffffffffffff)); w20 = *(uint64_t *)(in+(0*25+20)*8/sizeof(in[0])); out[0*32+25] = (start += ((w19 >> 34) | (w20 << 30) & 0x3ffffffffffff)); w21 = *(uint64_t *)(in+(0*25+21)*8/sizeof(in[0])); out[0*32+26] = (start += ((w20 >> 20) | (w21 << 44) & 0x3ffffffffffff)); out[0*32+27] = (start += ((w21 >> 6) & 0x3ffffffffffff)); w22 = *(uint64_t *)(in+(0*25+22)*8/sizeof(in[0])); out[0*32+28] = (start += ((w21 >> 56) | (w22 << 8) & 0x3ffffffffffff)); w23 = *(uint64_t *)(in+(0*25+23)*8/sizeof(in[0])); out[0*32+29] = (start += ((w22 >> 42) | (w23 << 22) & 0x3ffffffffffff)); w24 = *(uint64_t *)(in+(0*25+24)*8/sizeof(in[0])); out[0*32+30] = (start += ((w23 >> 28) | (w24 << 36) & 0x3ffffffffffff)); out[0*32+31] = (start += ((w24 >> 14)));;}; out += 32; in += 50*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_51(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*51)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(0*51+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffffffffffff)); w1 = *(uint64_t *)(in+(0*51+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 51) | (w1 << 13) & 0x7ffffffffffff)); w2 = *(uint64_t *)(in+(0*51+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 38) | (w2 << 26) & 0x7ffffffffffff)); w3 = *(uint64_t *)(in+(0*51+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 25) | (w3 << 39) & 0x7ffffffffffff)); out[0*64+ 4] = (start += ((w3 >> 12) & 0x7ffffffffffff)); w4 = *(uint64_t *)(in+(0*51+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w3 >> 63) | (w4 << 1) & 0x7ffffffffffff)); w5 = *(uint64_t *)(in+(0*51+5)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w4 >> 50) | (w5 << 14) & 0x7ffffffffffff)); w6 = *(uint64_t *)(in+(0*51+6)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w5 >> 37) | (w6 << 27) & 0x7ffffffffffff)); w7 = *(uint64_t *)(in+(0*51+7)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w6 >> 24) | (w7 << 40) & 0x7ffffffffffff)); out[0*64+ 9] = (start += ((w7 >> 11) & 0x7ffffffffffff)); w8 = *(uint64_t *)(in+(0*51+8)*8/sizeof(in[0])); out[0*64+10] = (start += ((w7 >> 62) | (w8 << 2) & 0x7ffffffffffff)); w9 = *(uint64_t *)(in+(0*51+9)*8/sizeof(in[0])); out[0*64+11] = (start += ((w8 >> 49) | (w9 << 15) & 0x7ffffffffffff)); w10 = *(uint64_t *)(in+(0*51+10)*8/sizeof(in[0])); out[0*64+12] = (start += ((w9 >> 36) | (w10 << 28) & 0x7ffffffffffff)); w11 = *(uint64_t *)(in+(0*51+11)*8/sizeof(in[0])); out[0*64+13] = (start += ((w10 >> 23) | (w11 << 41) & 0x7ffffffffffff)); out[0*64+14] = (start += ((w11 >> 10) & 0x7ffffffffffff)); w12 = *(uint64_t *)(in+(0*51+12)*8/sizeof(in[0])); out[0*64+15] = (start += ((w11 >> 61) | (w12 << 3) & 0x7ffffffffffff)); w13 = *(uint64_t *)(in+(0*51+13)*8/sizeof(in[0])); out[0*64+16] = (start += ((w12 >> 48) | (w13 << 16) & 0x7ffffffffffff)); w14 = *(uint64_t *)(in+(0*51+14)*8/sizeof(in[0])); out[0*64+17] = (start += ((w13 >> 35) | (w14 << 29) & 0x7ffffffffffff)); w15 = *(uint64_t *)(in+(0*51+15)*8/sizeof(in[0])); out[0*64+18] = (start += ((w14 >> 22) | (w15 << 42) & 0x7ffffffffffff)); out[0*64+19] = (start += ((w15 >> 9) & 0x7ffffffffffff)); w16 = *(uint64_t *)(in+(0*51+16)*8/sizeof(in[0])); out[0*64+20] = (start += ((w15 >> 60) | (w16 << 4) & 0x7ffffffffffff)); w17 = *(uint64_t *)(in+(0*51+17)*8/sizeof(in[0])); out[0*64+21] = (start += ((w16 >> 47) | (w17 << 17) & 0x7ffffffffffff)); w18 = *(uint64_t *)(in+(0*51+18)*8/sizeof(in[0])); out[0*64+22] = (start += ((w17 >> 34) | (w18 << 30) & 0x7ffffffffffff)); w19 = *(uint64_t *)(in+(0*51+19)*8/sizeof(in[0])); out[0*64+23] = (start += ((w18 >> 21) | (w19 << 43) & 0x7ffffffffffff)); out[0*64+24] = (start += ((w19 >> 8) & 0x7ffffffffffff)); w20 = *(uint64_t *)(in+(0*51+20)*8/sizeof(in[0])); out[0*64+25] = (start += ((w19 >> 59) | (w20 << 5) & 0x7ffffffffffff)); w21 = *(uint64_t *)(in+(0*51+21)*8/sizeof(in[0])); out[0*64+26] = (start += ((w20 >> 46) | (w21 << 18) & 0x7ffffffffffff)); w22 = *(uint64_t *)(in+(0*51+22)*8/sizeof(in[0])); out[0*64+27] = (start += ((w21 >> 33) | (w22 << 31) & 0x7ffffffffffff)); w23 = *(uint64_t *)(in+(0*51+23)*8/sizeof(in[0])); out[0*64+28] = (start += ((w22 >> 20) | (w23 << 44) & 0x7ffffffffffff)); out[0*64+29] = (start += ((w23 >> 7) & 0x7ffffffffffff)); w24 = *(uint64_t *)(in+(0*51+24)*8/sizeof(in[0])); out[0*64+30] = (start += ((w23 >> 58) | (w24 << 6) & 0x7ffffffffffff)); w25 = *(uint32_t *)(in+(0*51+25)*8/sizeof(in[0])); out[0*64+31] = (start += ((w24 >> 45) | (w25 << 19) & 0x7ffffffffffff));;}; out += 32; in += 51*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_52(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*52)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffffffffffff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*16+ 1] = (start += ((w0 >> 52) | (w1 << 12) & 0xfffffffffffff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*16+ 2] = (start += ((w1 >> 40) | (w2 << 24) & 0xfffffffffffff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*16+ 3] = (start += ((w2 >> 28) | (w3 << 36) & 0xfffffffffffff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*16+ 4] = (start += ((w3 >> 16) | (w4 << 48) & 0xfffffffffffff)); out[0*16+ 5] = (start += ((w4 >> 4) & 0xfffffffffffff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*16+ 6] = (start += ((w4 >> 56) | (w5 << 8) & 0xfffffffffffff)); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*16+ 7] = (start += ((w5 >> 44) | (w6 << 20) & 0xfffffffffffff)); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*16+ 8] = (start += ((w6 >> 32) | (w7 << 32) & 0xfffffffffffff)); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*16+ 9] = (start += ((w7 >> 20) | (w8 << 44) & 0xfffffffffffff)); out[0*16+10] = (start += ((w8 >> 8) & 0xfffffffffffff)); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*16+11] = (start += ((w8 >> 60) | (w9 << 4) & 0xfffffffffffff)); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*16+12] = (start += ((w9 >> 48) | (w10 << 16) & 0xfffffffffffff)); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*16+13] = (start += ((w10 >> 36) | (w11 << 28) & 0xfffffffffffff)); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*16+14] = (start += ((w11 >> 24) | (w12 << 40) & 0xfffffffffffff)); out[0*16+15] = (start += ((w12 >> 12)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(1*13+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffffffffffff)); w1 = *(uint64_t *)(in+(1*13+1)*8/sizeof(in[0])); out[1*16+ 1] = (start += ((w0 >> 52) | (w1 << 12) & 0xfffffffffffff)); w2 = *(uint64_t *)(in+(1*13+2)*8/sizeof(in[0])); out[1*16+ 2] = (start += ((w1 >> 40) | (w2 << 24) & 0xfffffffffffff)); w3 = *(uint64_t *)(in+(1*13+3)*8/sizeof(in[0])); out[1*16+ 3] = (start += ((w2 >> 28) | (w3 << 36) & 0xfffffffffffff)); w4 = *(uint64_t *)(in+(1*13+4)*8/sizeof(in[0])); out[1*16+ 4] = (start += ((w3 >> 16) | (w4 << 48) & 0xfffffffffffff)); out[1*16+ 5] = (start += ((w4 >> 4) & 0xfffffffffffff)); w5 = *(uint64_t *)(in+(1*13+5)*8/sizeof(in[0])); out[1*16+ 6] = (start += ((w4 >> 56) | (w5 << 8) & 0xfffffffffffff)); w6 = *(uint64_t *)(in+(1*13+6)*8/sizeof(in[0])); out[1*16+ 7] = (start += ((w5 >> 44) | (w6 << 20) & 0xfffffffffffff)); w7 = *(uint64_t *)(in+(1*13+7)*8/sizeof(in[0])); out[1*16+ 8] = (start += ((w6 >> 32) | (w7 << 32) & 0xfffffffffffff)); w8 = *(uint64_t *)(in+(1*13+8)*8/sizeof(in[0])); out[1*16+ 9] = (start += ((w7 >> 20) | (w8 << 44) & 0xfffffffffffff)); out[1*16+10] = (start += ((w8 >> 8) & 0xfffffffffffff)); w9 = *(uint64_t *)(in+(1*13+9)*8/sizeof(in[0])); out[1*16+11] = (start += ((w8 >> 60) | (w9 << 4) & 0xfffffffffffff)); w10 = *(uint64_t *)(in+(1*13+10)*8/sizeof(in[0])); out[1*16+12] = (start += ((w9 >> 48) | (w10 << 16) & 0xfffffffffffff)); w11 = *(uint64_t *)(in+(1*13+11)*8/sizeof(in[0])); out[1*16+13] = (start += ((w10 >> 36) | (w11 << 28) & 0xfffffffffffff)); w12 = *(uint64_t *)(in+(1*13+12)*8/sizeof(in[0])); out[1*16+14] = (start += ((w11 >> 24) | (w12 << 40) & 0xfffffffffffff)); out[1*16+15] = (start += ((w12 >> 12)));;}; out += 32; in += 52*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_53(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*53)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26; w0 = *(uint64_t *)(in+(0*53+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffffffffffff)); w1 = *(uint64_t *)(in+(0*53+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 53) | (w1 << 11) & 0x1fffffffffffff)); w2 = *(uint64_t *)(in+(0*53+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 42) | (w2 << 22) & 0x1fffffffffffff)); w3 = *(uint64_t *)(in+(0*53+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 31) | (w3 << 33) & 0x1fffffffffffff)); w4 = *(uint64_t *)(in+(0*53+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w3 >> 20) | (w4 << 44) & 0x1fffffffffffff)); out[0*64+ 5] = (start += ((w4 >> 9) & 0x1fffffffffffff)); w5 = *(uint64_t *)(in+(0*53+5)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w4 >> 62) | (w5 << 2) & 0x1fffffffffffff)); w6 = *(uint64_t *)(in+(0*53+6)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w5 >> 51) | (w6 << 13) & 0x1fffffffffffff)); w7 = *(uint64_t *)(in+(0*53+7)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w6 >> 40) | (w7 << 24) & 0x1fffffffffffff)); w8 = *(uint64_t *)(in+(0*53+8)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w7 >> 29) | (w8 << 35) & 0x1fffffffffffff)); w9 = *(uint64_t *)(in+(0*53+9)*8/sizeof(in[0])); out[0*64+10] = (start += ((w8 >> 18) | (w9 << 46) & 0x1fffffffffffff)); out[0*64+11] = (start += ((w9 >> 7) & 0x1fffffffffffff)); w10 = *(uint64_t *)(in+(0*53+10)*8/sizeof(in[0])); out[0*64+12] = (start += ((w9 >> 60) | (w10 << 4) & 0x1fffffffffffff)); w11 = *(uint64_t *)(in+(0*53+11)*8/sizeof(in[0])); out[0*64+13] = (start += ((w10 >> 49) | (w11 << 15) & 0x1fffffffffffff)); w12 = *(uint64_t *)(in+(0*53+12)*8/sizeof(in[0])); out[0*64+14] = (start += ((w11 >> 38) | (w12 << 26) & 0x1fffffffffffff)); w13 = *(uint64_t *)(in+(0*53+13)*8/sizeof(in[0])); out[0*64+15] = (start += ((w12 >> 27) | (w13 << 37) & 0x1fffffffffffff)); w14 = *(uint64_t *)(in+(0*53+14)*8/sizeof(in[0])); out[0*64+16] = (start += ((w13 >> 16) | (w14 << 48) & 0x1fffffffffffff)); out[0*64+17] = (start += ((w14 >> 5) & 0x1fffffffffffff)); w15 = *(uint64_t *)(in+(0*53+15)*8/sizeof(in[0])); out[0*64+18] = (start += ((w14 >> 58) | (w15 << 6) & 0x1fffffffffffff)); w16 = *(uint64_t *)(in+(0*53+16)*8/sizeof(in[0])); out[0*64+19] = (start += ((w15 >> 47) | (w16 << 17) & 0x1fffffffffffff)); w17 = *(uint64_t *)(in+(0*53+17)*8/sizeof(in[0])); out[0*64+20] = (start += ((w16 >> 36) | (w17 << 28) & 0x1fffffffffffff)); w18 = *(uint64_t *)(in+(0*53+18)*8/sizeof(in[0])); out[0*64+21] = (start += ((w17 >> 25) | (w18 << 39) & 0x1fffffffffffff)); w19 = *(uint64_t *)(in+(0*53+19)*8/sizeof(in[0])); out[0*64+22] = (start += ((w18 >> 14) | (w19 << 50) & 0x1fffffffffffff)); out[0*64+23] = (start += ((w19 >> 3) & 0x1fffffffffffff)); w20 = *(uint64_t *)(in+(0*53+20)*8/sizeof(in[0])); out[0*64+24] = (start += ((w19 >> 56) | (w20 << 8) & 0x1fffffffffffff)); w21 = *(uint64_t *)(in+(0*53+21)*8/sizeof(in[0])); out[0*64+25] = (start += ((w20 >> 45) | (w21 << 19) & 0x1fffffffffffff)); w22 = *(uint64_t *)(in+(0*53+22)*8/sizeof(in[0])); out[0*64+26] = (start += ((w21 >> 34) | (w22 << 30) & 0x1fffffffffffff)); w23 = *(uint64_t *)(in+(0*53+23)*8/sizeof(in[0])); out[0*64+27] = (start += ((w22 >> 23) | (w23 << 41) & 0x1fffffffffffff)); w24 = *(uint64_t *)(in+(0*53+24)*8/sizeof(in[0])); out[0*64+28] = (start += ((w23 >> 12) | (w24 << 52) & 0x1fffffffffffff)); out[0*64+29] = (start += ((w24 >> 1) & 0x1fffffffffffff)); w25 = *(uint64_t *)(in+(0*53+25)*8/sizeof(in[0])); out[0*64+30] = (start += ((w24 >> 54) | (w25 << 10) & 0x1fffffffffffff)); w26 = *(uint32_t *)(in+(0*53+26)*8/sizeof(in[0])); out[0*64+31] = (start += ((w25 >> 43) | (w26 << 21) & 0x1fffffffffffff));;}; out += 32; in += 53*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_54(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*54)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffffffffffff)); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 54) | (w1 << 10) & 0x3fffffffffffff)); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w1 >> 44) | (w2 << 20) & 0x3fffffffffffff)); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w2 >> 34) | (w3 << 30) & 0x3fffffffffffff)); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w3 >> 24) | (w4 << 40) & 0x3fffffffffffff)); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w4 >> 14) | (w5 << 50) & 0x3fffffffffffff)); out[0*32+ 6] = (start += ((w5 >> 4) & 0x3fffffffffffff)); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w5 >> 58) | (w6 << 6) & 0x3fffffffffffff)); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w6 >> 48) | (w7 << 16) & 0x3fffffffffffff)); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w7 >> 38) | (w8 << 26) & 0x3fffffffffffff)); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*32+10] = (start += ((w8 >> 28) | (w9 << 36) & 0x3fffffffffffff)); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*32+11] = (start += ((w9 >> 18) | (w10 << 46) & 0x3fffffffffffff)); out[0*32+12] = (start += ((w10 >> 8) & 0x3fffffffffffff)); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*32+13] = (start += ((w10 >> 62) | (w11 << 2) & 0x3fffffffffffff)); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*32+14] = (start += ((w11 >> 52) | (w12 << 12) & 0x3fffffffffffff)); w13 = *(uint64_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*32+15] = (start += ((w12 >> 42) | (w13 << 22) & 0x3fffffffffffff)); w14 = *(uint64_t *)(in+(0*27+14)*8/sizeof(in[0])); out[0*32+16] = (start += ((w13 >> 32) | (w14 << 32) & 0x3fffffffffffff)); w15 = *(uint64_t *)(in+(0*27+15)*8/sizeof(in[0])); out[0*32+17] = (start += ((w14 >> 22) | (w15 << 42) & 0x3fffffffffffff)); w16 = *(uint64_t *)(in+(0*27+16)*8/sizeof(in[0])); out[0*32+18] = (start += ((w15 >> 12) | (w16 << 52) & 0x3fffffffffffff)); out[0*32+19] = (start += ((w16 >> 2) & 0x3fffffffffffff)); w17 = *(uint64_t *)(in+(0*27+17)*8/sizeof(in[0])); out[0*32+20] = (start += ((w16 >> 56) | (w17 << 8) & 0x3fffffffffffff)); w18 = *(uint64_t *)(in+(0*27+18)*8/sizeof(in[0])); out[0*32+21] = (start += ((w17 >> 46) | (w18 << 18) & 0x3fffffffffffff)); w19 = *(uint64_t *)(in+(0*27+19)*8/sizeof(in[0])); out[0*32+22] = (start += ((w18 >> 36) | (w19 << 28) & 0x3fffffffffffff)); w20 = *(uint64_t *)(in+(0*27+20)*8/sizeof(in[0])); out[0*32+23] = (start += ((w19 >> 26) | (w20 << 38) & 0x3fffffffffffff)); w21 = *(uint64_t *)(in+(0*27+21)*8/sizeof(in[0])); out[0*32+24] = (start += ((w20 >> 16) | (w21 << 48) & 0x3fffffffffffff)); out[0*32+25] = (start += ((w21 >> 6) & 0x3fffffffffffff)); w22 = *(uint64_t *)(in+(0*27+22)*8/sizeof(in[0])); out[0*32+26] = (start += ((w21 >> 60) | (w22 << 4) & 0x3fffffffffffff)); w23 = *(uint64_t *)(in+(0*27+23)*8/sizeof(in[0])); out[0*32+27] = (start += ((w22 >> 50) | (w23 << 14) & 0x3fffffffffffff)); w24 = *(uint64_t *)(in+(0*27+24)*8/sizeof(in[0])); out[0*32+28] = (start += ((w23 >> 40) | (w24 << 24) & 0x3fffffffffffff)); w25 = *(uint64_t *)(in+(0*27+25)*8/sizeof(in[0])); out[0*32+29] = (start += ((w24 >> 30) | (w25 << 34) & 0x3fffffffffffff)); w26 = *(uint64_t *)(in+(0*27+26)*8/sizeof(in[0])); out[0*32+30] = (start += ((w25 >> 20) | (w26 << 44) & 0x3fffffffffffff)); out[0*32+31] = (start += ((w26 >> 10)));;}; out += 32; in += 54*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_55(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*55)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(0*55+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffffffffffff)); w1 = *(uint64_t *)(in+(0*55+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 55) | (w1 << 9) & 0x7fffffffffffff)); w2 = *(uint64_t *)(in+(0*55+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 46) | (w2 << 18) & 0x7fffffffffffff)); w3 = *(uint64_t *)(in+(0*55+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 37) | (w3 << 27) & 0x7fffffffffffff)); w4 = *(uint64_t *)(in+(0*55+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w3 >> 28) | (w4 << 36) & 0x7fffffffffffff)); w5 = *(uint64_t *)(in+(0*55+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w4 >> 19) | (w5 << 45) & 0x7fffffffffffff)); w6 = *(uint64_t *)(in+(0*55+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w5 >> 10) | (w6 << 54) & 0x7fffffffffffff)); out[0*64+ 7] = (start += ((w6 >> 1) & 0x7fffffffffffff)); w7 = *(uint64_t *)(in+(0*55+7)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w6 >> 56) | (w7 << 8) & 0x7fffffffffffff)); w8 = *(uint64_t *)(in+(0*55+8)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w7 >> 47) | (w8 << 17) & 0x7fffffffffffff)); w9 = *(uint64_t *)(in+(0*55+9)*8/sizeof(in[0])); out[0*64+10] = (start += ((w8 >> 38) | (w9 << 26) & 0x7fffffffffffff)); w10 = *(uint64_t *)(in+(0*55+10)*8/sizeof(in[0])); out[0*64+11] = (start += ((w9 >> 29) | (w10 << 35) & 0x7fffffffffffff)); w11 = *(uint64_t *)(in+(0*55+11)*8/sizeof(in[0])); out[0*64+12] = (start += ((w10 >> 20) | (w11 << 44) & 0x7fffffffffffff)); w12 = *(uint64_t *)(in+(0*55+12)*8/sizeof(in[0])); out[0*64+13] = (start += ((w11 >> 11) | (w12 << 53) & 0x7fffffffffffff)); out[0*64+14] = (start += ((w12 >> 2) & 0x7fffffffffffff)); w13 = *(uint64_t *)(in+(0*55+13)*8/sizeof(in[0])); out[0*64+15] = (start += ((w12 >> 57) | (w13 << 7) & 0x7fffffffffffff)); w14 = *(uint64_t *)(in+(0*55+14)*8/sizeof(in[0])); out[0*64+16] = (start += ((w13 >> 48) | (w14 << 16) & 0x7fffffffffffff)); w15 = *(uint64_t *)(in+(0*55+15)*8/sizeof(in[0])); out[0*64+17] = (start += ((w14 >> 39) | (w15 << 25) & 0x7fffffffffffff)); w16 = *(uint64_t *)(in+(0*55+16)*8/sizeof(in[0])); out[0*64+18] = (start += ((w15 >> 30) | (w16 << 34) & 0x7fffffffffffff)); w17 = *(uint64_t *)(in+(0*55+17)*8/sizeof(in[0])); out[0*64+19] = (start += ((w16 >> 21) | (w17 << 43) & 0x7fffffffffffff)); w18 = *(uint64_t *)(in+(0*55+18)*8/sizeof(in[0])); out[0*64+20] = (start += ((w17 >> 12) | (w18 << 52) & 0x7fffffffffffff)); out[0*64+21] = (start += ((w18 >> 3) & 0x7fffffffffffff)); w19 = *(uint64_t *)(in+(0*55+19)*8/sizeof(in[0])); out[0*64+22] = (start += ((w18 >> 58) | (w19 << 6) & 0x7fffffffffffff)); w20 = *(uint64_t *)(in+(0*55+20)*8/sizeof(in[0])); out[0*64+23] = (start += ((w19 >> 49) | (w20 << 15) & 0x7fffffffffffff)); w21 = *(uint64_t *)(in+(0*55+21)*8/sizeof(in[0])); out[0*64+24] = (start += ((w20 >> 40) | (w21 << 24) & 0x7fffffffffffff)); w22 = *(uint64_t *)(in+(0*55+22)*8/sizeof(in[0])); out[0*64+25] = (start += ((w21 >> 31) | (w22 << 33) & 0x7fffffffffffff)); w23 = *(uint64_t *)(in+(0*55+23)*8/sizeof(in[0])); out[0*64+26] = (start += ((w22 >> 22) | (w23 << 42) & 0x7fffffffffffff)); w24 = *(uint64_t *)(in+(0*55+24)*8/sizeof(in[0])); out[0*64+27] = (start += ((w23 >> 13) | (w24 << 51) & 0x7fffffffffffff)); out[0*64+28] = (start += ((w24 >> 4) & 0x7fffffffffffff)); w25 = *(uint64_t *)(in+(0*55+25)*8/sizeof(in[0])); out[0*64+29] = (start += ((w24 >> 59) | (w25 << 5) & 0x7fffffffffffff)); w26 = *(uint64_t *)(in+(0*55+26)*8/sizeof(in[0])); out[0*64+30] = (start += ((w25 >> 50) | (w26 << 14) & 0x7fffffffffffff)); w27 = *(uint32_t *)(in+(0*55+27)*8/sizeof(in[0])); out[0*64+31] = (start += ((w26 >> 41) | (w27 << 23) & 0x7fffffffffffff));;}; out += 32; in += 55*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_56(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*56)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xffffffffffffff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*8+ 1] = (start += ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*8+ 2] = (start += ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*8+ 3] = (start += ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*8+ 4] = (start += ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*8+ 5] = (start += ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*8+ 6] = (start += ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)); out[0*8+ 7] = (start += ((w6 >> 8)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xffffffffffffff)); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*8+ 1] = (start += ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*8+ 2] = (start += ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*8+ 3] = (start += ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*8+ 4] = (start += ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*8+ 5] = (start += ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*8+ 6] = (start += ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)); out[1*8+ 7] = (start += ((w6 >> 8)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(2*7+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xffffffffffffff)); w1 = *(uint64_t *)(in+(2*7+1)*8/sizeof(in[0])); out[2*8+ 1] = (start += ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)); w2 = *(uint64_t *)(in+(2*7+2)*8/sizeof(in[0])); out[2*8+ 2] = (start += ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)); w3 = *(uint64_t *)(in+(2*7+3)*8/sizeof(in[0])); out[2*8+ 3] = (start += ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)); w4 = *(uint64_t *)(in+(2*7+4)*8/sizeof(in[0])); out[2*8+ 4] = (start += ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)); w5 = *(uint64_t *)(in+(2*7+5)*8/sizeof(in[0])); out[2*8+ 5] = (start += ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)); w6 = *(uint64_t *)(in+(2*7+6)*8/sizeof(in[0])); out[2*8+ 6] = (start += ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)); out[2*8+ 7] = (start += ((w6 >> 8)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(3*7+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xffffffffffffff)); w1 = *(uint64_t *)(in+(3*7+1)*8/sizeof(in[0])); out[3*8+ 1] = (start += ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)); w2 = *(uint64_t *)(in+(3*7+2)*8/sizeof(in[0])); out[3*8+ 2] = (start += ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)); w3 = *(uint64_t *)(in+(3*7+3)*8/sizeof(in[0])); out[3*8+ 3] = (start += ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)); w4 = *(uint64_t *)(in+(3*7+4)*8/sizeof(in[0])); out[3*8+ 4] = (start += ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)); w5 = *(uint64_t *)(in+(3*7+5)*8/sizeof(in[0])); out[3*8+ 5] = (start += ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)); w6 = *(uint64_t *)(in+(3*7+6)*8/sizeof(in[0])); out[3*8+ 6] = (start += ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)); out[3*8+ 7] = (start += ((w6 >> 8)));;}; out += 32; in += 56*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_57(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*57)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28; w0 = *(uint64_t *)(in+(0*57+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffffffffffffff)); w1 = *(uint64_t *)(in+(0*57+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 57) | (w1 << 7) & 0x1ffffffffffffff)); w2 = *(uint64_t *)(in+(0*57+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 50) | (w2 << 14) & 0x1ffffffffffffff)); w3 = *(uint64_t *)(in+(0*57+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 43) | (w3 << 21) & 0x1ffffffffffffff)); w4 = *(uint64_t *)(in+(0*57+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w3 >> 36) | (w4 << 28) & 0x1ffffffffffffff)); w5 = *(uint64_t *)(in+(0*57+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w4 >> 29) | (w5 << 35) & 0x1ffffffffffffff)); w6 = *(uint64_t *)(in+(0*57+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w5 >> 22) | (w6 << 42) & 0x1ffffffffffffff)); w7 = *(uint64_t *)(in+(0*57+7)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w6 >> 15) | (w7 << 49) & 0x1ffffffffffffff)); w8 = *(uint64_t *)(in+(0*57+8)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w7 >> 8) | (w8 << 56) & 0x1ffffffffffffff)); out[0*64+ 9] = (start += ((w8 >> 1) & 0x1ffffffffffffff)); w9 = *(uint64_t *)(in+(0*57+9)*8/sizeof(in[0])); out[0*64+10] = (start += ((w8 >> 58) | (w9 << 6) & 0x1ffffffffffffff)); w10 = *(uint64_t *)(in+(0*57+10)*8/sizeof(in[0])); out[0*64+11] = (start += ((w9 >> 51) | (w10 << 13) & 0x1ffffffffffffff)); w11 = *(uint64_t *)(in+(0*57+11)*8/sizeof(in[0])); out[0*64+12] = (start += ((w10 >> 44) | (w11 << 20) & 0x1ffffffffffffff)); w12 = *(uint64_t *)(in+(0*57+12)*8/sizeof(in[0])); out[0*64+13] = (start += ((w11 >> 37) | (w12 << 27) & 0x1ffffffffffffff)); w13 = *(uint64_t *)(in+(0*57+13)*8/sizeof(in[0])); out[0*64+14] = (start += ((w12 >> 30) | (w13 << 34) & 0x1ffffffffffffff)); w14 = *(uint64_t *)(in+(0*57+14)*8/sizeof(in[0])); out[0*64+15] = (start += ((w13 >> 23) | (w14 << 41) & 0x1ffffffffffffff)); w15 = *(uint64_t *)(in+(0*57+15)*8/sizeof(in[0])); out[0*64+16] = (start += ((w14 >> 16) | (w15 << 48) & 0x1ffffffffffffff)); w16 = *(uint64_t *)(in+(0*57+16)*8/sizeof(in[0])); out[0*64+17] = (start += ((w15 >> 9) | (w16 << 55) & 0x1ffffffffffffff)); out[0*64+18] = (start += ((w16 >> 2) & 0x1ffffffffffffff)); w17 = *(uint64_t *)(in+(0*57+17)*8/sizeof(in[0])); out[0*64+19] = (start += ((w16 >> 59) | (w17 << 5) & 0x1ffffffffffffff)); w18 = *(uint64_t *)(in+(0*57+18)*8/sizeof(in[0])); out[0*64+20] = (start += ((w17 >> 52) | (w18 << 12) & 0x1ffffffffffffff)); w19 = *(uint64_t *)(in+(0*57+19)*8/sizeof(in[0])); out[0*64+21] = (start += ((w18 >> 45) | (w19 << 19) & 0x1ffffffffffffff)); w20 = *(uint64_t *)(in+(0*57+20)*8/sizeof(in[0])); out[0*64+22] = (start += ((w19 >> 38) | (w20 << 26) & 0x1ffffffffffffff)); w21 = *(uint64_t *)(in+(0*57+21)*8/sizeof(in[0])); out[0*64+23] = (start += ((w20 >> 31) | (w21 << 33) & 0x1ffffffffffffff)); w22 = *(uint64_t *)(in+(0*57+22)*8/sizeof(in[0])); out[0*64+24] = (start += ((w21 >> 24) | (w22 << 40) & 0x1ffffffffffffff)); w23 = *(uint64_t *)(in+(0*57+23)*8/sizeof(in[0])); out[0*64+25] = (start += ((w22 >> 17) | (w23 << 47) & 0x1ffffffffffffff)); w24 = *(uint64_t *)(in+(0*57+24)*8/sizeof(in[0])); out[0*64+26] = (start += ((w23 >> 10) | (w24 << 54) & 0x1ffffffffffffff)); out[0*64+27] = (start += ((w24 >> 3) & 0x1ffffffffffffff)); w25 = *(uint64_t *)(in+(0*57+25)*8/sizeof(in[0])); out[0*64+28] = (start += ((w24 >> 60) | (w25 << 4) & 0x1ffffffffffffff)); w26 = *(uint64_t *)(in+(0*57+26)*8/sizeof(in[0])); out[0*64+29] = (start += ((w25 >> 53) | (w26 << 11) & 0x1ffffffffffffff)); w27 = *(uint64_t *)(in+(0*57+27)*8/sizeof(in[0])); out[0*64+30] = (start += ((w26 >> 46) | (w27 << 18) & 0x1ffffffffffffff)); w28 = *(uint32_t *)(in+(0*57+28)*8/sizeof(in[0])); out[0*64+31] = (start += ((w27 >> 39) | (w28 << 25) & 0x1ffffffffffffff));;}; out += 32; in += 57*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_58(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*58)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffffffffffffff)); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 58) | (w1 << 6) & 0x3ffffffffffffff)); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w1 >> 52) | (w2 << 12) & 0x3ffffffffffffff)); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w2 >> 46) | (w3 << 18) & 0x3ffffffffffffff)); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w3 >> 40) | (w4 << 24) & 0x3ffffffffffffff)); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w4 >> 34) | (w5 << 30) & 0x3ffffffffffffff)); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w5 >> 28) | (w6 << 36) & 0x3ffffffffffffff)); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w6 >> 22) | (w7 << 42) & 0x3ffffffffffffff)); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w7 >> 16) | (w8 << 48) & 0x3ffffffffffffff)); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w8 >> 10) | (w9 << 54) & 0x3ffffffffffffff)); out[0*32+10] = (start += ((w9 >> 4) & 0x3ffffffffffffff)); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*32+11] = (start += ((w9 >> 62) | (w10 << 2) & 0x3ffffffffffffff)); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*32+12] = (start += ((w10 >> 56) | (w11 << 8) & 0x3ffffffffffffff)); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*32+13] = (start += ((w11 >> 50) | (w12 << 14) & 0x3ffffffffffffff)); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*32+14] = (start += ((w12 >> 44) | (w13 << 20) & 0x3ffffffffffffff)); w14 = *(uint64_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*32+15] = (start += ((w13 >> 38) | (w14 << 26) & 0x3ffffffffffffff)); w15 = *(uint64_t *)(in+(0*29+15)*8/sizeof(in[0])); out[0*32+16] = (start += ((w14 >> 32) | (w15 << 32) & 0x3ffffffffffffff)); w16 = *(uint64_t *)(in+(0*29+16)*8/sizeof(in[0])); out[0*32+17] = (start += ((w15 >> 26) | (w16 << 38) & 0x3ffffffffffffff)); w17 = *(uint64_t *)(in+(0*29+17)*8/sizeof(in[0])); out[0*32+18] = (start += ((w16 >> 20) | (w17 << 44) & 0x3ffffffffffffff)); w18 = *(uint64_t *)(in+(0*29+18)*8/sizeof(in[0])); out[0*32+19] = (start += ((w17 >> 14) | (w18 << 50) & 0x3ffffffffffffff)); w19 = *(uint64_t *)(in+(0*29+19)*8/sizeof(in[0])); out[0*32+20] = (start += ((w18 >> 8) | (w19 << 56) & 0x3ffffffffffffff)); out[0*32+21] = (start += ((w19 >> 2) & 0x3ffffffffffffff)); w20 = *(uint64_t *)(in+(0*29+20)*8/sizeof(in[0])); out[0*32+22] = (start += ((w19 >> 60) | (w20 << 4) & 0x3ffffffffffffff)); w21 = *(uint64_t *)(in+(0*29+21)*8/sizeof(in[0])); out[0*32+23] = (start += ((w20 >> 54) | (w21 << 10) & 0x3ffffffffffffff)); w22 = *(uint64_t *)(in+(0*29+22)*8/sizeof(in[0])); out[0*32+24] = (start += ((w21 >> 48) | (w22 << 16) & 0x3ffffffffffffff)); w23 = *(uint64_t *)(in+(0*29+23)*8/sizeof(in[0])); out[0*32+25] = (start += ((w22 >> 42) | (w23 << 22) & 0x3ffffffffffffff)); w24 = *(uint64_t *)(in+(0*29+24)*8/sizeof(in[0])); out[0*32+26] = (start += ((w23 >> 36) | (w24 << 28) & 0x3ffffffffffffff)); w25 = *(uint64_t *)(in+(0*29+25)*8/sizeof(in[0])); out[0*32+27] = (start += ((w24 >> 30) | (w25 << 34) & 0x3ffffffffffffff)); w26 = *(uint64_t *)(in+(0*29+26)*8/sizeof(in[0])); out[0*32+28] = (start += ((w25 >> 24) | (w26 << 40) & 0x3ffffffffffffff)); w27 = *(uint64_t *)(in+(0*29+27)*8/sizeof(in[0])); out[0*32+29] = (start += ((w26 >> 18) | (w27 << 46) & 0x3ffffffffffffff)); w28 = *(uint64_t *)(in+(0*29+28)*8/sizeof(in[0])); out[0*32+30] = (start += ((w27 >> 12) | (w28 << 52) & 0x3ffffffffffffff)); out[0*32+31] = (start += ((w28 >> 6)));;}; out += 32; in += 58*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_59(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*59)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(0*59+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffffffffffffff)); w1 = *(uint64_t *)(in+(0*59+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 59) | (w1 << 5) & 0x7ffffffffffffff)); w2 = *(uint64_t *)(in+(0*59+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 54) | (w2 << 10) & 0x7ffffffffffffff)); w3 = *(uint64_t *)(in+(0*59+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 49) | (w3 << 15) & 0x7ffffffffffffff)); w4 = *(uint64_t *)(in+(0*59+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w3 >> 44) | (w4 << 20) & 0x7ffffffffffffff)); w5 = *(uint64_t *)(in+(0*59+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w4 >> 39) | (w5 << 25) & 0x7ffffffffffffff)); w6 = *(uint64_t *)(in+(0*59+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w5 >> 34) | (w6 << 30) & 0x7ffffffffffffff)); w7 = *(uint64_t *)(in+(0*59+7)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w6 >> 29) | (w7 << 35) & 0x7ffffffffffffff)); w8 = *(uint64_t *)(in+(0*59+8)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w7 >> 24) | (w8 << 40) & 0x7ffffffffffffff)); w9 = *(uint64_t *)(in+(0*59+9)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w8 >> 19) | (w9 << 45) & 0x7ffffffffffffff)); w10 = *(uint64_t *)(in+(0*59+10)*8/sizeof(in[0])); out[0*64+10] = (start += ((w9 >> 14) | (w10 << 50) & 0x7ffffffffffffff)); w11 = *(uint64_t *)(in+(0*59+11)*8/sizeof(in[0])); out[0*64+11] = (start += ((w10 >> 9) | (w11 << 55) & 0x7ffffffffffffff)); out[0*64+12] = (start += ((w11 >> 4) & 0x7ffffffffffffff)); w12 = *(uint64_t *)(in+(0*59+12)*8/sizeof(in[0])); out[0*64+13] = (start += ((w11 >> 63) | (w12 << 1) & 0x7ffffffffffffff)); w13 = *(uint64_t *)(in+(0*59+13)*8/sizeof(in[0])); out[0*64+14] = (start += ((w12 >> 58) | (w13 << 6) & 0x7ffffffffffffff)); w14 = *(uint64_t *)(in+(0*59+14)*8/sizeof(in[0])); out[0*64+15] = (start += ((w13 >> 53) | (w14 << 11) & 0x7ffffffffffffff)); w15 = *(uint64_t *)(in+(0*59+15)*8/sizeof(in[0])); out[0*64+16] = (start += ((w14 >> 48) | (w15 << 16) & 0x7ffffffffffffff)); w16 = *(uint64_t *)(in+(0*59+16)*8/sizeof(in[0])); out[0*64+17] = (start += ((w15 >> 43) | (w16 << 21) & 0x7ffffffffffffff)); w17 = *(uint64_t *)(in+(0*59+17)*8/sizeof(in[0])); out[0*64+18] = (start += ((w16 >> 38) | (w17 << 26) & 0x7ffffffffffffff)); w18 = *(uint64_t *)(in+(0*59+18)*8/sizeof(in[0])); out[0*64+19] = (start += ((w17 >> 33) | (w18 << 31) & 0x7ffffffffffffff)); w19 = *(uint64_t *)(in+(0*59+19)*8/sizeof(in[0])); out[0*64+20] = (start += ((w18 >> 28) | (w19 << 36) & 0x7ffffffffffffff)); w20 = *(uint64_t *)(in+(0*59+20)*8/sizeof(in[0])); out[0*64+21] = (start += ((w19 >> 23) | (w20 << 41) & 0x7ffffffffffffff)); w21 = *(uint64_t *)(in+(0*59+21)*8/sizeof(in[0])); out[0*64+22] = (start += ((w20 >> 18) | (w21 << 46) & 0x7ffffffffffffff)); w22 = *(uint64_t *)(in+(0*59+22)*8/sizeof(in[0])); out[0*64+23] = (start += ((w21 >> 13) | (w22 << 51) & 0x7ffffffffffffff)); w23 = *(uint64_t *)(in+(0*59+23)*8/sizeof(in[0])); out[0*64+24] = (start += ((w22 >> 8) | (w23 << 56) & 0x7ffffffffffffff)); out[0*64+25] = (start += ((w23 >> 3) & 0x7ffffffffffffff)); w24 = *(uint64_t *)(in+(0*59+24)*8/sizeof(in[0])); out[0*64+26] = (start += ((w23 >> 62) | (w24 << 2) & 0x7ffffffffffffff)); w25 = *(uint64_t *)(in+(0*59+25)*8/sizeof(in[0])); out[0*64+27] = (start += ((w24 >> 57) | (w25 << 7) & 0x7ffffffffffffff)); w26 = *(uint64_t *)(in+(0*59+26)*8/sizeof(in[0])); out[0*64+28] = (start += ((w25 >> 52) | (w26 << 12) & 0x7ffffffffffffff)); w27 = *(uint64_t *)(in+(0*59+27)*8/sizeof(in[0])); out[0*64+29] = (start += ((w26 >> 47) | (w27 << 17) & 0x7ffffffffffffff)); w28 = *(uint64_t *)(in+(0*59+28)*8/sizeof(in[0])); out[0*64+30] = (start += ((w27 >> 42) | (w28 << 22) & 0x7ffffffffffffff)); w29 = *(uint32_t *)(in+(0*59+29)*8/sizeof(in[0])); out[0*64+31] = (start += ((w28 >> 37) | (w29 << 27) & 0x7ffffffffffffff));;}; out += 32; in += 59*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_60(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*60)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffffffffffffff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*16+ 1] = (start += ((w0 >> 60) | (w1 << 4) & 0xfffffffffffffff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*16+ 2] = (start += ((w1 >> 56) | (w2 << 8) & 0xfffffffffffffff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*16+ 3] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffffffffffffff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*16+ 4] = (start += ((w3 >> 48) | (w4 << 16) & 0xfffffffffffffff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*16+ 5] = (start += ((w4 >> 44) | (w5 << 20) & 0xfffffffffffffff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*16+ 6] = (start += ((w5 >> 40) | (w6 << 24) & 0xfffffffffffffff)); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*16+ 7] = (start += ((w6 >> 36) | (w7 << 28) & 0xfffffffffffffff)); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*16+ 8] = (start += ((w7 >> 32) | (w8 << 32) & 0xfffffffffffffff)); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*16+ 9] = (start += ((w8 >> 28) | (w9 << 36) & 0xfffffffffffffff)); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*16+10] = (start += ((w9 >> 24) | (w10 << 40) & 0xfffffffffffffff)); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*16+11] = (start += ((w10 >> 20) | (w11 << 44) & 0xfffffffffffffff)); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*16+12] = (start += ((w11 >> 16) | (w12 << 48) & 0xfffffffffffffff)); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*16+13] = (start += ((w12 >> 12) | (w13 << 52) & 0xfffffffffffffff)); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*16+14] = (start += ((w13 >> 8) | (w14 << 56) & 0xfffffffffffffff)); out[0*16+15] = (start += ((w14 >> 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(1*15+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffffffffffffff)); w1 = *(uint64_t *)(in+(1*15+1)*8/sizeof(in[0])); out[1*16+ 1] = (start += ((w0 >> 60) | (w1 << 4) & 0xfffffffffffffff)); w2 = *(uint64_t *)(in+(1*15+2)*8/sizeof(in[0])); out[1*16+ 2] = (start += ((w1 >> 56) | (w2 << 8) & 0xfffffffffffffff)); w3 = *(uint64_t *)(in+(1*15+3)*8/sizeof(in[0])); out[1*16+ 3] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffffffffffffff)); w4 = *(uint64_t *)(in+(1*15+4)*8/sizeof(in[0])); out[1*16+ 4] = (start += ((w3 >> 48) | (w4 << 16) & 0xfffffffffffffff)); w5 = *(uint64_t *)(in+(1*15+5)*8/sizeof(in[0])); out[1*16+ 5] = (start += ((w4 >> 44) | (w5 << 20) & 0xfffffffffffffff)); w6 = *(uint64_t *)(in+(1*15+6)*8/sizeof(in[0])); out[1*16+ 6] = (start += ((w5 >> 40) | (w6 << 24) & 0xfffffffffffffff)); w7 = *(uint64_t *)(in+(1*15+7)*8/sizeof(in[0])); out[1*16+ 7] = (start += ((w6 >> 36) | (w7 << 28) & 0xfffffffffffffff)); w8 = *(uint64_t *)(in+(1*15+8)*8/sizeof(in[0])); out[1*16+ 8] = (start += ((w7 >> 32) | (w8 << 32) & 0xfffffffffffffff)); w9 = *(uint64_t *)(in+(1*15+9)*8/sizeof(in[0])); out[1*16+ 9] = (start += ((w8 >> 28) | (w9 << 36) & 0xfffffffffffffff)); w10 = *(uint64_t *)(in+(1*15+10)*8/sizeof(in[0])); out[1*16+10] = (start += ((w9 >> 24) | (w10 << 40) & 0xfffffffffffffff)); w11 = *(uint64_t *)(in+(1*15+11)*8/sizeof(in[0])); out[1*16+11] = (start += ((w10 >> 20) | (w11 << 44) & 0xfffffffffffffff)); w12 = *(uint64_t *)(in+(1*15+12)*8/sizeof(in[0])); out[1*16+12] = (start += ((w11 >> 16) | (w12 << 48) & 0xfffffffffffffff)); w13 = *(uint64_t *)(in+(1*15+13)*8/sizeof(in[0])); out[1*16+13] = (start += ((w12 >> 12) | (w13 << 52) & 0xfffffffffffffff)); w14 = *(uint64_t *)(in+(1*15+14)*8/sizeof(in[0])); out[1*16+14] = (start += ((w13 >> 8) | (w14 << 56) & 0xfffffffffffffff)); out[1*16+15] = (start += ((w14 >> 4)));;}; out += 32; in += 60*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_61(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*61)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30; w0 = *(uint64_t *)(in+(0*61+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffffffffffffff)); w1 = *(uint64_t *)(in+(0*61+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 61) | (w1 << 3) & 0x1fffffffffffffff)); w2 = *(uint64_t *)(in+(0*61+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 58) | (w2 << 6) & 0x1fffffffffffffff)); w3 = *(uint64_t *)(in+(0*61+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 55) | (w3 << 9) & 0x1fffffffffffffff)); w4 = *(uint64_t *)(in+(0*61+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w3 >> 52) | (w4 << 12) & 0x1fffffffffffffff)); w5 = *(uint64_t *)(in+(0*61+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w4 >> 49) | (w5 << 15) & 0x1fffffffffffffff)); w6 = *(uint64_t *)(in+(0*61+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w5 >> 46) | (w6 << 18) & 0x1fffffffffffffff)); w7 = *(uint64_t *)(in+(0*61+7)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w6 >> 43) | (w7 << 21) & 0x1fffffffffffffff)); w8 = *(uint64_t *)(in+(0*61+8)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w7 >> 40) | (w8 << 24) & 0x1fffffffffffffff)); w9 = *(uint64_t *)(in+(0*61+9)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w8 >> 37) | (w9 << 27) & 0x1fffffffffffffff)); w10 = *(uint64_t *)(in+(0*61+10)*8/sizeof(in[0])); out[0*64+10] = (start += ((w9 >> 34) | (w10 << 30) & 0x1fffffffffffffff)); w11 = *(uint64_t *)(in+(0*61+11)*8/sizeof(in[0])); out[0*64+11] = (start += ((w10 >> 31) | (w11 << 33) & 0x1fffffffffffffff)); w12 = *(uint64_t *)(in+(0*61+12)*8/sizeof(in[0])); out[0*64+12] = (start += ((w11 >> 28) | (w12 << 36) & 0x1fffffffffffffff)); w13 = *(uint64_t *)(in+(0*61+13)*8/sizeof(in[0])); out[0*64+13] = (start += ((w12 >> 25) | (w13 << 39) & 0x1fffffffffffffff)); w14 = *(uint64_t *)(in+(0*61+14)*8/sizeof(in[0])); out[0*64+14] = (start += ((w13 >> 22) | (w14 << 42) & 0x1fffffffffffffff)); w15 = *(uint64_t *)(in+(0*61+15)*8/sizeof(in[0])); out[0*64+15] = (start += ((w14 >> 19) | (w15 << 45) & 0x1fffffffffffffff)); w16 = *(uint64_t *)(in+(0*61+16)*8/sizeof(in[0])); out[0*64+16] = (start += ((w15 >> 16) | (w16 << 48) & 0x1fffffffffffffff)); w17 = *(uint64_t *)(in+(0*61+17)*8/sizeof(in[0])); out[0*64+17] = (start += ((w16 >> 13) | (w17 << 51) & 0x1fffffffffffffff)); w18 = *(uint64_t *)(in+(0*61+18)*8/sizeof(in[0])); out[0*64+18] = (start += ((w17 >> 10) | (w18 << 54) & 0x1fffffffffffffff)); w19 = *(uint64_t *)(in+(0*61+19)*8/sizeof(in[0])); out[0*64+19] = (start += ((w18 >> 7) | (w19 << 57) & 0x1fffffffffffffff)); w20 = *(uint64_t *)(in+(0*61+20)*8/sizeof(in[0])); out[0*64+20] = (start += ((w19 >> 4) | (w20 << 60) & 0x1fffffffffffffff)); out[0*64+21] = (start += ((w20 >> 1) & 0x1fffffffffffffff)); w21 = *(uint64_t *)(in+(0*61+21)*8/sizeof(in[0])); out[0*64+22] = (start += ((w20 >> 62) | (w21 << 2) & 0x1fffffffffffffff)); w22 = *(uint64_t *)(in+(0*61+22)*8/sizeof(in[0])); out[0*64+23] = (start += ((w21 >> 59) | (w22 << 5) & 0x1fffffffffffffff)); w23 = *(uint64_t *)(in+(0*61+23)*8/sizeof(in[0])); out[0*64+24] = (start += ((w22 >> 56) | (w23 << 8) & 0x1fffffffffffffff)); w24 = *(uint64_t *)(in+(0*61+24)*8/sizeof(in[0])); out[0*64+25] = (start += ((w23 >> 53) | (w24 << 11) & 0x1fffffffffffffff)); w25 = *(uint64_t *)(in+(0*61+25)*8/sizeof(in[0])); out[0*64+26] = (start += ((w24 >> 50) | (w25 << 14) & 0x1fffffffffffffff)); w26 = *(uint64_t *)(in+(0*61+26)*8/sizeof(in[0])); out[0*64+27] = (start += ((w25 >> 47) | (w26 << 17) & 0x1fffffffffffffff)); w27 = *(uint64_t *)(in+(0*61+27)*8/sizeof(in[0])); out[0*64+28] = (start += ((w26 >> 44) | (w27 << 20) & 0x1fffffffffffffff)); w28 = *(uint64_t *)(in+(0*61+28)*8/sizeof(in[0])); out[0*64+29] = (start += ((w27 >> 41) | (w28 << 23) & 0x1fffffffffffffff)); w29 = *(uint64_t *)(in+(0*61+29)*8/sizeof(in[0])); out[0*64+30] = (start += ((w28 >> 38) | (w29 << 26) & 0x1fffffffffffffff)); w30 = *(uint32_t *)(in+(0*61+30)*8/sizeof(in[0])); out[0*64+31] = (start += ((w29 >> 35) | (w30 << 29) & 0x1fffffffffffffff));;}; out += 32; in += 61*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_62(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*62)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffffffffffffff)); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 62) | (w1 << 2) & 0x3fffffffffffffff)); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w1 >> 60) | (w2 << 4) & 0x3fffffffffffffff)); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w2 >> 58) | (w3 << 6) & 0x3fffffffffffffff)); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w3 >> 56) | (w4 << 8) & 0x3fffffffffffffff)); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w4 >> 54) | (w5 << 10) & 0x3fffffffffffffff)); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w5 >> 52) | (w6 << 12) & 0x3fffffffffffffff)); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w6 >> 50) | (w7 << 14) & 0x3fffffffffffffff)); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w7 >> 48) | (w8 << 16) & 0x3fffffffffffffff)); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w8 >> 46) | (w9 << 18) & 0x3fffffffffffffff)); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*32+10] = (start += ((w9 >> 44) | (w10 << 20) & 0x3fffffffffffffff)); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*32+11] = (start += ((w10 >> 42) | (w11 << 22) & 0x3fffffffffffffff)); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*32+12] = (start += ((w11 >> 40) | (w12 << 24) & 0x3fffffffffffffff)); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*32+13] = (start += ((w12 >> 38) | (w13 << 26) & 0x3fffffffffffffff)); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*32+14] = (start += ((w13 >> 36) | (w14 << 28) & 0x3fffffffffffffff)); w15 = *(uint64_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*32+15] = (start += ((w14 >> 34) | (w15 << 30) & 0x3fffffffffffffff)); w16 = *(uint64_t *)(in+(0*31+16)*8/sizeof(in[0])); out[0*32+16] = (start += ((w15 >> 32) | (w16 << 32) & 0x3fffffffffffffff)); w17 = *(uint64_t *)(in+(0*31+17)*8/sizeof(in[0])); out[0*32+17] = (start += ((w16 >> 30) | (w17 << 34) & 0x3fffffffffffffff)); w18 = *(uint64_t *)(in+(0*31+18)*8/sizeof(in[0])); out[0*32+18] = (start += ((w17 >> 28) | (w18 << 36) & 0x3fffffffffffffff)); w19 = *(uint64_t *)(in+(0*31+19)*8/sizeof(in[0])); out[0*32+19] = (start += ((w18 >> 26) | (w19 << 38) & 0x3fffffffffffffff)); w20 = *(uint64_t *)(in+(0*31+20)*8/sizeof(in[0])); out[0*32+20] = (start += ((w19 >> 24) | (w20 << 40) & 0x3fffffffffffffff)); w21 = *(uint64_t *)(in+(0*31+21)*8/sizeof(in[0])); out[0*32+21] = (start += ((w20 >> 22) | (w21 << 42) & 0x3fffffffffffffff)); w22 = *(uint64_t *)(in+(0*31+22)*8/sizeof(in[0])); out[0*32+22] = (start += ((w21 >> 20) | (w22 << 44) & 0x3fffffffffffffff)); w23 = *(uint64_t *)(in+(0*31+23)*8/sizeof(in[0])); out[0*32+23] = (start += ((w22 >> 18) | (w23 << 46) & 0x3fffffffffffffff)); w24 = *(uint64_t *)(in+(0*31+24)*8/sizeof(in[0])); out[0*32+24] = (start += ((w23 >> 16) | (w24 << 48) & 0x3fffffffffffffff)); w25 = *(uint64_t *)(in+(0*31+25)*8/sizeof(in[0])); out[0*32+25] = (start += ((w24 >> 14) | (w25 << 50) & 0x3fffffffffffffff)); w26 = *(uint64_t *)(in+(0*31+26)*8/sizeof(in[0])); out[0*32+26] = (start += ((w25 >> 12) | (w26 << 52) & 0x3fffffffffffffff)); w27 = *(uint64_t *)(in+(0*31+27)*8/sizeof(in[0])); out[0*32+27] = (start += ((w26 >> 10) | (w27 << 54) & 0x3fffffffffffffff)); w28 = *(uint64_t *)(in+(0*31+28)*8/sizeof(in[0])); out[0*32+28] = (start += ((w27 >> 8) | (w28 << 56) & 0x3fffffffffffffff)); w29 = *(uint64_t *)(in+(0*31+29)*8/sizeof(in[0])); out[0*32+29] = (start += ((w28 >> 6) | (w29 << 58) & 0x3fffffffffffffff)); w30 = *(uint64_t *)(in+(0*31+30)*8/sizeof(in[0])); out[0*32+30] = (start += ((w29 >> 4) | (w30 << 60) & 0x3fffffffffffffff)); out[0*32+31] = (start += ((w30 >> 2)));;}; out += 32; in += 62*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_63(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*63)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(0*63+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffffffffffffff)); w1 = *(uint64_t *)(in+(0*63+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 63) | (w1 << 1) & 0x7fffffffffffffff)); w2 = *(uint64_t *)(in+(0*63+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 62) | (w2 << 2) & 0x7fffffffffffffff)); w3 = *(uint64_t *)(in+(0*63+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 61) | (w3 << 3) & 0x7fffffffffffffff)); w4 = *(uint64_t *)(in+(0*63+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w3 >> 60) | (w4 << 4) & 0x7fffffffffffffff)); w5 = *(uint64_t *)(in+(0*63+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w4 >> 59) | (w5 << 5) & 0x7fffffffffffffff)); w6 = *(uint64_t *)(in+(0*63+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w5 >> 58) | (w6 << 6) & 0x7fffffffffffffff)); w7 = *(uint64_t *)(in+(0*63+7)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w6 >> 57) | (w7 << 7) & 0x7fffffffffffffff)); w8 = *(uint64_t *)(in+(0*63+8)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w7 >> 56) | (w8 << 8) & 0x7fffffffffffffff)); w9 = *(uint64_t *)(in+(0*63+9)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w8 >> 55) | (w9 << 9) & 0x7fffffffffffffff)); w10 = *(uint64_t *)(in+(0*63+10)*8/sizeof(in[0])); out[0*64+10] = (start += ((w9 >> 54) | (w10 << 10) & 0x7fffffffffffffff)); w11 = *(uint64_t *)(in+(0*63+11)*8/sizeof(in[0])); out[0*64+11] = (start += ((w10 >> 53) | (w11 << 11) & 0x7fffffffffffffff)); w12 = *(uint64_t *)(in+(0*63+12)*8/sizeof(in[0])); out[0*64+12] = (start += ((w11 >> 52) | (w12 << 12) & 0x7fffffffffffffff)); w13 = *(uint64_t *)(in+(0*63+13)*8/sizeof(in[0])); out[0*64+13] = (start += ((w12 >> 51) | (w13 << 13) & 0x7fffffffffffffff)); w14 = *(uint64_t *)(in+(0*63+14)*8/sizeof(in[0])); out[0*64+14] = (start += ((w13 >> 50) | (w14 << 14) & 0x7fffffffffffffff)); w15 = *(uint64_t *)(in+(0*63+15)*8/sizeof(in[0])); out[0*64+15] = (start += ((w14 >> 49) | (w15 << 15) & 0x7fffffffffffffff)); w16 = *(uint64_t *)(in+(0*63+16)*8/sizeof(in[0])); out[0*64+16] = (start += ((w15 >> 48) | (w16 << 16) & 0x7fffffffffffffff)); w17 = *(uint64_t *)(in+(0*63+17)*8/sizeof(in[0])); out[0*64+17] = (start += ((w16 >> 47) | (w17 << 17) & 0x7fffffffffffffff)); w18 = *(uint64_t *)(in+(0*63+18)*8/sizeof(in[0])); out[0*64+18] = (start += ((w17 >> 46) | (w18 << 18) & 0x7fffffffffffffff)); w19 = *(uint64_t *)(in+(0*63+19)*8/sizeof(in[0])); out[0*64+19] = (start += ((w18 >> 45) | (w19 << 19) & 0x7fffffffffffffff)); w20 = *(uint64_t *)(in+(0*63+20)*8/sizeof(in[0])); out[0*64+20] = (start += ((w19 >> 44) | (w20 << 20) & 0x7fffffffffffffff)); w21 = *(uint64_t *)(in+(0*63+21)*8/sizeof(in[0])); out[0*64+21] = (start += ((w20 >> 43) | (w21 << 21) & 0x7fffffffffffffff)); w22 = *(uint64_t *)(in+(0*63+22)*8/sizeof(in[0])); out[0*64+22] = (start += ((w21 >> 42) | (w22 << 22) & 0x7fffffffffffffff)); w23 = *(uint64_t *)(in+(0*63+23)*8/sizeof(in[0])); out[0*64+23] = (start += ((w22 >> 41) | (w23 << 23) & 0x7fffffffffffffff)); w24 = *(uint64_t *)(in+(0*63+24)*8/sizeof(in[0])); out[0*64+24] = (start += ((w23 >> 40) | (w24 << 24) & 0x7fffffffffffffff)); w25 = *(uint64_t *)(in+(0*63+25)*8/sizeof(in[0])); out[0*64+25] = (start += ((w24 >> 39) | (w25 << 25) & 0x7fffffffffffffff)); w26 = *(uint64_t *)(in+(0*63+26)*8/sizeof(in[0])); out[0*64+26] = (start += ((w25 >> 38) | (w26 << 26) & 0x7fffffffffffffff)); w27 = *(uint64_t *)(in+(0*63+27)*8/sizeof(in[0])); out[0*64+27] = (start += ((w26 >> 37) | (w27 << 27) & 0x7fffffffffffffff)); w28 = *(uint64_t *)(in+(0*63+28)*8/sizeof(in[0])); out[0*64+28] = (start += ((w27 >> 36) | (w28 << 28) & 0x7fffffffffffffff)); w29 = *(uint64_t *)(in+(0*63+29)*8/sizeof(in[0])); out[0*64+29] = (start += ((w28 >> 35) | (w29 << 29) & 0x7fffffffffffffff)); w30 = *(uint64_t *)(in+(0*63+30)*8/sizeof(in[0])); out[0*64+30] = (start += ((w29 >> 34) | (w30 << 30) & 0x7fffffffffffffff)); w31 = *(uint32_t *)(in+(0*63+31)*8/sizeof(in[0])); out[0*64+31] = (start += ((w30 >> 33) | (w31 << 31) & 0x7fffffffffffffff));;}; out += 32; in += 63*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitdunpack64_64(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*64)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(4*1+0)*8/sizeof(in[0])); out[4*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(5*1+0)*8/sizeof(in[0])); out[5*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(6*1+0)*8/sizeof(in[0])); out[6*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(7*1+0)*8/sizeof(in[0])); out[7*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(8*1+0)*8/sizeof(in[0])); out[8*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(9*1+0)*8/sizeof(in[0])); out[9*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(10*1+0)*8/sizeof(in[0])); out[10*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(11*1+0)*8/sizeof(in[0])); out[11*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(12*1+0)*8/sizeof(in[0])); out[12*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(13*1+0)*8/sizeof(in[0])); out[13*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(14*1+0)*8/sizeof(in[0])); out[14*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(15*1+0)*8/sizeof(in[0])); out[15*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(16*1+0)*8/sizeof(in[0])); out[16*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(17*1+0)*8/sizeof(in[0])); out[17*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(18*1+0)*8/sizeof(in[0])); out[18*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(19*1+0)*8/sizeof(in[0])); out[19*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(20*1+0)*8/sizeof(in[0])); out[20*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(21*1+0)*8/sizeof(in[0])); out[21*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(22*1+0)*8/sizeof(in[0])); out[22*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(23*1+0)*8/sizeof(in[0])); out[23*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(24*1+0)*8/sizeof(in[0])); out[24*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(25*1+0)*8/sizeof(in[0])); out[25*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(26*1+0)*8/sizeof(in[0])); out[26*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(27*1+0)*8/sizeof(in[0])); out[27*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(28*1+0)*8/sizeof(in[0])); out[28*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(29*1+0)*8/sizeof(in[0])); out[29*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(30*1+0)*8/sizeof(in[0])); out[30*1+ 0] = (start += ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(31*1+0)*8/sizeof(in[0])); out[31*1+ 0] = (start += ((w0 )));;}; out += 32; in += 64*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D64 bitdunpacka64[] = {
  &bitdunpack64_0,
  &bitdunpack64_1,
  &bitdunpack64_2,
  &bitdunpack64_3,
  &bitdunpack64_4,
  &bitdunpack64_5,
  &bitdunpack64_6,
  &bitdunpack64_7,
  &bitdunpack64_8,
  &bitdunpack64_9,
  &bitdunpack64_10,
  &bitdunpack64_11,
  &bitdunpack64_12,
  &bitdunpack64_13,
  &bitdunpack64_14,
  &bitdunpack64_15,
  &bitdunpack64_16,
  &bitdunpack64_17,
  &bitdunpack64_18,
  &bitdunpack64_19,
  &bitdunpack64_20,
  &bitdunpack64_21,
  &bitdunpack64_22,
  &bitdunpack64_23,
  &bitdunpack64_24,
  &bitdunpack64_25,
  &bitdunpack64_26,
  &bitdunpack64_27,
  &bitdunpack64_28,
  &bitdunpack64_29,
  &bitdunpack64_30,
  &bitdunpack64_31,
  &bitdunpack64_32,
  &bitdunpack64_33,
  &bitdunpack64_34,
  &bitdunpack64_35,
  &bitdunpack64_36,
  &bitdunpack64_37,
  &bitdunpack64_38,
  &bitdunpack64_39,
  &bitdunpack64_40,
  &bitdunpack64_41,
  &bitdunpack64_42,
  &bitdunpack64_43,
  &bitdunpack64_44,
  &bitdunpack64_45,
  &bitdunpack64_46,
  &bitdunpack64_47,
  &bitdunpack64_48,
  &bitdunpack64_49,
  &bitdunpack64_50,
  &bitdunpack64_51,
  &bitdunpack64_52,
  &bitdunpack64_53,
  &bitdunpack64_54,
  &bitdunpack64_55,
  &bitdunpack64_56,
  &bitdunpack64_57,
  &bitdunpack64_58,
  &bitdunpack64_59,
  &bitdunpack64_60,
  &bitdunpack64_61,
  &bitdunpack64_62,
  &bitdunpack64_63,
  &bitdunpack64_64
};
unsigned char *bitdunpack64( const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start, unsigned b) { return bitdunpacka64[ b](in, n, out, start); }
unsigned char *bitzunpack8_0(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint8_t *out_ = out+n; do { { { out[0*0+ 0] = (start += zigzagdec8(0)); out[0*0+ 1] = (start += zigzagdec8(0)); out[0*0+ 2] = (start += zigzagdec8(0)); out[0*0+ 3] = (start += zigzagdec8(0)); out[0*0+ 4] = (start += zigzagdec8(0)); out[0*0+ 5] = (start += zigzagdec8(0)); out[0*0+ 6] = (start += zigzagdec8(0)); out[0*0+ 7] = (start += zigzagdec8(0)); out[0*0+ 8] = (start += zigzagdec8(0)); out[0*0+ 9] = (start += zigzagdec8(0)); out[0*0+10] = (start += zigzagdec8(0)); out[0*0+11] = (start += zigzagdec8(0)); out[0*0+12] = (start += zigzagdec8(0)); out[0*0+13] = (start += zigzagdec8(0)); out[0*0+14] = (start += zigzagdec8(0)); out[0*0+15] = (start += zigzagdec8(0)); out[0*0+16] = (start += zigzagdec8(0)); out[0*0+17] = (start += zigzagdec8(0)); out[0*0+18] = (start += zigzagdec8(0)); out[0*0+19] = (start += zigzagdec8(0)); out[0*0+20] = (start += zigzagdec8(0)); out[0*0+21] = (start += zigzagdec8(0)); out[0*0+22] = (start += zigzagdec8(0)); out[0*0+23] = (start += zigzagdec8(0)); out[0*0+24] = (start += zigzagdec8(0)); out[0*0+25] = (start += zigzagdec8(0)); out[0*0+26] = (start += zigzagdec8(0)); out[0*0+27] = (start += zigzagdec8(0)); out[0*0+28] = (start += zigzagdec8(0)); out[0*0+29] = (start += zigzagdec8(0)); out[0*0+30] = (start += zigzagdec8(0)); out[0*0+31] = (start += zigzagdec8(0));;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitzunpack8_1(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec8((w0 ) & 0x1)); out[0*32+ 1] = (start += zigzagdec8((w0 >> 1) & 0x1)); out[0*32+ 2] = (start += zigzagdec8((w0 >> 2) & 0x1)); out[0*32+ 3] = (start += zigzagdec8((w0 >> 3) & 0x1)); out[0*32+ 4] = (start += zigzagdec8((w0 >> 4) & 0x1)); out[0*32+ 5] = (start += zigzagdec8((w0 >> 5) & 0x1)); out[0*32+ 6] = (start += zigzagdec8((w0 >> 6) & 0x1)); out[0*32+ 7] = (start += zigzagdec8((w0 >> 7) & 0x1)); out[0*32+ 8] = (start += zigzagdec8((w0 >> 8) & 0x1)); out[0*32+ 9] = (start += zigzagdec8((w0 >> 9) & 0x1)); out[0*32+10] = (start += zigzagdec8((w0 >> 10) & 0x1)); out[0*32+11] = (start += zigzagdec8((w0 >> 11) & 0x1)); out[0*32+12] = (start += zigzagdec8((w0 >> 12) & 0x1)); out[0*32+13] = (start += zigzagdec8((w0 >> 13) & 0x1)); out[0*32+14] = (start += zigzagdec8((w0 >> 14) & 0x1)); out[0*32+15] = (start += zigzagdec8((w0 >> 15) & 0x1)); out[0*32+16] = (start += zigzagdec8((w0 >> 16) & 0x1)); out[0*32+17] = (start += zigzagdec8((w0 >> 17) & 0x1)); out[0*32+18] = (start += zigzagdec8((w0 >> 18) & 0x1)); out[0*32+19] = (start += zigzagdec8((w0 >> 19) & 0x1)); out[0*32+20] = (start += zigzagdec8((w0 >> 20) & 0x1)); out[0*32+21] = (start += zigzagdec8((w0 >> 21) & 0x1)); out[0*32+22] = (start += zigzagdec8((w0 >> 22) & 0x1)); out[0*32+23] = (start += zigzagdec8((w0 >> 23) & 0x1)); out[0*32+24] = (start += zigzagdec8((w0 >> 24) & 0x1)); out[0*32+25] = (start += zigzagdec8((w0 >> 25) & 0x1)); out[0*32+26] = (start += zigzagdec8((w0 >> 26) & 0x1)); out[0*32+27] = (start += zigzagdec8((w0 >> 27) & 0x1)); out[0*32+28] = (start += zigzagdec8((w0 >> 28) & 0x1)); out[0*32+29] = (start += zigzagdec8((w0 >> 29) & 0x1)); out[0*32+30] = (start += zigzagdec8((w0 >> 30) & 0x1)); out[0*32+31] = (start += zigzagdec8((w0 >> 31)));;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack8_2(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec8((w0 ) & 0x3)); out[0*32+ 1] = (start += zigzagdec8((w0 >> 2) & 0x3)); out[0*32+ 2] = (start += zigzagdec8((w0 >> 4) & 0x3)); out[0*32+ 3] = (start += zigzagdec8((w0 >> 6) & 0x3)); out[0*32+ 4] = (start += zigzagdec8((w0 >> 8) & 0x3)); out[0*32+ 5] = (start += zigzagdec8((w0 >> 10) & 0x3)); out[0*32+ 6] = (start += zigzagdec8((w0 >> 12) & 0x3)); out[0*32+ 7] = (start += zigzagdec8((w0 >> 14) & 0x3)); out[0*32+ 8] = (start += zigzagdec8((w0 >> 16) & 0x3)); out[0*32+ 9] = (start += zigzagdec8((w0 >> 18) & 0x3)); out[0*32+10] = (start += zigzagdec8((w0 >> 20) & 0x3)); out[0*32+11] = (start += zigzagdec8((w0 >> 22) & 0x3)); out[0*32+12] = (start += zigzagdec8((w0 >> 24) & 0x3)); out[0*32+13] = (start += zigzagdec8((w0 >> 26) & 0x3)); out[0*32+14] = (start += zigzagdec8((w0 >> 28) & 0x3)); out[0*32+15] = (start += zigzagdec8((w0 >> 30) & 0x3)); out[0*32+16] = (start += zigzagdec8((w0 >> 32) & 0x3)); out[0*32+17] = (start += zigzagdec8((w0 >> 34) & 0x3)); out[0*32+18] = (start += zigzagdec8((w0 >> 36) & 0x3)); out[0*32+19] = (start += zigzagdec8((w0 >> 38) & 0x3)); out[0*32+20] = (start += zigzagdec8((w0 >> 40) & 0x3)); out[0*32+21] = (start += zigzagdec8((w0 >> 42) & 0x3)); out[0*32+22] = (start += zigzagdec8((w0 >> 44) & 0x3)); out[0*32+23] = (start += zigzagdec8((w0 >> 46) & 0x3)); out[0*32+24] = (start += zigzagdec8((w0 >> 48) & 0x3)); out[0*32+25] = (start += zigzagdec8((w0 >> 50) & 0x3)); out[0*32+26] = (start += zigzagdec8((w0 >> 52) & 0x3)); out[0*32+27] = (start += zigzagdec8((w0 >> 54) & 0x3)); out[0*32+28] = (start += zigzagdec8((w0 >> 56) & 0x3)); out[0*32+29] = (start += zigzagdec8((w0 >> 58) & 0x3)); out[0*32+30] = (start += zigzagdec8((w0 >> 60) & 0x3)); out[0*32+31] = (start += zigzagdec8((w0 >> 62)));;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack8_3(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec8((w0 ) & 0x7)); out[0*64+ 1] = (start += zigzagdec8((w0 >> 3) & 0x7)); out[0*64+ 2] = (start += zigzagdec8((w0 >> 6) & 0x7)); out[0*64+ 3] = (start += zigzagdec8((w0 >> 9) & 0x7)); out[0*64+ 4] = (start += zigzagdec8((w0 >> 12) & 0x7)); out[0*64+ 5] = (start += zigzagdec8((w0 >> 15) & 0x7)); out[0*64+ 6] = (start += zigzagdec8((w0 >> 18) & 0x7)); out[0*64+ 7] = (start += zigzagdec8((w0 >> 21) & 0x7)); out[0*64+ 8] = (start += zigzagdec8((w0 >> 24) & 0x7)); out[0*64+ 9] = (start += zigzagdec8((w0 >> 27) & 0x7)); out[0*64+10] = (start += zigzagdec8((w0 >> 30) & 0x7)); out[0*64+11] = (start += zigzagdec8((w0 >> 33) & 0x7)); out[0*64+12] = (start += zigzagdec8((w0 >> 36) & 0x7)); out[0*64+13] = (start += zigzagdec8((w0 >> 39) & 0x7)); out[0*64+14] = (start += zigzagdec8((w0 >> 42) & 0x7)); out[0*64+15] = (start += zigzagdec8((w0 >> 45) & 0x7)); out[0*64+16] = (start += zigzagdec8((w0 >> 48) & 0x7)); out[0*64+17] = (start += zigzagdec8((w0 >> 51) & 0x7)); out[0*64+18] = (start += zigzagdec8((w0 >> 54) & 0x7)); out[0*64+19] = (start += zigzagdec8((w0 >> 57) & 0x7)); out[0*64+20] = (start += zigzagdec8((w0 >> 60) & 0x7)); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec8((w0 >> 63) | (w1 << 1) & 0x7)); out[0*64+22] = (start += zigzagdec8((w1 >> 2) & 0x7)); out[0*64+23] = (start += zigzagdec8((w1 >> 5) & 0x7)); out[0*64+24] = (start += zigzagdec8((w1 >> 8) & 0x7)); out[0*64+25] = (start += zigzagdec8((w1 >> 11) & 0x7)); out[0*64+26] = (start += zigzagdec8((w1 >> 14) & 0x7)); out[0*64+27] = (start += zigzagdec8((w1 >> 17) & 0x7)); out[0*64+28] = (start += zigzagdec8((w1 >> 20) & 0x7)); out[0*64+29] = (start += zigzagdec8((w1 >> 23) & 0x7)); out[0*64+30] = (start += zigzagdec8((w1 >> 26) & 0x7)); out[0*64+31] = (start += zigzagdec8((w1 >> 29) & 0x7));;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack8_4(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec8((w0 ) & 0xf)); out[0*16+ 1] = (start += zigzagdec8((w0 >> 4) & 0xf)); out[0*16+ 2] = (start += zigzagdec8((w0 >> 8) & 0xf)); out[0*16+ 3] = (start += zigzagdec8((w0 >> 12) & 0xf)); out[0*16+ 4] = (start += zigzagdec8((w0 >> 16) & 0xf)); out[0*16+ 5] = (start += zigzagdec8((w0 >> 20) & 0xf)); out[0*16+ 6] = (start += zigzagdec8((w0 >> 24) & 0xf)); out[0*16+ 7] = (start += zigzagdec8((w0 >> 28) & 0xf)); out[0*16+ 8] = (start += zigzagdec8((w0 >> 32) & 0xf)); out[0*16+ 9] = (start += zigzagdec8((w0 >> 36) & 0xf)); out[0*16+10] = (start += zigzagdec8((w0 >> 40) & 0xf)); out[0*16+11] = (start += zigzagdec8((w0 >> 44) & 0xf)); out[0*16+12] = (start += zigzagdec8((w0 >> 48) & 0xf)); out[0*16+13] = (start += zigzagdec8((w0 >> 52) & 0xf)); out[0*16+14] = (start += zigzagdec8((w0 >> 56) & 0xf)); out[0*16+15] = (start += zigzagdec8((w0 >> 60)));;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec8((w0 ) & 0xf)); out[1*16+ 1] = (start += zigzagdec8((w0 >> 4) & 0xf)); out[1*16+ 2] = (start += zigzagdec8((w0 >> 8) & 0xf)); out[1*16+ 3] = (start += zigzagdec8((w0 >> 12) & 0xf)); out[1*16+ 4] = (start += zigzagdec8((w0 >> 16) & 0xf)); out[1*16+ 5] = (start += zigzagdec8((w0 >> 20) & 0xf)); out[1*16+ 6] = (start += zigzagdec8((w0 >> 24) & 0xf)); out[1*16+ 7] = (start += zigzagdec8((w0 >> 28) & 0xf)); out[1*16+ 8] = (start += zigzagdec8((w0 >> 32) & 0xf)); out[1*16+ 9] = (start += zigzagdec8((w0 >> 36) & 0xf)); out[1*16+10] = (start += zigzagdec8((w0 >> 40) & 0xf)); out[1*16+11] = (start += zigzagdec8((w0 >> 44) & 0xf)); out[1*16+12] = (start += zigzagdec8((w0 >> 48) & 0xf)); out[1*16+13] = (start += zigzagdec8((w0 >> 52) & 0xf)); out[1*16+14] = (start += zigzagdec8((w0 >> 56) & 0xf)); out[1*16+15] = (start += zigzagdec8((w0 >> 60)));;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack8_5(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec8((w0 ) & 0x1f)); out[0*64+ 1] = (start += zigzagdec8((w0 >> 5) & 0x1f)); out[0*64+ 2] = (start += zigzagdec8((w0 >> 10) & 0x1f)); out[0*64+ 3] = (start += zigzagdec8((w0 >> 15) & 0x1f)); out[0*64+ 4] = (start += zigzagdec8((w0 >> 20) & 0x1f)); out[0*64+ 5] = (start += zigzagdec8((w0 >> 25) & 0x1f)); out[0*64+ 6] = (start += zigzagdec8((w0 >> 30) & 0x1f)); out[0*64+ 7] = (start += zigzagdec8((w0 >> 35) & 0x1f)); out[0*64+ 8] = (start += zigzagdec8((w0 >> 40) & 0x1f)); out[0*64+ 9] = (start += zigzagdec8((w0 >> 45) & 0x1f)); out[0*64+10] = (start += zigzagdec8((w0 >> 50) & 0x1f)); out[0*64+11] = (start += zigzagdec8((w0 >> 55) & 0x1f)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec8((w0 >> 60) | (w1 << 4) & 0x1f)); out[0*64+13] = (start += zigzagdec8((w1 >> 1) & 0x1f)); out[0*64+14] = (start += zigzagdec8((w1 >> 6) & 0x1f)); out[0*64+15] = (start += zigzagdec8((w1 >> 11) & 0x1f)); out[0*64+16] = (start += zigzagdec8((w1 >> 16) & 0x1f)); out[0*64+17] = (start += zigzagdec8((w1 >> 21) & 0x1f)); out[0*64+18] = (start += zigzagdec8((w1 >> 26) & 0x1f)); out[0*64+19] = (start += zigzagdec8((w1 >> 31) & 0x1f)); out[0*64+20] = (start += zigzagdec8((w1 >> 36) & 0x1f)); out[0*64+21] = (start += zigzagdec8((w1 >> 41) & 0x1f)); out[0*64+22] = (start += zigzagdec8((w1 >> 46) & 0x1f)); out[0*64+23] = (start += zigzagdec8((w1 >> 51) & 0x1f)); out[0*64+24] = (start += zigzagdec8((w1 >> 56) & 0x1f)); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec8((w1 >> 61) | (w2 << 3) & 0x1f)); out[0*64+26] = (start += zigzagdec8((w2 >> 2) & 0x1f)); out[0*64+27] = (start += zigzagdec8((w2 >> 7) & 0x1f)); out[0*64+28] = (start += zigzagdec8((w2 >> 12) & 0x1f)); out[0*64+29] = (start += zigzagdec8((w2 >> 17) & 0x1f)); out[0*64+30] = (start += zigzagdec8((w2 >> 22) & 0x1f)); out[0*64+31] = (start += zigzagdec8((w2 >> 27) & 0x1f));;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack8_6(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec8((w0 ) & 0x3f)); out[0*32+ 1] = (start += zigzagdec8((w0 >> 6) & 0x3f)); out[0*32+ 2] = (start += zigzagdec8((w0 >> 12) & 0x3f)); out[0*32+ 3] = (start += zigzagdec8((w0 >> 18) & 0x3f)); out[0*32+ 4] = (start += zigzagdec8((w0 >> 24) & 0x3f)); out[0*32+ 5] = (start += zigzagdec8((w0 >> 30) & 0x3f)); out[0*32+ 6] = (start += zigzagdec8((w0 >> 36) & 0x3f)); out[0*32+ 7] = (start += zigzagdec8((w0 >> 42) & 0x3f)); out[0*32+ 8] = (start += zigzagdec8((w0 >> 48) & 0x3f)); out[0*32+ 9] = (start += zigzagdec8((w0 >> 54) & 0x3f)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start += zigzagdec8((w0 >> 60) | (w1 << 4) & 0x3f)); out[0*32+11] = (start += zigzagdec8((w1 >> 2) & 0x3f)); out[0*32+12] = (start += zigzagdec8((w1 >> 8) & 0x3f)); out[0*32+13] = (start += zigzagdec8((w1 >> 14) & 0x3f)); out[0*32+14] = (start += zigzagdec8((w1 >> 20) & 0x3f)); out[0*32+15] = (start += zigzagdec8((w1 >> 26) & 0x3f)); out[0*32+16] = (start += zigzagdec8((w1 >> 32) & 0x3f)); out[0*32+17] = (start += zigzagdec8((w1 >> 38) & 0x3f)); out[0*32+18] = (start += zigzagdec8((w1 >> 44) & 0x3f)); out[0*32+19] = (start += zigzagdec8((w1 >> 50) & 0x3f)); out[0*32+20] = (start += zigzagdec8((w1 >> 56) & 0x3f)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start += zigzagdec8((w1 >> 62) | (w2 << 2) & 0x3f)); out[0*32+22] = (start += zigzagdec8((w2 >> 4) & 0x3f)); out[0*32+23] = (start += zigzagdec8((w2 >> 10) & 0x3f)); out[0*32+24] = (start += zigzagdec8((w2 >> 16) & 0x3f)); out[0*32+25] = (start += zigzagdec8((w2 >> 22) & 0x3f)); out[0*32+26] = (start += zigzagdec8((w2 >> 28) & 0x3f)); out[0*32+27] = (start += zigzagdec8((w2 >> 34) & 0x3f)); out[0*32+28] = (start += zigzagdec8((w2 >> 40) & 0x3f)); out[0*32+29] = (start += zigzagdec8((w2 >> 46) & 0x3f)); out[0*32+30] = (start += zigzagdec8((w2 >> 52) & 0x3f)); out[0*32+31] = (start += zigzagdec8((w2 >> 58)));;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack8_7(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec8((w0 ) & 0x7f)); out[0*64+ 1] = (start += zigzagdec8((w0 >> 7) & 0x7f)); out[0*64+ 2] = (start += zigzagdec8((w0 >> 14) & 0x7f)); out[0*64+ 3] = (start += zigzagdec8((w0 >> 21) & 0x7f)); out[0*64+ 4] = (start += zigzagdec8((w0 >> 28) & 0x7f)); out[0*64+ 5] = (start += zigzagdec8((w0 >> 35) & 0x7f)); out[0*64+ 6] = (start += zigzagdec8((w0 >> 42) & 0x7f)); out[0*64+ 7] = (start += zigzagdec8((w0 >> 49) & 0x7f)); out[0*64+ 8] = (start += zigzagdec8((w0 >> 56) & 0x7f)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec8((w0 >> 63) | (w1 << 1) & 0x7f)); out[0*64+10] = (start += zigzagdec8((w1 >> 6) & 0x7f)); out[0*64+11] = (start += zigzagdec8((w1 >> 13) & 0x7f)); out[0*64+12] = (start += zigzagdec8((w1 >> 20) & 0x7f)); out[0*64+13] = (start += zigzagdec8((w1 >> 27) & 0x7f)); out[0*64+14] = (start += zigzagdec8((w1 >> 34) & 0x7f)); out[0*64+15] = (start += zigzagdec8((w1 >> 41) & 0x7f)); out[0*64+16] = (start += zigzagdec8((w1 >> 48) & 0x7f)); out[0*64+17] = (start += zigzagdec8((w1 >> 55) & 0x7f)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec8((w1 >> 62) | (w2 << 2) & 0x7f)); out[0*64+19] = (start += zigzagdec8((w2 >> 5) & 0x7f)); out[0*64+20] = (start += zigzagdec8((w2 >> 12) & 0x7f)); out[0*64+21] = (start += zigzagdec8((w2 >> 19) & 0x7f)); out[0*64+22] = (start += zigzagdec8((w2 >> 26) & 0x7f)); out[0*64+23] = (start += zigzagdec8((w2 >> 33) & 0x7f)); out[0*64+24] = (start += zigzagdec8((w2 >> 40) & 0x7f)); out[0*64+25] = (start += zigzagdec8((w2 >> 47) & 0x7f)); out[0*64+26] = (start += zigzagdec8((w2 >> 54) & 0x7f)); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec8((w2 >> 61) | (w3 << 3) & 0x7f)); out[0*64+28] = (start += zigzagdec8((w3 >> 4) & 0x7f)); out[0*64+29] = (start += zigzagdec8((w3 >> 11) & 0x7f)); out[0*64+30] = (start += zigzagdec8((w3 >> 18) & 0x7f)); out[0*64+31] = (start += zigzagdec8((w3 >> 25) & 0x7f));;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack8_8(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += zigzagdec8((w0 ) & 0xff)); out[0*8+ 1] = (start += zigzagdec8((w0 >> 8) & 0xff)); out[0*8+ 2] = (start += zigzagdec8((w0 >> 16) & 0xff)); out[0*8+ 3] = (start += zigzagdec8((w0 >> 24) & 0xff)); out[0*8+ 4] = (start += zigzagdec8((w0 >> 32) & 0xff)); out[0*8+ 5] = (start += zigzagdec8((w0 >> 40) & 0xff)); out[0*8+ 6] = (start += zigzagdec8((w0 >> 48) & 0xff)); out[0*8+ 7] = (start += zigzagdec8((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += zigzagdec8((w0 ) & 0xff)); out[1*8+ 1] = (start += zigzagdec8((w0 >> 8) & 0xff)); out[1*8+ 2] = (start += zigzagdec8((w0 >> 16) & 0xff)); out[1*8+ 3] = (start += zigzagdec8((w0 >> 24) & 0xff)); out[1*8+ 4] = (start += zigzagdec8((w0 >> 32) & 0xff)); out[1*8+ 5] = (start += zigzagdec8((w0 >> 40) & 0xff)); out[1*8+ 6] = (start += zigzagdec8((w0 >> 48) & 0xff)); out[1*8+ 7] = (start += zigzagdec8((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += zigzagdec8((w0 ) & 0xff)); out[2*8+ 1] = (start += zigzagdec8((w0 >> 8) & 0xff)); out[2*8+ 2] = (start += zigzagdec8((w0 >> 16) & 0xff)); out[2*8+ 3] = (start += zigzagdec8((w0 >> 24) & 0xff)); out[2*8+ 4] = (start += zigzagdec8((w0 >> 32) & 0xff)); out[2*8+ 5] = (start += zigzagdec8((w0 >> 40) & 0xff)); out[2*8+ 6] = (start += zigzagdec8((w0 >> 48) & 0xff)); out[2*8+ 7] = (start += zigzagdec8((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += zigzagdec8((w0 ) & 0xff)); out[3*8+ 1] = (start += zigzagdec8((w0 >> 8) & 0xff)); out[3*8+ 2] = (start += zigzagdec8((w0 >> 16) & 0xff)); out[3*8+ 3] = (start += zigzagdec8((w0 >> 24) & 0xff)); out[3*8+ 4] = (start += zigzagdec8((w0 >> 32) & 0xff)); out[3*8+ 5] = (start += zigzagdec8((w0 >> 40) & 0xff)); out[3*8+ 6] = (start += zigzagdec8((w0 >> 48) & 0xff)); out[3*8+ 7] = (start += zigzagdec8((w0 >> 56)));;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D8 bitzunpacka8[] = {
  &bitzunpack8_0,
  &bitzunpack8_1,
  &bitzunpack8_2,
  &bitzunpack8_3,
  &bitzunpack8_4,
  &bitzunpack8_5,
  &bitzunpack8_6,
  &bitzunpack8_7,
  &bitzunpack8_8
};
unsigned char *bitzunpack8( const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start, unsigned b) { return bitzunpacka8[ b](in, n, out, start); }
unsigned char *bitzunpack16_0(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint16_t *out_ = out+n; do { { { out[0*0+ 0] = (start += zigzagdec16(0)); out[0*0+ 1] = (start += zigzagdec16(0)); out[0*0+ 2] = (start += zigzagdec16(0)); out[0*0+ 3] = (start += zigzagdec16(0)); out[0*0+ 4] = (start += zigzagdec16(0)); out[0*0+ 5] = (start += zigzagdec16(0)); out[0*0+ 6] = (start += zigzagdec16(0)); out[0*0+ 7] = (start += zigzagdec16(0)); out[0*0+ 8] = (start += zigzagdec16(0)); out[0*0+ 9] = (start += zigzagdec16(0)); out[0*0+10] = (start += zigzagdec16(0)); out[0*0+11] = (start += zigzagdec16(0)); out[0*0+12] = (start += zigzagdec16(0)); out[0*0+13] = (start += zigzagdec16(0)); out[0*0+14] = (start += zigzagdec16(0)); out[0*0+15] = (start += zigzagdec16(0)); out[0*0+16] = (start += zigzagdec16(0)); out[0*0+17] = (start += zigzagdec16(0)); out[0*0+18] = (start += zigzagdec16(0)); out[0*0+19] = (start += zigzagdec16(0)); out[0*0+20] = (start += zigzagdec16(0)); out[0*0+21] = (start += zigzagdec16(0)); out[0*0+22] = (start += zigzagdec16(0)); out[0*0+23] = (start += zigzagdec16(0)); out[0*0+24] = (start += zigzagdec16(0)); out[0*0+25] = (start += zigzagdec16(0)); out[0*0+26] = (start += zigzagdec16(0)); out[0*0+27] = (start += zigzagdec16(0)); out[0*0+28] = (start += zigzagdec16(0)); out[0*0+29] = (start += zigzagdec16(0)); out[0*0+30] = (start += zigzagdec16(0)); out[0*0+31] = (start += zigzagdec16(0));;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitzunpack16_1(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec16((w0 ) & 0x1)); out[0*32+ 1] = (start += zigzagdec16((w0 >> 1) & 0x1)); out[0*32+ 2] = (start += zigzagdec16((w0 >> 2) & 0x1)); out[0*32+ 3] = (start += zigzagdec16((w0 >> 3) & 0x1)); out[0*32+ 4] = (start += zigzagdec16((w0 >> 4) & 0x1)); out[0*32+ 5] = (start += zigzagdec16((w0 >> 5) & 0x1)); out[0*32+ 6] = (start += zigzagdec16((w0 >> 6) & 0x1)); out[0*32+ 7] = (start += zigzagdec16((w0 >> 7) & 0x1)); out[0*32+ 8] = (start += zigzagdec16((w0 >> 8) & 0x1)); out[0*32+ 9] = (start += zigzagdec16((w0 >> 9) & 0x1)); out[0*32+10] = (start += zigzagdec16((w0 >> 10) & 0x1)); out[0*32+11] = (start += zigzagdec16((w0 >> 11) & 0x1)); out[0*32+12] = (start += zigzagdec16((w0 >> 12) & 0x1)); out[0*32+13] = (start += zigzagdec16((w0 >> 13) & 0x1)); out[0*32+14] = (start += zigzagdec16((w0 >> 14) & 0x1)); out[0*32+15] = (start += zigzagdec16((w0 >> 15) & 0x1)); out[0*32+16] = (start += zigzagdec16((w0 >> 16) & 0x1)); out[0*32+17] = (start += zigzagdec16((w0 >> 17) & 0x1)); out[0*32+18] = (start += zigzagdec16((w0 >> 18) & 0x1)); out[0*32+19] = (start += zigzagdec16((w0 >> 19) & 0x1)); out[0*32+20] = (start += zigzagdec16((w0 >> 20) & 0x1)); out[0*32+21] = (start += zigzagdec16((w0 >> 21) & 0x1)); out[0*32+22] = (start += zigzagdec16((w0 >> 22) & 0x1)); out[0*32+23] = (start += zigzagdec16((w0 >> 23) & 0x1)); out[0*32+24] = (start += zigzagdec16((w0 >> 24) & 0x1)); out[0*32+25] = (start += zigzagdec16((w0 >> 25) & 0x1)); out[0*32+26] = (start += zigzagdec16((w0 >> 26) & 0x1)); out[0*32+27] = (start += zigzagdec16((w0 >> 27) & 0x1)); out[0*32+28] = (start += zigzagdec16((w0 >> 28) & 0x1)); out[0*32+29] = (start += zigzagdec16((w0 >> 29) & 0x1)); out[0*32+30] = (start += zigzagdec16((w0 >> 30) & 0x1)); out[0*32+31] = (start += zigzagdec16((w0 >> 31)));;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_2(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec16((w0 ) & 0x3)); out[0*32+ 1] = (start += zigzagdec16((w0 >> 2) & 0x3)); out[0*32+ 2] = (start += zigzagdec16((w0 >> 4) & 0x3)); out[0*32+ 3] = (start += zigzagdec16((w0 >> 6) & 0x3)); out[0*32+ 4] = (start += zigzagdec16((w0 >> 8) & 0x3)); out[0*32+ 5] = (start += zigzagdec16((w0 >> 10) & 0x3)); out[0*32+ 6] = (start += zigzagdec16((w0 >> 12) & 0x3)); out[0*32+ 7] = (start += zigzagdec16((w0 >> 14) & 0x3)); out[0*32+ 8] = (start += zigzagdec16((w0 >> 16) & 0x3)); out[0*32+ 9] = (start += zigzagdec16((w0 >> 18) & 0x3)); out[0*32+10] = (start += zigzagdec16((w0 >> 20) & 0x3)); out[0*32+11] = (start += zigzagdec16((w0 >> 22) & 0x3)); out[0*32+12] = (start += zigzagdec16((w0 >> 24) & 0x3)); out[0*32+13] = (start += zigzagdec16((w0 >> 26) & 0x3)); out[0*32+14] = (start += zigzagdec16((w0 >> 28) & 0x3)); out[0*32+15] = (start += zigzagdec16((w0 >> 30) & 0x3)); out[0*32+16] = (start += zigzagdec16((w0 >> 32) & 0x3)); out[0*32+17] = (start += zigzagdec16((w0 >> 34) & 0x3)); out[0*32+18] = (start += zigzagdec16((w0 >> 36) & 0x3)); out[0*32+19] = (start += zigzagdec16((w0 >> 38) & 0x3)); out[0*32+20] = (start += zigzagdec16((w0 >> 40) & 0x3)); out[0*32+21] = (start += zigzagdec16((w0 >> 42) & 0x3)); out[0*32+22] = (start += zigzagdec16((w0 >> 44) & 0x3)); out[0*32+23] = (start += zigzagdec16((w0 >> 46) & 0x3)); out[0*32+24] = (start += zigzagdec16((w0 >> 48) & 0x3)); out[0*32+25] = (start += zigzagdec16((w0 >> 50) & 0x3)); out[0*32+26] = (start += zigzagdec16((w0 >> 52) & 0x3)); out[0*32+27] = (start += zigzagdec16((w0 >> 54) & 0x3)); out[0*32+28] = (start += zigzagdec16((w0 >> 56) & 0x3)); out[0*32+29] = (start += zigzagdec16((w0 >> 58) & 0x3)); out[0*32+30] = (start += zigzagdec16((w0 >> 60) & 0x3)); out[0*32+31] = (start += zigzagdec16((w0 >> 62)));;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_3(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec16((w0 ) & 0x7)); out[0*64+ 1] = (start += zigzagdec16((w0 >> 3) & 0x7)); out[0*64+ 2] = (start += zigzagdec16((w0 >> 6) & 0x7)); out[0*64+ 3] = (start += zigzagdec16((w0 >> 9) & 0x7)); out[0*64+ 4] = (start += zigzagdec16((w0 >> 12) & 0x7)); out[0*64+ 5] = (start += zigzagdec16((w0 >> 15) & 0x7)); out[0*64+ 6] = (start += zigzagdec16((w0 >> 18) & 0x7)); out[0*64+ 7] = (start += zigzagdec16((w0 >> 21) & 0x7)); out[0*64+ 8] = (start += zigzagdec16((w0 >> 24) & 0x7)); out[0*64+ 9] = (start += zigzagdec16((w0 >> 27) & 0x7)); out[0*64+10] = (start += zigzagdec16((w0 >> 30) & 0x7)); out[0*64+11] = (start += zigzagdec16((w0 >> 33) & 0x7)); out[0*64+12] = (start += zigzagdec16((w0 >> 36) & 0x7)); out[0*64+13] = (start += zigzagdec16((w0 >> 39) & 0x7)); out[0*64+14] = (start += zigzagdec16((w0 >> 42) & 0x7)); out[0*64+15] = (start += zigzagdec16((w0 >> 45) & 0x7)); out[0*64+16] = (start += zigzagdec16((w0 >> 48) & 0x7)); out[0*64+17] = (start += zigzagdec16((w0 >> 51) & 0x7)); out[0*64+18] = (start += zigzagdec16((w0 >> 54) & 0x7)); out[0*64+19] = (start += zigzagdec16((w0 >> 57) & 0x7)); out[0*64+20] = (start += zigzagdec16((w0 >> 60) & 0x7)); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec16((w0 >> 63) | (w1 << 1) & 0x7)); out[0*64+22] = (start += zigzagdec16((w1 >> 2) & 0x7)); out[0*64+23] = (start += zigzagdec16((w1 >> 5) & 0x7)); out[0*64+24] = (start += zigzagdec16((w1 >> 8) & 0x7)); out[0*64+25] = (start += zigzagdec16((w1 >> 11) & 0x7)); out[0*64+26] = (start += zigzagdec16((w1 >> 14) & 0x7)); out[0*64+27] = (start += zigzagdec16((w1 >> 17) & 0x7)); out[0*64+28] = (start += zigzagdec16((w1 >> 20) & 0x7)); out[0*64+29] = (start += zigzagdec16((w1 >> 23) & 0x7)); out[0*64+30] = (start += zigzagdec16((w1 >> 26) & 0x7)); out[0*64+31] = (start += zigzagdec16((w1 >> 29) & 0x7));;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_4(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec16((w0 ) & 0xf)); out[0*16+ 1] = (start += zigzagdec16((w0 >> 4) & 0xf)); out[0*16+ 2] = (start += zigzagdec16((w0 >> 8) & 0xf)); out[0*16+ 3] = (start += zigzagdec16((w0 >> 12) & 0xf)); out[0*16+ 4] = (start += zigzagdec16((w0 >> 16) & 0xf)); out[0*16+ 5] = (start += zigzagdec16((w0 >> 20) & 0xf)); out[0*16+ 6] = (start += zigzagdec16((w0 >> 24) & 0xf)); out[0*16+ 7] = (start += zigzagdec16((w0 >> 28) & 0xf)); out[0*16+ 8] = (start += zigzagdec16((w0 >> 32) & 0xf)); out[0*16+ 9] = (start += zigzagdec16((w0 >> 36) & 0xf)); out[0*16+10] = (start += zigzagdec16((w0 >> 40) & 0xf)); out[0*16+11] = (start += zigzagdec16((w0 >> 44) & 0xf)); out[0*16+12] = (start += zigzagdec16((w0 >> 48) & 0xf)); out[0*16+13] = (start += zigzagdec16((w0 >> 52) & 0xf)); out[0*16+14] = (start += zigzagdec16((w0 >> 56) & 0xf)); out[0*16+15] = (start += zigzagdec16((w0 >> 60)));;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec16((w0 ) & 0xf)); out[1*16+ 1] = (start += zigzagdec16((w0 >> 4) & 0xf)); out[1*16+ 2] = (start += zigzagdec16((w0 >> 8) & 0xf)); out[1*16+ 3] = (start += zigzagdec16((w0 >> 12) & 0xf)); out[1*16+ 4] = (start += zigzagdec16((w0 >> 16) & 0xf)); out[1*16+ 5] = (start += zigzagdec16((w0 >> 20) & 0xf)); out[1*16+ 6] = (start += zigzagdec16((w0 >> 24) & 0xf)); out[1*16+ 7] = (start += zigzagdec16((w0 >> 28) & 0xf)); out[1*16+ 8] = (start += zigzagdec16((w0 >> 32) & 0xf)); out[1*16+ 9] = (start += zigzagdec16((w0 >> 36) & 0xf)); out[1*16+10] = (start += zigzagdec16((w0 >> 40) & 0xf)); out[1*16+11] = (start += zigzagdec16((w0 >> 44) & 0xf)); out[1*16+12] = (start += zigzagdec16((w0 >> 48) & 0xf)); out[1*16+13] = (start += zigzagdec16((w0 >> 52) & 0xf)); out[1*16+14] = (start += zigzagdec16((w0 >> 56) & 0xf)); out[1*16+15] = (start += zigzagdec16((w0 >> 60)));;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_5(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec16((w0 ) & 0x1f)); out[0*64+ 1] = (start += zigzagdec16((w0 >> 5) & 0x1f)); out[0*64+ 2] = (start += zigzagdec16((w0 >> 10) & 0x1f)); out[0*64+ 3] = (start += zigzagdec16((w0 >> 15) & 0x1f)); out[0*64+ 4] = (start += zigzagdec16((w0 >> 20) & 0x1f)); out[0*64+ 5] = (start += zigzagdec16((w0 >> 25) & 0x1f)); out[0*64+ 6] = (start += zigzagdec16((w0 >> 30) & 0x1f)); out[0*64+ 7] = (start += zigzagdec16((w0 >> 35) & 0x1f)); out[0*64+ 8] = (start += zigzagdec16((w0 >> 40) & 0x1f)); out[0*64+ 9] = (start += zigzagdec16((w0 >> 45) & 0x1f)); out[0*64+10] = (start += zigzagdec16((w0 >> 50) & 0x1f)); out[0*64+11] = (start += zigzagdec16((w0 >> 55) & 0x1f)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec16((w0 >> 60) | (w1 << 4) & 0x1f)); out[0*64+13] = (start += zigzagdec16((w1 >> 1) & 0x1f)); out[0*64+14] = (start += zigzagdec16((w1 >> 6) & 0x1f)); out[0*64+15] = (start += zigzagdec16((w1 >> 11) & 0x1f)); out[0*64+16] = (start += zigzagdec16((w1 >> 16) & 0x1f)); out[0*64+17] = (start += zigzagdec16((w1 >> 21) & 0x1f)); out[0*64+18] = (start += zigzagdec16((w1 >> 26) & 0x1f)); out[0*64+19] = (start += zigzagdec16((w1 >> 31) & 0x1f)); out[0*64+20] = (start += zigzagdec16((w1 >> 36) & 0x1f)); out[0*64+21] = (start += zigzagdec16((w1 >> 41) & 0x1f)); out[0*64+22] = (start += zigzagdec16((w1 >> 46) & 0x1f)); out[0*64+23] = (start += zigzagdec16((w1 >> 51) & 0x1f)); out[0*64+24] = (start += zigzagdec16((w1 >> 56) & 0x1f)); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec16((w1 >> 61) | (w2 << 3) & 0x1f)); out[0*64+26] = (start += zigzagdec16((w2 >> 2) & 0x1f)); out[0*64+27] = (start += zigzagdec16((w2 >> 7) & 0x1f)); out[0*64+28] = (start += zigzagdec16((w2 >> 12) & 0x1f)); out[0*64+29] = (start += zigzagdec16((w2 >> 17) & 0x1f)); out[0*64+30] = (start += zigzagdec16((w2 >> 22) & 0x1f)); out[0*64+31] = (start += zigzagdec16((w2 >> 27) & 0x1f));;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_6(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec16((w0 ) & 0x3f)); out[0*32+ 1] = (start += zigzagdec16((w0 >> 6) & 0x3f)); out[0*32+ 2] = (start += zigzagdec16((w0 >> 12) & 0x3f)); out[0*32+ 3] = (start += zigzagdec16((w0 >> 18) & 0x3f)); out[0*32+ 4] = (start += zigzagdec16((w0 >> 24) & 0x3f)); out[0*32+ 5] = (start += zigzagdec16((w0 >> 30) & 0x3f)); out[0*32+ 6] = (start += zigzagdec16((w0 >> 36) & 0x3f)); out[0*32+ 7] = (start += zigzagdec16((w0 >> 42) & 0x3f)); out[0*32+ 8] = (start += zigzagdec16((w0 >> 48) & 0x3f)); out[0*32+ 9] = (start += zigzagdec16((w0 >> 54) & 0x3f)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start += zigzagdec16((w0 >> 60) | (w1 << 4) & 0x3f)); out[0*32+11] = (start += zigzagdec16((w1 >> 2) & 0x3f)); out[0*32+12] = (start += zigzagdec16((w1 >> 8) & 0x3f)); out[0*32+13] = (start += zigzagdec16((w1 >> 14) & 0x3f)); out[0*32+14] = (start += zigzagdec16((w1 >> 20) & 0x3f)); out[0*32+15] = (start += zigzagdec16((w1 >> 26) & 0x3f)); out[0*32+16] = (start += zigzagdec16((w1 >> 32) & 0x3f)); out[0*32+17] = (start += zigzagdec16((w1 >> 38) & 0x3f)); out[0*32+18] = (start += zigzagdec16((w1 >> 44) & 0x3f)); out[0*32+19] = (start += zigzagdec16((w1 >> 50) & 0x3f)); out[0*32+20] = (start += zigzagdec16((w1 >> 56) & 0x3f)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start += zigzagdec16((w1 >> 62) | (w2 << 2) & 0x3f)); out[0*32+22] = (start += zigzagdec16((w2 >> 4) & 0x3f)); out[0*32+23] = (start += zigzagdec16((w2 >> 10) & 0x3f)); out[0*32+24] = (start += zigzagdec16((w2 >> 16) & 0x3f)); out[0*32+25] = (start += zigzagdec16((w2 >> 22) & 0x3f)); out[0*32+26] = (start += zigzagdec16((w2 >> 28) & 0x3f)); out[0*32+27] = (start += zigzagdec16((w2 >> 34) & 0x3f)); out[0*32+28] = (start += zigzagdec16((w2 >> 40) & 0x3f)); out[0*32+29] = (start += zigzagdec16((w2 >> 46) & 0x3f)); out[0*32+30] = (start += zigzagdec16((w2 >> 52) & 0x3f)); out[0*32+31] = (start += zigzagdec16((w2 >> 58)));;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_7(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec16((w0 ) & 0x7f)); out[0*64+ 1] = (start += zigzagdec16((w0 >> 7) & 0x7f)); out[0*64+ 2] = (start += zigzagdec16((w0 >> 14) & 0x7f)); out[0*64+ 3] = (start += zigzagdec16((w0 >> 21) & 0x7f)); out[0*64+ 4] = (start += zigzagdec16((w0 >> 28) & 0x7f)); out[0*64+ 5] = (start += zigzagdec16((w0 >> 35) & 0x7f)); out[0*64+ 6] = (start += zigzagdec16((w0 >> 42) & 0x7f)); out[0*64+ 7] = (start += zigzagdec16((w0 >> 49) & 0x7f)); out[0*64+ 8] = (start += zigzagdec16((w0 >> 56) & 0x7f)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec16((w0 >> 63) | (w1 << 1) & 0x7f)); out[0*64+10] = (start += zigzagdec16((w1 >> 6) & 0x7f)); out[0*64+11] = (start += zigzagdec16((w1 >> 13) & 0x7f)); out[0*64+12] = (start += zigzagdec16((w1 >> 20) & 0x7f)); out[0*64+13] = (start += zigzagdec16((w1 >> 27) & 0x7f)); out[0*64+14] = (start += zigzagdec16((w1 >> 34) & 0x7f)); out[0*64+15] = (start += zigzagdec16((w1 >> 41) & 0x7f)); out[0*64+16] = (start += zigzagdec16((w1 >> 48) & 0x7f)); out[0*64+17] = (start += zigzagdec16((w1 >> 55) & 0x7f)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec16((w1 >> 62) | (w2 << 2) & 0x7f)); out[0*64+19] = (start += zigzagdec16((w2 >> 5) & 0x7f)); out[0*64+20] = (start += zigzagdec16((w2 >> 12) & 0x7f)); out[0*64+21] = (start += zigzagdec16((w2 >> 19) & 0x7f)); out[0*64+22] = (start += zigzagdec16((w2 >> 26) & 0x7f)); out[0*64+23] = (start += zigzagdec16((w2 >> 33) & 0x7f)); out[0*64+24] = (start += zigzagdec16((w2 >> 40) & 0x7f)); out[0*64+25] = (start += zigzagdec16((w2 >> 47) & 0x7f)); out[0*64+26] = (start += zigzagdec16((w2 >> 54) & 0x7f)); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec16((w2 >> 61) | (w3 << 3) & 0x7f)); out[0*64+28] = (start += zigzagdec16((w3 >> 4) & 0x7f)); out[0*64+29] = (start += zigzagdec16((w3 >> 11) & 0x7f)); out[0*64+30] = (start += zigzagdec16((w3 >> 18) & 0x7f)); out[0*64+31] = (start += zigzagdec16((w3 >> 25) & 0x7f));;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_8(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += zigzagdec16((w0 ) & 0xff)); out[0*8+ 1] = (start += zigzagdec16((w0 >> 8) & 0xff)); out[0*8+ 2] = (start += zigzagdec16((w0 >> 16) & 0xff)); out[0*8+ 3] = (start += zigzagdec16((w0 >> 24) & 0xff)); out[0*8+ 4] = (start += zigzagdec16((w0 >> 32) & 0xff)); out[0*8+ 5] = (start += zigzagdec16((w0 >> 40) & 0xff)); out[0*8+ 6] = (start += zigzagdec16((w0 >> 48) & 0xff)); out[0*8+ 7] = (start += zigzagdec16((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += zigzagdec16((w0 ) & 0xff)); out[1*8+ 1] = (start += zigzagdec16((w0 >> 8) & 0xff)); out[1*8+ 2] = (start += zigzagdec16((w0 >> 16) & 0xff)); out[1*8+ 3] = (start += zigzagdec16((w0 >> 24) & 0xff)); out[1*8+ 4] = (start += zigzagdec16((w0 >> 32) & 0xff)); out[1*8+ 5] = (start += zigzagdec16((w0 >> 40) & 0xff)); out[1*8+ 6] = (start += zigzagdec16((w0 >> 48) & 0xff)); out[1*8+ 7] = (start += zigzagdec16((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += zigzagdec16((w0 ) & 0xff)); out[2*8+ 1] = (start += zigzagdec16((w0 >> 8) & 0xff)); out[2*8+ 2] = (start += zigzagdec16((w0 >> 16) & 0xff)); out[2*8+ 3] = (start += zigzagdec16((w0 >> 24) & 0xff)); out[2*8+ 4] = (start += zigzagdec16((w0 >> 32) & 0xff)); out[2*8+ 5] = (start += zigzagdec16((w0 >> 40) & 0xff)); out[2*8+ 6] = (start += zigzagdec16((w0 >> 48) & 0xff)); out[2*8+ 7] = (start += zigzagdec16((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += zigzagdec16((w0 ) & 0xff)); out[3*8+ 1] = (start += zigzagdec16((w0 >> 8) & 0xff)); out[3*8+ 2] = (start += zigzagdec16((w0 >> 16) & 0xff)); out[3*8+ 3] = (start += zigzagdec16((w0 >> 24) & 0xff)); out[3*8+ 4] = (start += zigzagdec16((w0 >> 32) & 0xff)); out[3*8+ 5] = (start += zigzagdec16((w0 >> 40) & 0xff)); out[3*8+ 6] = (start += zigzagdec16((w0 >> 48) & 0xff)); out[3*8+ 7] = (start += zigzagdec16((w0 >> 56)));;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_9(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec16((w0 ) & 0x1ff)); out[0*64+ 1] = (start += zigzagdec16((w0 >> 9) & 0x1ff)); out[0*64+ 2] = (start += zigzagdec16((w0 >> 18) & 0x1ff)); out[0*64+ 3] = (start += zigzagdec16((w0 >> 27) & 0x1ff)); out[0*64+ 4] = (start += zigzagdec16((w0 >> 36) & 0x1ff)); out[0*64+ 5] = (start += zigzagdec16((w0 >> 45) & 0x1ff)); out[0*64+ 6] = (start += zigzagdec16((w0 >> 54) & 0x1ff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec16((w0 >> 63) | (w1 << 1) & 0x1ff)); out[0*64+ 8] = (start += zigzagdec16((w1 >> 8) & 0x1ff)); out[0*64+ 9] = (start += zigzagdec16((w1 >> 17) & 0x1ff)); out[0*64+10] = (start += zigzagdec16((w1 >> 26) & 0x1ff)); out[0*64+11] = (start += zigzagdec16((w1 >> 35) & 0x1ff)); out[0*64+12] = (start += zigzagdec16((w1 >> 44) & 0x1ff)); out[0*64+13] = (start += zigzagdec16((w1 >> 53) & 0x1ff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec16((w1 >> 62) | (w2 << 2) & 0x1ff)); out[0*64+15] = (start += zigzagdec16((w2 >> 7) & 0x1ff)); out[0*64+16] = (start += zigzagdec16((w2 >> 16) & 0x1ff)); out[0*64+17] = (start += zigzagdec16((w2 >> 25) & 0x1ff)); out[0*64+18] = (start += zigzagdec16((w2 >> 34) & 0x1ff)); out[0*64+19] = (start += zigzagdec16((w2 >> 43) & 0x1ff)); out[0*64+20] = (start += zigzagdec16((w2 >> 52) & 0x1ff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec16((w2 >> 61) | (w3 << 3) & 0x1ff)); out[0*64+22] = (start += zigzagdec16((w3 >> 6) & 0x1ff)); out[0*64+23] = (start += zigzagdec16((w3 >> 15) & 0x1ff)); out[0*64+24] = (start += zigzagdec16((w3 >> 24) & 0x1ff)); out[0*64+25] = (start += zigzagdec16((w3 >> 33) & 0x1ff)); out[0*64+26] = (start += zigzagdec16((w3 >> 42) & 0x1ff)); out[0*64+27] = (start += zigzagdec16((w3 >> 51) & 0x1ff)); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec16((w3 >> 60) | (w4 << 4) & 0x1ff)); out[0*64+29] = (start += zigzagdec16((w4 >> 5) & 0x1ff)); out[0*64+30] = (start += zigzagdec16((w4 >> 14) & 0x1ff)); out[0*64+31] = (start += zigzagdec16((w4 >> 23) & 0x1ff));;}; out += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_10(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec16((w0 ) & 0x3ff)); out[0*32+ 1] = (start += zigzagdec16((w0 >> 10) & 0x3ff)); out[0*32+ 2] = (start += zigzagdec16((w0 >> 20) & 0x3ff)); out[0*32+ 3] = (start += zigzagdec16((w0 >> 30) & 0x3ff)); out[0*32+ 4] = (start += zigzagdec16((w0 >> 40) & 0x3ff)); out[0*32+ 5] = (start += zigzagdec16((w0 >> 50) & 0x3ff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (start += zigzagdec16((w0 >> 60) | (w1 << 4) & 0x3ff)); out[0*32+ 7] = (start += zigzagdec16((w1 >> 6) & 0x3ff)); out[0*32+ 8] = (start += zigzagdec16((w1 >> 16) & 0x3ff)); out[0*32+ 9] = (start += zigzagdec16((w1 >> 26) & 0x3ff)); out[0*32+10] = (start += zigzagdec16((w1 >> 36) & 0x3ff)); out[0*32+11] = (start += zigzagdec16((w1 >> 46) & 0x3ff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (start += zigzagdec16((w1 >> 56) | (w2 << 8) & 0x3ff)); out[0*32+13] = (start += zigzagdec16((w2 >> 2) & 0x3ff)); out[0*32+14] = (start += zigzagdec16((w2 >> 12) & 0x3ff)); out[0*32+15] = (start += zigzagdec16((w2 >> 22) & 0x3ff)); out[0*32+16] = (start += zigzagdec16((w2 >> 32) & 0x3ff)); out[0*32+17] = (start += zigzagdec16((w2 >> 42) & 0x3ff)); out[0*32+18] = (start += zigzagdec16((w2 >> 52) & 0x3ff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (start += zigzagdec16((w2 >> 62) | (w3 << 2) & 0x3ff)); out[0*32+20] = (start += zigzagdec16((w3 >> 8) & 0x3ff)); out[0*32+21] = (start += zigzagdec16((w3 >> 18) & 0x3ff)); out[0*32+22] = (start += zigzagdec16((w3 >> 28) & 0x3ff)); out[0*32+23] = (start += zigzagdec16((w3 >> 38) & 0x3ff)); out[0*32+24] = (start += zigzagdec16((w3 >> 48) & 0x3ff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (start += zigzagdec16((w3 >> 58) | (w4 << 6) & 0x3ff)); out[0*32+26] = (start += zigzagdec16((w4 >> 4) & 0x3ff)); out[0*32+27] = (start += zigzagdec16((w4 >> 14) & 0x3ff)); out[0*32+28] = (start += zigzagdec16((w4 >> 24) & 0x3ff)); out[0*32+29] = (start += zigzagdec16((w4 >> 34) & 0x3ff)); out[0*32+30] = (start += zigzagdec16((w4 >> 44) & 0x3ff)); out[0*32+31] = (start += zigzagdec16((w4 >> 54)));;}; out += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_11(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec16((w0 ) & 0x7ff)); out[0*64+ 1] = (start += zigzagdec16((w0 >> 11) & 0x7ff)); out[0*64+ 2] = (start += zigzagdec16((w0 >> 22) & 0x7ff)); out[0*64+ 3] = (start += zigzagdec16((w0 >> 33) & 0x7ff)); out[0*64+ 4] = (start += zigzagdec16((w0 >> 44) & 0x7ff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec16((w0 >> 55) | (w1 << 9) & 0x7ff)); out[0*64+ 6] = (start += zigzagdec16((w1 >> 2) & 0x7ff)); out[0*64+ 7] = (start += zigzagdec16((w1 >> 13) & 0x7ff)); out[0*64+ 8] = (start += zigzagdec16((w1 >> 24) & 0x7ff)); out[0*64+ 9] = (start += zigzagdec16((w1 >> 35) & 0x7ff)); out[0*64+10] = (start += zigzagdec16((w1 >> 46) & 0x7ff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec16((w1 >> 57) | (w2 << 7) & 0x7ff)); out[0*64+12] = (start += zigzagdec16((w2 >> 4) & 0x7ff)); out[0*64+13] = (start += zigzagdec16((w2 >> 15) & 0x7ff)); out[0*64+14] = (start += zigzagdec16((w2 >> 26) & 0x7ff)); out[0*64+15] = (start += zigzagdec16((w2 >> 37) & 0x7ff)); out[0*64+16] = (start += zigzagdec16((w2 >> 48) & 0x7ff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec16((w2 >> 59) | (w3 << 5) & 0x7ff)); out[0*64+18] = (start += zigzagdec16((w3 >> 6) & 0x7ff)); out[0*64+19] = (start += zigzagdec16((w3 >> 17) & 0x7ff)); out[0*64+20] = (start += zigzagdec16((w3 >> 28) & 0x7ff)); out[0*64+21] = (start += zigzagdec16((w3 >> 39) & 0x7ff)); out[0*64+22] = (start += zigzagdec16((w3 >> 50) & 0x7ff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec16((w3 >> 61) | (w4 << 3) & 0x7ff)); out[0*64+24] = (start += zigzagdec16((w4 >> 8) & 0x7ff)); out[0*64+25] = (start += zigzagdec16((w4 >> 19) & 0x7ff)); out[0*64+26] = (start += zigzagdec16((w4 >> 30) & 0x7ff)); out[0*64+27] = (start += zigzagdec16((w4 >> 41) & 0x7ff)); out[0*64+28] = (start += zigzagdec16((w4 >> 52) & 0x7ff)); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec16((w4 >> 63) | (w5 << 1) & 0x7ff)); out[0*64+30] = (start += zigzagdec16((w5 >> 10) & 0x7ff)); out[0*64+31] = (start += zigzagdec16((w5 >> 21) & 0x7ff));;}; out += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_12(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec16((w0 ) & 0xfff)); out[0*16+ 1] = (start += zigzagdec16((w0 >> 12) & 0xfff)); out[0*16+ 2] = (start += zigzagdec16((w0 >> 24) & 0xfff)); out[0*16+ 3] = (start += zigzagdec16((w0 >> 36) & 0xfff)); out[0*16+ 4] = (start += zigzagdec16((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (start += zigzagdec16((w0 >> 60) | (w1 << 4) & 0xfff)); out[0*16+ 6] = (start += zigzagdec16((w1 >> 8) & 0xfff)); out[0*16+ 7] = (start += zigzagdec16((w1 >> 20) & 0xfff)); out[0*16+ 8] = (start += zigzagdec16((w1 >> 32) & 0xfff)); out[0*16+ 9] = (start += zigzagdec16((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (start += zigzagdec16((w1 >> 56) | (w2 << 8) & 0xfff)); out[0*16+11] = (start += zigzagdec16((w2 >> 4) & 0xfff)); out[0*16+12] = (start += zigzagdec16((w2 >> 16) & 0xfff)); out[0*16+13] = (start += zigzagdec16((w2 >> 28) & 0xfff)); out[0*16+14] = (start += zigzagdec16((w2 >> 40) & 0xfff)); out[0*16+15] = (start += zigzagdec16((w2 >> 52)));;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec16((w0 ) & 0xfff)); out[1*16+ 1] = (start += zigzagdec16((w0 >> 12) & 0xfff)); out[1*16+ 2] = (start += zigzagdec16((w0 >> 24) & 0xfff)); out[1*16+ 3] = (start += zigzagdec16((w0 >> 36) & 0xfff)); out[1*16+ 4] = (start += zigzagdec16((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (start += zigzagdec16((w0 >> 60) | (w1 << 4) & 0xfff)); out[1*16+ 6] = (start += zigzagdec16((w1 >> 8) & 0xfff)); out[1*16+ 7] = (start += zigzagdec16((w1 >> 20) & 0xfff)); out[1*16+ 8] = (start += zigzagdec16((w1 >> 32) & 0xfff)); out[1*16+ 9] = (start += zigzagdec16((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (start += zigzagdec16((w1 >> 56) | (w2 << 8) & 0xfff)); out[1*16+11] = (start += zigzagdec16((w2 >> 4) & 0xfff)); out[1*16+12] = (start += zigzagdec16((w2 >> 16) & 0xfff)); out[1*16+13] = (start += zigzagdec16((w2 >> 28) & 0xfff)); out[1*16+14] = (start += zigzagdec16((w2 >> 40) & 0xfff)); out[1*16+15] = (start += zigzagdec16((w2 >> 52)));;}; out += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_13(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec16((w0 ) & 0x1fff)); out[0*64+ 1] = (start += zigzagdec16((w0 >> 13) & 0x1fff)); out[0*64+ 2] = (start += zigzagdec16((w0 >> 26) & 0x1fff)); out[0*64+ 3] = (start += zigzagdec16((w0 >> 39) & 0x1fff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec16((w0 >> 52) | (w1 << 12) & 0x1fff)); out[0*64+ 5] = (start += zigzagdec16((w1 >> 1) & 0x1fff)); out[0*64+ 6] = (start += zigzagdec16((w1 >> 14) & 0x1fff)); out[0*64+ 7] = (start += zigzagdec16((w1 >> 27) & 0x1fff)); out[0*64+ 8] = (start += zigzagdec16((w1 >> 40) & 0x1fff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec16((w1 >> 53) | (w2 << 11) & 0x1fff)); out[0*64+10] = (start += zigzagdec16((w2 >> 2) & 0x1fff)); out[0*64+11] = (start += zigzagdec16((w2 >> 15) & 0x1fff)); out[0*64+12] = (start += zigzagdec16((w2 >> 28) & 0x1fff)); out[0*64+13] = (start += zigzagdec16((w2 >> 41) & 0x1fff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec16((w2 >> 54) | (w3 << 10) & 0x1fff)); out[0*64+15] = (start += zigzagdec16((w3 >> 3) & 0x1fff)); out[0*64+16] = (start += zigzagdec16((w3 >> 16) & 0x1fff)); out[0*64+17] = (start += zigzagdec16((w3 >> 29) & 0x1fff)); out[0*64+18] = (start += zigzagdec16((w3 >> 42) & 0x1fff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec16((w3 >> 55) | (w4 << 9) & 0x1fff)); out[0*64+20] = (start += zigzagdec16((w4 >> 4) & 0x1fff)); out[0*64+21] = (start += zigzagdec16((w4 >> 17) & 0x1fff)); out[0*64+22] = (start += zigzagdec16((w4 >> 30) & 0x1fff)); out[0*64+23] = (start += zigzagdec16((w4 >> 43) & 0x1fff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec16((w4 >> 56) | (w5 << 8) & 0x1fff)); out[0*64+25] = (start += zigzagdec16((w5 >> 5) & 0x1fff)); out[0*64+26] = (start += zigzagdec16((w5 >> 18) & 0x1fff)); out[0*64+27] = (start += zigzagdec16((w5 >> 31) & 0x1fff)); out[0*64+28] = (start += zigzagdec16((w5 >> 44) & 0x1fff)); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec16((w5 >> 57) | (w6 << 7) & 0x1fff)); out[0*64+30] = (start += zigzagdec16((w6 >> 6) & 0x1fff)); out[0*64+31] = (start += zigzagdec16((w6 >> 19) & 0x1fff));;}; out += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_14(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec16((w0 ) & 0x3fff)); out[0*32+ 1] = (start += zigzagdec16((w0 >> 14) & 0x3fff)); out[0*32+ 2] = (start += zigzagdec16((w0 >> 28) & 0x3fff)); out[0*32+ 3] = (start += zigzagdec16((w0 >> 42) & 0x3fff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (start += zigzagdec16((w0 >> 56) | (w1 << 8) & 0x3fff)); out[0*32+ 5] = (start += zigzagdec16((w1 >> 6) & 0x3fff)); out[0*32+ 6] = (start += zigzagdec16((w1 >> 20) & 0x3fff)); out[0*32+ 7] = (start += zigzagdec16((w1 >> 34) & 0x3fff)); out[0*32+ 8] = (start += zigzagdec16((w1 >> 48) & 0x3fff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (start += zigzagdec16((w1 >> 62) | (w2 << 2) & 0x3fff)); out[0*32+10] = (start += zigzagdec16((w2 >> 12) & 0x3fff)); out[0*32+11] = (start += zigzagdec16((w2 >> 26) & 0x3fff)); out[0*32+12] = (start += zigzagdec16((w2 >> 40) & 0x3fff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (start += zigzagdec16((w2 >> 54) | (w3 << 10) & 0x3fff)); out[0*32+14] = (start += zigzagdec16((w3 >> 4) & 0x3fff)); out[0*32+15] = (start += zigzagdec16((w3 >> 18) & 0x3fff)); out[0*32+16] = (start += zigzagdec16((w3 >> 32) & 0x3fff)); out[0*32+17] = (start += zigzagdec16((w3 >> 46) & 0x3fff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (start += zigzagdec16((w3 >> 60) | (w4 << 4) & 0x3fff)); out[0*32+19] = (start += zigzagdec16((w4 >> 10) & 0x3fff)); out[0*32+20] = (start += zigzagdec16((w4 >> 24) & 0x3fff)); out[0*32+21] = (start += zigzagdec16((w4 >> 38) & 0x3fff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (start += zigzagdec16((w4 >> 52) | (w5 << 12) & 0x3fff)); out[0*32+23] = (start += zigzagdec16((w5 >> 2) & 0x3fff)); out[0*32+24] = (start += zigzagdec16((w5 >> 16) & 0x3fff)); out[0*32+25] = (start += zigzagdec16((w5 >> 30) & 0x3fff)); out[0*32+26] = (start += zigzagdec16((w5 >> 44) & 0x3fff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (start += zigzagdec16((w5 >> 58) | (w6 << 6) & 0x3fff)); out[0*32+28] = (start += zigzagdec16((w6 >> 8) & 0x3fff)); out[0*32+29] = (start += zigzagdec16((w6 >> 22) & 0x3fff)); out[0*32+30] = (start += zigzagdec16((w6 >> 36) & 0x3fff)); out[0*32+31] = (start += zigzagdec16((w6 >> 50)));;}; out += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_15(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec16((w0 ) & 0x7fff)); out[0*64+ 1] = (start += zigzagdec16((w0 >> 15) & 0x7fff)); out[0*64+ 2] = (start += zigzagdec16((w0 >> 30) & 0x7fff)); out[0*64+ 3] = (start += zigzagdec16((w0 >> 45) & 0x7fff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec16((w0 >> 60) | (w1 << 4) & 0x7fff)); out[0*64+ 5] = (start += zigzagdec16((w1 >> 11) & 0x7fff)); out[0*64+ 6] = (start += zigzagdec16((w1 >> 26) & 0x7fff)); out[0*64+ 7] = (start += zigzagdec16((w1 >> 41) & 0x7fff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec16((w1 >> 56) | (w2 << 8) & 0x7fff)); out[0*64+ 9] = (start += zigzagdec16((w2 >> 7) & 0x7fff)); out[0*64+10] = (start += zigzagdec16((w2 >> 22) & 0x7fff)); out[0*64+11] = (start += zigzagdec16((w2 >> 37) & 0x7fff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec16((w2 >> 52) | (w3 << 12) & 0x7fff)); out[0*64+13] = (start += zigzagdec16((w3 >> 3) & 0x7fff)); out[0*64+14] = (start += zigzagdec16((w3 >> 18) & 0x7fff)); out[0*64+15] = (start += zigzagdec16((w3 >> 33) & 0x7fff)); out[0*64+16] = (start += zigzagdec16((w3 >> 48) & 0x7fff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec16((w3 >> 63) | (w4 << 1) & 0x7fff)); out[0*64+18] = (start += zigzagdec16((w4 >> 14) & 0x7fff)); out[0*64+19] = (start += zigzagdec16((w4 >> 29) & 0x7fff)); out[0*64+20] = (start += zigzagdec16((w4 >> 44) & 0x7fff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec16((w4 >> 59) | (w5 << 5) & 0x7fff)); out[0*64+22] = (start += zigzagdec16((w5 >> 10) & 0x7fff)); out[0*64+23] = (start += zigzagdec16((w5 >> 25) & 0x7fff)); out[0*64+24] = (start += zigzagdec16((w5 >> 40) & 0x7fff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec16((w5 >> 55) | (w6 << 9) & 0x7fff)); out[0*64+26] = (start += zigzagdec16((w6 >> 6) & 0x7fff)); out[0*64+27] = (start += zigzagdec16((w6 >> 21) & 0x7fff)); out[0*64+28] = (start += zigzagdec16((w6 >> 36) & 0x7fff)); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec16((w6 >> 51) | (w7 << 13) & 0x7fff)); out[0*64+30] = (start += zigzagdec16((w7 >> 2) & 0x7fff)); out[0*64+31] = (start += zigzagdec16((w7 >> 17) & 0x7fff));;}; out += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack16_16(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = (start += zigzagdec16(*(uint16_t *)(in+0*8+ 0))); out[0*4+ 1] = (start += zigzagdec16(*(uint16_t *)(in+0*8+ 2))); out[0*4+ 2] = (start += zigzagdec16(*(uint16_t *)(in+0*8+ 4))); out[0*4+ 3] = (start += zigzagdec16(*(uint16_t *)(in+0*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = (start += zigzagdec16(*(uint16_t *)(in+1*8+ 0))); out[1*4+ 1] = (start += zigzagdec16(*(uint16_t *)(in+1*8+ 2))); out[1*4+ 2] = (start += zigzagdec16(*(uint16_t *)(in+1*8+ 4))); out[1*4+ 3] = (start += zigzagdec16(*(uint16_t *)(in+1*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = (start += zigzagdec16(*(uint16_t *)(in+2*8+ 0))); out[2*4+ 1] = (start += zigzagdec16(*(uint16_t *)(in+2*8+ 2))); out[2*4+ 2] = (start += zigzagdec16(*(uint16_t *)(in+2*8+ 4))); out[2*4+ 3] = (start += zigzagdec16(*(uint16_t *)(in+2*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = (start += zigzagdec16(*(uint16_t *)(in+3*8+ 0))); out[3*4+ 1] = (start += zigzagdec16(*(uint16_t *)(in+3*8+ 2))); out[3*4+ 2] = (start += zigzagdec16(*(uint16_t *)(in+3*8+ 4))); out[3*4+ 3] = (start += zigzagdec16(*(uint16_t *)(in+3*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = (start += zigzagdec16(*(uint16_t *)(in+4*8+ 0))); out[4*4+ 1] = (start += zigzagdec16(*(uint16_t *)(in+4*8+ 2))); out[4*4+ 2] = (start += zigzagdec16(*(uint16_t *)(in+4*8+ 4))); out[4*4+ 3] = (start += zigzagdec16(*(uint16_t *)(in+4*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = (start += zigzagdec16(*(uint16_t *)(in+5*8+ 0))); out[5*4+ 1] = (start += zigzagdec16(*(uint16_t *)(in+5*8+ 2))); out[5*4+ 2] = (start += zigzagdec16(*(uint16_t *)(in+5*8+ 4))); out[5*4+ 3] = (start += zigzagdec16(*(uint16_t *)(in+5*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = (start += zigzagdec16(*(uint16_t *)(in+6*8+ 0))); out[6*4+ 1] = (start += zigzagdec16(*(uint16_t *)(in+6*8+ 2))); out[6*4+ 2] = (start += zigzagdec16(*(uint16_t *)(in+6*8+ 4))); out[6*4+ 3] = (start += zigzagdec16(*(uint16_t *)(in+6*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = (start += zigzagdec16(*(uint16_t *)(in+7*8+ 0))); out[7*4+ 1] = (start += zigzagdec16(*(uint16_t *)(in+7*8+ 2))); out[7*4+ 2] = (start += zigzagdec16(*(uint16_t *)(in+7*8+ 4))); out[7*4+ 3] = (start += zigzagdec16(*(uint16_t *)(in+7*8+ 6)));;}; out += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D16 bitzunpacka16[] = {
  &bitzunpack16_0,
  &bitzunpack16_1,
  &bitzunpack16_2,
  &bitzunpack16_3,
  &bitzunpack16_4,
  &bitzunpack16_5,
  &bitzunpack16_6,
  &bitzunpack16_7,
  &bitzunpack16_8,
  &bitzunpack16_9,
  &bitzunpack16_10,
  &bitzunpack16_11,
  &bitzunpack16_12,
  &bitzunpack16_13,
  &bitzunpack16_14,
  &bitzunpack16_15,
  &bitzunpack16_16
};
unsigned char *bitzunpack16( const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start, unsigned b) { return bitzunpacka16[ b](in, n, out, start); }
unsigned char *bitzunpack32_0(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint32_t *out_ = out+n; do { { { out[0*0+ 0] = (start += zigzagdec32(0)); out[0*0+ 1] = (start += zigzagdec32(0)); out[0*0+ 2] = (start += zigzagdec32(0)); out[0*0+ 3] = (start += zigzagdec32(0)); out[0*0+ 4] = (start += zigzagdec32(0)); out[0*0+ 5] = (start += zigzagdec32(0)); out[0*0+ 6] = (start += zigzagdec32(0)); out[0*0+ 7] = (start += zigzagdec32(0)); out[0*0+ 8] = (start += zigzagdec32(0)); out[0*0+ 9] = (start += zigzagdec32(0)); out[0*0+10] = (start += zigzagdec32(0)); out[0*0+11] = (start += zigzagdec32(0)); out[0*0+12] = (start += zigzagdec32(0)); out[0*0+13] = (start += zigzagdec32(0)); out[0*0+14] = (start += zigzagdec32(0)); out[0*0+15] = (start += zigzagdec32(0)); out[0*0+16] = (start += zigzagdec32(0)); out[0*0+17] = (start += zigzagdec32(0)); out[0*0+18] = (start += zigzagdec32(0)); out[0*0+19] = (start += zigzagdec32(0)); out[0*0+20] = (start += zigzagdec32(0)); out[0*0+21] = (start += zigzagdec32(0)); out[0*0+22] = (start += zigzagdec32(0)); out[0*0+23] = (start += zigzagdec32(0)); out[0*0+24] = (start += zigzagdec32(0)); out[0*0+25] = (start += zigzagdec32(0)); out[0*0+26] = (start += zigzagdec32(0)); out[0*0+27] = (start += zigzagdec32(0)); out[0*0+28] = (start += zigzagdec32(0)); out[0*0+29] = (start += zigzagdec32(0)); out[0*0+30] = (start += zigzagdec32(0)); out[0*0+31] = (start += zigzagdec32(0));;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitzunpack32_1(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec32((w0 ) & 0x1)); out[0*32+ 1] = (start += zigzagdec32((w0 >> 1) & 0x1)); out[0*32+ 2] = (start += zigzagdec32((w0 >> 2) & 0x1)); out[0*32+ 3] = (start += zigzagdec32((w0 >> 3) & 0x1)); out[0*32+ 4] = (start += zigzagdec32((w0 >> 4) & 0x1)); out[0*32+ 5] = (start += zigzagdec32((w0 >> 5) & 0x1)); out[0*32+ 6] = (start += zigzagdec32((w0 >> 6) & 0x1)); out[0*32+ 7] = (start += zigzagdec32((w0 >> 7) & 0x1)); out[0*32+ 8] = (start += zigzagdec32((w0 >> 8) & 0x1)); out[0*32+ 9] = (start += zigzagdec32((w0 >> 9) & 0x1)); out[0*32+10] = (start += zigzagdec32((w0 >> 10) & 0x1)); out[0*32+11] = (start += zigzagdec32((w0 >> 11) & 0x1)); out[0*32+12] = (start += zigzagdec32((w0 >> 12) & 0x1)); out[0*32+13] = (start += zigzagdec32((w0 >> 13) & 0x1)); out[0*32+14] = (start += zigzagdec32((w0 >> 14) & 0x1)); out[0*32+15] = (start += zigzagdec32((w0 >> 15) & 0x1)); out[0*32+16] = (start += zigzagdec32((w0 >> 16) & 0x1)); out[0*32+17] = (start += zigzagdec32((w0 >> 17) & 0x1)); out[0*32+18] = (start += zigzagdec32((w0 >> 18) & 0x1)); out[0*32+19] = (start += zigzagdec32((w0 >> 19) & 0x1)); out[0*32+20] = (start += zigzagdec32((w0 >> 20) & 0x1)); out[0*32+21] = (start += zigzagdec32((w0 >> 21) & 0x1)); out[0*32+22] = (start += zigzagdec32((w0 >> 22) & 0x1)); out[0*32+23] = (start += zigzagdec32((w0 >> 23) & 0x1)); out[0*32+24] = (start += zigzagdec32((w0 >> 24) & 0x1)); out[0*32+25] = (start += zigzagdec32((w0 >> 25) & 0x1)); out[0*32+26] = (start += zigzagdec32((w0 >> 26) & 0x1)); out[0*32+27] = (start += zigzagdec32((w0 >> 27) & 0x1)); out[0*32+28] = (start += zigzagdec32((w0 >> 28) & 0x1)); out[0*32+29] = (start += zigzagdec32((w0 >> 29) & 0x1)); out[0*32+30] = (start += zigzagdec32((w0 >> 30) & 0x1)); out[0*32+31] = (start += zigzagdec32((w0 >> 31)));;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_2(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec32((w0 ) & 0x3)); out[0*32+ 1] = (start += zigzagdec32((w0 >> 2) & 0x3)); out[0*32+ 2] = (start += zigzagdec32((w0 >> 4) & 0x3)); out[0*32+ 3] = (start += zigzagdec32((w0 >> 6) & 0x3)); out[0*32+ 4] = (start += zigzagdec32((w0 >> 8) & 0x3)); out[0*32+ 5] = (start += zigzagdec32((w0 >> 10) & 0x3)); out[0*32+ 6] = (start += zigzagdec32((w0 >> 12) & 0x3)); out[0*32+ 7] = (start += zigzagdec32((w0 >> 14) & 0x3)); out[0*32+ 8] = (start += zigzagdec32((w0 >> 16) & 0x3)); out[0*32+ 9] = (start += zigzagdec32((w0 >> 18) & 0x3)); out[0*32+10] = (start += zigzagdec32((w0 >> 20) & 0x3)); out[0*32+11] = (start += zigzagdec32((w0 >> 22) & 0x3)); out[0*32+12] = (start += zigzagdec32((w0 >> 24) & 0x3)); out[0*32+13] = (start += zigzagdec32((w0 >> 26) & 0x3)); out[0*32+14] = (start += zigzagdec32((w0 >> 28) & 0x3)); out[0*32+15] = (start += zigzagdec32((w0 >> 30) & 0x3)); out[0*32+16] = (start += zigzagdec32((w0 >> 32) & 0x3)); out[0*32+17] = (start += zigzagdec32((w0 >> 34) & 0x3)); out[0*32+18] = (start += zigzagdec32((w0 >> 36) & 0x3)); out[0*32+19] = (start += zigzagdec32((w0 >> 38) & 0x3)); out[0*32+20] = (start += zigzagdec32((w0 >> 40) & 0x3)); out[0*32+21] = (start += zigzagdec32((w0 >> 42) & 0x3)); out[0*32+22] = (start += zigzagdec32((w0 >> 44) & 0x3)); out[0*32+23] = (start += zigzagdec32((w0 >> 46) & 0x3)); out[0*32+24] = (start += zigzagdec32((w0 >> 48) & 0x3)); out[0*32+25] = (start += zigzagdec32((w0 >> 50) & 0x3)); out[0*32+26] = (start += zigzagdec32((w0 >> 52) & 0x3)); out[0*32+27] = (start += zigzagdec32((w0 >> 54) & 0x3)); out[0*32+28] = (start += zigzagdec32((w0 >> 56) & 0x3)); out[0*32+29] = (start += zigzagdec32((w0 >> 58) & 0x3)); out[0*32+30] = (start += zigzagdec32((w0 >> 60) & 0x3)); out[0*32+31] = (start += zigzagdec32((w0 >> 62)));;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_3(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x7)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 3) & 0x7)); out[0*64+ 2] = (start += zigzagdec32((w0 >> 6) & 0x7)); out[0*64+ 3] = (start += zigzagdec32((w0 >> 9) & 0x7)); out[0*64+ 4] = (start += zigzagdec32((w0 >> 12) & 0x7)); out[0*64+ 5] = (start += zigzagdec32((w0 >> 15) & 0x7)); out[0*64+ 6] = (start += zigzagdec32((w0 >> 18) & 0x7)); out[0*64+ 7] = (start += zigzagdec32((w0 >> 21) & 0x7)); out[0*64+ 8] = (start += zigzagdec32((w0 >> 24) & 0x7)); out[0*64+ 9] = (start += zigzagdec32((w0 >> 27) & 0x7)); out[0*64+10] = (start += zigzagdec32((w0 >> 30) & 0x7)); out[0*64+11] = (start += zigzagdec32((w0 >> 33) & 0x7)); out[0*64+12] = (start += zigzagdec32((w0 >> 36) & 0x7)); out[0*64+13] = (start += zigzagdec32((w0 >> 39) & 0x7)); out[0*64+14] = (start += zigzagdec32((w0 >> 42) & 0x7)); out[0*64+15] = (start += zigzagdec32((w0 >> 45) & 0x7)); out[0*64+16] = (start += zigzagdec32((w0 >> 48) & 0x7)); out[0*64+17] = (start += zigzagdec32((w0 >> 51) & 0x7)); out[0*64+18] = (start += zigzagdec32((w0 >> 54) & 0x7)); out[0*64+19] = (start += zigzagdec32((w0 >> 57) & 0x7)); out[0*64+20] = (start += zigzagdec32((w0 >> 60) & 0x7)); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec32((w0 >> 63) | (w1 << 1) & 0x7)); out[0*64+22] = (start += zigzagdec32((w1 >> 2) & 0x7)); out[0*64+23] = (start += zigzagdec32((w1 >> 5) & 0x7)); out[0*64+24] = (start += zigzagdec32((w1 >> 8) & 0x7)); out[0*64+25] = (start += zigzagdec32((w1 >> 11) & 0x7)); out[0*64+26] = (start += zigzagdec32((w1 >> 14) & 0x7)); out[0*64+27] = (start += zigzagdec32((w1 >> 17) & 0x7)); out[0*64+28] = (start += zigzagdec32((w1 >> 20) & 0x7)); out[0*64+29] = (start += zigzagdec32((w1 >> 23) & 0x7)); out[0*64+30] = (start += zigzagdec32((w1 >> 26) & 0x7)); out[0*64+31] = (start += zigzagdec32((w1 >> 29) & 0x7));;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_4(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec32((w0 ) & 0xf)); out[0*16+ 1] = (start += zigzagdec32((w0 >> 4) & 0xf)); out[0*16+ 2] = (start += zigzagdec32((w0 >> 8) & 0xf)); out[0*16+ 3] = (start += zigzagdec32((w0 >> 12) & 0xf)); out[0*16+ 4] = (start += zigzagdec32((w0 >> 16) & 0xf)); out[0*16+ 5] = (start += zigzagdec32((w0 >> 20) & 0xf)); out[0*16+ 6] = (start += zigzagdec32((w0 >> 24) & 0xf)); out[0*16+ 7] = (start += zigzagdec32((w0 >> 28) & 0xf)); out[0*16+ 8] = (start += zigzagdec32((w0 >> 32) & 0xf)); out[0*16+ 9] = (start += zigzagdec32((w0 >> 36) & 0xf)); out[0*16+10] = (start += zigzagdec32((w0 >> 40) & 0xf)); out[0*16+11] = (start += zigzagdec32((w0 >> 44) & 0xf)); out[0*16+12] = (start += zigzagdec32((w0 >> 48) & 0xf)); out[0*16+13] = (start += zigzagdec32((w0 >> 52) & 0xf)); out[0*16+14] = (start += zigzagdec32((w0 >> 56) & 0xf)); out[0*16+15] = (start += zigzagdec32((w0 >> 60)));;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec32((w0 ) & 0xf)); out[1*16+ 1] = (start += zigzagdec32((w0 >> 4) & 0xf)); out[1*16+ 2] = (start += zigzagdec32((w0 >> 8) & 0xf)); out[1*16+ 3] = (start += zigzagdec32((w0 >> 12) & 0xf)); out[1*16+ 4] = (start += zigzagdec32((w0 >> 16) & 0xf)); out[1*16+ 5] = (start += zigzagdec32((w0 >> 20) & 0xf)); out[1*16+ 6] = (start += zigzagdec32((w0 >> 24) & 0xf)); out[1*16+ 7] = (start += zigzagdec32((w0 >> 28) & 0xf)); out[1*16+ 8] = (start += zigzagdec32((w0 >> 32) & 0xf)); out[1*16+ 9] = (start += zigzagdec32((w0 >> 36) & 0xf)); out[1*16+10] = (start += zigzagdec32((w0 >> 40) & 0xf)); out[1*16+11] = (start += zigzagdec32((w0 >> 44) & 0xf)); out[1*16+12] = (start += zigzagdec32((w0 >> 48) & 0xf)); out[1*16+13] = (start += zigzagdec32((w0 >> 52) & 0xf)); out[1*16+14] = (start += zigzagdec32((w0 >> 56) & 0xf)); out[1*16+15] = (start += zigzagdec32((w0 >> 60)));;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_5(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x1f)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 5) & 0x1f)); out[0*64+ 2] = (start += zigzagdec32((w0 >> 10) & 0x1f)); out[0*64+ 3] = (start += zigzagdec32((w0 >> 15) & 0x1f)); out[0*64+ 4] = (start += zigzagdec32((w0 >> 20) & 0x1f)); out[0*64+ 5] = (start += zigzagdec32((w0 >> 25) & 0x1f)); out[0*64+ 6] = (start += zigzagdec32((w0 >> 30) & 0x1f)); out[0*64+ 7] = (start += zigzagdec32((w0 >> 35) & 0x1f)); out[0*64+ 8] = (start += zigzagdec32((w0 >> 40) & 0x1f)); out[0*64+ 9] = (start += zigzagdec32((w0 >> 45) & 0x1f)); out[0*64+10] = (start += zigzagdec32((w0 >> 50) & 0x1f)); out[0*64+11] = (start += zigzagdec32((w0 >> 55) & 0x1f)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec32((w0 >> 60) | (w1 << 4) & 0x1f)); out[0*64+13] = (start += zigzagdec32((w1 >> 1) & 0x1f)); out[0*64+14] = (start += zigzagdec32((w1 >> 6) & 0x1f)); out[0*64+15] = (start += zigzagdec32((w1 >> 11) & 0x1f)); out[0*64+16] = (start += zigzagdec32((w1 >> 16) & 0x1f)); out[0*64+17] = (start += zigzagdec32((w1 >> 21) & 0x1f)); out[0*64+18] = (start += zigzagdec32((w1 >> 26) & 0x1f)); out[0*64+19] = (start += zigzagdec32((w1 >> 31) & 0x1f)); out[0*64+20] = (start += zigzagdec32((w1 >> 36) & 0x1f)); out[0*64+21] = (start += zigzagdec32((w1 >> 41) & 0x1f)); out[0*64+22] = (start += zigzagdec32((w1 >> 46) & 0x1f)); out[0*64+23] = (start += zigzagdec32((w1 >> 51) & 0x1f)); out[0*64+24] = (start += zigzagdec32((w1 >> 56) & 0x1f)); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec32((w1 >> 61) | (w2 << 3) & 0x1f)); out[0*64+26] = (start += zigzagdec32((w2 >> 2) & 0x1f)); out[0*64+27] = (start += zigzagdec32((w2 >> 7) & 0x1f)); out[0*64+28] = (start += zigzagdec32((w2 >> 12) & 0x1f)); out[0*64+29] = (start += zigzagdec32((w2 >> 17) & 0x1f)); out[0*64+30] = (start += zigzagdec32((w2 >> 22) & 0x1f)); out[0*64+31] = (start += zigzagdec32((w2 >> 27) & 0x1f));;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_6(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec32((w0 ) & 0x3f)); out[0*32+ 1] = (start += zigzagdec32((w0 >> 6) & 0x3f)); out[0*32+ 2] = (start += zigzagdec32((w0 >> 12) & 0x3f)); out[0*32+ 3] = (start += zigzagdec32((w0 >> 18) & 0x3f)); out[0*32+ 4] = (start += zigzagdec32((w0 >> 24) & 0x3f)); out[0*32+ 5] = (start += zigzagdec32((w0 >> 30) & 0x3f)); out[0*32+ 6] = (start += zigzagdec32((w0 >> 36) & 0x3f)); out[0*32+ 7] = (start += zigzagdec32((w0 >> 42) & 0x3f)); out[0*32+ 8] = (start += zigzagdec32((w0 >> 48) & 0x3f)); out[0*32+ 9] = (start += zigzagdec32((w0 >> 54) & 0x3f)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start += zigzagdec32((w0 >> 60) | (w1 << 4) & 0x3f)); out[0*32+11] = (start += zigzagdec32((w1 >> 2) & 0x3f)); out[0*32+12] = (start += zigzagdec32((w1 >> 8) & 0x3f)); out[0*32+13] = (start += zigzagdec32((w1 >> 14) & 0x3f)); out[0*32+14] = (start += zigzagdec32((w1 >> 20) & 0x3f)); out[0*32+15] = (start += zigzagdec32((w1 >> 26) & 0x3f)); out[0*32+16] = (start += zigzagdec32((w1 >> 32) & 0x3f)); out[0*32+17] = (start += zigzagdec32((w1 >> 38) & 0x3f)); out[0*32+18] = (start += zigzagdec32((w1 >> 44) & 0x3f)); out[0*32+19] = (start += zigzagdec32((w1 >> 50) & 0x3f)); out[0*32+20] = (start += zigzagdec32((w1 >> 56) & 0x3f)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start += zigzagdec32((w1 >> 62) | (w2 << 2) & 0x3f)); out[0*32+22] = (start += zigzagdec32((w2 >> 4) & 0x3f)); out[0*32+23] = (start += zigzagdec32((w2 >> 10) & 0x3f)); out[0*32+24] = (start += zigzagdec32((w2 >> 16) & 0x3f)); out[0*32+25] = (start += zigzagdec32((w2 >> 22) & 0x3f)); out[0*32+26] = (start += zigzagdec32((w2 >> 28) & 0x3f)); out[0*32+27] = (start += zigzagdec32((w2 >> 34) & 0x3f)); out[0*32+28] = (start += zigzagdec32((w2 >> 40) & 0x3f)); out[0*32+29] = (start += zigzagdec32((w2 >> 46) & 0x3f)); out[0*32+30] = (start += zigzagdec32((w2 >> 52) & 0x3f)); out[0*32+31] = (start += zigzagdec32((w2 >> 58)));;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_7(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x7f)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 7) & 0x7f)); out[0*64+ 2] = (start += zigzagdec32((w0 >> 14) & 0x7f)); out[0*64+ 3] = (start += zigzagdec32((w0 >> 21) & 0x7f)); out[0*64+ 4] = (start += zigzagdec32((w0 >> 28) & 0x7f)); out[0*64+ 5] = (start += zigzagdec32((w0 >> 35) & 0x7f)); out[0*64+ 6] = (start += zigzagdec32((w0 >> 42) & 0x7f)); out[0*64+ 7] = (start += zigzagdec32((w0 >> 49) & 0x7f)); out[0*64+ 8] = (start += zigzagdec32((w0 >> 56) & 0x7f)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec32((w0 >> 63) | (w1 << 1) & 0x7f)); out[0*64+10] = (start += zigzagdec32((w1 >> 6) & 0x7f)); out[0*64+11] = (start += zigzagdec32((w1 >> 13) & 0x7f)); out[0*64+12] = (start += zigzagdec32((w1 >> 20) & 0x7f)); out[0*64+13] = (start += zigzagdec32((w1 >> 27) & 0x7f)); out[0*64+14] = (start += zigzagdec32((w1 >> 34) & 0x7f)); out[0*64+15] = (start += zigzagdec32((w1 >> 41) & 0x7f)); out[0*64+16] = (start += zigzagdec32((w1 >> 48) & 0x7f)); out[0*64+17] = (start += zigzagdec32((w1 >> 55) & 0x7f)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec32((w1 >> 62) | (w2 << 2) & 0x7f)); out[0*64+19] = (start += zigzagdec32((w2 >> 5) & 0x7f)); out[0*64+20] = (start += zigzagdec32((w2 >> 12) & 0x7f)); out[0*64+21] = (start += zigzagdec32((w2 >> 19) & 0x7f)); out[0*64+22] = (start += zigzagdec32((w2 >> 26) & 0x7f)); out[0*64+23] = (start += zigzagdec32((w2 >> 33) & 0x7f)); out[0*64+24] = (start += zigzagdec32((w2 >> 40) & 0x7f)); out[0*64+25] = (start += zigzagdec32((w2 >> 47) & 0x7f)); out[0*64+26] = (start += zigzagdec32((w2 >> 54) & 0x7f)); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec32((w2 >> 61) | (w3 << 3) & 0x7f)); out[0*64+28] = (start += zigzagdec32((w3 >> 4) & 0x7f)); out[0*64+29] = (start += zigzagdec32((w3 >> 11) & 0x7f)); out[0*64+30] = (start += zigzagdec32((w3 >> 18) & 0x7f)); out[0*64+31] = (start += zigzagdec32((w3 >> 25) & 0x7f));;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_8(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += zigzagdec32((w0 ) & 0xff)); out[0*8+ 1] = (start += zigzagdec32((w0 >> 8) & 0xff)); out[0*8+ 2] = (start += zigzagdec32((w0 >> 16) & 0xff)); out[0*8+ 3] = (start += zigzagdec32((w0 >> 24) & 0xff)); out[0*8+ 4] = (start += zigzagdec32((w0 >> 32) & 0xff)); out[0*8+ 5] = (start += zigzagdec32((w0 >> 40) & 0xff)); out[0*8+ 6] = (start += zigzagdec32((w0 >> 48) & 0xff)); out[0*8+ 7] = (start += zigzagdec32((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += zigzagdec32((w0 ) & 0xff)); out[1*8+ 1] = (start += zigzagdec32((w0 >> 8) & 0xff)); out[1*8+ 2] = (start += zigzagdec32((w0 >> 16) & 0xff)); out[1*8+ 3] = (start += zigzagdec32((w0 >> 24) & 0xff)); out[1*8+ 4] = (start += zigzagdec32((w0 >> 32) & 0xff)); out[1*8+ 5] = (start += zigzagdec32((w0 >> 40) & 0xff)); out[1*8+ 6] = (start += zigzagdec32((w0 >> 48) & 0xff)); out[1*8+ 7] = (start += zigzagdec32((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += zigzagdec32((w0 ) & 0xff)); out[2*8+ 1] = (start += zigzagdec32((w0 >> 8) & 0xff)); out[2*8+ 2] = (start += zigzagdec32((w0 >> 16) & 0xff)); out[2*8+ 3] = (start += zigzagdec32((w0 >> 24) & 0xff)); out[2*8+ 4] = (start += zigzagdec32((w0 >> 32) & 0xff)); out[2*8+ 5] = (start += zigzagdec32((w0 >> 40) & 0xff)); out[2*8+ 6] = (start += zigzagdec32((w0 >> 48) & 0xff)); out[2*8+ 7] = (start += zigzagdec32((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += zigzagdec32((w0 ) & 0xff)); out[3*8+ 1] = (start += zigzagdec32((w0 >> 8) & 0xff)); out[3*8+ 2] = (start += zigzagdec32((w0 >> 16) & 0xff)); out[3*8+ 3] = (start += zigzagdec32((w0 >> 24) & 0xff)); out[3*8+ 4] = (start += zigzagdec32((w0 >> 32) & 0xff)); out[3*8+ 5] = (start += zigzagdec32((w0 >> 40) & 0xff)); out[3*8+ 6] = (start += zigzagdec32((w0 >> 48) & 0xff)); out[3*8+ 7] = (start += zigzagdec32((w0 >> 56)));;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_9(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x1ff)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 9) & 0x1ff)); out[0*64+ 2] = (start += zigzagdec32((w0 >> 18) & 0x1ff)); out[0*64+ 3] = (start += zigzagdec32((w0 >> 27) & 0x1ff)); out[0*64+ 4] = (start += zigzagdec32((w0 >> 36) & 0x1ff)); out[0*64+ 5] = (start += zigzagdec32((w0 >> 45) & 0x1ff)); out[0*64+ 6] = (start += zigzagdec32((w0 >> 54) & 0x1ff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec32((w0 >> 63) | (w1 << 1) & 0x1ff)); out[0*64+ 8] = (start += zigzagdec32((w1 >> 8) & 0x1ff)); out[0*64+ 9] = (start += zigzagdec32((w1 >> 17) & 0x1ff)); out[0*64+10] = (start += zigzagdec32((w1 >> 26) & 0x1ff)); out[0*64+11] = (start += zigzagdec32((w1 >> 35) & 0x1ff)); out[0*64+12] = (start += zigzagdec32((w1 >> 44) & 0x1ff)); out[0*64+13] = (start += zigzagdec32((w1 >> 53) & 0x1ff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec32((w1 >> 62) | (w2 << 2) & 0x1ff)); out[0*64+15] = (start += zigzagdec32((w2 >> 7) & 0x1ff)); out[0*64+16] = (start += zigzagdec32((w2 >> 16) & 0x1ff)); out[0*64+17] = (start += zigzagdec32((w2 >> 25) & 0x1ff)); out[0*64+18] = (start += zigzagdec32((w2 >> 34) & 0x1ff)); out[0*64+19] = (start += zigzagdec32((w2 >> 43) & 0x1ff)); out[0*64+20] = (start += zigzagdec32((w2 >> 52) & 0x1ff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec32((w2 >> 61) | (w3 << 3) & 0x1ff)); out[0*64+22] = (start += zigzagdec32((w3 >> 6) & 0x1ff)); out[0*64+23] = (start += zigzagdec32((w3 >> 15) & 0x1ff)); out[0*64+24] = (start += zigzagdec32((w3 >> 24) & 0x1ff)); out[0*64+25] = (start += zigzagdec32((w3 >> 33) & 0x1ff)); out[0*64+26] = (start += zigzagdec32((w3 >> 42) & 0x1ff)); out[0*64+27] = (start += zigzagdec32((w3 >> 51) & 0x1ff)); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec32((w3 >> 60) | (w4 << 4) & 0x1ff)); out[0*64+29] = (start += zigzagdec32((w4 >> 5) & 0x1ff)); out[0*64+30] = (start += zigzagdec32((w4 >> 14) & 0x1ff)); out[0*64+31] = (start += zigzagdec32((w4 >> 23) & 0x1ff));;}; out += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_10(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec32((w0 ) & 0x3ff)); out[0*32+ 1] = (start += zigzagdec32((w0 >> 10) & 0x3ff)); out[0*32+ 2] = (start += zigzagdec32((w0 >> 20) & 0x3ff)); out[0*32+ 3] = (start += zigzagdec32((w0 >> 30) & 0x3ff)); out[0*32+ 4] = (start += zigzagdec32((w0 >> 40) & 0x3ff)); out[0*32+ 5] = (start += zigzagdec32((w0 >> 50) & 0x3ff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (start += zigzagdec32((w0 >> 60) | (w1 << 4) & 0x3ff)); out[0*32+ 7] = (start += zigzagdec32((w1 >> 6) & 0x3ff)); out[0*32+ 8] = (start += zigzagdec32((w1 >> 16) & 0x3ff)); out[0*32+ 9] = (start += zigzagdec32((w1 >> 26) & 0x3ff)); out[0*32+10] = (start += zigzagdec32((w1 >> 36) & 0x3ff)); out[0*32+11] = (start += zigzagdec32((w1 >> 46) & 0x3ff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (start += zigzagdec32((w1 >> 56) | (w2 << 8) & 0x3ff)); out[0*32+13] = (start += zigzagdec32((w2 >> 2) & 0x3ff)); out[0*32+14] = (start += zigzagdec32((w2 >> 12) & 0x3ff)); out[0*32+15] = (start += zigzagdec32((w2 >> 22) & 0x3ff)); out[0*32+16] = (start += zigzagdec32((w2 >> 32) & 0x3ff)); out[0*32+17] = (start += zigzagdec32((w2 >> 42) & 0x3ff)); out[0*32+18] = (start += zigzagdec32((w2 >> 52) & 0x3ff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (start += zigzagdec32((w2 >> 62) | (w3 << 2) & 0x3ff)); out[0*32+20] = (start += zigzagdec32((w3 >> 8) & 0x3ff)); out[0*32+21] = (start += zigzagdec32((w3 >> 18) & 0x3ff)); out[0*32+22] = (start += zigzagdec32((w3 >> 28) & 0x3ff)); out[0*32+23] = (start += zigzagdec32((w3 >> 38) & 0x3ff)); out[0*32+24] = (start += zigzagdec32((w3 >> 48) & 0x3ff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (start += zigzagdec32((w3 >> 58) | (w4 << 6) & 0x3ff)); out[0*32+26] = (start += zigzagdec32((w4 >> 4) & 0x3ff)); out[0*32+27] = (start += zigzagdec32((w4 >> 14) & 0x3ff)); out[0*32+28] = (start += zigzagdec32((w4 >> 24) & 0x3ff)); out[0*32+29] = (start += zigzagdec32((w4 >> 34) & 0x3ff)); out[0*32+30] = (start += zigzagdec32((w4 >> 44) & 0x3ff)); out[0*32+31] = (start += zigzagdec32((w4 >> 54)));;}; out += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_11(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x7ff)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 11) & 0x7ff)); out[0*64+ 2] = (start += zigzagdec32((w0 >> 22) & 0x7ff)); out[0*64+ 3] = (start += zigzagdec32((w0 >> 33) & 0x7ff)); out[0*64+ 4] = (start += zigzagdec32((w0 >> 44) & 0x7ff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec32((w0 >> 55) | (w1 << 9) & 0x7ff)); out[0*64+ 6] = (start += zigzagdec32((w1 >> 2) & 0x7ff)); out[0*64+ 7] = (start += zigzagdec32((w1 >> 13) & 0x7ff)); out[0*64+ 8] = (start += zigzagdec32((w1 >> 24) & 0x7ff)); out[0*64+ 9] = (start += zigzagdec32((w1 >> 35) & 0x7ff)); out[0*64+10] = (start += zigzagdec32((w1 >> 46) & 0x7ff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec32((w1 >> 57) | (w2 << 7) & 0x7ff)); out[0*64+12] = (start += zigzagdec32((w2 >> 4) & 0x7ff)); out[0*64+13] = (start += zigzagdec32((w2 >> 15) & 0x7ff)); out[0*64+14] = (start += zigzagdec32((w2 >> 26) & 0x7ff)); out[0*64+15] = (start += zigzagdec32((w2 >> 37) & 0x7ff)); out[0*64+16] = (start += zigzagdec32((w2 >> 48) & 0x7ff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec32((w2 >> 59) | (w3 << 5) & 0x7ff)); out[0*64+18] = (start += zigzagdec32((w3 >> 6) & 0x7ff)); out[0*64+19] = (start += zigzagdec32((w3 >> 17) & 0x7ff)); out[0*64+20] = (start += zigzagdec32((w3 >> 28) & 0x7ff)); out[0*64+21] = (start += zigzagdec32((w3 >> 39) & 0x7ff)); out[0*64+22] = (start += zigzagdec32((w3 >> 50) & 0x7ff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec32((w3 >> 61) | (w4 << 3) & 0x7ff)); out[0*64+24] = (start += zigzagdec32((w4 >> 8) & 0x7ff)); out[0*64+25] = (start += zigzagdec32((w4 >> 19) & 0x7ff)); out[0*64+26] = (start += zigzagdec32((w4 >> 30) & 0x7ff)); out[0*64+27] = (start += zigzagdec32((w4 >> 41) & 0x7ff)); out[0*64+28] = (start += zigzagdec32((w4 >> 52) & 0x7ff)); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec32((w4 >> 63) | (w5 << 1) & 0x7ff)); out[0*64+30] = (start += zigzagdec32((w5 >> 10) & 0x7ff)); out[0*64+31] = (start += zigzagdec32((w5 >> 21) & 0x7ff));;}; out += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_12(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec32((w0 ) & 0xfff)); out[0*16+ 1] = (start += zigzagdec32((w0 >> 12) & 0xfff)); out[0*16+ 2] = (start += zigzagdec32((w0 >> 24) & 0xfff)); out[0*16+ 3] = (start += zigzagdec32((w0 >> 36) & 0xfff)); out[0*16+ 4] = (start += zigzagdec32((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (start += zigzagdec32((w0 >> 60) | (w1 << 4) & 0xfff)); out[0*16+ 6] = (start += zigzagdec32((w1 >> 8) & 0xfff)); out[0*16+ 7] = (start += zigzagdec32((w1 >> 20) & 0xfff)); out[0*16+ 8] = (start += zigzagdec32((w1 >> 32) & 0xfff)); out[0*16+ 9] = (start += zigzagdec32((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (start += zigzagdec32((w1 >> 56) | (w2 << 8) & 0xfff)); out[0*16+11] = (start += zigzagdec32((w2 >> 4) & 0xfff)); out[0*16+12] = (start += zigzagdec32((w2 >> 16) & 0xfff)); out[0*16+13] = (start += zigzagdec32((w2 >> 28) & 0xfff)); out[0*16+14] = (start += zigzagdec32((w2 >> 40) & 0xfff)); out[0*16+15] = (start += zigzagdec32((w2 >> 52)));;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec32((w0 ) & 0xfff)); out[1*16+ 1] = (start += zigzagdec32((w0 >> 12) & 0xfff)); out[1*16+ 2] = (start += zigzagdec32((w0 >> 24) & 0xfff)); out[1*16+ 3] = (start += zigzagdec32((w0 >> 36) & 0xfff)); out[1*16+ 4] = (start += zigzagdec32((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (start += zigzagdec32((w0 >> 60) | (w1 << 4) & 0xfff)); out[1*16+ 6] = (start += zigzagdec32((w1 >> 8) & 0xfff)); out[1*16+ 7] = (start += zigzagdec32((w1 >> 20) & 0xfff)); out[1*16+ 8] = (start += zigzagdec32((w1 >> 32) & 0xfff)); out[1*16+ 9] = (start += zigzagdec32((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (start += zigzagdec32((w1 >> 56) | (w2 << 8) & 0xfff)); out[1*16+11] = (start += zigzagdec32((w2 >> 4) & 0xfff)); out[1*16+12] = (start += zigzagdec32((w2 >> 16) & 0xfff)); out[1*16+13] = (start += zigzagdec32((w2 >> 28) & 0xfff)); out[1*16+14] = (start += zigzagdec32((w2 >> 40) & 0xfff)); out[1*16+15] = (start += zigzagdec32((w2 >> 52)));;}; out += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_13(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x1fff)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 13) & 0x1fff)); out[0*64+ 2] = (start += zigzagdec32((w0 >> 26) & 0x1fff)); out[0*64+ 3] = (start += zigzagdec32((w0 >> 39) & 0x1fff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec32((w0 >> 52) | (w1 << 12) & 0x1fff)); out[0*64+ 5] = (start += zigzagdec32((w1 >> 1) & 0x1fff)); out[0*64+ 6] = (start += zigzagdec32((w1 >> 14) & 0x1fff)); out[0*64+ 7] = (start += zigzagdec32((w1 >> 27) & 0x1fff)); out[0*64+ 8] = (start += zigzagdec32((w1 >> 40) & 0x1fff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec32((w1 >> 53) | (w2 << 11) & 0x1fff)); out[0*64+10] = (start += zigzagdec32((w2 >> 2) & 0x1fff)); out[0*64+11] = (start += zigzagdec32((w2 >> 15) & 0x1fff)); out[0*64+12] = (start += zigzagdec32((w2 >> 28) & 0x1fff)); out[0*64+13] = (start += zigzagdec32((w2 >> 41) & 0x1fff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec32((w2 >> 54) | (w3 << 10) & 0x1fff)); out[0*64+15] = (start += zigzagdec32((w3 >> 3) & 0x1fff)); out[0*64+16] = (start += zigzagdec32((w3 >> 16) & 0x1fff)); out[0*64+17] = (start += zigzagdec32((w3 >> 29) & 0x1fff)); out[0*64+18] = (start += zigzagdec32((w3 >> 42) & 0x1fff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec32((w3 >> 55) | (w4 << 9) & 0x1fff)); out[0*64+20] = (start += zigzagdec32((w4 >> 4) & 0x1fff)); out[0*64+21] = (start += zigzagdec32((w4 >> 17) & 0x1fff)); out[0*64+22] = (start += zigzagdec32((w4 >> 30) & 0x1fff)); out[0*64+23] = (start += zigzagdec32((w4 >> 43) & 0x1fff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec32((w4 >> 56) | (w5 << 8) & 0x1fff)); out[0*64+25] = (start += zigzagdec32((w5 >> 5) & 0x1fff)); out[0*64+26] = (start += zigzagdec32((w5 >> 18) & 0x1fff)); out[0*64+27] = (start += zigzagdec32((w5 >> 31) & 0x1fff)); out[0*64+28] = (start += zigzagdec32((w5 >> 44) & 0x1fff)); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec32((w5 >> 57) | (w6 << 7) & 0x1fff)); out[0*64+30] = (start += zigzagdec32((w6 >> 6) & 0x1fff)); out[0*64+31] = (start += zigzagdec32((w6 >> 19) & 0x1fff));;}; out += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_14(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec32((w0 ) & 0x3fff)); out[0*32+ 1] = (start += zigzagdec32((w0 >> 14) & 0x3fff)); out[0*32+ 2] = (start += zigzagdec32((w0 >> 28) & 0x3fff)); out[0*32+ 3] = (start += zigzagdec32((w0 >> 42) & 0x3fff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (start += zigzagdec32((w0 >> 56) | (w1 << 8) & 0x3fff)); out[0*32+ 5] = (start += zigzagdec32((w1 >> 6) & 0x3fff)); out[0*32+ 6] = (start += zigzagdec32((w1 >> 20) & 0x3fff)); out[0*32+ 7] = (start += zigzagdec32((w1 >> 34) & 0x3fff)); out[0*32+ 8] = (start += zigzagdec32((w1 >> 48) & 0x3fff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (start += zigzagdec32((w1 >> 62) | (w2 << 2) & 0x3fff)); out[0*32+10] = (start += zigzagdec32((w2 >> 12) & 0x3fff)); out[0*32+11] = (start += zigzagdec32((w2 >> 26) & 0x3fff)); out[0*32+12] = (start += zigzagdec32((w2 >> 40) & 0x3fff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (start += zigzagdec32((w2 >> 54) | (w3 << 10) & 0x3fff)); out[0*32+14] = (start += zigzagdec32((w3 >> 4) & 0x3fff)); out[0*32+15] = (start += zigzagdec32((w3 >> 18) & 0x3fff)); out[0*32+16] = (start += zigzagdec32((w3 >> 32) & 0x3fff)); out[0*32+17] = (start += zigzagdec32((w3 >> 46) & 0x3fff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (start += zigzagdec32((w3 >> 60) | (w4 << 4) & 0x3fff)); out[0*32+19] = (start += zigzagdec32((w4 >> 10) & 0x3fff)); out[0*32+20] = (start += zigzagdec32((w4 >> 24) & 0x3fff)); out[0*32+21] = (start += zigzagdec32((w4 >> 38) & 0x3fff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (start += zigzagdec32((w4 >> 52) | (w5 << 12) & 0x3fff)); out[0*32+23] = (start += zigzagdec32((w5 >> 2) & 0x3fff)); out[0*32+24] = (start += zigzagdec32((w5 >> 16) & 0x3fff)); out[0*32+25] = (start += zigzagdec32((w5 >> 30) & 0x3fff)); out[0*32+26] = (start += zigzagdec32((w5 >> 44) & 0x3fff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (start += zigzagdec32((w5 >> 58) | (w6 << 6) & 0x3fff)); out[0*32+28] = (start += zigzagdec32((w6 >> 8) & 0x3fff)); out[0*32+29] = (start += zigzagdec32((w6 >> 22) & 0x3fff)); out[0*32+30] = (start += zigzagdec32((w6 >> 36) & 0x3fff)); out[0*32+31] = (start += zigzagdec32((w6 >> 50)));;}; out += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_15(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x7fff)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 15) & 0x7fff)); out[0*64+ 2] = (start += zigzagdec32((w0 >> 30) & 0x7fff)); out[0*64+ 3] = (start += zigzagdec32((w0 >> 45) & 0x7fff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec32((w0 >> 60) | (w1 << 4) & 0x7fff)); out[0*64+ 5] = (start += zigzagdec32((w1 >> 11) & 0x7fff)); out[0*64+ 6] = (start += zigzagdec32((w1 >> 26) & 0x7fff)); out[0*64+ 7] = (start += zigzagdec32((w1 >> 41) & 0x7fff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec32((w1 >> 56) | (w2 << 8) & 0x7fff)); out[0*64+ 9] = (start += zigzagdec32((w2 >> 7) & 0x7fff)); out[0*64+10] = (start += zigzagdec32((w2 >> 22) & 0x7fff)); out[0*64+11] = (start += zigzagdec32((w2 >> 37) & 0x7fff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec32((w2 >> 52) | (w3 << 12) & 0x7fff)); out[0*64+13] = (start += zigzagdec32((w3 >> 3) & 0x7fff)); out[0*64+14] = (start += zigzagdec32((w3 >> 18) & 0x7fff)); out[0*64+15] = (start += zigzagdec32((w3 >> 33) & 0x7fff)); out[0*64+16] = (start += zigzagdec32((w3 >> 48) & 0x7fff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec32((w3 >> 63) | (w4 << 1) & 0x7fff)); out[0*64+18] = (start += zigzagdec32((w4 >> 14) & 0x7fff)); out[0*64+19] = (start += zigzagdec32((w4 >> 29) & 0x7fff)); out[0*64+20] = (start += zigzagdec32((w4 >> 44) & 0x7fff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec32((w4 >> 59) | (w5 << 5) & 0x7fff)); out[0*64+22] = (start += zigzagdec32((w5 >> 10) & 0x7fff)); out[0*64+23] = (start += zigzagdec32((w5 >> 25) & 0x7fff)); out[0*64+24] = (start += zigzagdec32((w5 >> 40) & 0x7fff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec32((w5 >> 55) | (w6 << 9) & 0x7fff)); out[0*64+26] = (start += zigzagdec32((w6 >> 6) & 0x7fff)); out[0*64+27] = (start += zigzagdec32((w6 >> 21) & 0x7fff)); out[0*64+28] = (start += zigzagdec32((w6 >> 36) & 0x7fff)); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec32((w6 >> 51) | (w7 << 13) & 0x7fff)); out[0*64+30] = (start += zigzagdec32((w7 >> 2) & 0x7fff)); out[0*64+31] = (start += zigzagdec32((w7 >> 17) & 0x7fff));;}; out += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_16(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = (start += zigzagdec32(*(uint16_t *)(in+0*8+ 0))); out[0*4+ 1] = (start += zigzagdec32(*(uint16_t *)(in+0*8+ 2))); out[0*4+ 2] = (start += zigzagdec32(*(uint16_t *)(in+0*8+ 4))); out[0*4+ 3] = (start += zigzagdec32(*(uint16_t *)(in+0*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = (start += zigzagdec32(*(uint16_t *)(in+1*8+ 0))); out[1*4+ 1] = (start += zigzagdec32(*(uint16_t *)(in+1*8+ 2))); out[1*4+ 2] = (start += zigzagdec32(*(uint16_t *)(in+1*8+ 4))); out[1*4+ 3] = (start += zigzagdec32(*(uint16_t *)(in+1*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = (start += zigzagdec32(*(uint16_t *)(in+2*8+ 0))); out[2*4+ 1] = (start += zigzagdec32(*(uint16_t *)(in+2*8+ 2))); out[2*4+ 2] = (start += zigzagdec32(*(uint16_t *)(in+2*8+ 4))); out[2*4+ 3] = (start += zigzagdec32(*(uint16_t *)(in+2*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = (start += zigzagdec32(*(uint16_t *)(in+3*8+ 0))); out[3*4+ 1] = (start += zigzagdec32(*(uint16_t *)(in+3*8+ 2))); out[3*4+ 2] = (start += zigzagdec32(*(uint16_t *)(in+3*8+ 4))); out[3*4+ 3] = (start += zigzagdec32(*(uint16_t *)(in+3*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = (start += zigzagdec32(*(uint16_t *)(in+4*8+ 0))); out[4*4+ 1] = (start += zigzagdec32(*(uint16_t *)(in+4*8+ 2))); out[4*4+ 2] = (start += zigzagdec32(*(uint16_t *)(in+4*8+ 4))); out[4*4+ 3] = (start += zigzagdec32(*(uint16_t *)(in+4*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = (start += zigzagdec32(*(uint16_t *)(in+5*8+ 0))); out[5*4+ 1] = (start += zigzagdec32(*(uint16_t *)(in+5*8+ 2))); out[5*4+ 2] = (start += zigzagdec32(*(uint16_t *)(in+5*8+ 4))); out[5*4+ 3] = (start += zigzagdec32(*(uint16_t *)(in+5*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = (start += zigzagdec32(*(uint16_t *)(in+6*8+ 0))); out[6*4+ 1] = (start += zigzagdec32(*(uint16_t *)(in+6*8+ 2))); out[6*4+ 2] = (start += zigzagdec32(*(uint16_t *)(in+6*8+ 4))); out[6*4+ 3] = (start += zigzagdec32(*(uint16_t *)(in+6*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = (start += zigzagdec32(*(uint16_t *)(in+7*8+ 0))); out[7*4+ 1] = (start += zigzagdec32(*(uint16_t *)(in+7*8+ 2))); out[7*4+ 2] = (start += zigzagdec32(*(uint16_t *)(in+7*8+ 4))); out[7*4+ 3] = (start += zigzagdec32(*(uint16_t *)(in+7*8+ 6)));;}; out += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_17(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*17)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x1ffff)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 17) & 0x1ffff)); out[0*64+ 2] = (start += zigzagdec32((w0 >> 34) & 0x1ffff)); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec32((w0 >> 51) | (w1 << 13) & 0x1ffff)); out[0*64+ 4] = (start += zigzagdec32((w1 >> 4) & 0x1ffff)); out[0*64+ 5] = (start += zigzagdec32((w1 >> 21) & 0x1ffff)); out[0*64+ 6] = (start += zigzagdec32((w1 >> 38) & 0x1ffff)); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec32((w1 >> 55) | (w2 << 9) & 0x1ffff)); out[0*64+ 8] = (start += zigzagdec32((w2 >> 8) & 0x1ffff)); out[0*64+ 9] = (start += zigzagdec32((w2 >> 25) & 0x1ffff)); out[0*64+10] = (start += zigzagdec32((w2 >> 42) & 0x1ffff)); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec32((w2 >> 59) | (w3 << 5) & 0x1ffff)); out[0*64+12] = (start += zigzagdec32((w3 >> 12) & 0x1ffff)); out[0*64+13] = (start += zigzagdec32((w3 >> 29) & 0x1ffff)); out[0*64+14] = (start += zigzagdec32((w3 >> 46) & 0x1ffff)); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec32((w3 >> 63) | (w4 << 1) & 0x1ffff)); out[0*64+16] = (start += zigzagdec32((w4 >> 16) & 0x1ffff)); out[0*64+17] = (start += zigzagdec32((w4 >> 33) & 0x1ffff)); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec32((w4 >> 50) | (w5 << 14) & 0x1ffff)); out[0*64+19] = (start += zigzagdec32((w5 >> 3) & 0x1ffff)); out[0*64+20] = (start += zigzagdec32((w5 >> 20) & 0x1ffff)); out[0*64+21] = (start += zigzagdec32((w5 >> 37) & 0x1ffff)); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec32((w5 >> 54) | (w6 << 10) & 0x1ffff)); out[0*64+23] = (start += zigzagdec32((w6 >> 7) & 0x1ffff)); out[0*64+24] = (start += zigzagdec32((w6 >> 24) & 0x1ffff)); out[0*64+25] = (start += zigzagdec32((w6 >> 41) & 0x1ffff)); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec32((w6 >> 58) | (w7 << 6) & 0x1ffff)); out[0*64+27] = (start += zigzagdec32((w7 >> 11) & 0x1ffff)); out[0*64+28] = (start += zigzagdec32((w7 >> 28) & 0x1ffff)); out[0*64+29] = (start += zigzagdec32((w7 >> 45) & 0x1ffff)); w8 = *(uint32_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec32((w7 >> 62) | (w8 << 2) & 0x1ffff)); out[0*64+31] = (start += zigzagdec32((w8 >> 15) & 0x1ffff));;}; out += 32; in += 17*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_18(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*18)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec32((w0 ) & 0x3ffff)); out[0*32+ 1] = (start += zigzagdec32((w0 >> 18) & 0x3ffff)); out[0*32+ 2] = (start += zigzagdec32((w0 >> 36) & 0x3ffff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*32+ 3] = (start += zigzagdec32((w0 >> 54) | (w1 << 10) & 0x3ffff)); out[0*32+ 4] = (start += zigzagdec32((w1 >> 8) & 0x3ffff)); out[0*32+ 5] = (start += zigzagdec32((w1 >> 26) & 0x3ffff)); out[0*32+ 6] = (start += zigzagdec32((w1 >> 44) & 0x3ffff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*32+ 7] = (start += zigzagdec32((w1 >> 62) | (w2 << 2) & 0x3ffff)); out[0*32+ 8] = (start += zigzagdec32((w2 >> 16) & 0x3ffff)); out[0*32+ 9] = (start += zigzagdec32((w2 >> 34) & 0x3ffff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*32+10] = (start += zigzagdec32((w2 >> 52) | (w3 << 12) & 0x3ffff)); out[0*32+11] = (start += zigzagdec32((w3 >> 6) & 0x3ffff)); out[0*32+12] = (start += zigzagdec32((w3 >> 24) & 0x3ffff)); out[0*32+13] = (start += zigzagdec32((w3 >> 42) & 0x3ffff)); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*32+14] = (start += zigzagdec32((w3 >> 60) | (w4 << 4) & 0x3ffff)); out[0*32+15] = (start += zigzagdec32((w4 >> 14) & 0x3ffff)); out[0*32+16] = (start += zigzagdec32((w4 >> 32) & 0x3ffff)); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*32+17] = (start += zigzagdec32((w4 >> 50) | (w5 << 14) & 0x3ffff)); out[0*32+18] = (start += zigzagdec32((w5 >> 4) & 0x3ffff)); out[0*32+19] = (start += zigzagdec32((w5 >> 22) & 0x3ffff)); out[0*32+20] = (start += zigzagdec32((w5 >> 40) & 0x3ffff)); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*32+21] = (start += zigzagdec32((w5 >> 58) | (w6 << 6) & 0x3ffff)); out[0*32+22] = (start += zigzagdec32((w6 >> 12) & 0x3ffff)); out[0*32+23] = (start += zigzagdec32((w6 >> 30) & 0x3ffff)); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*32+24] = (start += zigzagdec32((w6 >> 48) | (w7 << 16) & 0x3ffff)); out[0*32+25] = (start += zigzagdec32((w7 >> 2) & 0x3ffff)); out[0*32+26] = (start += zigzagdec32((w7 >> 20) & 0x3ffff)); out[0*32+27] = (start += zigzagdec32((w7 >> 38) & 0x3ffff)); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*32+28] = (start += zigzagdec32((w7 >> 56) | (w8 << 8) & 0x3ffff)); out[0*32+29] = (start += zigzagdec32((w8 >> 10) & 0x3ffff)); out[0*32+30] = (start += zigzagdec32((w8 >> 28) & 0x3ffff)); out[0*32+31] = (start += zigzagdec32((w8 >> 46)));;}; out += 32; in += 18*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_19(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*19)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x7ffff)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 19) & 0x7ffff)); out[0*64+ 2] = (start += zigzagdec32((w0 >> 38) & 0x7ffff)); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec32((w0 >> 57) | (w1 << 7) & 0x7ffff)); out[0*64+ 4] = (start += zigzagdec32((w1 >> 12) & 0x7ffff)); out[0*64+ 5] = (start += zigzagdec32((w1 >> 31) & 0x7ffff)); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec32((w1 >> 50) | (w2 << 14) & 0x7ffff)); out[0*64+ 7] = (start += zigzagdec32((w2 >> 5) & 0x7ffff)); out[0*64+ 8] = (start += zigzagdec32((w2 >> 24) & 0x7ffff)); out[0*64+ 9] = (start += zigzagdec32((w2 >> 43) & 0x7ffff)); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec32((w2 >> 62) | (w3 << 2) & 0x7ffff)); out[0*64+11] = (start += zigzagdec32((w3 >> 17) & 0x7ffff)); out[0*64+12] = (start += zigzagdec32((w3 >> 36) & 0x7ffff)); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec32((w3 >> 55) | (w4 << 9) & 0x7ffff)); out[0*64+14] = (start += zigzagdec32((w4 >> 10) & 0x7ffff)); out[0*64+15] = (start += zigzagdec32((w4 >> 29) & 0x7ffff)); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec32((w4 >> 48) | (w5 << 16) & 0x7ffff)); out[0*64+17] = (start += zigzagdec32((w5 >> 3) & 0x7ffff)); out[0*64+18] = (start += zigzagdec32((w5 >> 22) & 0x7ffff)); out[0*64+19] = (start += zigzagdec32((w5 >> 41) & 0x7ffff)); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec32((w5 >> 60) | (w6 << 4) & 0x7ffff)); out[0*64+21] = (start += zigzagdec32((w6 >> 15) & 0x7ffff)); out[0*64+22] = (start += zigzagdec32((w6 >> 34) & 0x7ffff)); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec32((w6 >> 53) | (w7 << 11) & 0x7ffff)); out[0*64+24] = (start += zigzagdec32((w7 >> 8) & 0x7ffff)); out[0*64+25] = (start += zigzagdec32((w7 >> 27) & 0x7ffff)); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec32((w7 >> 46) | (w8 << 18) & 0x7ffff)); out[0*64+27] = (start += zigzagdec32((w8 >> 1) & 0x7ffff)); out[0*64+28] = (start += zigzagdec32((w8 >> 20) & 0x7ffff)); out[0*64+29] = (start += zigzagdec32((w8 >> 39) & 0x7ffff)); w9 = *(uint32_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec32((w8 >> 58) | (w9 << 6) & 0x7ffff)); out[0*64+31] = (start += zigzagdec32((w9 >> 13) & 0x7ffff));;}; out += 32; in += 19*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_20(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*20)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec32((w0 ) & 0xfffff)); out[0*16+ 1] = (start += zigzagdec32((w0 >> 20) & 0xfffff)); out[0*16+ 2] = (start += zigzagdec32((w0 >> 40) & 0xfffff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*16+ 3] = (start += zigzagdec32((w0 >> 60) | (w1 << 4) & 0xfffff)); out[0*16+ 4] = (start += zigzagdec32((w1 >> 16) & 0xfffff)); out[0*16+ 5] = (start += zigzagdec32((w1 >> 36) & 0xfffff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*16+ 6] = (start += zigzagdec32((w1 >> 56) | (w2 << 8) & 0xfffff)); out[0*16+ 7] = (start += zigzagdec32((w2 >> 12) & 0xfffff)); out[0*16+ 8] = (start += zigzagdec32((w2 >> 32) & 0xfffff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*16+ 9] = (start += zigzagdec32((w2 >> 52) | (w3 << 12) & 0xfffff)); out[0*16+10] = (start += zigzagdec32((w3 >> 8) & 0xfffff)); out[0*16+11] = (start += zigzagdec32((w3 >> 28) & 0xfffff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*16+12] = (start += zigzagdec32((w3 >> 48) | (w4 << 16) & 0xfffff)); out[0*16+13] = (start += zigzagdec32((w4 >> 4) & 0xfffff)); out[0*16+14] = (start += zigzagdec32((w4 >> 24) & 0xfffff)); out[0*16+15] = (start += zigzagdec32((w4 >> 44)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec32((w0 ) & 0xfffff)); out[1*16+ 1] = (start += zigzagdec32((w0 >> 20) & 0xfffff)); out[1*16+ 2] = (start += zigzagdec32((w0 >> 40) & 0xfffff)); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*16+ 3] = (start += zigzagdec32((w0 >> 60) | (w1 << 4) & 0xfffff)); out[1*16+ 4] = (start += zigzagdec32((w1 >> 16) & 0xfffff)); out[1*16+ 5] = (start += zigzagdec32((w1 >> 36) & 0xfffff)); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*16+ 6] = (start += zigzagdec32((w1 >> 56) | (w2 << 8) & 0xfffff)); out[1*16+ 7] = (start += zigzagdec32((w2 >> 12) & 0xfffff)); out[1*16+ 8] = (start += zigzagdec32((w2 >> 32) & 0xfffff)); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*16+ 9] = (start += zigzagdec32((w2 >> 52) | (w3 << 12) & 0xfffff)); out[1*16+10] = (start += zigzagdec32((w3 >> 8) & 0xfffff)); out[1*16+11] = (start += zigzagdec32((w3 >> 28) & 0xfffff)); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*16+12] = (start += zigzagdec32((w3 >> 48) | (w4 << 16) & 0xfffff)); out[1*16+13] = (start += zigzagdec32((w4 >> 4) & 0xfffff)); out[1*16+14] = (start += zigzagdec32((w4 >> 24) & 0xfffff)); out[1*16+15] = (start += zigzagdec32((w4 >> 44)));;}; out += 32; in += 20*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_21(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*21)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x1fffff)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 21) & 0x1fffff)); out[0*64+ 2] = (start += zigzagdec32((w0 >> 42) & 0x1fffff)); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec32((w0 >> 63) | (w1 << 1) & 0x1fffff)); out[0*64+ 4] = (start += zigzagdec32((w1 >> 20) & 0x1fffff)); out[0*64+ 5] = (start += zigzagdec32((w1 >> 41) & 0x1fffff)); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec32((w1 >> 62) | (w2 << 2) & 0x1fffff)); out[0*64+ 7] = (start += zigzagdec32((w2 >> 19) & 0x1fffff)); out[0*64+ 8] = (start += zigzagdec32((w2 >> 40) & 0x1fffff)); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec32((w2 >> 61) | (w3 << 3) & 0x1fffff)); out[0*64+10] = (start += zigzagdec32((w3 >> 18) & 0x1fffff)); out[0*64+11] = (start += zigzagdec32((w3 >> 39) & 0x1fffff)); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec32((w3 >> 60) | (w4 << 4) & 0x1fffff)); out[0*64+13] = (start += zigzagdec32((w4 >> 17) & 0x1fffff)); out[0*64+14] = (start += zigzagdec32((w4 >> 38) & 0x1fffff)); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec32((w4 >> 59) | (w5 << 5) & 0x1fffff)); out[0*64+16] = (start += zigzagdec32((w5 >> 16) & 0x1fffff)); out[0*64+17] = (start += zigzagdec32((w5 >> 37) & 0x1fffff)); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec32((w5 >> 58) | (w6 << 6) & 0x1fffff)); out[0*64+19] = (start += zigzagdec32((w6 >> 15) & 0x1fffff)); out[0*64+20] = (start += zigzagdec32((w6 >> 36) & 0x1fffff)); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec32((w6 >> 57) | (w7 << 7) & 0x1fffff)); out[0*64+22] = (start += zigzagdec32((w7 >> 14) & 0x1fffff)); out[0*64+23] = (start += zigzagdec32((w7 >> 35) & 0x1fffff)); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec32((w7 >> 56) | (w8 << 8) & 0x1fffff)); out[0*64+25] = (start += zigzagdec32((w8 >> 13) & 0x1fffff)); out[0*64+26] = (start += zigzagdec32((w8 >> 34) & 0x1fffff)); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec32((w8 >> 55) | (w9 << 9) & 0x1fffff)); out[0*64+28] = (start += zigzagdec32((w9 >> 12) & 0x1fffff)); out[0*64+29] = (start += zigzagdec32((w9 >> 33) & 0x1fffff)); w10 = *(uint32_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec32((w9 >> 54) | (w10 << 10) & 0x1fffff)); out[0*64+31] = (start += zigzagdec32((w10 >> 11) & 0x1fffff));;}; out += 32; in += 21*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_22(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*22)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec32((w0 ) & 0x3fffff)); out[0*32+ 1] = (start += zigzagdec32((w0 >> 22) & 0x3fffff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += zigzagdec32((w0 >> 44) | (w1 << 20) & 0x3fffff)); out[0*32+ 3] = (start += zigzagdec32((w1 >> 2) & 0x3fffff)); out[0*32+ 4] = (start += zigzagdec32((w1 >> 24) & 0x3fffff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*32+ 5] = (start += zigzagdec32((w1 >> 46) | (w2 << 18) & 0x3fffff)); out[0*32+ 6] = (start += zigzagdec32((w2 >> 4) & 0x3fffff)); out[0*32+ 7] = (start += zigzagdec32((w2 >> 26) & 0x3fffff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*32+ 8] = (start += zigzagdec32((w2 >> 48) | (w3 << 16) & 0x3fffff)); out[0*32+ 9] = (start += zigzagdec32((w3 >> 6) & 0x3fffff)); out[0*32+10] = (start += zigzagdec32((w3 >> 28) & 0x3fffff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*32+11] = (start += zigzagdec32((w3 >> 50) | (w4 << 14) & 0x3fffff)); out[0*32+12] = (start += zigzagdec32((w4 >> 8) & 0x3fffff)); out[0*32+13] = (start += zigzagdec32((w4 >> 30) & 0x3fffff)); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*32+14] = (start += zigzagdec32((w4 >> 52) | (w5 << 12) & 0x3fffff)); out[0*32+15] = (start += zigzagdec32((w5 >> 10) & 0x3fffff)); out[0*32+16] = (start += zigzagdec32((w5 >> 32) & 0x3fffff)); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*32+17] = (start += zigzagdec32((w5 >> 54) | (w6 << 10) & 0x3fffff)); out[0*32+18] = (start += zigzagdec32((w6 >> 12) & 0x3fffff)); out[0*32+19] = (start += zigzagdec32((w6 >> 34) & 0x3fffff)); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*32+20] = (start += zigzagdec32((w6 >> 56) | (w7 << 8) & 0x3fffff)); out[0*32+21] = (start += zigzagdec32((w7 >> 14) & 0x3fffff)); out[0*32+22] = (start += zigzagdec32((w7 >> 36) & 0x3fffff)); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*32+23] = (start += zigzagdec32((w7 >> 58) | (w8 << 6) & 0x3fffff)); out[0*32+24] = (start += zigzagdec32((w8 >> 16) & 0x3fffff)); out[0*32+25] = (start += zigzagdec32((w8 >> 38) & 0x3fffff)); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*32+26] = (start += zigzagdec32((w8 >> 60) | (w9 << 4) & 0x3fffff)); out[0*32+27] = (start += zigzagdec32((w9 >> 18) & 0x3fffff)); out[0*32+28] = (start += zigzagdec32((w9 >> 40) & 0x3fffff)); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*32+29] = (start += zigzagdec32((w9 >> 62) | (w10 << 2) & 0x3fffff)); out[0*32+30] = (start += zigzagdec32((w10 >> 20) & 0x3fffff)); out[0*32+31] = (start += zigzagdec32((w10 >> 42)));;}; out += 32; in += 22*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_23(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*23)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x7fffff)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 23) & 0x7fffff)); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec32((w0 >> 46) | (w1 << 18) & 0x7fffff)); out[0*64+ 3] = (start += zigzagdec32((w1 >> 5) & 0x7fffff)); out[0*64+ 4] = (start += zigzagdec32((w1 >> 28) & 0x7fffff)); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec32((w1 >> 51) | (w2 << 13) & 0x7fffff)); out[0*64+ 6] = (start += zigzagdec32((w2 >> 10) & 0x7fffff)); out[0*64+ 7] = (start += zigzagdec32((w2 >> 33) & 0x7fffff)); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec32((w2 >> 56) | (w3 << 8) & 0x7fffff)); out[0*64+ 9] = (start += zigzagdec32((w3 >> 15) & 0x7fffff)); out[0*64+10] = (start += zigzagdec32((w3 >> 38) & 0x7fffff)); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec32((w3 >> 61) | (w4 << 3) & 0x7fffff)); out[0*64+12] = (start += zigzagdec32((w4 >> 20) & 0x7fffff)); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec32((w4 >> 43) | (w5 << 21) & 0x7fffff)); out[0*64+14] = (start += zigzagdec32((w5 >> 2) & 0x7fffff)); out[0*64+15] = (start += zigzagdec32((w5 >> 25) & 0x7fffff)); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec32((w5 >> 48) | (w6 << 16) & 0x7fffff)); out[0*64+17] = (start += zigzagdec32((w6 >> 7) & 0x7fffff)); out[0*64+18] = (start += zigzagdec32((w6 >> 30) & 0x7fffff)); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec32((w6 >> 53) | (w7 << 11) & 0x7fffff)); out[0*64+20] = (start += zigzagdec32((w7 >> 12) & 0x7fffff)); out[0*64+21] = (start += zigzagdec32((w7 >> 35) & 0x7fffff)); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec32((w7 >> 58) | (w8 << 6) & 0x7fffff)); out[0*64+23] = (start += zigzagdec32((w8 >> 17) & 0x7fffff)); out[0*64+24] = (start += zigzagdec32((w8 >> 40) & 0x7fffff)); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec32((w8 >> 63) | (w9 << 1) & 0x7fffff)); out[0*64+26] = (start += zigzagdec32((w9 >> 22) & 0x7fffff)); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec32((w9 >> 45) | (w10 << 19) & 0x7fffff)); out[0*64+28] = (start += zigzagdec32((w10 >> 4) & 0x7fffff)); out[0*64+29] = (start += zigzagdec32((w10 >> 27) & 0x7fffff)); w11 = *(uint32_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec32((w10 >> 50) | (w11 << 14) & 0x7fffff)); out[0*64+31] = (start += zigzagdec32((w11 >> 9) & 0x7fffff));;}; out += 32; in += 23*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_24(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*24)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += zigzagdec32((w0 ) & 0xffffff)); out[0*8+ 1] = (start += zigzagdec32((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*8+ 2] = (start += zigzagdec32((w0 >> 48) | (w1 << 16) & 0xffffff)); out[0*8+ 3] = (start += zigzagdec32((w1 >> 8) & 0xffffff)); out[0*8+ 4] = (start += zigzagdec32((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*8+ 5] = (start += zigzagdec32((w1 >> 56) | (w2 << 8) & 0xffffff)); out[0*8+ 6] = (start += zigzagdec32((w2 >> 16) & 0xffffff)); out[0*8+ 7] = (start += zigzagdec32((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += zigzagdec32((w0 ) & 0xffffff)); out[1*8+ 1] = (start += zigzagdec32((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*8+ 2] = (start += zigzagdec32((w0 >> 48) | (w1 << 16) & 0xffffff)); out[1*8+ 3] = (start += zigzagdec32((w1 >> 8) & 0xffffff)); out[1*8+ 4] = (start += zigzagdec32((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*8+ 5] = (start += zigzagdec32((w1 >> 56) | (w2 << 8) & 0xffffff)); out[1*8+ 6] = (start += zigzagdec32((w2 >> 16) & 0xffffff)); out[1*8+ 7] = (start += zigzagdec32((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += zigzagdec32((w0 ) & 0xffffff)); out[2*8+ 1] = (start += zigzagdec32((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*8+ 2] = (start += zigzagdec32((w0 >> 48) | (w1 << 16) & 0xffffff)); out[2*8+ 3] = (start += zigzagdec32((w1 >> 8) & 0xffffff)); out[2*8+ 4] = (start += zigzagdec32((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*8+ 5] = (start += zigzagdec32((w1 >> 56) | (w2 << 8) & 0xffffff)); out[2*8+ 6] = (start += zigzagdec32((w2 >> 16) & 0xffffff)); out[2*8+ 7] = (start += zigzagdec32((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += zigzagdec32((w0 ) & 0xffffff)); out[3*8+ 1] = (start += zigzagdec32((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*8+ 2] = (start += zigzagdec32((w0 >> 48) | (w1 << 16) & 0xffffff)); out[3*8+ 3] = (start += zigzagdec32((w1 >> 8) & 0xffffff)); out[3*8+ 4] = (start += zigzagdec32((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*8+ 5] = (start += zigzagdec32((w1 >> 56) | (w2 << 8) & 0xffffff)); out[3*8+ 6] = (start += zigzagdec32((w2 >> 16) & 0xffffff)); out[3*8+ 7] = (start += zigzagdec32((w2 >> 40)));;}; out += 32; in += 24*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_25(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*25)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x1ffffff)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 25) & 0x1ffffff)); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec32((w0 >> 50) | (w1 << 14) & 0x1ffffff)); out[0*64+ 3] = (start += zigzagdec32((w1 >> 11) & 0x1ffffff)); out[0*64+ 4] = (start += zigzagdec32((w1 >> 36) & 0x1ffffff)); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec32((w1 >> 61) | (w2 << 3) & 0x1ffffff)); out[0*64+ 6] = (start += zigzagdec32((w2 >> 22) & 0x1ffffff)); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec32((w2 >> 47) | (w3 << 17) & 0x1ffffff)); out[0*64+ 8] = (start += zigzagdec32((w3 >> 8) & 0x1ffffff)); out[0*64+ 9] = (start += zigzagdec32((w3 >> 33) & 0x1ffffff)); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec32((w3 >> 58) | (w4 << 6) & 0x1ffffff)); out[0*64+11] = (start += zigzagdec32((w4 >> 19) & 0x1ffffff)); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec32((w4 >> 44) | (w5 << 20) & 0x1ffffff)); out[0*64+13] = (start += zigzagdec32((w5 >> 5) & 0x1ffffff)); out[0*64+14] = (start += zigzagdec32((w5 >> 30) & 0x1ffffff)); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec32((w5 >> 55) | (w6 << 9) & 0x1ffffff)); out[0*64+16] = (start += zigzagdec32((w6 >> 16) & 0x1ffffff)); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec32((w6 >> 41) | (w7 << 23) & 0x1ffffff)); out[0*64+18] = (start += zigzagdec32((w7 >> 2) & 0x1ffffff)); out[0*64+19] = (start += zigzagdec32((w7 >> 27) & 0x1ffffff)); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec32((w7 >> 52) | (w8 << 12) & 0x1ffffff)); out[0*64+21] = (start += zigzagdec32((w8 >> 13) & 0x1ffffff)); out[0*64+22] = (start += zigzagdec32((w8 >> 38) & 0x1ffffff)); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec32((w8 >> 63) | (w9 << 1) & 0x1ffffff)); out[0*64+24] = (start += zigzagdec32((w9 >> 24) & 0x1ffffff)); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec32((w9 >> 49) | (w10 << 15) & 0x1ffffff)); out[0*64+26] = (start += zigzagdec32((w10 >> 10) & 0x1ffffff)); out[0*64+27] = (start += zigzagdec32((w10 >> 35) & 0x1ffffff)); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec32((w10 >> 60) | (w11 << 4) & 0x1ffffff)); out[0*64+29] = (start += zigzagdec32((w11 >> 21) & 0x1ffffff)); w12 = *(uint32_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec32((w11 >> 46) | (w12 << 18) & 0x1ffffff)); out[0*64+31] = (start += zigzagdec32((w12 >> 7) & 0x1ffffff));;}; out += 32; in += 25*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_26(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*26)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec32((w0 ) & 0x3ffffff)); out[0*32+ 1] = (start += zigzagdec32((w0 >> 26) & 0x3ffffff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += zigzagdec32((w0 >> 52) | (w1 << 12) & 0x3ffffff)); out[0*32+ 3] = (start += zigzagdec32((w1 >> 14) & 0x3ffffff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*32+ 4] = (start += zigzagdec32((w1 >> 40) | (w2 << 24) & 0x3ffffff)); out[0*32+ 5] = (start += zigzagdec32((w2 >> 2) & 0x3ffffff)); out[0*32+ 6] = (start += zigzagdec32((w2 >> 28) & 0x3ffffff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*32+ 7] = (start += zigzagdec32((w2 >> 54) | (w3 << 10) & 0x3ffffff)); out[0*32+ 8] = (start += zigzagdec32((w3 >> 16) & 0x3ffffff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*32+ 9] = (start += zigzagdec32((w3 >> 42) | (w4 << 22) & 0x3ffffff)); out[0*32+10] = (start += zigzagdec32((w4 >> 4) & 0x3ffffff)); out[0*32+11] = (start += zigzagdec32((w4 >> 30) & 0x3ffffff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*32+12] = (start += zigzagdec32((w4 >> 56) | (w5 << 8) & 0x3ffffff)); out[0*32+13] = (start += zigzagdec32((w5 >> 18) & 0x3ffffff)); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*32+14] = (start += zigzagdec32((w5 >> 44) | (w6 << 20) & 0x3ffffff)); out[0*32+15] = (start += zigzagdec32((w6 >> 6) & 0x3ffffff)); out[0*32+16] = (start += zigzagdec32((w6 >> 32) & 0x3ffffff)); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*32+17] = (start += zigzagdec32((w6 >> 58) | (w7 << 6) & 0x3ffffff)); out[0*32+18] = (start += zigzagdec32((w7 >> 20) & 0x3ffffff)); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*32+19] = (start += zigzagdec32((w7 >> 46) | (w8 << 18) & 0x3ffffff)); out[0*32+20] = (start += zigzagdec32((w8 >> 8) & 0x3ffffff)); out[0*32+21] = (start += zigzagdec32((w8 >> 34) & 0x3ffffff)); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*32+22] = (start += zigzagdec32((w8 >> 60) | (w9 << 4) & 0x3ffffff)); out[0*32+23] = (start += zigzagdec32((w9 >> 22) & 0x3ffffff)); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*32+24] = (start += zigzagdec32((w9 >> 48) | (w10 << 16) & 0x3ffffff)); out[0*32+25] = (start += zigzagdec32((w10 >> 10) & 0x3ffffff)); out[0*32+26] = (start += zigzagdec32((w10 >> 36) & 0x3ffffff)); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*32+27] = (start += zigzagdec32((w10 >> 62) | (w11 << 2) & 0x3ffffff)); out[0*32+28] = (start += zigzagdec32((w11 >> 24) & 0x3ffffff)); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*32+29] = (start += zigzagdec32((w11 >> 50) | (w12 << 14) & 0x3ffffff)); out[0*32+30] = (start += zigzagdec32((w12 >> 12) & 0x3ffffff)); out[0*32+31] = (start += zigzagdec32((w12 >> 38)));;}; out += 32; in += 26*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_27(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*27)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x7ffffff)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 27) & 0x7ffffff)); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec32((w0 >> 54) | (w1 << 10) & 0x7ffffff)); out[0*64+ 3] = (start += zigzagdec32((w1 >> 17) & 0x7ffffff)); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec32((w1 >> 44) | (w2 << 20) & 0x7ffffff)); out[0*64+ 5] = (start += zigzagdec32((w2 >> 7) & 0x7ffffff)); out[0*64+ 6] = (start += zigzagdec32((w2 >> 34) & 0x7ffffff)); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec32((w2 >> 61) | (w3 << 3) & 0x7ffffff)); out[0*64+ 8] = (start += zigzagdec32((w3 >> 24) & 0x7ffffff)); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec32((w3 >> 51) | (w4 << 13) & 0x7ffffff)); out[0*64+10] = (start += zigzagdec32((w4 >> 14) & 0x7ffffff)); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec32((w4 >> 41) | (w5 << 23) & 0x7ffffff)); out[0*64+12] = (start += zigzagdec32((w5 >> 4) & 0x7ffffff)); out[0*64+13] = (start += zigzagdec32((w5 >> 31) & 0x7ffffff)); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec32((w5 >> 58) | (w6 << 6) & 0x7ffffff)); out[0*64+15] = (start += zigzagdec32((w6 >> 21) & 0x7ffffff)); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec32((w6 >> 48) | (w7 << 16) & 0x7ffffff)); out[0*64+17] = (start += zigzagdec32((w7 >> 11) & 0x7ffffff)); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec32((w7 >> 38) | (w8 << 26) & 0x7ffffff)); out[0*64+19] = (start += zigzagdec32((w8 >> 1) & 0x7ffffff)); out[0*64+20] = (start += zigzagdec32((w8 >> 28) & 0x7ffffff)); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec32((w8 >> 55) | (w9 << 9) & 0x7ffffff)); out[0*64+22] = (start += zigzagdec32((w9 >> 18) & 0x7ffffff)); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec32((w9 >> 45) | (w10 << 19) & 0x7ffffff)); out[0*64+24] = (start += zigzagdec32((w10 >> 8) & 0x7ffffff)); out[0*64+25] = (start += zigzagdec32((w10 >> 35) & 0x7ffffff)); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec32((w10 >> 62) | (w11 << 2) & 0x7ffffff)); out[0*64+27] = (start += zigzagdec32((w11 >> 25) & 0x7ffffff)); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec32((w11 >> 52) | (w12 << 12) & 0x7ffffff)); out[0*64+29] = (start += zigzagdec32((w12 >> 15) & 0x7ffffff)); w13 = *(uint32_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec32((w12 >> 42) | (w13 << 22) & 0x7ffffff)); out[0*64+31] = (start += zigzagdec32((w13 >> 5) & 0x7ffffff));;}; out += 32; in += 27*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_28(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*28)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec32((w0 ) & 0xfffffff)); out[0*16+ 1] = (start += zigzagdec32((w0 >> 28) & 0xfffffff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*16+ 2] = (start += zigzagdec32((w0 >> 56) | (w1 << 8) & 0xfffffff)); out[0*16+ 3] = (start += zigzagdec32((w1 >> 20) & 0xfffffff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*16+ 4] = (start += zigzagdec32((w1 >> 48) | (w2 << 16) & 0xfffffff)); out[0*16+ 5] = (start += zigzagdec32((w2 >> 12) & 0xfffffff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*16+ 6] = (start += zigzagdec32((w2 >> 40) | (w3 << 24) & 0xfffffff)); out[0*16+ 7] = (start += zigzagdec32((w3 >> 4) & 0xfffffff)); out[0*16+ 8] = (start += zigzagdec32((w3 >> 32) & 0xfffffff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*16+ 9] = (start += zigzagdec32((w3 >> 60) | (w4 << 4) & 0xfffffff)); out[0*16+10] = (start += zigzagdec32((w4 >> 24) & 0xfffffff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*16+11] = (start += zigzagdec32((w4 >> 52) | (w5 << 12) & 0xfffffff)); out[0*16+12] = (start += zigzagdec32((w5 >> 16) & 0xfffffff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*16+13] = (start += zigzagdec32((w5 >> 44) | (w6 << 20) & 0xfffffff)); out[0*16+14] = (start += zigzagdec32((w6 >> 8) & 0xfffffff)); out[0*16+15] = (start += zigzagdec32((w6 >> 36)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec32((w0 ) & 0xfffffff)); out[1*16+ 1] = (start += zigzagdec32((w0 >> 28) & 0xfffffff)); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*16+ 2] = (start += zigzagdec32((w0 >> 56) | (w1 << 8) & 0xfffffff)); out[1*16+ 3] = (start += zigzagdec32((w1 >> 20) & 0xfffffff)); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*16+ 4] = (start += zigzagdec32((w1 >> 48) | (w2 << 16) & 0xfffffff)); out[1*16+ 5] = (start += zigzagdec32((w2 >> 12) & 0xfffffff)); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*16+ 6] = (start += zigzagdec32((w2 >> 40) | (w3 << 24) & 0xfffffff)); out[1*16+ 7] = (start += zigzagdec32((w3 >> 4) & 0xfffffff)); out[1*16+ 8] = (start += zigzagdec32((w3 >> 32) & 0xfffffff)); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*16+ 9] = (start += zigzagdec32((w3 >> 60) | (w4 << 4) & 0xfffffff)); out[1*16+10] = (start += zigzagdec32((w4 >> 24) & 0xfffffff)); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*16+11] = (start += zigzagdec32((w4 >> 52) | (w5 << 12) & 0xfffffff)); out[1*16+12] = (start += zigzagdec32((w5 >> 16) & 0xfffffff)); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*16+13] = (start += zigzagdec32((w5 >> 44) | (w6 << 20) & 0xfffffff)); out[1*16+14] = (start += zigzagdec32((w6 >> 8) & 0xfffffff)); out[1*16+15] = (start += zigzagdec32((w6 >> 36)));;}; out += 32; in += 28*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_29(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*29)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x1fffffff)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 29) & 0x1fffffff)); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec32((w0 >> 58) | (w1 << 6) & 0x1fffffff)); out[0*64+ 3] = (start += zigzagdec32((w1 >> 23) & 0x1fffffff)); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec32((w1 >> 52) | (w2 << 12) & 0x1fffffff)); out[0*64+ 5] = (start += zigzagdec32((w2 >> 17) & 0x1fffffff)); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec32((w2 >> 46) | (w3 << 18) & 0x1fffffff)); out[0*64+ 7] = (start += zigzagdec32((w3 >> 11) & 0x1fffffff)); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec32((w3 >> 40) | (w4 << 24) & 0x1fffffff)); out[0*64+ 9] = (start += zigzagdec32((w4 >> 5) & 0x1fffffff)); out[0*64+10] = (start += zigzagdec32((w4 >> 34) & 0x1fffffff)); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec32((w4 >> 63) | (w5 << 1) & 0x1fffffff)); out[0*64+12] = (start += zigzagdec32((w5 >> 28) & 0x1fffffff)); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec32((w5 >> 57) | (w6 << 7) & 0x1fffffff)); out[0*64+14] = (start += zigzagdec32((w6 >> 22) & 0x1fffffff)); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec32((w6 >> 51) | (w7 << 13) & 0x1fffffff)); out[0*64+16] = (start += zigzagdec32((w7 >> 16) & 0x1fffffff)); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec32((w7 >> 45) | (w8 << 19) & 0x1fffffff)); out[0*64+18] = (start += zigzagdec32((w8 >> 10) & 0x1fffffff)); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec32((w8 >> 39) | (w9 << 25) & 0x1fffffff)); out[0*64+20] = (start += zigzagdec32((w9 >> 4) & 0x1fffffff)); out[0*64+21] = (start += zigzagdec32((w9 >> 33) & 0x1fffffff)); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec32((w9 >> 62) | (w10 << 2) & 0x1fffffff)); out[0*64+23] = (start += zigzagdec32((w10 >> 27) & 0x1fffffff)); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec32((w10 >> 56) | (w11 << 8) & 0x1fffffff)); out[0*64+25] = (start += zigzagdec32((w11 >> 21) & 0x1fffffff)); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec32((w11 >> 50) | (w12 << 14) & 0x1fffffff)); out[0*64+27] = (start += zigzagdec32((w12 >> 15) & 0x1fffffff)); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec32((w12 >> 44) | (w13 << 20) & 0x1fffffff)); out[0*64+29] = (start += zigzagdec32((w13 >> 9) & 0x1fffffff)); w14 = *(uint32_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec32((w13 >> 38) | (w14 << 26) & 0x1fffffff)); out[0*64+31] = (start += zigzagdec32((w14 >> 3) & 0x1fffffff));;}; out += 32; in += 29*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_30(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*30)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec32((w0 ) & 0x3fffffff)); out[0*32+ 1] = (start += zigzagdec32((w0 >> 30) & 0x3fffffff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += zigzagdec32((w0 >> 60) | (w1 << 4) & 0x3fffffff)); out[0*32+ 3] = (start += zigzagdec32((w1 >> 26) & 0x3fffffff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*32+ 4] = (start += zigzagdec32((w1 >> 56) | (w2 << 8) & 0x3fffffff)); out[0*32+ 5] = (start += zigzagdec32((w2 >> 22) & 0x3fffffff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*32+ 6] = (start += zigzagdec32((w2 >> 52) | (w3 << 12) & 0x3fffffff)); out[0*32+ 7] = (start += zigzagdec32((w3 >> 18) & 0x3fffffff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*32+ 8] = (start += zigzagdec32((w3 >> 48) | (w4 << 16) & 0x3fffffff)); out[0*32+ 9] = (start += zigzagdec32((w4 >> 14) & 0x3fffffff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*32+10] = (start += zigzagdec32((w4 >> 44) | (w5 << 20) & 0x3fffffff)); out[0*32+11] = (start += zigzagdec32((w5 >> 10) & 0x3fffffff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*32+12] = (start += zigzagdec32((w5 >> 40) | (w6 << 24) & 0x3fffffff)); out[0*32+13] = (start += zigzagdec32((w6 >> 6) & 0x3fffffff)); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*32+14] = (start += zigzagdec32((w6 >> 36) | (w7 << 28) & 0x3fffffff)); out[0*32+15] = (start += zigzagdec32((w7 >> 2) & 0x3fffffff)); out[0*32+16] = (start += zigzagdec32((w7 >> 32) & 0x3fffffff)); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*32+17] = (start += zigzagdec32((w7 >> 62) | (w8 << 2) & 0x3fffffff)); out[0*32+18] = (start += zigzagdec32((w8 >> 28) & 0x3fffffff)); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*32+19] = (start += zigzagdec32((w8 >> 58) | (w9 << 6) & 0x3fffffff)); out[0*32+20] = (start += zigzagdec32((w9 >> 24) & 0x3fffffff)); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*32+21] = (start += zigzagdec32((w9 >> 54) | (w10 << 10) & 0x3fffffff)); out[0*32+22] = (start += zigzagdec32((w10 >> 20) & 0x3fffffff)); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*32+23] = (start += zigzagdec32((w10 >> 50) | (w11 << 14) & 0x3fffffff)); out[0*32+24] = (start += zigzagdec32((w11 >> 16) & 0x3fffffff)); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*32+25] = (start += zigzagdec32((w11 >> 46) | (w12 << 18) & 0x3fffffff)); out[0*32+26] = (start += zigzagdec32((w12 >> 12) & 0x3fffffff)); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*32+27] = (start += zigzagdec32((w12 >> 42) | (w13 << 22) & 0x3fffffff)); out[0*32+28] = (start += zigzagdec32((w13 >> 8) & 0x3fffffff)); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*32+29] = (start += zigzagdec32((w13 >> 38) | (w14 << 26) & 0x3fffffff)); out[0*32+30] = (start += zigzagdec32((w14 >> 4) & 0x3fffffff)); out[0*32+31] = (start += zigzagdec32((w14 >> 34)));;}; out += 32; in += 30*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_31(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*31)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec32((w0 ) & 0x7fffffff)); out[0*64+ 1] = (start += zigzagdec32((w0 >> 31) & 0x7fffffff)); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec32((w0 >> 62) | (w1 << 2) & 0x7fffffff)); out[0*64+ 3] = (start += zigzagdec32((w1 >> 29) & 0x7fffffff)); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec32((w1 >> 60) | (w2 << 4) & 0x7fffffff)); out[0*64+ 5] = (start += zigzagdec32((w2 >> 27) & 0x7fffffff)); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec32((w2 >> 58) | (w3 << 6) & 0x7fffffff)); out[0*64+ 7] = (start += zigzagdec32((w3 >> 25) & 0x7fffffff)); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec32((w3 >> 56) | (w4 << 8) & 0x7fffffff)); out[0*64+ 9] = (start += zigzagdec32((w4 >> 23) & 0x7fffffff)); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec32((w4 >> 54) | (w5 << 10) & 0x7fffffff)); out[0*64+11] = (start += zigzagdec32((w5 >> 21) & 0x7fffffff)); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec32((w5 >> 52) | (w6 << 12) & 0x7fffffff)); out[0*64+13] = (start += zigzagdec32((w6 >> 19) & 0x7fffffff)); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec32((w6 >> 50) | (w7 << 14) & 0x7fffffff)); out[0*64+15] = (start += zigzagdec32((w7 >> 17) & 0x7fffffff)); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec32((w7 >> 48) | (w8 << 16) & 0x7fffffff)); out[0*64+17] = (start += zigzagdec32((w8 >> 15) & 0x7fffffff)); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec32((w8 >> 46) | (w9 << 18) & 0x7fffffff)); out[0*64+19] = (start += zigzagdec32((w9 >> 13) & 0x7fffffff)); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec32((w9 >> 44) | (w10 << 20) & 0x7fffffff)); out[0*64+21] = (start += zigzagdec32((w10 >> 11) & 0x7fffffff)); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec32((w10 >> 42) | (w11 << 22) & 0x7fffffff)); out[0*64+23] = (start += zigzagdec32((w11 >> 9) & 0x7fffffff)); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec32((w11 >> 40) | (w12 << 24) & 0x7fffffff)); out[0*64+25] = (start += zigzagdec32((w12 >> 7) & 0x7fffffff)); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec32((w12 >> 38) | (w13 << 26) & 0x7fffffff)); out[0*64+27] = (start += zigzagdec32((w13 >> 5) & 0x7fffffff)); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec32((w13 >> 36) | (w14 << 28) & 0x7fffffff)); out[0*64+29] = (start += zigzagdec32((w14 >> 3) & 0x7fffffff)); w15 = *(uint32_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec32((w14 >> 34) | (w15 << 30) & 0x7fffffff)); out[0*64+31] = (start += zigzagdec32((w15 >> 1) & 0x7fffffff));;}; out += 32; in += 31*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack32_32(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*32)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[0*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+0*8+ 0))); out[0*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+0*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[1*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+1*8+ 0))); out[1*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+1*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[2*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+2*8+ 0))); out[2*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+2*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[3*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+3*8+ 0))); out[3*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+3*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[4*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+4*8+ 0))); out[4*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+4*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[5*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+5*8+ 0))); out[5*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+5*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[6*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+6*8+ 0))); out[6*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+6*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[7*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+7*8+ 0))); out[7*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+7*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[8*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+8*8+ 0))); out[8*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+8*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[9*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+9*8+ 0))); out[9*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+9*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[10*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+10*8+ 0))); out[10*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+10*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[11*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+11*8+ 0))); out[11*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+11*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[12*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+12*8+ 0))); out[12*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+12*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[13*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+13*8+ 0))); out[13*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+13*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[14*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+14*8+ 0))); out[14*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+14*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[15*2+ 0] = (start += zigzagdec32(*(uint32_t *)(in+15*8+ 0))); out[15*2+ 1] = (start += zigzagdec32(*(uint32_t *)(in+15*8+ 4)));;}; out += 32; in += 32*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D32 bitzunpacka32[] = {
  &bitzunpack32_0,
  &bitzunpack32_1,
  &bitzunpack32_2,
  &bitzunpack32_3,
  &bitzunpack32_4,
  &bitzunpack32_5,
  &bitzunpack32_6,
  &bitzunpack32_7,
  &bitzunpack32_8,
  &bitzunpack32_9,
  &bitzunpack32_10,
  &bitzunpack32_11,
  &bitzunpack32_12,
  &bitzunpack32_13,
  &bitzunpack32_14,
  &bitzunpack32_15,
  &bitzunpack32_16,
  &bitzunpack32_17,
  &bitzunpack32_18,
  &bitzunpack32_19,
  &bitzunpack32_20,
  &bitzunpack32_21,
  &bitzunpack32_22,
  &bitzunpack32_23,
  &bitzunpack32_24,
  &bitzunpack32_25,
  &bitzunpack32_26,
  &bitzunpack32_27,
  &bitzunpack32_28,
  &bitzunpack32_29,
  &bitzunpack32_30,
  &bitzunpack32_31,
  &bitzunpack32_32
};
unsigned char *bitzunpack32( const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start, unsigned b) { return bitzunpacka32[ b](in, n, out, start); }
unsigned char *bitzunpack64_0(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint64_t *out_ = out+n; do { { { out[0*0+ 0] = (start += zigzagdec64(0)); out[0*0+ 1] = (start += zigzagdec64(0)); out[0*0+ 2] = (start += zigzagdec64(0)); out[0*0+ 3] = (start += zigzagdec64(0)); out[0*0+ 4] = (start += zigzagdec64(0)); out[0*0+ 5] = (start += zigzagdec64(0)); out[0*0+ 6] = (start += zigzagdec64(0)); out[0*0+ 7] = (start += zigzagdec64(0)); out[0*0+ 8] = (start += zigzagdec64(0)); out[0*0+ 9] = (start += zigzagdec64(0)); out[0*0+10] = (start += zigzagdec64(0)); out[0*0+11] = (start += zigzagdec64(0)); out[0*0+12] = (start += zigzagdec64(0)); out[0*0+13] = (start += zigzagdec64(0)); out[0*0+14] = (start += zigzagdec64(0)); out[0*0+15] = (start += zigzagdec64(0)); out[0*0+16] = (start += zigzagdec64(0)); out[0*0+17] = (start += zigzagdec64(0)); out[0*0+18] = (start += zigzagdec64(0)); out[0*0+19] = (start += zigzagdec64(0)); out[0*0+20] = (start += zigzagdec64(0)); out[0*0+21] = (start += zigzagdec64(0)); out[0*0+22] = (start += zigzagdec64(0)); out[0*0+23] = (start += zigzagdec64(0)); out[0*0+24] = (start += zigzagdec64(0)); out[0*0+25] = (start += zigzagdec64(0)); out[0*0+26] = (start += zigzagdec64(0)); out[0*0+27] = (start += zigzagdec64(0)); out[0*0+28] = (start += zigzagdec64(0)); out[0*0+29] = (start += zigzagdec64(0)); out[0*0+30] = (start += zigzagdec64(0)); out[0*0+31] = (start += zigzagdec64(0));;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitzunpack64_1(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x1)); out[0*32+ 1] = (start += zigzagdec64((w0 >> 1) & 0x1)); out[0*32+ 2] = (start += zigzagdec64((w0 >> 2) & 0x1)); out[0*32+ 3] = (start += zigzagdec64((w0 >> 3) & 0x1)); out[0*32+ 4] = (start += zigzagdec64((w0 >> 4) & 0x1)); out[0*32+ 5] = (start += zigzagdec64((w0 >> 5) & 0x1)); out[0*32+ 6] = (start += zigzagdec64((w0 >> 6) & 0x1)); out[0*32+ 7] = (start += zigzagdec64((w0 >> 7) & 0x1)); out[0*32+ 8] = (start += zigzagdec64((w0 >> 8) & 0x1)); out[0*32+ 9] = (start += zigzagdec64((w0 >> 9) & 0x1)); out[0*32+10] = (start += zigzagdec64((w0 >> 10) & 0x1)); out[0*32+11] = (start += zigzagdec64((w0 >> 11) & 0x1)); out[0*32+12] = (start += zigzagdec64((w0 >> 12) & 0x1)); out[0*32+13] = (start += zigzagdec64((w0 >> 13) & 0x1)); out[0*32+14] = (start += zigzagdec64((w0 >> 14) & 0x1)); out[0*32+15] = (start += zigzagdec64((w0 >> 15) & 0x1)); out[0*32+16] = (start += zigzagdec64((w0 >> 16) & 0x1)); out[0*32+17] = (start += zigzagdec64((w0 >> 17) & 0x1)); out[0*32+18] = (start += zigzagdec64((w0 >> 18) & 0x1)); out[0*32+19] = (start += zigzagdec64((w0 >> 19) & 0x1)); out[0*32+20] = (start += zigzagdec64((w0 >> 20) & 0x1)); out[0*32+21] = (start += zigzagdec64((w0 >> 21) & 0x1)); out[0*32+22] = (start += zigzagdec64((w0 >> 22) & 0x1)); out[0*32+23] = (start += zigzagdec64((w0 >> 23) & 0x1)); out[0*32+24] = (start += zigzagdec64((w0 >> 24) & 0x1)); out[0*32+25] = (start += zigzagdec64((w0 >> 25) & 0x1)); out[0*32+26] = (start += zigzagdec64((w0 >> 26) & 0x1)); out[0*32+27] = (start += zigzagdec64((w0 >> 27) & 0x1)); out[0*32+28] = (start += zigzagdec64((w0 >> 28) & 0x1)); out[0*32+29] = (start += zigzagdec64((w0 >> 29) & 0x1)); out[0*32+30] = (start += zigzagdec64((w0 >> 30) & 0x1)); out[0*32+31] = (start += zigzagdec64((w0 >> 31)));;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_2(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3)); out[0*32+ 1] = (start += zigzagdec64((w0 >> 2) & 0x3)); out[0*32+ 2] = (start += zigzagdec64((w0 >> 4) & 0x3)); out[0*32+ 3] = (start += zigzagdec64((w0 >> 6) & 0x3)); out[0*32+ 4] = (start += zigzagdec64((w0 >> 8) & 0x3)); out[0*32+ 5] = (start += zigzagdec64((w0 >> 10) & 0x3)); out[0*32+ 6] = (start += zigzagdec64((w0 >> 12) & 0x3)); out[0*32+ 7] = (start += zigzagdec64((w0 >> 14) & 0x3)); out[0*32+ 8] = (start += zigzagdec64((w0 >> 16) & 0x3)); out[0*32+ 9] = (start += zigzagdec64((w0 >> 18) & 0x3)); out[0*32+10] = (start += zigzagdec64((w0 >> 20) & 0x3)); out[0*32+11] = (start += zigzagdec64((w0 >> 22) & 0x3)); out[0*32+12] = (start += zigzagdec64((w0 >> 24) & 0x3)); out[0*32+13] = (start += zigzagdec64((w0 >> 26) & 0x3)); out[0*32+14] = (start += zigzagdec64((w0 >> 28) & 0x3)); out[0*32+15] = (start += zigzagdec64((w0 >> 30) & 0x3)); out[0*32+16] = (start += zigzagdec64((w0 >> 32) & 0x3)); out[0*32+17] = (start += zigzagdec64((w0 >> 34) & 0x3)); out[0*32+18] = (start += zigzagdec64((w0 >> 36) & 0x3)); out[0*32+19] = (start += zigzagdec64((w0 >> 38) & 0x3)); out[0*32+20] = (start += zigzagdec64((w0 >> 40) & 0x3)); out[0*32+21] = (start += zigzagdec64((w0 >> 42) & 0x3)); out[0*32+22] = (start += zigzagdec64((w0 >> 44) & 0x3)); out[0*32+23] = (start += zigzagdec64((w0 >> 46) & 0x3)); out[0*32+24] = (start += zigzagdec64((w0 >> 48) & 0x3)); out[0*32+25] = (start += zigzagdec64((w0 >> 50) & 0x3)); out[0*32+26] = (start += zigzagdec64((w0 >> 52) & 0x3)); out[0*32+27] = (start += zigzagdec64((w0 >> 54) & 0x3)); out[0*32+28] = (start += zigzagdec64((w0 >> 56) & 0x3)); out[0*32+29] = (start += zigzagdec64((w0 >> 58) & 0x3)); out[0*32+30] = (start += zigzagdec64((w0 >> 60) & 0x3)); out[0*32+31] = (start += zigzagdec64((w0 >> 62)));;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_3(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 3) & 0x7)); out[0*64+ 2] = (start += zigzagdec64((w0 >> 6) & 0x7)); out[0*64+ 3] = (start += zigzagdec64((w0 >> 9) & 0x7)); out[0*64+ 4] = (start += zigzagdec64((w0 >> 12) & 0x7)); out[0*64+ 5] = (start += zigzagdec64((w0 >> 15) & 0x7)); out[0*64+ 6] = (start += zigzagdec64((w0 >> 18) & 0x7)); out[0*64+ 7] = (start += zigzagdec64((w0 >> 21) & 0x7)); out[0*64+ 8] = (start += zigzagdec64((w0 >> 24) & 0x7)); out[0*64+ 9] = (start += zigzagdec64((w0 >> 27) & 0x7)); out[0*64+10] = (start += zigzagdec64((w0 >> 30) & 0x7)); out[0*64+11] = (start += zigzagdec64((w0 >> 33) & 0x7)); out[0*64+12] = (start += zigzagdec64((w0 >> 36) & 0x7)); out[0*64+13] = (start += zigzagdec64((w0 >> 39) & 0x7)); out[0*64+14] = (start += zigzagdec64((w0 >> 42) & 0x7)); out[0*64+15] = (start += zigzagdec64((w0 >> 45) & 0x7)); out[0*64+16] = (start += zigzagdec64((w0 >> 48) & 0x7)); out[0*64+17] = (start += zigzagdec64((w0 >> 51) & 0x7)); out[0*64+18] = (start += zigzagdec64((w0 >> 54) & 0x7)); out[0*64+19] = (start += zigzagdec64((w0 >> 57) & 0x7)); out[0*64+20] = (start += zigzagdec64((w0 >> 60) & 0x7)); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w0 >> 63) | (w1 << 1) & 0x7)); out[0*64+22] = (start += zigzagdec64((w1 >> 2) & 0x7)); out[0*64+23] = (start += zigzagdec64((w1 >> 5) & 0x7)); out[0*64+24] = (start += zigzagdec64((w1 >> 8) & 0x7)); out[0*64+25] = (start += zigzagdec64((w1 >> 11) & 0x7)); out[0*64+26] = (start += zigzagdec64((w1 >> 14) & 0x7)); out[0*64+27] = (start += zigzagdec64((w1 >> 17) & 0x7)); out[0*64+28] = (start += zigzagdec64((w1 >> 20) & 0x7)); out[0*64+29] = (start += zigzagdec64((w1 >> 23) & 0x7)); out[0*64+30] = (start += zigzagdec64((w1 >> 26) & 0x7)); out[0*64+31] = (start += zigzagdec64((w1 >> 29) & 0x7));;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_4(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec64((w0 ) & 0xf)); out[0*16+ 1] = (start += zigzagdec64((w0 >> 4) & 0xf)); out[0*16+ 2] = (start += zigzagdec64((w0 >> 8) & 0xf)); out[0*16+ 3] = (start += zigzagdec64((w0 >> 12) & 0xf)); out[0*16+ 4] = (start += zigzagdec64((w0 >> 16) & 0xf)); out[0*16+ 5] = (start += zigzagdec64((w0 >> 20) & 0xf)); out[0*16+ 6] = (start += zigzagdec64((w0 >> 24) & 0xf)); out[0*16+ 7] = (start += zigzagdec64((w0 >> 28) & 0xf)); out[0*16+ 8] = (start += zigzagdec64((w0 >> 32) & 0xf)); out[0*16+ 9] = (start += zigzagdec64((w0 >> 36) & 0xf)); out[0*16+10] = (start += zigzagdec64((w0 >> 40) & 0xf)); out[0*16+11] = (start += zigzagdec64((w0 >> 44) & 0xf)); out[0*16+12] = (start += zigzagdec64((w0 >> 48) & 0xf)); out[0*16+13] = (start += zigzagdec64((w0 >> 52) & 0xf)); out[0*16+14] = (start += zigzagdec64((w0 >> 56) & 0xf)); out[0*16+15] = (start += zigzagdec64((w0 >> 60)));;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec64((w0 ) & 0xf)); out[1*16+ 1] = (start += zigzagdec64((w0 >> 4) & 0xf)); out[1*16+ 2] = (start += zigzagdec64((w0 >> 8) & 0xf)); out[1*16+ 3] = (start += zigzagdec64((w0 >> 12) & 0xf)); out[1*16+ 4] = (start += zigzagdec64((w0 >> 16) & 0xf)); out[1*16+ 5] = (start += zigzagdec64((w0 >> 20) & 0xf)); out[1*16+ 6] = (start += zigzagdec64((w0 >> 24) & 0xf)); out[1*16+ 7] = (start += zigzagdec64((w0 >> 28) & 0xf)); out[1*16+ 8] = (start += zigzagdec64((w0 >> 32) & 0xf)); out[1*16+ 9] = (start += zigzagdec64((w0 >> 36) & 0xf)); out[1*16+10] = (start += zigzagdec64((w0 >> 40) & 0xf)); out[1*16+11] = (start += zigzagdec64((w0 >> 44) & 0xf)); out[1*16+12] = (start += zigzagdec64((w0 >> 48) & 0xf)); out[1*16+13] = (start += zigzagdec64((w0 >> 52) & 0xf)); out[1*16+14] = (start += zigzagdec64((w0 >> 56) & 0xf)); out[1*16+15] = (start += zigzagdec64((w0 >> 60)));;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_5(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1f)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 5) & 0x1f)); out[0*64+ 2] = (start += zigzagdec64((w0 >> 10) & 0x1f)); out[0*64+ 3] = (start += zigzagdec64((w0 >> 15) & 0x1f)); out[0*64+ 4] = (start += zigzagdec64((w0 >> 20) & 0x1f)); out[0*64+ 5] = (start += zigzagdec64((w0 >> 25) & 0x1f)); out[0*64+ 6] = (start += zigzagdec64((w0 >> 30) & 0x1f)); out[0*64+ 7] = (start += zigzagdec64((w0 >> 35) & 0x1f)); out[0*64+ 8] = (start += zigzagdec64((w0 >> 40) & 0x1f)); out[0*64+ 9] = (start += zigzagdec64((w0 >> 45) & 0x1f)); out[0*64+10] = (start += zigzagdec64((w0 >> 50) & 0x1f)); out[0*64+11] = (start += zigzagdec64((w0 >> 55) & 0x1f)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w0 >> 60) | (w1 << 4) & 0x1f)); out[0*64+13] = (start += zigzagdec64((w1 >> 1) & 0x1f)); out[0*64+14] = (start += zigzagdec64((w1 >> 6) & 0x1f)); out[0*64+15] = (start += zigzagdec64((w1 >> 11) & 0x1f)); out[0*64+16] = (start += zigzagdec64((w1 >> 16) & 0x1f)); out[0*64+17] = (start += zigzagdec64((w1 >> 21) & 0x1f)); out[0*64+18] = (start += zigzagdec64((w1 >> 26) & 0x1f)); out[0*64+19] = (start += zigzagdec64((w1 >> 31) & 0x1f)); out[0*64+20] = (start += zigzagdec64((w1 >> 36) & 0x1f)); out[0*64+21] = (start += zigzagdec64((w1 >> 41) & 0x1f)); out[0*64+22] = (start += zigzagdec64((w1 >> 46) & 0x1f)); out[0*64+23] = (start += zigzagdec64((w1 >> 51) & 0x1f)); out[0*64+24] = (start += zigzagdec64((w1 >> 56) & 0x1f)); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w1 >> 61) | (w2 << 3) & 0x1f)); out[0*64+26] = (start += zigzagdec64((w2 >> 2) & 0x1f)); out[0*64+27] = (start += zigzagdec64((w2 >> 7) & 0x1f)); out[0*64+28] = (start += zigzagdec64((w2 >> 12) & 0x1f)); out[0*64+29] = (start += zigzagdec64((w2 >> 17) & 0x1f)); out[0*64+30] = (start += zigzagdec64((w2 >> 22) & 0x1f)); out[0*64+31] = (start += zigzagdec64((w2 >> 27) & 0x1f));;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_6(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3f)); out[0*32+ 1] = (start += zigzagdec64((w0 >> 6) & 0x3f)); out[0*32+ 2] = (start += zigzagdec64((w0 >> 12) & 0x3f)); out[0*32+ 3] = (start += zigzagdec64((w0 >> 18) & 0x3f)); out[0*32+ 4] = (start += zigzagdec64((w0 >> 24) & 0x3f)); out[0*32+ 5] = (start += zigzagdec64((w0 >> 30) & 0x3f)); out[0*32+ 6] = (start += zigzagdec64((w0 >> 36) & 0x3f)); out[0*32+ 7] = (start += zigzagdec64((w0 >> 42) & 0x3f)); out[0*32+ 8] = (start += zigzagdec64((w0 >> 48) & 0x3f)); out[0*32+ 9] = (start += zigzagdec64((w0 >> 54) & 0x3f)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start += zigzagdec64((w0 >> 60) | (w1 << 4) & 0x3f)); out[0*32+11] = (start += zigzagdec64((w1 >> 2) & 0x3f)); out[0*32+12] = (start += zigzagdec64((w1 >> 8) & 0x3f)); out[0*32+13] = (start += zigzagdec64((w1 >> 14) & 0x3f)); out[0*32+14] = (start += zigzagdec64((w1 >> 20) & 0x3f)); out[0*32+15] = (start += zigzagdec64((w1 >> 26) & 0x3f)); out[0*32+16] = (start += zigzagdec64((w1 >> 32) & 0x3f)); out[0*32+17] = (start += zigzagdec64((w1 >> 38) & 0x3f)); out[0*32+18] = (start += zigzagdec64((w1 >> 44) & 0x3f)); out[0*32+19] = (start += zigzagdec64((w1 >> 50) & 0x3f)); out[0*32+20] = (start += zigzagdec64((w1 >> 56) & 0x3f)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start += zigzagdec64((w1 >> 62) | (w2 << 2) & 0x3f)); out[0*32+22] = (start += zigzagdec64((w2 >> 4) & 0x3f)); out[0*32+23] = (start += zigzagdec64((w2 >> 10) & 0x3f)); out[0*32+24] = (start += zigzagdec64((w2 >> 16) & 0x3f)); out[0*32+25] = (start += zigzagdec64((w2 >> 22) & 0x3f)); out[0*32+26] = (start += zigzagdec64((w2 >> 28) & 0x3f)); out[0*32+27] = (start += zigzagdec64((w2 >> 34) & 0x3f)); out[0*32+28] = (start += zigzagdec64((w2 >> 40) & 0x3f)); out[0*32+29] = (start += zigzagdec64((w2 >> 46) & 0x3f)); out[0*32+30] = (start += zigzagdec64((w2 >> 52) & 0x3f)); out[0*32+31] = (start += zigzagdec64((w2 >> 58)));;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_7(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7f)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 7) & 0x7f)); out[0*64+ 2] = (start += zigzagdec64((w0 >> 14) & 0x7f)); out[0*64+ 3] = (start += zigzagdec64((w0 >> 21) & 0x7f)); out[0*64+ 4] = (start += zigzagdec64((w0 >> 28) & 0x7f)); out[0*64+ 5] = (start += zigzagdec64((w0 >> 35) & 0x7f)); out[0*64+ 6] = (start += zigzagdec64((w0 >> 42) & 0x7f)); out[0*64+ 7] = (start += zigzagdec64((w0 >> 49) & 0x7f)); out[0*64+ 8] = (start += zigzagdec64((w0 >> 56) & 0x7f)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w0 >> 63) | (w1 << 1) & 0x7f)); out[0*64+10] = (start += zigzagdec64((w1 >> 6) & 0x7f)); out[0*64+11] = (start += zigzagdec64((w1 >> 13) & 0x7f)); out[0*64+12] = (start += zigzagdec64((w1 >> 20) & 0x7f)); out[0*64+13] = (start += zigzagdec64((w1 >> 27) & 0x7f)); out[0*64+14] = (start += zigzagdec64((w1 >> 34) & 0x7f)); out[0*64+15] = (start += zigzagdec64((w1 >> 41) & 0x7f)); out[0*64+16] = (start += zigzagdec64((w1 >> 48) & 0x7f)); out[0*64+17] = (start += zigzagdec64((w1 >> 55) & 0x7f)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w1 >> 62) | (w2 << 2) & 0x7f)); out[0*64+19] = (start += zigzagdec64((w2 >> 5) & 0x7f)); out[0*64+20] = (start += zigzagdec64((w2 >> 12) & 0x7f)); out[0*64+21] = (start += zigzagdec64((w2 >> 19) & 0x7f)); out[0*64+22] = (start += zigzagdec64((w2 >> 26) & 0x7f)); out[0*64+23] = (start += zigzagdec64((w2 >> 33) & 0x7f)); out[0*64+24] = (start += zigzagdec64((w2 >> 40) & 0x7f)); out[0*64+25] = (start += zigzagdec64((w2 >> 47) & 0x7f)); out[0*64+26] = (start += zigzagdec64((w2 >> 54) & 0x7f)); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w2 >> 61) | (w3 << 3) & 0x7f)); out[0*64+28] = (start += zigzagdec64((w3 >> 4) & 0x7f)); out[0*64+29] = (start += zigzagdec64((w3 >> 11) & 0x7f)); out[0*64+30] = (start += zigzagdec64((w3 >> 18) & 0x7f)); out[0*64+31] = (start += zigzagdec64((w3 >> 25) & 0x7f));;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_8(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += zigzagdec64((w0 ) & 0xff)); out[0*8+ 1] = (start += zigzagdec64((w0 >> 8) & 0xff)); out[0*8+ 2] = (start += zigzagdec64((w0 >> 16) & 0xff)); out[0*8+ 3] = (start += zigzagdec64((w0 >> 24) & 0xff)); out[0*8+ 4] = (start += zigzagdec64((w0 >> 32) & 0xff)); out[0*8+ 5] = (start += zigzagdec64((w0 >> 40) & 0xff)); out[0*8+ 6] = (start += zigzagdec64((w0 >> 48) & 0xff)); out[0*8+ 7] = (start += zigzagdec64((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += zigzagdec64((w0 ) & 0xff)); out[1*8+ 1] = (start += zigzagdec64((w0 >> 8) & 0xff)); out[1*8+ 2] = (start += zigzagdec64((w0 >> 16) & 0xff)); out[1*8+ 3] = (start += zigzagdec64((w0 >> 24) & 0xff)); out[1*8+ 4] = (start += zigzagdec64((w0 >> 32) & 0xff)); out[1*8+ 5] = (start += zigzagdec64((w0 >> 40) & 0xff)); out[1*8+ 6] = (start += zigzagdec64((w0 >> 48) & 0xff)); out[1*8+ 7] = (start += zigzagdec64((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += zigzagdec64((w0 ) & 0xff)); out[2*8+ 1] = (start += zigzagdec64((w0 >> 8) & 0xff)); out[2*8+ 2] = (start += zigzagdec64((w0 >> 16) & 0xff)); out[2*8+ 3] = (start += zigzagdec64((w0 >> 24) & 0xff)); out[2*8+ 4] = (start += zigzagdec64((w0 >> 32) & 0xff)); out[2*8+ 5] = (start += zigzagdec64((w0 >> 40) & 0xff)); out[2*8+ 6] = (start += zigzagdec64((w0 >> 48) & 0xff)); out[2*8+ 7] = (start += zigzagdec64((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += zigzagdec64((w0 ) & 0xff)); out[3*8+ 1] = (start += zigzagdec64((w0 >> 8) & 0xff)); out[3*8+ 2] = (start += zigzagdec64((w0 >> 16) & 0xff)); out[3*8+ 3] = (start += zigzagdec64((w0 >> 24) & 0xff)); out[3*8+ 4] = (start += zigzagdec64((w0 >> 32) & 0xff)); out[3*8+ 5] = (start += zigzagdec64((w0 >> 40) & 0xff)); out[3*8+ 6] = (start += zigzagdec64((w0 >> 48) & 0xff)); out[3*8+ 7] = (start += zigzagdec64((w0 >> 56)));;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_9(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1ff)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 9) & 0x1ff)); out[0*64+ 2] = (start += zigzagdec64((w0 >> 18) & 0x1ff)); out[0*64+ 3] = (start += zigzagdec64((w0 >> 27) & 0x1ff)); out[0*64+ 4] = (start += zigzagdec64((w0 >> 36) & 0x1ff)); out[0*64+ 5] = (start += zigzagdec64((w0 >> 45) & 0x1ff)); out[0*64+ 6] = (start += zigzagdec64((w0 >> 54) & 0x1ff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w0 >> 63) | (w1 << 1) & 0x1ff)); out[0*64+ 8] = (start += zigzagdec64((w1 >> 8) & 0x1ff)); out[0*64+ 9] = (start += zigzagdec64((w1 >> 17) & 0x1ff)); out[0*64+10] = (start += zigzagdec64((w1 >> 26) & 0x1ff)); out[0*64+11] = (start += zigzagdec64((w1 >> 35) & 0x1ff)); out[0*64+12] = (start += zigzagdec64((w1 >> 44) & 0x1ff)); out[0*64+13] = (start += zigzagdec64((w1 >> 53) & 0x1ff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w1 >> 62) | (w2 << 2) & 0x1ff)); out[0*64+15] = (start += zigzagdec64((w2 >> 7) & 0x1ff)); out[0*64+16] = (start += zigzagdec64((w2 >> 16) & 0x1ff)); out[0*64+17] = (start += zigzagdec64((w2 >> 25) & 0x1ff)); out[0*64+18] = (start += zigzagdec64((w2 >> 34) & 0x1ff)); out[0*64+19] = (start += zigzagdec64((w2 >> 43) & 0x1ff)); out[0*64+20] = (start += zigzagdec64((w2 >> 52) & 0x1ff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w2 >> 61) | (w3 << 3) & 0x1ff)); out[0*64+22] = (start += zigzagdec64((w3 >> 6) & 0x1ff)); out[0*64+23] = (start += zigzagdec64((w3 >> 15) & 0x1ff)); out[0*64+24] = (start += zigzagdec64((w3 >> 24) & 0x1ff)); out[0*64+25] = (start += zigzagdec64((w3 >> 33) & 0x1ff)); out[0*64+26] = (start += zigzagdec64((w3 >> 42) & 0x1ff)); out[0*64+27] = (start += zigzagdec64((w3 >> 51) & 0x1ff)); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w3 >> 60) | (w4 << 4) & 0x1ff)); out[0*64+29] = (start += zigzagdec64((w4 >> 5) & 0x1ff)); out[0*64+30] = (start += zigzagdec64((w4 >> 14) & 0x1ff)); out[0*64+31] = (start += zigzagdec64((w4 >> 23) & 0x1ff));;}; out += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_10(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3ff)); out[0*32+ 1] = (start += zigzagdec64((w0 >> 10) & 0x3ff)); out[0*32+ 2] = (start += zigzagdec64((w0 >> 20) & 0x3ff)); out[0*32+ 3] = (start += zigzagdec64((w0 >> 30) & 0x3ff)); out[0*32+ 4] = (start += zigzagdec64((w0 >> 40) & 0x3ff)); out[0*32+ 5] = (start += zigzagdec64((w0 >> 50) & 0x3ff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (start += zigzagdec64((w0 >> 60) | (w1 << 4) & 0x3ff)); out[0*32+ 7] = (start += zigzagdec64((w1 >> 6) & 0x3ff)); out[0*32+ 8] = (start += zigzagdec64((w1 >> 16) & 0x3ff)); out[0*32+ 9] = (start += zigzagdec64((w1 >> 26) & 0x3ff)); out[0*32+10] = (start += zigzagdec64((w1 >> 36) & 0x3ff)); out[0*32+11] = (start += zigzagdec64((w1 >> 46) & 0x3ff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0x3ff)); out[0*32+13] = (start += zigzagdec64((w2 >> 2) & 0x3ff)); out[0*32+14] = (start += zigzagdec64((w2 >> 12) & 0x3ff)); out[0*32+15] = (start += zigzagdec64((w2 >> 22) & 0x3ff)); out[0*32+16] = (start += zigzagdec64((w2 >> 32) & 0x3ff)); out[0*32+17] = (start += zigzagdec64((w2 >> 42) & 0x3ff)); out[0*32+18] = (start += zigzagdec64((w2 >> 52) & 0x3ff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (start += zigzagdec64((w2 >> 62) | (w3 << 2) & 0x3ff)); out[0*32+20] = (start += zigzagdec64((w3 >> 8) & 0x3ff)); out[0*32+21] = (start += zigzagdec64((w3 >> 18) & 0x3ff)); out[0*32+22] = (start += zigzagdec64((w3 >> 28) & 0x3ff)); out[0*32+23] = (start += zigzagdec64((w3 >> 38) & 0x3ff)); out[0*32+24] = (start += zigzagdec64((w3 >> 48) & 0x3ff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (start += zigzagdec64((w3 >> 58) | (w4 << 6) & 0x3ff)); out[0*32+26] = (start += zigzagdec64((w4 >> 4) & 0x3ff)); out[0*32+27] = (start += zigzagdec64((w4 >> 14) & 0x3ff)); out[0*32+28] = (start += zigzagdec64((w4 >> 24) & 0x3ff)); out[0*32+29] = (start += zigzagdec64((w4 >> 34) & 0x3ff)); out[0*32+30] = (start += zigzagdec64((w4 >> 44) & 0x3ff)); out[0*32+31] = (start += zigzagdec64((w4 >> 54)));;}; out += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_11(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7ff)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 11) & 0x7ff)); out[0*64+ 2] = (start += zigzagdec64((w0 >> 22) & 0x7ff)); out[0*64+ 3] = (start += zigzagdec64((w0 >> 33) & 0x7ff)); out[0*64+ 4] = (start += zigzagdec64((w0 >> 44) & 0x7ff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w0 >> 55) | (w1 << 9) & 0x7ff)); out[0*64+ 6] = (start += zigzagdec64((w1 >> 2) & 0x7ff)); out[0*64+ 7] = (start += zigzagdec64((w1 >> 13) & 0x7ff)); out[0*64+ 8] = (start += zigzagdec64((w1 >> 24) & 0x7ff)); out[0*64+ 9] = (start += zigzagdec64((w1 >> 35) & 0x7ff)); out[0*64+10] = (start += zigzagdec64((w1 >> 46) & 0x7ff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w1 >> 57) | (w2 << 7) & 0x7ff)); out[0*64+12] = (start += zigzagdec64((w2 >> 4) & 0x7ff)); out[0*64+13] = (start += zigzagdec64((w2 >> 15) & 0x7ff)); out[0*64+14] = (start += zigzagdec64((w2 >> 26) & 0x7ff)); out[0*64+15] = (start += zigzagdec64((w2 >> 37) & 0x7ff)); out[0*64+16] = (start += zigzagdec64((w2 >> 48) & 0x7ff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w2 >> 59) | (w3 << 5) & 0x7ff)); out[0*64+18] = (start += zigzagdec64((w3 >> 6) & 0x7ff)); out[0*64+19] = (start += zigzagdec64((w3 >> 17) & 0x7ff)); out[0*64+20] = (start += zigzagdec64((w3 >> 28) & 0x7ff)); out[0*64+21] = (start += zigzagdec64((w3 >> 39) & 0x7ff)); out[0*64+22] = (start += zigzagdec64((w3 >> 50) & 0x7ff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w3 >> 61) | (w4 << 3) & 0x7ff)); out[0*64+24] = (start += zigzagdec64((w4 >> 8) & 0x7ff)); out[0*64+25] = (start += zigzagdec64((w4 >> 19) & 0x7ff)); out[0*64+26] = (start += zigzagdec64((w4 >> 30) & 0x7ff)); out[0*64+27] = (start += zigzagdec64((w4 >> 41) & 0x7ff)); out[0*64+28] = (start += zigzagdec64((w4 >> 52) & 0x7ff)); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w4 >> 63) | (w5 << 1) & 0x7ff)); out[0*64+30] = (start += zigzagdec64((w5 >> 10) & 0x7ff)); out[0*64+31] = (start += zigzagdec64((w5 >> 21) & 0x7ff));;}; out += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_12(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec64((w0 ) & 0xfff)); out[0*16+ 1] = (start += zigzagdec64((w0 >> 12) & 0xfff)); out[0*16+ 2] = (start += zigzagdec64((w0 >> 24) & 0xfff)); out[0*16+ 3] = (start += zigzagdec64((w0 >> 36) & 0xfff)); out[0*16+ 4] = (start += zigzagdec64((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (start += zigzagdec64((w0 >> 60) | (w1 << 4) & 0xfff)); out[0*16+ 6] = (start += zigzagdec64((w1 >> 8) & 0xfff)); out[0*16+ 7] = (start += zigzagdec64((w1 >> 20) & 0xfff)); out[0*16+ 8] = (start += zigzagdec64((w1 >> 32) & 0xfff)); out[0*16+ 9] = (start += zigzagdec64((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0xfff)); out[0*16+11] = (start += zigzagdec64((w2 >> 4) & 0xfff)); out[0*16+12] = (start += zigzagdec64((w2 >> 16) & 0xfff)); out[0*16+13] = (start += zigzagdec64((w2 >> 28) & 0xfff)); out[0*16+14] = (start += zigzagdec64((w2 >> 40) & 0xfff)); out[0*16+15] = (start += zigzagdec64((w2 >> 52)));;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec64((w0 ) & 0xfff)); out[1*16+ 1] = (start += zigzagdec64((w0 >> 12) & 0xfff)); out[1*16+ 2] = (start += zigzagdec64((w0 >> 24) & 0xfff)); out[1*16+ 3] = (start += zigzagdec64((w0 >> 36) & 0xfff)); out[1*16+ 4] = (start += zigzagdec64((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (start += zigzagdec64((w0 >> 60) | (w1 << 4) & 0xfff)); out[1*16+ 6] = (start += zigzagdec64((w1 >> 8) & 0xfff)); out[1*16+ 7] = (start += zigzagdec64((w1 >> 20) & 0xfff)); out[1*16+ 8] = (start += zigzagdec64((w1 >> 32) & 0xfff)); out[1*16+ 9] = (start += zigzagdec64((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0xfff)); out[1*16+11] = (start += zigzagdec64((w2 >> 4) & 0xfff)); out[1*16+12] = (start += zigzagdec64((w2 >> 16) & 0xfff)); out[1*16+13] = (start += zigzagdec64((w2 >> 28) & 0xfff)); out[1*16+14] = (start += zigzagdec64((w2 >> 40) & 0xfff)); out[1*16+15] = (start += zigzagdec64((w2 >> 52)));;}; out += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_13(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1fff)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 13) & 0x1fff)); out[0*64+ 2] = (start += zigzagdec64((w0 >> 26) & 0x1fff)); out[0*64+ 3] = (start += zigzagdec64((w0 >> 39) & 0x1fff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w0 >> 52) | (w1 << 12) & 0x1fff)); out[0*64+ 5] = (start += zigzagdec64((w1 >> 1) & 0x1fff)); out[0*64+ 6] = (start += zigzagdec64((w1 >> 14) & 0x1fff)); out[0*64+ 7] = (start += zigzagdec64((w1 >> 27) & 0x1fff)); out[0*64+ 8] = (start += zigzagdec64((w1 >> 40) & 0x1fff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w1 >> 53) | (w2 << 11) & 0x1fff)); out[0*64+10] = (start += zigzagdec64((w2 >> 2) & 0x1fff)); out[0*64+11] = (start += zigzagdec64((w2 >> 15) & 0x1fff)); out[0*64+12] = (start += zigzagdec64((w2 >> 28) & 0x1fff)); out[0*64+13] = (start += zigzagdec64((w2 >> 41) & 0x1fff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w2 >> 54) | (w3 << 10) & 0x1fff)); out[0*64+15] = (start += zigzagdec64((w3 >> 3) & 0x1fff)); out[0*64+16] = (start += zigzagdec64((w3 >> 16) & 0x1fff)); out[0*64+17] = (start += zigzagdec64((w3 >> 29) & 0x1fff)); out[0*64+18] = (start += zigzagdec64((w3 >> 42) & 0x1fff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w3 >> 55) | (w4 << 9) & 0x1fff)); out[0*64+20] = (start += zigzagdec64((w4 >> 4) & 0x1fff)); out[0*64+21] = (start += zigzagdec64((w4 >> 17) & 0x1fff)); out[0*64+22] = (start += zigzagdec64((w4 >> 30) & 0x1fff)); out[0*64+23] = (start += zigzagdec64((w4 >> 43) & 0x1fff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w4 >> 56) | (w5 << 8) & 0x1fff)); out[0*64+25] = (start += zigzagdec64((w5 >> 5) & 0x1fff)); out[0*64+26] = (start += zigzagdec64((w5 >> 18) & 0x1fff)); out[0*64+27] = (start += zigzagdec64((w5 >> 31) & 0x1fff)); out[0*64+28] = (start += zigzagdec64((w5 >> 44) & 0x1fff)); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w5 >> 57) | (w6 << 7) & 0x1fff)); out[0*64+30] = (start += zigzagdec64((w6 >> 6) & 0x1fff)); out[0*64+31] = (start += zigzagdec64((w6 >> 19) & 0x1fff));;}; out += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_14(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3fff)); out[0*32+ 1] = (start += zigzagdec64((w0 >> 14) & 0x3fff)); out[0*32+ 2] = (start += zigzagdec64((w0 >> 28) & 0x3fff)); out[0*32+ 3] = (start += zigzagdec64((w0 >> 42) & 0x3fff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (start += zigzagdec64((w0 >> 56) | (w1 << 8) & 0x3fff)); out[0*32+ 5] = (start += zigzagdec64((w1 >> 6) & 0x3fff)); out[0*32+ 6] = (start += zigzagdec64((w1 >> 20) & 0x3fff)); out[0*32+ 7] = (start += zigzagdec64((w1 >> 34) & 0x3fff)); out[0*32+ 8] = (start += zigzagdec64((w1 >> 48) & 0x3fff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (start += zigzagdec64((w1 >> 62) | (w2 << 2) & 0x3fff)); out[0*32+10] = (start += zigzagdec64((w2 >> 12) & 0x3fff)); out[0*32+11] = (start += zigzagdec64((w2 >> 26) & 0x3fff)); out[0*32+12] = (start += zigzagdec64((w2 >> 40) & 0x3fff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (start += zigzagdec64((w2 >> 54) | (w3 << 10) & 0x3fff)); out[0*32+14] = (start += zigzagdec64((w3 >> 4) & 0x3fff)); out[0*32+15] = (start += zigzagdec64((w3 >> 18) & 0x3fff)); out[0*32+16] = (start += zigzagdec64((w3 >> 32) & 0x3fff)); out[0*32+17] = (start += zigzagdec64((w3 >> 46) & 0x3fff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (start += zigzagdec64((w3 >> 60) | (w4 << 4) & 0x3fff)); out[0*32+19] = (start += zigzagdec64((w4 >> 10) & 0x3fff)); out[0*32+20] = (start += zigzagdec64((w4 >> 24) & 0x3fff)); out[0*32+21] = (start += zigzagdec64((w4 >> 38) & 0x3fff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (start += zigzagdec64((w4 >> 52) | (w5 << 12) & 0x3fff)); out[0*32+23] = (start += zigzagdec64((w5 >> 2) & 0x3fff)); out[0*32+24] = (start += zigzagdec64((w5 >> 16) & 0x3fff)); out[0*32+25] = (start += zigzagdec64((w5 >> 30) & 0x3fff)); out[0*32+26] = (start += zigzagdec64((w5 >> 44) & 0x3fff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (start += zigzagdec64((w5 >> 58) | (w6 << 6) & 0x3fff)); out[0*32+28] = (start += zigzagdec64((w6 >> 8) & 0x3fff)); out[0*32+29] = (start += zigzagdec64((w6 >> 22) & 0x3fff)); out[0*32+30] = (start += zigzagdec64((w6 >> 36) & 0x3fff)); out[0*32+31] = (start += zigzagdec64((w6 >> 50)));;}; out += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_15(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7fff)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 15) & 0x7fff)); out[0*64+ 2] = (start += zigzagdec64((w0 >> 30) & 0x7fff)); out[0*64+ 3] = (start += zigzagdec64((w0 >> 45) & 0x7fff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w0 >> 60) | (w1 << 4) & 0x7fff)); out[0*64+ 5] = (start += zigzagdec64((w1 >> 11) & 0x7fff)); out[0*64+ 6] = (start += zigzagdec64((w1 >> 26) & 0x7fff)); out[0*64+ 7] = (start += zigzagdec64((w1 >> 41) & 0x7fff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0x7fff)); out[0*64+ 9] = (start += zigzagdec64((w2 >> 7) & 0x7fff)); out[0*64+10] = (start += zigzagdec64((w2 >> 22) & 0x7fff)); out[0*64+11] = (start += zigzagdec64((w2 >> 37) & 0x7fff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w2 >> 52) | (w3 << 12) & 0x7fff)); out[0*64+13] = (start += zigzagdec64((w3 >> 3) & 0x7fff)); out[0*64+14] = (start += zigzagdec64((w3 >> 18) & 0x7fff)); out[0*64+15] = (start += zigzagdec64((w3 >> 33) & 0x7fff)); out[0*64+16] = (start += zigzagdec64((w3 >> 48) & 0x7fff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w3 >> 63) | (w4 << 1) & 0x7fff)); out[0*64+18] = (start += zigzagdec64((w4 >> 14) & 0x7fff)); out[0*64+19] = (start += zigzagdec64((w4 >> 29) & 0x7fff)); out[0*64+20] = (start += zigzagdec64((w4 >> 44) & 0x7fff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w4 >> 59) | (w5 << 5) & 0x7fff)); out[0*64+22] = (start += zigzagdec64((w5 >> 10) & 0x7fff)); out[0*64+23] = (start += zigzagdec64((w5 >> 25) & 0x7fff)); out[0*64+24] = (start += zigzagdec64((w5 >> 40) & 0x7fff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w5 >> 55) | (w6 << 9) & 0x7fff)); out[0*64+26] = (start += zigzagdec64((w6 >> 6) & 0x7fff)); out[0*64+27] = (start += zigzagdec64((w6 >> 21) & 0x7fff)); out[0*64+28] = (start += zigzagdec64((w6 >> 36) & 0x7fff)); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w6 >> 51) | (w7 << 13) & 0x7fff)); out[0*64+30] = (start += zigzagdec64((w7 >> 2) & 0x7fff)); out[0*64+31] = (start += zigzagdec64((w7 >> 17) & 0x7fff));;}; out += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_16(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = (start += zigzagdec64(*(uint16_t *)(in+0*8+ 0))); out[0*4+ 1] = (start += zigzagdec64(*(uint16_t *)(in+0*8+ 2))); out[0*4+ 2] = (start += zigzagdec64(*(uint16_t *)(in+0*8+ 4))); out[0*4+ 3] = (start += zigzagdec64(*(uint16_t *)(in+0*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = (start += zigzagdec64(*(uint16_t *)(in+1*8+ 0))); out[1*4+ 1] = (start += zigzagdec64(*(uint16_t *)(in+1*8+ 2))); out[1*4+ 2] = (start += zigzagdec64(*(uint16_t *)(in+1*8+ 4))); out[1*4+ 3] = (start += zigzagdec64(*(uint16_t *)(in+1*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = (start += zigzagdec64(*(uint16_t *)(in+2*8+ 0))); out[2*4+ 1] = (start += zigzagdec64(*(uint16_t *)(in+2*8+ 2))); out[2*4+ 2] = (start += zigzagdec64(*(uint16_t *)(in+2*8+ 4))); out[2*4+ 3] = (start += zigzagdec64(*(uint16_t *)(in+2*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = (start += zigzagdec64(*(uint16_t *)(in+3*8+ 0))); out[3*4+ 1] = (start += zigzagdec64(*(uint16_t *)(in+3*8+ 2))); out[3*4+ 2] = (start += zigzagdec64(*(uint16_t *)(in+3*8+ 4))); out[3*4+ 3] = (start += zigzagdec64(*(uint16_t *)(in+3*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = (start += zigzagdec64(*(uint16_t *)(in+4*8+ 0))); out[4*4+ 1] = (start += zigzagdec64(*(uint16_t *)(in+4*8+ 2))); out[4*4+ 2] = (start += zigzagdec64(*(uint16_t *)(in+4*8+ 4))); out[4*4+ 3] = (start += zigzagdec64(*(uint16_t *)(in+4*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = (start += zigzagdec64(*(uint16_t *)(in+5*8+ 0))); out[5*4+ 1] = (start += zigzagdec64(*(uint16_t *)(in+5*8+ 2))); out[5*4+ 2] = (start += zigzagdec64(*(uint16_t *)(in+5*8+ 4))); out[5*4+ 3] = (start += zigzagdec64(*(uint16_t *)(in+5*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = (start += zigzagdec64(*(uint16_t *)(in+6*8+ 0))); out[6*4+ 1] = (start += zigzagdec64(*(uint16_t *)(in+6*8+ 2))); out[6*4+ 2] = (start += zigzagdec64(*(uint16_t *)(in+6*8+ 4))); out[6*4+ 3] = (start += zigzagdec64(*(uint16_t *)(in+6*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = (start += zigzagdec64(*(uint16_t *)(in+7*8+ 0))); out[7*4+ 1] = (start += zigzagdec64(*(uint16_t *)(in+7*8+ 2))); out[7*4+ 2] = (start += zigzagdec64(*(uint16_t *)(in+7*8+ 4))); out[7*4+ 3] = (start += zigzagdec64(*(uint16_t *)(in+7*8+ 6)));;}; out += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_17(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*17)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1ffff)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 17) & 0x1ffff)); out[0*64+ 2] = (start += zigzagdec64((w0 >> 34) & 0x1ffff)); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w0 >> 51) | (w1 << 13) & 0x1ffff)); out[0*64+ 4] = (start += zigzagdec64((w1 >> 4) & 0x1ffff)); out[0*64+ 5] = (start += zigzagdec64((w1 >> 21) & 0x1ffff)); out[0*64+ 6] = (start += zigzagdec64((w1 >> 38) & 0x1ffff)); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w1 >> 55) | (w2 << 9) & 0x1ffff)); out[0*64+ 8] = (start += zigzagdec64((w2 >> 8) & 0x1ffff)); out[0*64+ 9] = (start += zigzagdec64((w2 >> 25) & 0x1ffff)); out[0*64+10] = (start += zigzagdec64((w2 >> 42) & 0x1ffff)); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w2 >> 59) | (w3 << 5) & 0x1ffff)); out[0*64+12] = (start += zigzagdec64((w3 >> 12) & 0x1ffff)); out[0*64+13] = (start += zigzagdec64((w3 >> 29) & 0x1ffff)); out[0*64+14] = (start += zigzagdec64((w3 >> 46) & 0x1ffff)); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w3 >> 63) | (w4 << 1) & 0x1ffff)); out[0*64+16] = (start += zigzagdec64((w4 >> 16) & 0x1ffff)); out[0*64+17] = (start += zigzagdec64((w4 >> 33) & 0x1ffff)); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w4 >> 50) | (w5 << 14) & 0x1ffff)); out[0*64+19] = (start += zigzagdec64((w5 >> 3) & 0x1ffff)); out[0*64+20] = (start += zigzagdec64((w5 >> 20) & 0x1ffff)); out[0*64+21] = (start += zigzagdec64((w5 >> 37) & 0x1ffff)); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w5 >> 54) | (w6 << 10) & 0x1ffff)); out[0*64+23] = (start += zigzagdec64((w6 >> 7) & 0x1ffff)); out[0*64+24] = (start += zigzagdec64((w6 >> 24) & 0x1ffff)); out[0*64+25] = (start += zigzagdec64((w6 >> 41) & 0x1ffff)); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w6 >> 58) | (w7 << 6) & 0x1ffff)); out[0*64+27] = (start += zigzagdec64((w7 >> 11) & 0x1ffff)); out[0*64+28] = (start += zigzagdec64((w7 >> 28) & 0x1ffff)); out[0*64+29] = (start += zigzagdec64((w7 >> 45) & 0x1ffff)); w8 = *(uint32_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w7 >> 62) | (w8 << 2) & 0x1ffff)); out[0*64+31] = (start += zigzagdec64((w8 >> 15) & 0x1ffff));;}; out += 32; in += 17*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_18(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*18)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3ffff)); out[0*32+ 1] = (start += zigzagdec64((w0 >> 18) & 0x3ffff)); out[0*32+ 2] = (start += zigzagdec64((w0 >> 36) & 0x3ffff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*32+ 3] = (start += zigzagdec64((w0 >> 54) | (w1 << 10) & 0x3ffff)); out[0*32+ 4] = (start += zigzagdec64((w1 >> 8) & 0x3ffff)); out[0*32+ 5] = (start += zigzagdec64((w1 >> 26) & 0x3ffff)); out[0*32+ 6] = (start += zigzagdec64((w1 >> 44) & 0x3ffff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*32+ 7] = (start += zigzagdec64((w1 >> 62) | (w2 << 2) & 0x3ffff)); out[0*32+ 8] = (start += zigzagdec64((w2 >> 16) & 0x3ffff)); out[0*32+ 9] = (start += zigzagdec64((w2 >> 34) & 0x3ffff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*32+10] = (start += zigzagdec64((w2 >> 52) | (w3 << 12) & 0x3ffff)); out[0*32+11] = (start += zigzagdec64((w3 >> 6) & 0x3ffff)); out[0*32+12] = (start += zigzagdec64((w3 >> 24) & 0x3ffff)); out[0*32+13] = (start += zigzagdec64((w3 >> 42) & 0x3ffff)); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*32+14] = (start += zigzagdec64((w3 >> 60) | (w4 << 4) & 0x3ffff)); out[0*32+15] = (start += zigzagdec64((w4 >> 14) & 0x3ffff)); out[0*32+16] = (start += zigzagdec64((w4 >> 32) & 0x3ffff)); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*32+17] = (start += zigzagdec64((w4 >> 50) | (w5 << 14) & 0x3ffff)); out[0*32+18] = (start += zigzagdec64((w5 >> 4) & 0x3ffff)); out[0*32+19] = (start += zigzagdec64((w5 >> 22) & 0x3ffff)); out[0*32+20] = (start += zigzagdec64((w5 >> 40) & 0x3ffff)); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*32+21] = (start += zigzagdec64((w5 >> 58) | (w6 << 6) & 0x3ffff)); out[0*32+22] = (start += zigzagdec64((w6 >> 12) & 0x3ffff)); out[0*32+23] = (start += zigzagdec64((w6 >> 30) & 0x3ffff)); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*32+24] = (start += zigzagdec64((w6 >> 48) | (w7 << 16) & 0x3ffff)); out[0*32+25] = (start += zigzagdec64((w7 >> 2) & 0x3ffff)); out[0*32+26] = (start += zigzagdec64((w7 >> 20) & 0x3ffff)); out[0*32+27] = (start += zigzagdec64((w7 >> 38) & 0x3ffff)); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*32+28] = (start += zigzagdec64((w7 >> 56) | (w8 << 8) & 0x3ffff)); out[0*32+29] = (start += zigzagdec64((w8 >> 10) & 0x3ffff)); out[0*32+30] = (start += zigzagdec64((w8 >> 28) & 0x3ffff)); out[0*32+31] = (start += zigzagdec64((w8 >> 46)));;}; out += 32; in += 18*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_19(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*19)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7ffff)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 19) & 0x7ffff)); out[0*64+ 2] = (start += zigzagdec64((w0 >> 38) & 0x7ffff)); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w0 >> 57) | (w1 << 7) & 0x7ffff)); out[0*64+ 4] = (start += zigzagdec64((w1 >> 12) & 0x7ffff)); out[0*64+ 5] = (start += zigzagdec64((w1 >> 31) & 0x7ffff)); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w1 >> 50) | (w2 << 14) & 0x7ffff)); out[0*64+ 7] = (start += zigzagdec64((w2 >> 5) & 0x7ffff)); out[0*64+ 8] = (start += zigzagdec64((w2 >> 24) & 0x7ffff)); out[0*64+ 9] = (start += zigzagdec64((w2 >> 43) & 0x7ffff)); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w2 >> 62) | (w3 << 2) & 0x7ffff)); out[0*64+11] = (start += zigzagdec64((w3 >> 17) & 0x7ffff)); out[0*64+12] = (start += zigzagdec64((w3 >> 36) & 0x7ffff)); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w3 >> 55) | (w4 << 9) & 0x7ffff)); out[0*64+14] = (start += zigzagdec64((w4 >> 10) & 0x7ffff)); out[0*64+15] = (start += zigzagdec64((w4 >> 29) & 0x7ffff)); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w4 >> 48) | (w5 << 16) & 0x7ffff)); out[0*64+17] = (start += zigzagdec64((w5 >> 3) & 0x7ffff)); out[0*64+18] = (start += zigzagdec64((w5 >> 22) & 0x7ffff)); out[0*64+19] = (start += zigzagdec64((w5 >> 41) & 0x7ffff)); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w5 >> 60) | (w6 << 4) & 0x7ffff)); out[0*64+21] = (start += zigzagdec64((w6 >> 15) & 0x7ffff)); out[0*64+22] = (start += zigzagdec64((w6 >> 34) & 0x7ffff)); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w6 >> 53) | (w7 << 11) & 0x7ffff)); out[0*64+24] = (start += zigzagdec64((w7 >> 8) & 0x7ffff)); out[0*64+25] = (start += zigzagdec64((w7 >> 27) & 0x7ffff)); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w7 >> 46) | (w8 << 18) & 0x7ffff)); out[0*64+27] = (start += zigzagdec64((w8 >> 1) & 0x7ffff)); out[0*64+28] = (start += zigzagdec64((w8 >> 20) & 0x7ffff)); out[0*64+29] = (start += zigzagdec64((w8 >> 39) & 0x7ffff)); w9 = *(uint32_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w8 >> 58) | (w9 << 6) & 0x7ffff)); out[0*64+31] = (start += zigzagdec64((w9 >> 13) & 0x7ffff));;}; out += 32; in += 19*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_20(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*20)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec64((w0 ) & 0xfffff)); out[0*16+ 1] = (start += zigzagdec64((w0 >> 20) & 0xfffff)); out[0*16+ 2] = (start += zigzagdec64((w0 >> 40) & 0xfffff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*16+ 3] = (start += zigzagdec64((w0 >> 60) | (w1 << 4) & 0xfffff)); out[0*16+ 4] = (start += zigzagdec64((w1 >> 16) & 0xfffff)); out[0*16+ 5] = (start += zigzagdec64((w1 >> 36) & 0xfffff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*16+ 6] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0xfffff)); out[0*16+ 7] = (start += zigzagdec64((w2 >> 12) & 0xfffff)); out[0*16+ 8] = (start += zigzagdec64((w2 >> 32) & 0xfffff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*16+ 9] = (start += zigzagdec64((w2 >> 52) | (w3 << 12) & 0xfffff)); out[0*16+10] = (start += zigzagdec64((w3 >> 8) & 0xfffff)); out[0*16+11] = (start += zigzagdec64((w3 >> 28) & 0xfffff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*16+12] = (start += zigzagdec64((w3 >> 48) | (w4 << 16) & 0xfffff)); out[0*16+13] = (start += zigzagdec64((w4 >> 4) & 0xfffff)); out[0*16+14] = (start += zigzagdec64((w4 >> 24) & 0xfffff)); out[0*16+15] = (start += zigzagdec64((w4 >> 44)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec64((w0 ) & 0xfffff)); out[1*16+ 1] = (start += zigzagdec64((w0 >> 20) & 0xfffff)); out[1*16+ 2] = (start += zigzagdec64((w0 >> 40) & 0xfffff)); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*16+ 3] = (start += zigzagdec64((w0 >> 60) | (w1 << 4) & 0xfffff)); out[1*16+ 4] = (start += zigzagdec64((w1 >> 16) & 0xfffff)); out[1*16+ 5] = (start += zigzagdec64((w1 >> 36) & 0xfffff)); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*16+ 6] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0xfffff)); out[1*16+ 7] = (start += zigzagdec64((w2 >> 12) & 0xfffff)); out[1*16+ 8] = (start += zigzagdec64((w2 >> 32) & 0xfffff)); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*16+ 9] = (start += zigzagdec64((w2 >> 52) | (w3 << 12) & 0xfffff)); out[1*16+10] = (start += zigzagdec64((w3 >> 8) & 0xfffff)); out[1*16+11] = (start += zigzagdec64((w3 >> 28) & 0xfffff)); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*16+12] = (start += zigzagdec64((w3 >> 48) | (w4 << 16) & 0xfffff)); out[1*16+13] = (start += zigzagdec64((w4 >> 4) & 0xfffff)); out[1*16+14] = (start += zigzagdec64((w4 >> 24) & 0xfffff)); out[1*16+15] = (start += zigzagdec64((w4 >> 44)));;}; out += 32; in += 20*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_21(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*21)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1fffff)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 21) & 0x1fffff)); out[0*64+ 2] = (start += zigzagdec64((w0 >> 42) & 0x1fffff)); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w0 >> 63) | (w1 << 1) & 0x1fffff)); out[0*64+ 4] = (start += zigzagdec64((w1 >> 20) & 0x1fffff)); out[0*64+ 5] = (start += zigzagdec64((w1 >> 41) & 0x1fffff)); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w1 >> 62) | (w2 << 2) & 0x1fffff)); out[0*64+ 7] = (start += zigzagdec64((w2 >> 19) & 0x1fffff)); out[0*64+ 8] = (start += zigzagdec64((w2 >> 40) & 0x1fffff)); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w2 >> 61) | (w3 << 3) & 0x1fffff)); out[0*64+10] = (start += zigzagdec64((w3 >> 18) & 0x1fffff)); out[0*64+11] = (start += zigzagdec64((w3 >> 39) & 0x1fffff)); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w3 >> 60) | (w4 << 4) & 0x1fffff)); out[0*64+13] = (start += zigzagdec64((w4 >> 17) & 0x1fffff)); out[0*64+14] = (start += zigzagdec64((w4 >> 38) & 0x1fffff)); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w4 >> 59) | (w5 << 5) & 0x1fffff)); out[0*64+16] = (start += zigzagdec64((w5 >> 16) & 0x1fffff)); out[0*64+17] = (start += zigzagdec64((w5 >> 37) & 0x1fffff)); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w5 >> 58) | (w6 << 6) & 0x1fffff)); out[0*64+19] = (start += zigzagdec64((w6 >> 15) & 0x1fffff)); out[0*64+20] = (start += zigzagdec64((w6 >> 36) & 0x1fffff)); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w6 >> 57) | (w7 << 7) & 0x1fffff)); out[0*64+22] = (start += zigzagdec64((w7 >> 14) & 0x1fffff)); out[0*64+23] = (start += zigzagdec64((w7 >> 35) & 0x1fffff)); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w7 >> 56) | (w8 << 8) & 0x1fffff)); out[0*64+25] = (start += zigzagdec64((w8 >> 13) & 0x1fffff)); out[0*64+26] = (start += zigzagdec64((w8 >> 34) & 0x1fffff)); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w8 >> 55) | (w9 << 9) & 0x1fffff)); out[0*64+28] = (start += zigzagdec64((w9 >> 12) & 0x1fffff)); out[0*64+29] = (start += zigzagdec64((w9 >> 33) & 0x1fffff)); w10 = *(uint32_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w9 >> 54) | (w10 << 10) & 0x1fffff)); out[0*64+31] = (start += zigzagdec64((w10 >> 11) & 0x1fffff));;}; out += 32; in += 21*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_22(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*22)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3fffff)); out[0*32+ 1] = (start += zigzagdec64((w0 >> 22) & 0x3fffff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += zigzagdec64((w0 >> 44) | (w1 << 20) & 0x3fffff)); out[0*32+ 3] = (start += zigzagdec64((w1 >> 2) & 0x3fffff)); out[0*32+ 4] = (start += zigzagdec64((w1 >> 24) & 0x3fffff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*32+ 5] = (start += zigzagdec64((w1 >> 46) | (w2 << 18) & 0x3fffff)); out[0*32+ 6] = (start += zigzagdec64((w2 >> 4) & 0x3fffff)); out[0*32+ 7] = (start += zigzagdec64((w2 >> 26) & 0x3fffff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*32+ 8] = (start += zigzagdec64((w2 >> 48) | (w3 << 16) & 0x3fffff)); out[0*32+ 9] = (start += zigzagdec64((w3 >> 6) & 0x3fffff)); out[0*32+10] = (start += zigzagdec64((w3 >> 28) & 0x3fffff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*32+11] = (start += zigzagdec64((w3 >> 50) | (w4 << 14) & 0x3fffff)); out[0*32+12] = (start += zigzagdec64((w4 >> 8) & 0x3fffff)); out[0*32+13] = (start += zigzagdec64((w4 >> 30) & 0x3fffff)); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*32+14] = (start += zigzagdec64((w4 >> 52) | (w5 << 12) & 0x3fffff)); out[0*32+15] = (start += zigzagdec64((w5 >> 10) & 0x3fffff)); out[0*32+16] = (start += zigzagdec64((w5 >> 32) & 0x3fffff)); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*32+17] = (start += zigzagdec64((w5 >> 54) | (w6 << 10) & 0x3fffff)); out[0*32+18] = (start += zigzagdec64((w6 >> 12) & 0x3fffff)); out[0*32+19] = (start += zigzagdec64((w6 >> 34) & 0x3fffff)); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*32+20] = (start += zigzagdec64((w6 >> 56) | (w7 << 8) & 0x3fffff)); out[0*32+21] = (start += zigzagdec64((w7 >> 14) & 0x3fffff)); out[0*32+22] = (start += zigzagdec64((w7 >> 36) & 0x3fffff)); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*32+23] = (start += zigzagdec64((w7 >> 58) | (w8 << 6) & 0x3fffff)); out[0*32+24] = (start += zigzagdec64((w8 >> 16) & 0x3fffff)); out[0*32+25] = (start += zigzagdec64((w8 >> 38) & 0x3fffff)); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*32+26] = (start += zigzagdec64((w8 >> 60) | (w9 << 4) & 0x3fffff)); out[0*32+27] = (start += zigzagdec64((w9 >> 18) & 0x3fffff)); out[0*32+28] = (start += zigzagdec64((w9 >> 40) & 0x3fffff)); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*32+29] = (start += zigzagdec64((w9 >> 62) | (w10 << 2) & 0x3fffff)); out[0*32+30] = (start += zigzagdec64((w10 >> 20) & 0x3fffff)); out[0*32+31] = (start += zigzagdec64((w10 >> 42)));;}; out += 32; in += 22*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_23(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*23)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7fffff)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 23) & 0x7fffff)); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w0 >> 46) | (w1 << 18) & 0x7fffff)); out[0*64+ 3] = (start += zigzagdec64((w1 >> 5) & 0x7fffff)); out[0*64+ 4] = (start += zigzagdec64((w1 >> 28) & 0x7fffff)); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w1 >> 51) | (w2 << 13) & 0x7fffff)); out[0*64+ 6] = (start += zigzagdec64((w2 >> 10) & 0x7fffff)); out[0*64+ 7] = (start += zigzagdec64((w2 >> 33) & 0x7fffff)); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w2 >> 56) | (w3 << 8) & 0x7fffff)); out[0*64+ 9] = (start += zigzagdec64((w3 >> 15) & 0x7fffff)); out[0*64+10] = (start += zigzagdec64((w3 >> 38) & 0x7fffff)); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w3 >> 61) | (w4 << 3) & 0x7fffff)); out[0*64+12] = (start += zigzagdec64((w4 >> 20) & 0x7fffff)); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w4 >> 43) | (w5 << 21) & 0x7fffff)); out[0*64+14] = (start += zigzagdec64((w5 >> 2) & 0x7fffff)); out[0*64+15] = (start += zigzagdec64((w5 >> 25) & 0x7fffff)); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w5 >> 48) | (w6 << 16) & 0x7fffff)); out[0*64+17] = (start += zigzagdec64((w6 >> 7) & 0x7fffff)); out[0*64+18] = (start += zigzagdec64((w6 >> 30) & 0x7fffff)); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w6 >> 53) | (w7 << 11) & 0x7fffff)); out[0*64+20] = (start += zigzagdec64((w7 >> 12) & 0x7fffff)); out[0*64+21] = (start += zigzagdec64((w7 >> 35) & 0x7fffff)); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w7 >> 58) | (w8 << 6) & 0x7fffff)); out[0*64+23] = (start += zigzagdec64((w8 >> 17) & 0x7fffff)); out[0*64+24] = (start += zigzagdec64((w8 >> 40) & 0x7fffff)); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w8 >> 63) | (w9 << 1) & 0x7fffff)); out[0*64+26] = (start += zigzagdec64((w9 >> 22) & 0x7fffff)); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w9 >> 45) | (w10 << 19) & 0x7fffff)); out[0*64+28] = (start += zigzagdec64((w10 >> 4) & 0x7fffff)); out[0*64+29] = (start += zigzagdec64((w10 >> 27) & 0x7fffff)); w11 = *(uint32_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w10 >> 50) | (w11 << 14) & 0x7fffff)); out[0*64+31] = (start += zigzagdec64((w11 >> 9) & 0x7fffff));;}; out += 32; in += 23*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_24(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*24)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += zigzagdec64((w0 ) & 0xffffff)); out[0*8+ 1] = (start += zigzagdec64((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*8+ 2] = (start += zigzagdec64((w0 >> 48) | (w1 << 16) & 0xffffff)); out[0*8+ 3] = (start += zigzagdec64((w1 >> 8) & 0xffffff)); out[0*8+ 4] = (start += zigzagdec64((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*8+ 5] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0xffffff)); out[0*8+ 6] = (start += zigzagdec64((w2 >> 16) & 0xffffff)); out[0*8+ 7] = (start += zigzagdec64((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += zigzagdec64((w0 ) & 0xffffff)); out[1*8+ 1] = (start += zigzagdec64((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*8+ 2] = (start += zigzagdec64((w0 >> 48) | (w1 << 16) & 0xffffff)); out[1*8+ 3] = (start += zigzagdec64((w1 >> 8) & 0xffffff)); out[1*8+ 4] = (start += zigzagdec64((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*8+ 5] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0xffffff)); out[1*8+ 6] = (start += zigzagdec64((w2 >> 16) & 0xffffff)); out[1*8+ 7] = (start += zigzagdec64((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += zigzagdec64((w0 ) & 0xffffff)); out[2*8+ 1] = (start += zigzagdec64((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*8+ 2] = (start += zigzagdec64((w0 >> 48) | (w1 << 16) & 0xffffff)); out[2*8+ 3] = (start += zigzagdec64((w1 >> 8) & 0xffffff)); out[2*8+ 4] = (start += zigzagdec64((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*8+ 5] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0xffffff)); out[2*8+ 6] = (start += zigzagdec64((w2 >> 16) & 0xffffff)); out[2*8+ 7] = (start += zigzagdec64((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += zigzagdec64((w0 ) & 0xffffff)); out[3*8+ 1] = (start += zigzagdec64((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*8+ 2] = (start += zigzagdec64((w0 >> 48) | (w1 << 16) & 0xffffff)); out[3*8+ 3] = (start += zigzagdec64((w1 >> 8) & 0xffffff)); out[3*8+ 4] = (start += zigzagdec64((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*8+ 5] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0xffffff)); out[3*8+ 6] = (start += zigzagdec64((w2 >> 16) & 0xffffff)); out[3*8+ 7] = (start += zigzagdec64((w2 >> 40)));;}; out += 32; in += 24*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_25(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*25)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1ffffff)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 25) & 0x1ffffff)); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w0 >> 50) | (w1 << 14) & 0x1ffffff)); out[0*64+ 3] = (start += zigzagdec64((w1 >> 11) & 0x1ffffff)); out[0*64+ 4] = (start += zigzagdec64((w1 >> 36) & 0x1ffffff)); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w1 >> 61) | (w2 << 3) & 0x1ffffff)); out[0*64+ 6] = (start += zigzagdec64((w2 >> 22) & 0x1ffffff)); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w2 >> 47) | (w3 << 17) & 0x1ffffff)); out[0*64+ 8] = (start += zigzagdec64((w3 >> 8) & 0x1ffffff)); out[0*64+ 9] = (start += zigzagdec64((w3 >> 33) & 0x1ffffff)); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w3 >> 58) | (w4 << 6) & 0x1ffffff)); out[0*64+11] = (start += zigzagdec64((w4 >> 19) & 0x1ffffff)); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w4 >> 44) | (w5 << 20) & 0x1ffffff)); out[0*64+13] = (start += zigzagdec64((w5 >> 5) & 0x1ffffff)); out[0*64+14] = (start += zigzagdec64((w5 >> 30) & 0x1ffffff)); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w5 >> 55) | (w6 << 9) & 0x1ffffff)); out[0*64+16] = (start += zigzagdec64((w6 >> 16) & 0x1ffffff)); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w6 >> 41) | (w7 << 23) & 0x1ffffff)); out[0*64+18] = (start += zigzagdec64((w7 >> 2) & 0x1ffffff)); out[0*64+19] = (start += zigzagdec64((w7 >> 27) & 0x1ffffff)); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w7 >> 52) | (w8 << 12) & 0x1ffffff)); out[0*64+21] = (start += zigzagdec64((w8 >> 13) & 0x1ffffff)); out[0*64+22] = (start += zigzagdec64((w8 >> 38) & 0x1ffffff)); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w8 >> 63) | (w9 << 1) & 0x1ffffff)); out[0*64+24] = (start += zigzagdec64((w9 >> 24) & 0x1ffffff)); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w9 >> 49) | (w10 << 15) & 0x1ffffff)); out[0*64+26] = (start += zigzagdec64((w10 >> 10) & 0x1ffffff)); out[0*64+27] = (start += zigzagdec64((w10 >> 35) & 0x1ffffff)); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w10 >> 60) | (w11 << 4) & 0x1ffffff)); out[0*64+29] = (start += zigzagdec64((w11 >> 21) & 0x1ffffff)); w12 = *(uint32_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w11 >> 46) | (w12 << 18) & 0x1ffffff)); out[0*64+31] = (start += zigzagdec64((w12 >> 7) & 0x1ffffff));;}; out += 32; in += 25*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_26(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*26)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3ffffff)); out[0*32+ 1] = (start += zigzagdec64((w0 >> 26) & 0x3ffffff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += zigzagdec64((w0 >> 52) | (w1 << 12) & 0x3ffffff)); out[0*32+ 3] = (start += zigzagdec64((w1 >> 14) & 0x3ffffff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*32+ 4] = (start += zigzagdec64((w1 >> 40) | (w2 << 24) & 0x3ffffff)); out[0*32+ 5] = (start += zigzagdec64((w2 >> 2) & 0x3ffffff)); out[0*32+ 6] = (start += zigzagdec64((w2 >> 28) & 0x3ffffff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*32+ 7] = (start += zigzagdec64((w2 >> 54) | (w3 << 10) & 0x3ffffff)); out[0*32+ 8] = (start += zigzagdec64((w3 >> 16) & 0x3ffffff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*32+ 9] = (start += zigzagdec64((w3 >> 42) | (w4 << 22) & 0x3ffffff)); out[0*32+10] = (start += zigzagdec64((w4 >> 4) & 0x3ffffff)); out[0*32+11] = (start += zigzagdec64((w4 >> 30) & 0x3ffffff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*32+12] = (start += zigzagdec64((w4 >> 56) | (w5 << 8) & 0x3ffffff)); out[0*32+13] = (start += zigzagdec64((w5 >> 18) & 0x3ffffff)); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*32+14] = (start += zigzagdec64((w5 >> 44) | (w6 << 20) & 0x3ffffff)); out[0*32+15] = (start += zigzagdec64((w6 >> 6) & 0x3ffffff)); out[0*32+16] = (start += zigzagdec64((w6 >> 32) & 0x3ffffff)); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*32+17] = (start += zigzagdec64((w6 >> 58) | (w7 << 6) & 0x3ffffff)); out[0*32+18] = (start += zigzagdec64((w7 >> 20) & 0x3ffffff)); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*32+19] = (start += zigzagdec64((w7 >> 46) | (w8 << 18) & 0x3ffffff)); out[0*32+20] = (start += zigzagdec64((w8 >> 8) & 0x3ffffff)); out[0*32+21] = (start += zigzagdec64((w8 >> 34) & 0x3ffffff)); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*32+22] = (start += zigzagdec64((w8 >> 60) | (w9 << 4) & 0x3ffffff)); out[0*32+23] = (start += zigzagdec64((w9 >> 22) & 0x3ffffff)); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*32+24] = (start += zigzagdec64((w9 >> 48) | (w10 << 16) & 0x3ffffff)); out[0*32+25] = (start += zigzagdec64((w10 >> 10) & 0x3ffffff)); out[0*32+26] = (start += zigzagdec64((w10 >> 36) & 0x3ffffff)); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*32+27] = (start += zigzagdec64((w10 >> 62) | (w11 << 2) & 0x3ffffff)); out[0*32+28] = (start += zigzagdec64((w11 >> 24) & 0x3ffffff)); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*32+29] = (start += zigzagdec64((w11 >> 50) | (w12 << 14) & 0x3ffffff)); out[0*32+30] = (start += zigzagdec64((w12 >> 12) & 0x3ffffff)); out[0*32+31] = (start += zigzagdec64((w12 >> 38)));;}; out += 32; in += 26*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_27(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*27)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7ffffff)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 27) & 0x7ffffff)); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w0 >> 54) | (w1 << 10) & 0x7ffffff)); out[0*64+ 3] = (start += zigzagdec64((w1 >> 17) & 0x7ffffff)); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w1 >> 44) | (w2 << 20) & 0x7ffffff)); out[0*64+ 5] = (start += zigzagdec64((w2 >> 7) & 0x7ffffff)); out[0*64+ 6] = (start += zigzagdec64((w2 >> 34) & 0x7ffffff)); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w2 >> 61) | (w3 << 3) & 0x7ffffff)); out[0*64+ 8] = (start += zigzagdec64((w3 >> 24) & 0x7ffffff)); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w3 >> 51) | (w4 << 13) & 0x7ffffff)); out[0*64+10] = (start += zigzagdec64((w4 >> 14) & 0x7ffffff)); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w4 >> 41) | (w5 << 23) & 0x7ffffff)); out[0*64+12] = (start += zigzagdec64((w5 >> 4) & 0x7ffffff)); out[0*64+13] = (start += zigzagdec64((w5 >> 31) & 0x7ffffff)); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w5 >> 58) | (w6 << 6) & 0x7ffffff)); out[0*64+15] = (start += zigzagdec64((w6 >> 21) & 0x7ffffff)); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w6 >> 48) | (w7 << 16) & 0x7ffffff)); out[0*64+17] = (start += zigzagdec64((w7 >> 11) & 0x7ffffff)); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w7 >> 38) | (w8 << 26) & 0x7ffffff)); out[0*64+19] = (start += zigzagdec64((w8 >> 1) & 0x7ffffff)); out[0*64+20] = (start += zigzagdec64((w8 >> 28) & 0x7ffffff)); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w8 >> 55) | (w9 << 9) & 0x7ffffff)); out[0*64+22] = (start += zigzagdec64((w9 >> 18) & 0x7ffffff)); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w9 >> 45) | (w10 << 19) & 0x7ffffff)); out[0*64+24] = (start += zigzagdec64((w10 >> 8) & 0x7ffffff)); out[0*64+25] = (start += zigzagdec64((w10 >> 35) & 0x7ffffff)); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w10 >> 62) | (w11 << 2) & 0x7ffffff)); out[0*64+27] = (start += zigzagdec64((w11 >> 25) & 0x7ffffff)); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w11 >> 52) | (w12 << 12) & 0x7ffffff)); out[0*64+29] = (start += zigzagdec64((w12 >> 15) & 0x7ffffff)); w13 = *(uint32_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w12 >> 42) | (w13 << 22) & 0x7ffffff)); out[0*64+31] = (start += zigzagdec64((w13 >> 5) & 0x7ffffff));;}; out += 32; in += 27*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_28(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*28)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec64((w0 ) & 0xfffffff)); out[0*16+ 1] = (start += zigzagdec64((w0 >> 28) & 0xfffffff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*16+ 2] = (start += zigzagdec64((w0 >> 56) | (w1 << 8) & 0xfffffff)); out[0*16+ 3] = (start += zigzagdec64((w1 >> 20) & 0xfffffff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*16+ 4] = (start += zigzagdec64((w1 >> 48) | (w2 << 16) & 0xfffffff)); out[0*16+ 5] = (start += zigzagdec64((w2 >> 12) & 0xfffffff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*16+ 6] = (start += zigzagdec64((w2 >> 40) | (w3 << 24) & 0xfffffff)); out[0*16+ 7] = (start += zigzagdec64((w3 >> 4) & 0xfffffff)); out[0*16+ 8] = (start += zigzagdec64((w3 >> 32) & 0xfffffff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*16+ 9] = (start += zigzagdec64((w3 >> 60) | (w4 << 4) & 0xfffffff)); out[0*16+10] = (start += zigzagdec64((w4 >> 24) & 0xfffffff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*16+11] = (start += zigzagdec64((w4 >> 52) | (w5 << 12) & 0xfffffff)); out[0*16+12] = (start += zigzagdec64((w5 >> 16) & 0xfffffff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*16+13] = (start += zigzagdec64((w5 >> 44) | (w6 << 20) & 0xfffffff)); out[0*16+14] = (start += zigzagdec64((w6 >> 8) & 0xfffffff)); out[0*16+15] = (start += zigzagdec64((w6 >> 36)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec64((w0 ) & 0xfffffff)); out[1*16+ 1] = (start += zigzagdec64((w0 >> 28) & 0xfffffff)); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*16+ 2] = (start += zigzagdec64((w0 >> 56) | (w1 << 8) & 0xfffffff)); out[1*16+ 3] = (start += zigzagdec64((w1 >> 20) & 0xfffffff)); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*16+ 4] = (start += zigzagdec64((w1 >> 48) | (w2 << 16) & 0xfffffff)); out[1*16+ 5] = (start += zigzagdec64((w2 >> 12) & 0xfffffff)); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*16+ 6] = (start += zigzagdec64((w2 >> 40) | (w3 << 24) & 0xfffffff)); out[1*16+ 7] = (start += zigzagdec64((w3 >> 4) & 0xfffffff)); out[1*16+ 8] = (start += zigzagdec64((w3 >> 32) & 0xfffffff)); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*16+ 9] = (start += zigzagdec64((w3 >> 60) | (w4 << 4) & 0xfffffff)); out[1*16+10] = (start += zigzagdec64((w4 >> 24) & 0xfffffff)); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*16+11] = (start += zigzagdec64((w4 >> 52) | (w5 << 12) & 0xfffffff)); out[1*16+12] = (start += zigzagdec64((w5 >> 16) & 0xfffffff)); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*16+13] = (start += zigzagdec64((w5 >> 44) | (w6 << 20) & 0xfffffff)); out[1*16+14] = (start += zigzagdec64((w6 >> 8) & 0xfffffff)); out[1*16+15] = (start += zigzagdec64((w6 >> 36)));;}; out += 32; in += 28*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_29(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*29)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1fffffff)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 29) & 0x1fffffff)); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w0 >> 58) | (w1 << 6) & 0x1fffffff)); out[0*64+ 3] = (start += zigzagdec64((w1 >> 23) & 0x1fffffff)); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w1 >> 52) | (w2 << 12) & 0x1fffffff)); out[0*64+ 5] = (start += zigzagdec64((w2 >> 17) & 0x1fffffff)); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w2 >> 46) | (w3 << 18) & 0x1fffffff)); out[0*64+ 7] = (start += zigzagdec64((w3 >> 11) & 0x1fffffff)); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w3 >> 40) | (w4 << 24) & 0x1fffffff)); out[0*64+ 9] = (start += zigzagdec64((w4 >> 5) & 0x1fffffff)); out[0*64+10] = (start += zigzagdec64((w4 >> 34) & 0x1fffffff)); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w4 >> 63) | (w5 << 1) & 0x1fffffff)); out[0*64+12] = (start += zigzagdec64((w5 >> 28) & 0x1fffffff)); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w5 >> 57) | (w6 << 7) & 0x1fffffff)); out[0*64+14] = (start += zigzagdec64((w6 >> 22) & 0x1fffffff)); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w6 >> 51) | (w7 << 13) & 0x1fffffff)); out[0*64+16] = (start += zigzagdec64((w7 >> 16) & 0x1fffffff)); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w7 >> 45) | (w8 << 19) & 0x1fffffff)); out[0*64+18] = (start += zigzagdec64((w8 >> 10) & 0x1fffffff)); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w8 >> 39) | (w9 << 25) & 0x1fffffff)); out[0*64+20] = (start += zigzagdec64((w9 >> 4) & 0x1fffffff)); out[0*64+21] = (start += zigzagdec64((w9 >> 33) & 0x1fffffff)); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w9 >> 62) | (w10 << 2) & 0x1fffffff)); out[0*64+23] = (start += zigzagdec64((w10 >> 27) & 0x1fffffff)); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w10 >> 56) | (w11 << 8) & 0x1fffffff)); out[0*64+25] = (start += zigzagdec64((w11 >> 21) & 0x1fffffff)); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w11 >> 50) | (w12 << 14) & 0x1fffffff)); out[0*64+27] = (start += zigzagdec64((w12 >> 15) & 0x1fffffff)); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w12 >> 44) | (w13 << 20) & 0x1fffffff)); out[0*64+29] = (start += zigzagdec64((w13 >> 9) & 0x1fffffff)); w14 = *(uint32_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w13 >> 38) | (w14 << 26) & 0x1fffffff)); out[0*64+31] = (start += zigzagdec64((w14 >> 3) & 0x1fffffff));;}; out += 32; in += 29*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_30(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*30)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3fffffff)); out[0*32+ 1] = (start += zigzagdec64((w0 >> 30) & 0x3fffffff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += zigzagdec64((w0 >> 60) | (w1 << 4) & 0x3fffffff)); out[0*32+ 3] = (start += zigzagdec64((w1 >> 26) & 0x3fffffff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*32+ 4] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0x3fffffff)); out[0*32+ 5] = (start += zigzagdec64((w2 >> 22) & 0x3fffffff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*32+ 6] = (start += zigzagdec64((w2 >> 52) | (w3 << 12) & 0x3fffffff)); out[0*32+ 7] = (start += zigzagdec64((w3 >> 18) & 0x3fffffff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*32+ 8] = (start += zigzagdec64((w3 >> 48) | (w4 << 16) & 0x3fffffff)); out[0*32+ 9] = (start += zigzagdec64((w4 >> 14) & 0x3fffffff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*32+10] = (start += zigzagdec64((w4 >> 44) | (w5 << 20) & 0x3fffffff)); out[0*32+11] = (start += zigzagdec64((w5 >> 10) & 0x3fffffff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*32+12] = (start += zigzagdec64((w5 >> 40) | (w6 << 24) & 0x3fffffff)); out[0*32+13] = (start += zigzagdec64((w6 >> 6) & 0x3fffffff)); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*32+14] = (start += zigzagdec64((w6 >> 36) | (w7 << 28) & 0x3fffffff)); out[0*32+15] = (start += zigzagdec64((w7 >> 2) & 0x3fffffff)); out[0*32+16] = (start += zigzagdec64((w7 >> 32) & 0x3fffffff)); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*32+17] = (start += zigzagdec64((w7 >> 62) | (w8 << 2) & 0x3fffffff)); out[0*32+18] = (start += zigzagdec64((w8 >> 28) & 0x3fffffff)); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*32+19] = (start += zigzagdec64((w8 >> 58) | (w9 << 6) & 0x3fffffff)); out[0*32+20] = (start += zigzagdec64((w9 >> 24) & 0x3fffffff)); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*32+21] = (start += zigzagdec64((w9 >> 54) | (w10 << 10) & 0x3fffffff)); out[0*32+22] = (start += zigzagdec64((w10 >> 20) & 0x3fffffff)); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*32+23] = (start += zigzagdec64((w10 >> 50) | (w11 << 14) & 0x3fffffff)); out[0*32+24] = (start += zigzagdec64((w11 >> 16) & 0x3fffffff)); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*32+25] = (start += zigzagdec64((w11 >> 46) | (w12 << 18) & 0x3fffffff)); out[0*32+26] = (start += zigzagdec64((w12 >> 12) & 0x3fffffff)); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*32+27] = (start += zigzagdec64((w12 >> 42) | (w13 << 22) & 0x3fffffff)); out[0*32+28] = (start += zigzagdec64((w13 >> 8) & 0x3fffffff)); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*32+29] = (start += zigzagdec64((w13 >> 38) | (w14 << 26) & 0x3fffffff)); out[0*32+30] = (start += zigzagdec64((w14 >> 4) & 0x3fffffff)); out[0*32+31] = (start += zigzagdec64((w14 >> 34)));;}; out += 32; in += 30*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_31(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*31)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7fffffff)); out[0*64+ 1] = (start += zigzagdec64((w0 >> 31) & 0x7fffffff)); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w0 >> 62) | (w1 << 2) & 0x7fffffff)); out[0*64+ 3] = (start += zigzagdec64((w1 >> 29) & 0x7fffffff)); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w1 >> 60) | (w2 << 4) & 0x7fffffff)); out[0*64+ 5] = (start += zigzagdec64((w2 >> 27) & 0x7fffffff)); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w2 >> 58) | (w3 << 6) & 0x7fffffff)); out[0*64+ 7] = (start += zigzagdec64((w3 >> 25) & 0x7fffffff)); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w3 >> 56) | (w4 << 8) & 0x7fffffff)); out[0*64+ 9] = (start += zigzagdec64((w4 >> 23) & 0x7fffffff)); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w4 >> 54) | (w5 << 10) & 0x7fffffff)); out[0*64+11] = (start += zigzagdec64((w5 >> 21) & 0x7fffffff)); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w5 >> 52) | (w6 << 12) & 0x7fffffff)); out[0*64+13] = (start += zigzagdec64((w6 >> 19) & 0x7fffffff)); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w6 >> 50) | (w7 << 14) & 0x7fffffff)); out[0*64+15] = (start += zigzagdec64((w7 >> 17) & 0x7fffffff)); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w7 >> 48) | (w8 << 16) & 0x7fffffff)); out[0*64+17] = (start += zigzagdec64((w8 >> 15) & 0x7fffffff)); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w8 >> 46) | (w9 << 18) & 0x7fffffff)); out[0*64+19] = (start += zigzagdec64((w9 >> 13) & 0x7fffffff)); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w9 >> 44) | (w10 << 20) & 0x7fffffff)); out[0*64+21] = (start += zigzagdec64((w10 >> 11) & 0x7fffffff)); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w10 >> 42) | (w11 << 22) & 0x7fffffff)); out[0*64+23] = (start += zigzagdec64((w11 >> 9) & 0x7fffffff)); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w11 >> 40) | (w12 << 24) & 0x7fffffff)); out[0*64+25] = (start += zigzagdec64((w12 >> 7) & 0x7fffffff)); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w12 >> 38) | (w13 << 26) & 0x7fffffff)); out[0*64+27] = (start += zigzagdec64((w13 >> 5) & 0x7fffffff)); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w13 >> 36) | (w14 << 28) & 0x7fffffff)); out[0*64+29] = (start += zigzagdec64((w14 >> 3) & 0x7fffffff)); w15 = *(uint32_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w14 >> 34) | (w15 << 30) & 0x7fffffff)); out[0*64+31] = (start += zigzagdec64((w15 >> 1) & 0x7fffffff));;}; out += 32; in += 31*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_32(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*32)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[0*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+0*8+ 0))); out[0*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+0*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[1*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+1*8+ 0))); out[1*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+1*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[2*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+2*8+ 0))); out[2*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+2*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[3*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+3*8+ 0))); out[3*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+3*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[4*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+4*8+ 0))); out[4*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+4*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[5*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+5*8+ 0))); out[5*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+5*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[6*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+6*8+ 0))); out[6*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+6*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[7*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+7*8+ 0))); out[7*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+7*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[8*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+8*8+ 0))); out[8*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+8*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[9*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+9*8+ 0))); out[9*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+9*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[10*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+10*8+ 0))); out[10*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+10*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[11*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+11*8+ 0))); out[11*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+11*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[12*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+12*8+ 0))); out[12*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+12*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[13*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+13*8+ 0))); out[13*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+13*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[14*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+14*8+ 0))); out[14*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+14*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[15*2+ 0] = (start += zigzagdec64(*(uint32_t *)(in+15*8+ 0))); out[15*2+ 1] = (start += zigzagdec64(*(uint32_t *)(in+15*8+ 4)));;}; out += 32; in += 32*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_33(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*33)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16; w0 = *(uint64_t *)(in+(0*33+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1ffffffff)); w1 = *(uint64_t *)(in+(0*33+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 33) | (w1 << 31) & 0x1ffffffff)); out[0*64+ 2] = (start += zigzagdec64((w1 >> 2) & 0x1ffffffff)); w2 = *(uint64_t *)(in+(0*33+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w1 >> 35) | (w2 << 29) & 0x1ffffffff)); out[0*64+ 4] = (start += zigzagdec64((w2 >> 4) & 0x1ffffffff)); w3 = *(uint64_t *)(in+(0*33+3)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w2 >> 37) | (w3 << 27) & 0x1ffffffff)); out[0*64+ 6] = (start += zigzagdec64((w3 >> 6) & 0x1ffffffff)); w4 = *(uint64_t *)(in+(0*33+4)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w3 >> 39) | (w4 << 25) & 0x1ffffffff)); out[0*64+ 8] = (start += zigzagdec64((w4 >> 8) & 0x1ffffffff)); w5 = *(uint64_t *)(in+(0*33+5)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w4 >> 41) | (w5 << 23) & 0x1ffffffff)); out[0*64+10] = (start += zigzagdec64((w5 >> 10) & 0x1ffffffff)); w6 = *(uint64_t *)(in+(0*33+6)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w5 >> 43) | (w6 << 21) & 0x1ffffffff)); out[0*64+12] = (start += zigzagdec64((w6 >> 12) & 0x1ffffffff)); w7 = *(uint64_t *)(in+(0*33+7)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w6 >> 45) | (w7 << 19) & 0x1ffffffff)); out[0*64+14] = (start += zigzagdec64((w7 >> 14) & 0x1ffffffff)); w8 = *(uint64_t *)(in+(0*33+8)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w7 >> 47) | (w8 << 17) & 0x1ffffffff)); out[0*64+16] = (start += zigzagdec64((w8 >> 16) & 0x1ffffffff)); w9 = *(uint64_t *)(in+(0*33+9)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w8 >> 49) | (w9 << 15) & 0x1ffffffff)); out[0*64+18] = (start += zigzagdec64((w9 >> 18) & 0x1ffffffff)); w10 = *(uint64_t *)(in+(0*33+10)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w9 >> 51) | (w10 << 13) & 0x1ffffffff)); out[0*64+20] = (start += zigzagdec64((w10 >> 20) & 0x1ffffffff)); w11 = *(uint64_t *)(in+(0*33+11)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w10 >> 53) | (w11 << 11) & 0x1ffffffff)); out[0*64+22] = (start += zigzagdec64((w11 >> 22) & 0x1ffffffff)); w12 = *(uint64_t *)(in+(0*33+12)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w11 >> 55) | (w12 << 9) & 0x1ffffffff)); out[0*64+24] = (start += zigzagdec64((w12 >> 24) & 0x1ffffffff)); w13 = *(uint64_t *)(in+(0*33+13)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w12 >> 57) | (w13 << 7) & 0x1ffffffff)); out[0*64+26] = (start += zigzagdec64((w13 >> 26) & 0x1ffffffff)); w14 = *(uint64_t *)(in+(0*33+14)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w13 >> 59) | (w14 << 5) & 0x1ffffffff)); out[0*64+28] = (start += zigzagdec64((w14 >> 28) & 0x1ffffffff)); w15 = *(uint64_t *)(in+(0*33+15)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w14 >> 61) | (w15 << 3) & 0x1ffffffff)); out[0*64+30] = (start += zigzagdec64((w15 >> 30) & 0x1ffffffff)); w16 = *(uint32_t *)(in+(0*33+16)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w15 >> 63) | (w16 << 1) & 0x1ffffffff));;}; out += 32; in += 33*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_34(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*34)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3ffffffff)); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += zigzagdec64((w0 >> 34) | (w1 << 30) & 0x3ffffffff)); out[0*32+ 2] = (start += zigzagdec64((w1 >> 4) & 0x3ffffffff)); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*32+ 3] = (start += zigzagdec64((w1 >> 38) | (w2 << 26) & 0x3ffffffff)); out[0*32+ 4] = (start += zigzagdec64((w2 >> 8) & 0x3ffffffff)); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*32+ 5] = (start += zigzagdec64((w2 >> 42) | (w3 << 22) & 0x3ffffffff)); out[0*32+ 6] = (start += zigzagdec64((w3 >> 12) & 0x3ffffffff)); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*32+ 7] = (start += zigzagdec64((w3 >> 46) | (w4 << 18) & 0x3ffffffff)); out[0*32+ 8] = (start += zigzagdec64((w4 >> 16) & 0x3ffffffff)); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*32+ 9] = (start += zigzagdec64((w4 >> 50) | (w5 << 14) & 0x3ffffffff)); out[0*32+10] = (start += zigzagdec64((w5 >> 20) & 0x3ffffffff)); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*32+11] = (start += zigzagdec64((w5 >> 54) | (w6 << 10) & 0x3ffffffff)); out[0*32+12] = (start += zigzagdec64((w6 >> 24) & 0x3ffffffff)); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*32+13] = (start += zigzagdec64((w6 >> 58) | (w7 << 6) & 0x3ffffffff)); out[0*32+14] = (start += zigzagdec64((w7 >> 28) & 0x3ffffffff)); w8 = *(uint64_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*32+15] = (start += zigzagdec64((w7 >> 62) | (w8 << 2) & 0x3ffffffff)); w9 = *(uint64_t *)(in+(0*17+9)*8/sizeof(in[0])); out[0*32+16] = (start += zigzagdec64((w8 >> 32) | (w9 << 32) & 0x3ffffffff)); out[0*32+17] = (start += zigzagdec64((w9 >> 2) & 0x3ffffffff)); w10 = *(uint64_t *)(in+(0*17+10)*8/sizeof(in[0])); out[0*32+18] = (start += zigzagdec64((w9 >> 36) | (w10 << 28) & 0x3ffffffff)); out[0*32+19] = (start += zigzagdec64((w10 >> 6) & 0x3ffffffff)); w11 = *(uint64_t *)(in+(0*17+11)*8/sizeof(in[0])); out[0*32+20] = (start += zigzagdec64((w10 >> 40) | (w11 << 24) & 0x3ffffffff)); out[0*32+21] = (start += zigzagdec64((w11 >> 10) & 0x3ffffffff)); w12 = *(uint64_t *)(in+(0*17+12)*8/sizeof(in[0])); out[0*32+22] = (start += zigzagdec64((w11 >> 44) | (w12 << 20) & 0x3ffffffff)); out[0*32+23] = (start += zigzagdec64((w12 >> 14) & 0x3ffffffff)); w13 = *(uint64_t *)(in+(0*17+13)*8/sizeof(in[0])); out[0*32+24] = (start += zigzagdec64((w12 >> 48) | (w13 << 16) & 0x3ffffffff)); out[0*32+25] = (start += zigzagdec64((w13 >> 18) & 0x3ffffffff)); w14 = *(uint64_t *)(in+(0*17+14)*8/sizeof(in[0])); out[0*32+26] = (start += zigzagdec64((w13 >> 52) | (w14 << 12) & 0x3ffffffff)); out[0*32+27] = (start += zigzagdec64((w14 >> 22) & 0x3ffffffff)); w15 = *(uint64_t *)(in+(0*17+15)*8/sizeof(in[0])); out[0*32+28] = (start += zigzagdec64((w14 >> 56) | (w15 << 8) & 0x3ffffffff)); out[0*32+29] = (start += zigzagdec64((w15 >> 26) & 0x3ffffffff)); w16 = *(uint64_t *)(in+(0*17+16)*8/sizeof(in[0])); out[0*32+30] = (start += zigzagdec64((w15 >> 60) | (w16 << 4) & 0x3ffffffff)); out[0*32+31] = (start += zigzagdec64((w16 >> 30)));;}; out += 32; in += 34*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_35(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*35)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(0*35+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7ffffffff)); w1 = *(uint64_t *)(in+(0*35+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 35) | (w1 << 29) & 0x7ffffffff)); out[0*64+ 2] = (start += zigzagdec64((w1 >> 6) & 0x7ffffffff)); w2 = *(uint64_t *)(in+(0*35+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w1 >> 41) | (w2 << 23) & 0x7ffffffff)); out[0*64+ 4] = (start += zigzagdec64((w2 >> 12) & 0x7ffffffff)); w3 = *(uint64_t *)(in+(0*35+3)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w2 >> 47) | (w3 << 17) & 0x7ffffffff)); out[0*64+ 6] = (start += zigzagdec64((w3 >> 18) & 0x7ffffffff)); w4 = *(uint64_t *)(in+(0*35+4)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w3 >> 53) | (w4 << 11) & 0x7ffffffff)); out[0*64+ 8] = (start += zigzagdec64((w4 >> 24) & 0x7ffffffff)); w5 = *(uint64_t *)(in+(0*35+5)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w4 >> 59) | (w5 << 5) & 0x7ffffffff)); w6 = *(uint64_t *)(in+(0*35+6)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w5 >> 30) | (w6 << 34) & 0x7ffffffff)); out[0*64+11] = (start += zigzagdec64((w6 >> 1) & 0x7ffffffff)); w7 = *(uint64_t *)(in+(0*35+7)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w6 >> 36) | (w7 << 28) & 0x7ffffffff)); out[0*64+13] = (start += zigzagdec64((w7 >> 7) & 0x7ffffffff)); w8 = *(uint64_t *)(in+(0*35+8)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w7 >> 42) | (w8 << 22) & 0x7ffffffff)); out[0*64+15] = (start += zigzagdec64((w8 >> 13) & 0x7ffffffff)); w9 = *(uint64_t *)(in+(0*35+9)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w8 >> 48) | (w9 << 16) & 0x7ffffffff)); out[0*64+17] = (start += zigzagdec64((w9 >> 19) & 0x7ffffffff)); w10 = *(uint64_t *)(in+(0*35+10)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w9 >> 54) | (w10 << 10) & 0x7ffffffff)); out[0*64+19] = (start += zigzagdec64((w10 >> 25) & 0x7ffffffff)); w11 = *(uint64_t *)(in+(0*35+11)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w10 >> 60) | (w11 << 4) & 0x7ffffffff)); w12 = *(uint64_t *)(in+(0*35+12)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w11 >> 31) | (w12 << 33) & 0x7ffffffff)); out[0*64+22] = (start += zigzagdec64((w12 >> 2) & 0x7ffffffff)); w13 = *(uint64_t *)(in+(0*35+13)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w12 >> 37) | (w13 << 27) & 0x7ffffffff)); out[0*64+24] = (start += zigzagdec64((w13 >> 8) & 0x7ffffffff)); w14 = *(uint64_t *)(in+(0*35+14)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w13 >> 43) | (w14 << 21) & 0x7ffffffff)); out[0*64+26] = (start += zigzagdec64((w14 >> 14) & 0x7ffffffff)); w15 = *(uint64_t *)(in+(0*35+15)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w14 >> 49) | (w15 << 15) & 0x7ffffffff)); out[0*64+28] = (start += zigzagdec64((w15 >> 20) & 0x7ffffffff)); w16 = *(uint64_t *)(in+(0*35+16)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w15 >> 55) | (w16 << 9) & 0x7ffffffff)); out[0*64+30] = (start += zigzagdec64((w16 >> 26) & 0x7ffffffff)); w17 = *(uint32_t *)(in+(0*35+17)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w16 >> 61) | (w17 << 3) & 0x7ffffffff));;}; out += 32; in += 35*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_36(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*36)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec64((w0 ) & 0xfffffffff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*16+ 1] = (start += zigzagdec64((w0 >> 36) | (w1 << 28) & 0xfffffffff)); out[0*16+ 2] = (start += zigzagdec64((w1 >> 8) & 0xfffffffff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*16+ 3] = (start += zigzagdec64((w1 >> 44) | (w2 << 20) & 0xfffffffff)); out[0*16+ 4] = (start += zigzagdec64((w2 >> 16) & 0xfffffffff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*16+ 5] = (start += zigzagdec64((w2 >> 52) | (w3 << 12) & 0xfffffffff)); out[0*16+ 6] = (start += zigzagdec64((w3 >> 24) & 0xfffffffff)); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*16+ 7] = (start += zigzagdec64((w3 >> 60) | (w4 << 4) & 0xfffffffff)); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*16+ 8] = (start += zigzagdec64((w4 >> 32) | (w5 << 32) & 0xfffffffff)); out[0*16+ 9] = (start += zigzagdec64((w5 >> 4) & 0xfffffffff)); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*16+10] = (start += zigzagdec64((w5 >> 40) | (w6 << 24) & 0xfffffffff)); out[0*16+11] = (start += zigzagdec64((w6 >> 12) & 0xfffffffff)); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*16+12] = (start += zigzagdec64((w6 >> 48) | (w7 << 16) & 0xfffffffff)); out[0*16+13] = (start += zigzagdec64((w7 >> 20) & 0xfffffffff)); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*16+14] = (start += zigzagdec64((w7 >> 56) | (w8 << 8) & 0xfffffffff)); out[0*16+15] = (start += zigzagdec64((w8 >> 28)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(1*9+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec64((w0 ) & 0xfffffffff)); w1 = *(uint64_t *)(in+(1*9+1)*8/sizeof(in[0])); out[1*16+ 1] = (start += zigzagdec64((w0 >> 36) | (w1 << 28) & 0xfffffffff)); out[1*16+ 2] = (start += zigzagdec64((w1 >> 8) & 0xfffffffff)); w2 = *(uint64_t *)(in+(1*9+2)*8/sizeof(in[0])); out[1*16+ 3] = (start += zigzagdec64((w1 >> 44) | (w2 << 20) & 0xfffffffff)); out[1*16+ 4] = (start += zigzagdec64((w2 >> 16) & 0xfffffffff)); w3 = *(uint64_t *)(in+(1*9+3)*8/sizeof(in[0])); out[1*16+ 5] = (start += zigzagdec64((w2 >> 52) | (w3 << 12) & 0xfffffffff)); out[1*16+ 6] = (start += zigzagdec64((w3 >> 24) & 0xfffffffff)); w4 = *(uint64_t *)(in+(1*9+4)*8/sizeof(in[0])); out[1*16+ 7] = (start += zigzagdec64((w3 >> 60) | (w4 << 4) & 0xfffffffff)); w5 = *(uint64_t *)(in+(1*9+5)*8/sizeof(in[0])); out[1*16+ 8] = (start += zigzagdec64((w4 >> 32) | (w5 << 32) & 0xfffffffff)); out[1*16+ 9] = (start += zigzagdec64((w5 >> 4) & 0xfffffffff)); w6 = *(uint64_t *)(in+(1*9+6)*8/sizeof(in[0])); out[1*16+10] = (start += zigzagdec64((w5 >> 40) | (w6 << 24) & 0xfffffffff)); out[1*16+11] = (start += zigzagdec64((w6 >> 12) & 0xfffffffff)); w7 = *(uint64_t *)(in+(1*9+7)*8/sizeof(in[0])); out[1*16+12] = (start += zigzagdec64((w6 >> 48) | (w7 << 16) & 0xfffffffff)); out[1*16+13] = (start += zigzagdec64((w7 >> 20) & 0xfffffffff)); w8 = *(uint64_t *)(in+(1*9+8)*8/sizeof(in[0])); out[1*16+14] = (start += zigzagdec64((w7 >> 56) | (w8 << 8) & 0xfffffffff)); out[1*16+15] = (start += zigzagdec64((w8 >> 28)));;}; out += 32; in += 36*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_37(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*37)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18; w0 = *(uint64_t *)(in+(0*37+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1fffffffff)); w1 = *(uint64_t *)(in+(0*37+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 37) | (w1 << 27) & 0x1fffffffff)); out[0*64+ 2] = (start += zigzagdec64((w1 >> 10) & 0x1fffffffff)); w2 = *(uint64_t *)(in+(0*37+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w1 >> 47) | (w2 << 17) & 0x1fffffffff)); out[0*64+ 4] = (start += zigzagdec64((w2 >> 20) & 0x1fffffffff)); w3 = *(uint64_t *)(in+(0*37+3)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w2 >> 57) | (w3 << 7) & 0x1fffffffff)); w4 = *(uint64_t *)(in+(0*37+4)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w3 >> 30) | (w4 << 34) & 0x1fffffffff)); out[0*64+ 7] = (start += zigzagdec64((w4 >> 3) & 0x1fffffffff)); w5 = *(uint64_t *)(in+(0*37+5)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w4 >> 40) | (w5 << 24) & 0x1fffffffff)); out[0*64+ 9] = (start += zigzagdec64((w5 >> 13) & 0x1fffffffff)); w6 = *(uint64_t *)(in+(0*37+6)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w5 >> 50) | (w6 << 14) & 0x1fffffffff)); out[0*64+11] = (start += zigzagdec64((w6 >> 23) & 0x1fffffffff)); w7 = *(uint64_t *)(in+(0*37+7)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w6 >> 60) | (w7 << 4) & 0x1fffffffff)); w8 = *(uint64_t *)(in+(0*37+8)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w7 >> 33) | (w8 << 31) & 0x1fffffffff)); out[0*64+14] = (start += zigzagdec64((w8 >> 6) & 0x1fffffffff)); w9 = *(uint64_t *)(in+(0*37+9)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w8 >> 43) | (w9 << 21) & 0x1fffffffff)); out[0*64+16] = (start += zigzagdec64((w9 >> 16) & 0x1fffffffff)); w10 = *(uint64_t *)(in+(0*37+10)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w9 >> 53) | (w10 << 11) & 0x1fffffffff)); out[0*64+18] = (start += zigzagdec64((w10 >> 26) & 0x1fffffffff)); w11 = *(uint64_t *)(in+(0*37+11)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w10 >> 63) | (w11 << 1) & 0x1fffffffff)); w12 = *(uint64_t *)(in+(0*37+12)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w11 >> 36) | (w12 << 28) & 0x1fffffffff)); out[0*64+21] = (start += zigzagdec64((w12 >> 9) & 0x1fffffffff)); w13 = *(uint64_t *)(in+(0*37+13)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w12 >> 46) | (w13 << 18) & 0x1fffffffff)); out[0*64+23] = (start += zigzagdec64((w13 >> 19) & 0x1fffffffff)); w14 = *(uint64_t *)(in+(0*37+14)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w13 >> 56) | (w14 << 8) & 0x1fffffffff)); w15 = *(uint64_t *)(in+(0*37+15)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w14 >> 29) | (w15 << 35) & 0x1fffffffff)); out[0*64+26] = (start += zigzagdec64((w15 >> 2) & 0x1fffffffff)); w16 = *(uint64_t *)(in+(0*37+16)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w15 >> 39) | (w16 << 25) & 0x1fffffffff)); out[0*64+28] = (start += zigzagdec64((w16 >> 12) & 0x1fffffffff)); w17 = *(uint64_t *)(in+(0*37+17)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w16 >> 49) | (w17 << 15) & 0x1fffffffff)); out[0*64+30] = (start += zigzagdec64((w17 >> 22) & 0x1fffffffff)); w18 = *(uint32_t *)(in+(0*37+18)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w17 >> 59) | (w18 << 5) & 0x1fffffffff));;}; out += 32; in += 37*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_38(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*38)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3fffffffff)); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += zigzagdec64((w0 >> 38) | (w1 << 26) & 0x3fffffffff)); out[0*32+ 2] = (start += zigzagdec64((w1 >> 12) & 0x3fffffffff)); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*32+ 3] = (start += zigzagdec64((w1 >> 50) | (w2 << 14) & 0x3fffffffff)); out[0*32+ 4] = (start += zigzagdec64((w2 >> 24) & 0x3fffffffff)); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*32+ 5] = (start += zigzagdec64((w2 >> 62) | (w3 << 2) & 0x3fffffffff)); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*32+ 6] = (start += zigzagdec64((w3 >> 36) | (w4 << 28) & 0x3fffffffff)); out[0*32+ 7] = (start += zigzagdec64((w4 >> 10) & 0x3fffffffff)); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*32+ 8] = (start += zigzagdec64((w4 >> 48) | (w5 << 16) & 0x3fffffffff)); out[0*32+ 9] = (start += zigzagdec64((w5 >> 22) & 0x3fffffffff)); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*32+10] = (start += zigzagdec64((w5 >> 60) | (w6 << 4) & 0x3fffffffff)); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*32+11] = (start += zigzagdec64((w6 >> 34) | (w7 << 30) & 0x3fffffffff)); out[0*32+12] = (start += zigzagdec64((w7 >> 8) & 0x3fffffffff)); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*32+13] = (start += zigzagdec64((w7 >> 46) | (w8 << 18) & 0x3fffffffff)); out[0*32+14] = (start += zigzagdec64((w8 >> 20) & 0x3fffffffff)); w9 = *(uint64_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*32+15] = (start += zigzagdec64((w8 >> 58) | (w9 << 6) & 0x3fffffffff)); w10 = *(uint64_t *)(in+(0*19+10)*8/sizeof(in[0])); out[0*32+16] = (start += zigzagdec64((w9 >> 32) | (w10 << 32) & 0x3fffffffff)); out[0*32+17] = (start += zigzagdec64((w10 >> 6) & 0x3fffffffff)); w11 = *(uint64_t *)(in+(0*19+11)*8/sizeof(in[0])); out[0*32+18] = (start += zigzagdec64((w10 >> 44) | (w11 << 20) & 0x3fffffffff)); out[0*32+19] = (start += zigzagdec64((w11 >> 18) & 0x3fffffffff)); w12 = *(uint64_t *)(in+(0*19+12)*8/sizeof(in[0])); out[0*32+20] = (start += zigzagdec64((w11 >> 56) | (w12 << 8) & 0x3fffffffff)); w13 = *(uint64_t *)(in+(0*19+13)*8/sizeof(in[0])); out[0*32+21] = (start += zigzagdec64((w12 >> 30) | (w13 << 34) & 0x3fffffffff)); out[0*32+22] = (start += zigzagdec64((w13 >> 4) & 0x3fffffffff)); w14 = *(uint64_t *)(in+(0*19+14)*8/sizeof(in[0])); out[0*32+23] = (start += zigzagdec64((w13 >> 42) | (w14 << 22) & 0x3fffffffff)); out[0*32+24] = (start += zigzagdec64((w14 >> 16) & 0x3fffffffff)); w15 = *(uint64_t *)(in+(0*19+15)*8/sizeof(in[0])); out[0*32+25] = (start += zigzagdec64((w14 >> 54) | (w15 << 10) & 0x3fffffffff)); w16 = *(uint64_t *)(in+(0*19+16)*8/sizeof(in[0])); out[0*32+26] = (start += zigzagdec64((w15 >> 28) | (w16 << 36) & 0x3fffffffff)); out[0*32+27] = (start += zigzagdec64((w16 >> 2) & 0x3fffffffff)); w17 = *(uint64_t *)(in+(0*19+17)*8/sizeof(in[0])); out[0*32+28] = (start += zigzagdec64((w16 >> 40) | (w17 << 24) & 0x3fffffffff)); out[0*32+29] = (start += zigzagdec64((w17 >> 14) & 0x3fffffffff)); w18 = *(uint64_t *)(in+(0*19+18)*8/sizeof(in[0])); out[0*32+30] = (start += zigzagdec64((w17 >> 52) | (w18 << 12) & 0x3fffffffff)); out[0*32+31] = (start += zigzagdec64((w18 >> 26)));;}; out += 32; in += 38*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_39(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*39)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(0*39+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7fffffffff)); w1 = *(uint64_t *)(in+(0*39+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 39) | (w1 << 25) & 0x7fffffffff)); out[0*64+ 2] = (start += zigzagdec64((w1 >> 14) & 0x7fffffffff)); w2 = *(uint64_t *)(in+(0*39+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w1 >> 53) | (w2 << 11) & 0x7fffffffff)); w3 = *(uint64_t *)(in+(0*39+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w2 >> 28) | (w3 << 36) & 0x7fffffffff)); out[0*64+ 5] = (start += zigzagdec64((w3 >> 3) & 0x7fffffffff)); w4 = *(uint64_t *)(in+(0*39+4)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w3 >> 42) | (w4 << 22) & 0x7fffffffff)); out[0*64+ 7] = (start += zigzagdec64((w4 >> 17) & 0x7fffffffff)); w5 = *(uint64_t *)(in+(0*39+5)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w4 >> 56) | (w5 << 8) & 0x7fffffffff)); w6 = *(uint64_t *)(in+(0*39+6)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w5 >> 31) | (w6 << 33) & 0x7fffffffff)); out[0*64+10] = (start += zigzagdec64((w6 >> 6) & 0x7fffffffff)); w7 = *(uint64_t *)(in+(0*39+7)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w6 >> 45) | (w7 << 19) & 0x7fffffffff)); out[0*64+12] = (start += zigzagdec64((w7 >> 20) & 0x7fffffffff)); w8 = *(uint64_t *)(in+(0*39+8)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w7 >> 59) | (w8 << 5) & 0x7fffffffff)); w9 = *(uint64_t *)(in+(0*39+9)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w8 >> 34) | (w9 << 30) & 0x7fffffffff)); out[0*64+15] = (start += zigzagdec64((w9 >> 9) & 0x7fffffffff)); w10 = *(uint64_t *)(in+(0*39+10)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w9 >> 48) | (w10 << 16) & 0x7fffffffff)); out[0*64+17] = (start += zigzagdec64((w10 >> 23) & 0x7fffffffff)); w11 = *(uint64_t *)(in+(0*39+11)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w10 >> 62) | (w11 << 2) & 0x7fffffffff)); w12 = *(uint64_t *)(in+(0*39+12)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w11 >> 37) | (w12 << 27) & 0x7fffffffff)); out[0*64+20] = (start += zigzagdec64((w12 >> 12) & 0x7fffffffff)); w13 = *(uint64_t *)(in+(0*39+13)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w12 >> 51) | (w13 << 13) & 0x7fffffffff)); w14 = *(uint64_t *)(in+(0*39+14)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w13 >> 26) | (w14 << 38) & 0x7fffffffff)); out[0*64+23] = (start += zigzagdec64((w14 >> 1) & 0x7fffffffff)); w15 = *(uint64_t *)(in+(0*39+15)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w14 >> 40) | (w15 << 24) & 0x7fffffffff)); out[0*64+25] = (start += zigzagdec64((w15 >> 15) & 0x7fffffffff)); w16 = *(uint64_t *)(in+(0*39+16)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w15 >> 54) | (w16 << 10) & 0x7fffffffff)); w17 = *(uint64_t *)(in+(0*39+17)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w16 >> 29) | (w17 << 35) & 0x7fffffffff)); out[0*64+28] = (start += zigzagdec64((w17 >> 4) & 0x7fffffffff)); w18 = *(uint64_t *)(in+(0*39+18)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w17 >> 43) | (w18 << 21) & 0x7fffffffff)); out[0*64+30] = (start += zigzagdec64((w18 >> 18) & 0x7fffffffff)); w19 = *(uint32_t *)(in+(0*39+19)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w18 >> 57) | (w19 << 7) & 0x7fffffffff));;}; out += 32; in += 39*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_40(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*40)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*8+ 1] = (start += zigzagdec64((w0 >> 40) | (w1 << 24) & 0xffffffffff)); out[0*8+ 2] = (start += zigzagdec64((w1 >> 16) & 0xffffffffff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*8+ 3] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0xffffffffff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*8+ 4] = (start += zigzagdec64((w2 >> 32) | (w3 << 32) & 0xffffffffff)); out[0*8+ 5] = (start += zigzagdec64((w3 >> 8) & 0xffffffffff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*8+ 6] = (start += zigzagdec64((w3 >> 48) | (w4 << 16) & 0xffffffffff)); out[0*8+ 7] = (start += zigzagdec64((w4 >> 24)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffff)); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*8+ 1] = (start += zigzagdec64((w0 >> 40) | (w1 << 24) & 0xffffffffff)); out[1*8+ 2] = (start += zigzagdec64((w1 >> 16) & 0xffffffffff)); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*8+ 3] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0xffffffffff)); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*8+ 4] = (start += zigzagdec64((w2 >> 32) | (w3 << 32) & 0xffffffffff)); out[1*8+ 5] = (start += zigzagdec64((w3 >> 8) & 0xffffffffff)); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*8+ 6] = (start += zigzagdec64((w3 >> 48) | (w4 << 16) & 0xffffffffff)); out[1*8+ 7] = (start += zigzagdec64((w4 >> 24)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(2*5+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffff)); w1 = *(uint64_t *)(in+(2*5+1)*8/sizeof(in[0])); out[2*8+ 1] = (start += zigzagdec64((w0 >> 40) | (w1 << 24) & 0xffffffffff)); out[2*8+ 2] = (start += zigzagdec64((w1 >> 16) & 0xffffffffff)); w2 = *(uint64_t *)(in+(2*5+2)*8/sizeof(in[0])); out[2*8+ 3] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0xffffffffff)); w3 = *(uint64_t *)(in+(2*5+3)*8/sizeof(in[0])); out[2*8+ 4] = (start += zigzagdec64((w2 >> 32) | (w3 << 32) & 0xffffffffff)); out[2*8+ 5] = (start += zigzagdec64((w3 >> 8) & 0xffffffffff)); w4 = *(uint64_t *)(in+(2*5+4)*8/sizeof(in[0])); out[2*8+ 6] = (start += zigzagdec64((w3 >> 48) | (w4 << 16) & 0xffffffffff)); out[2*8+ 7] = (start += zigzagdec64((w4 >> 24)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(3*5+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffff)); w1 = *(uint64_t *)(in+(3*5+1)*8/sizeof(in[0])); out[3*8+ 1] = (start += zigzagdec64((w0 >> 40) | (w1 << 24) & 0xffffffffff)); out[3*8+ 2] = (start += zigzagdec64((w1 >> 16) & 0xffffffffff)); w2 = *(uint64_t *)(in+(3*5+2)*8/sizeof(in[0])); out[3*8+ 3] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0xffffffffff)); w3 = *(uint64_t *)(in+(3*5+3)*8/sizeof(in[0])); out[3*8+ 4] = (start += zigzagdec64((w2 >> 32) | (w3 << 32) & 0xffffffffff)); out[3*8+ 5] = (start += zigzagdec64((w3 >> 8) & 0xffffffffff)); w4 = *(uint64_t *)(in+(3*5+4)*8/sizeof(in[0])); out[3*8+ 6] = (start += zigzagdec64((w3 >> 48) | (w4 << 16) & 0xffffffffff)); out[3*8+ 7] = (start += zigzagdec64((w4 >> 24)));;}; out += 32; in += 40*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_41(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*41)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20; w0 = *(uint64_t *)(in+(0*41+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1ffffffffff)); w1 = *(uint64_t *)(in+(0*41+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 41) | (w1 << 23) & 0x1ffffffffff)); out[0*64+ 2] = (start += zigzagdec64((w1 >> 18) & 0x1ffffffffff)); w2 = *(uint64_t *)(in+(0*41+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w1 >> 59) | (w2 << 5) & 0x1ffffffffff)); w3 = *(uint64_t *)(in+(0*41+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w2 >> 36) | (w3 << 28) & 0x1ffffffffff)); out[0*64+ 5] = (start += zigzagdec64((w3 >> 13) & 0x1ffffffffff)); w4 = *(uint64_t *)(in+(0*41+4)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w3 >> 54) | (w4 << 10) & 0x1ffffffffff)); w5 = *(uint64_t *)(in+(0*41+5)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w4 >> 31) | (w5 << 33) & 0x1ffffffffff)); out[0*64+ 8] = (start += zigzagdec64((w5 >> 8) & 0x1ffffffffff)); w6 = *(uint64_t *)(in+(0*41+6)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w5 >> 49) | (w6 << 15) & 0x1ffffffffff)); w7 = *(uint64_t *)(in+(0*41+7)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w6 >> 26) | (w7 << 38) & 0x1ffffffffff)); out[0*64+11] = (start += zigzagdec64((w7 >> 3) & 0x1ffffffffff)); w8 = *(uint64_t *)(in+(0*41+8)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w7 >> 44) | (w8 << 20) & 0x1ffffffffff)); out[0*64+13] = (start += zigzagdec64((w8 >> 21) & 0x1ffffffffff)); w9 = *(uint64_t *)(in+(0*41+9)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w8 >> 62) | (w9 << 2) & 0x1ffffffffff)); w10 = *(uint64_t *)(in+(0*41+10)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w9 >> 39) | (w10 << 25) & 0x1ffffffffff)); out[0*64+16] = (start += zigzagdec64((w10 >> 16) & 0x1ffffffffff)); w11 = *(uint64_t *)(in+(0*41+11)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w10 >> 57) | (w11 << 7) & 0x1ffffffffff)); w12 = *(uint64_t *)(in+(0*41+12)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w11 >> 34) | (w12 << 30) & 0x1ffffffffff)); out[0*64+19] = (start += zigzagdec64((w12 >> 11) & 0x1ffffffffff)); w13 = *(uint64_t *)(in+(0*41+13)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w12 >> 52) | (w13 << 12) & 0x1ffffffffff)); w14 = *(uint64_t *)(in+(0*41+14)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w13 >> 29) | (w14 << 35) & 0x1ffffffffff)); out[0*64+22] = (start += zigzagdec64((w14 >> 6) & 0x1ffffffffff)); w15 = *(uint64_t *)(in+(0*41+15)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w14 >> 47) | (w15 << 17) & 0x1ffffffffff)); w16 = *(uint64_t *)(in+(0*41+16)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w15 >> 24) | (w16 << 40) & 0x1ffffffffff)); out[0*64+25] = (start += zigzagdec64((w16 >> 1) & 0x1ffffffffff)); w17 = *(uint64_t *)(in+(0*41+17)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w16 >> 42) | (w17 << 22) & 0x1ffffffffff)); out[0*64+27] = (start += zigzagdec64((w17 >> 19) & 0x1ffffffffff)); w18 = *(uint64_t *)(in+(0*41+18)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w17 >> 60) | (w18 << 4) & 0x1ffffffffff)); w19 = *(uint64_t *)(in+(0*41+19)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w18 >> 37) | (w19 << 27) & 0x1ffffffffff)); out[0*64+30] = (start += zigzagdec64((w19 >> 14) & 0x1ffffffffff)); w20 = *(uint32_t *)(in+(0*41+20)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w19 >> 55) | (w20 << 9) & 0x1ffffffffff));;}; out += 32; in += 41*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_42(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*42)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3ffffffffff)); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += zigzagdec64((w0 >> 42) | (w1 << 22) & 0x3ffffffffff)); out[0*32+ 2] = (start += zigzagdec64((w1 >> 20) & 0x3ffffffffff)); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*32+ 3] = (start += zigzagdec64((w1 >> 62) | (w2 << 2) & 0x3ffffffffff)); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*32+ 4] = (start += zigzagdec64((w2 >> 40) | (w3 << 24) & 0x3ffffffffff)); out[0*32+ 5] = (start += zigzagdec64((w3 >> 18) & 0x3ffffffffff)); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*32+ 6] = (start += zigzagdec64((w3 >> 60) | (w4 << 4) & 0x3ffffffffff)); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*32+ 7] = (start += zigzagdec64((w4 >> 38) | (w5 << 26) & 0x3ffffffffff)); out[0*32+ 8] = (start += zigzagdec64((w5 >> 16) & 0x3ffffffffff)); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*32+ 9] = (start += zigzagdec64((w5 >> 58) | (w6 << 6) & 0x3ffffffffff)); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*32+10] = (start += zigzagdec64((w6 >> 36) | (w7 << 28) & 0x3ffffffffff)); out[0*32+11] = (start += zigzagdec64((w7 >> 14) & 0x3ffffffffff)); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*32+12] = (start += zigzagdec64((w7 >> 56) | (w8 << 8) & 0x3ffffffffff)); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*32+13] = (start += zigzagdec64((w8 >> 34) | (w9 << 30) & 0x3ffffffffff)); out[0*32+14] = (start += zigzagdec64((w9 >> 12) & 0x3ffffffffff)); w10 = *(uint64_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*32+15] = (start += zigzagdec64((w9 >> 54) | (w10 << 10) & 0x3ffffffffff)); w11 = *(uint64_t *)(in+(0*21+11)*8/sizeof(in[0])); out[0*32+16] = (start += zigzagdec64((w10 >> 32) | (w11 << 32) & 0x3ffffffffff)); out[0*32+17] = (start += zigzagdec64((w11 >> 10) & 0x3ffffffffff)); w12 = *(uint64_t *)(in+(0*21+12)*8/sizeof(in[0])); out[0*32+18] = (start += zigzagdec64((w11 >> 52) | (w12 << 12) & 0x3ffffffffff)); w13 = *(uint64_t *)(in+(0*21+13)*8/sizeof(in[0])); out[0*32+19] = (start += zigzagdec64((w12 >> 30) | (w13 << 34) & 0x3ffffffffff)); out[0*32+20] = (start += zigzagdec64((w13 >> 8) & 0x3ffffffffff)); w14 = *(uint64_t *)(in+(0*21+14)*8/sizeof(in[0])); out[0*32+21] = (start += zigzagdec64((w13 >> 50) | (w14 << 14) & 0x3ffffffffff)); w15 = *(uint64_t *)(in+(0*21+15)*8/sizeof(in[0])); out[0*32+22] = (start += zigzagdec64((w14 >> 28) | (w15 << 36) & 0x3ffffffffff)); out[0*32+23] = (start += zigzagdec64((w15 >> 6) & 0x3ffffffffff)); w16 = *(uint64_t *)(in+(0*21+16)*8/sizeof(in[0])); out[0*32+24] = (start += zigzagdec64((w15 >> 48) | (w16 << 16) & 0x3ffffffffff)); w17 = *(uint64_t *)(in+(0*21+17)*8/sizeof(in[0])); out[0*32+25] = (start += zigzagdec64((w16 >> 26) | (w17 << 38) & 0x3ffffffffff)); out[0*32+26] = (start += zigzagdec64((w17 >> 4) & 0x3ffffffffff)); w18 = *(uint64_t *)(in+(0*21+18)*8/sizeof(in[0])); out[0*32+27] = (start += zigzagdec64((w17 >> 46) | (w18 << 18) & 0x3ffffffffff)); w19 = *(uint64_t *)(in+(0*21+19)*8/sizeof(in[0])); out[0*32+28] = (start += zigzagdec64((w18 >> 24) | (w19 << 40) & 0x3ffffffffff)); out[0*32+29] = (start += zigzagdec64((w19 >> 2) & 0x3ffffffffff)); w20 = *(uint64_t *)(in+(0*21+20)*8/sizeof(in[0])); out[0*32+30] = (start += zigzagdec64((w19 >> 44) | (w20 << 20) & 0x3ffffffffff)); out[0*32+31] = (start += zigzagdec64((w20 >> 22)));;}; out += 32; in += 42*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_43(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*43)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(0*43+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7ffffffffff)); w1 = *(uint64_t *)(in+(0*43+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 43) | (w1 << 21) & 0x7ffffffffff)); w2 = *(uint64_t *)(in+(0*43+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w1 >> 22) | (w2 << 42) & 0x7ffffffffff)); out[0*64+ 3] = (start += zigzagdec64((w2 >> 1) & 0x7ffffffffff)); w3 = *(uint64_t *)(in+(0*43+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w2 >> 44) | (w3 << 20) & 0x7ffffffffff)); w4 = *(uint64_t *)(in+(0*43+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w3 >> 23) | (w4 << 41) & 0x7ffffffffff)); out[0*64+ 6] = (start += zigzagdec64((w4 >> 2) & 0x7ffffffffff)); w5 = *(uint64_t *)(in+(0*43+5)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w4 >> 45) | (w5 << 19) & 0x7ffffffffff)); w6 = *(uint64_t *)(in+(0*43+6)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w5 >> 24) | (w6 << 40) & 0x7ffffffffff)); out[0*64+ 9] = (start += zigzagdec64((w6 >> 3) & 0x7ffffffffff)); w7 = *(uint64_t *)(in+(0*43+7)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w6 >> 46) | (w7 << 18) & 0x7ffffffffff)); w8 = *(uint64_t *)(in+(0*43+8)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w7 >> 25) | (w8 << 39) & 0x7ffffffffff)); out[0*64+12] = (start += zigzagdec64((w8 >> 4) & 0x7ffffffffff)); w9 = *(uint64_t *)(in+(0*43+9)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w8 >> 47) | (w9 << 17) & 0x7ffffffffff)); w10 = *(uint64_t *)(in+(0*43+10)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w9 >> 26) | (w10 << 38) & 0x7ffffffffff)); out[0*64+15] = (start += zigzagdec64((w10 >> 5) & 0x7ffffffffff)); w11 = *(uint64_t *)(in+(0*43+11)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w10 >> 48) | (w11 << 16) & 0x7ffffffffff)); w12 = *(uint64_t *)(in+(0*43+12)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w11 >> 27) | (w12 << 37) & 0x7ffffffffff)); out[0*64+18] = (start += zigzagdec64((w12 >> 6) & 0x7ffffffffff)); w13 = *(uint64_t *)(in+(0*43+13)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w12 >> 49) | (w13 << 15) & 0x7ffffffffff)); w14 = *(uint64_t *)(in+(0*43+14)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w13 >> 28) | (w14 << 36) & 0x7ffffffffff)); out[0*64+21] = (start += zigzagdec64((w14 >> 7) & 0x7ffffffffff)); w15 = *(uint64_t *)(in+(0*43+15)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w14 >> 50) | (w15 << 14) & 0x7ffffffffff)); w16 = *(uint64_t *)(in+(0*43+16)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w15 >> 29) | (w16 << 35) & 0x7ffffffffff)); out[0*64+24] = (start += zigzagdec64((w16 >> 8) & 0x7ffffffffff)); w17 = *(uint64_t *)(in+(0*43+17)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w16 >> 51) | (w17 << 13) & 0x7ffffffffff)); w18 = *(uint64_t *)(in+(0*43+18)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w17 >> 30) | (w18 << 34) & 0x7ffffffffff)); out[0*64+27] = (start += zigzagdec64((w18 >> 9) & 0x7ffffffffff)); w19 = *(uint64_t *)(in+(0*43+19)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w18 >> 52) | (w19 << 12) & 0x7ffffffffff)); w20 = *(uint64_t *)(in+(0*43+20)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w19 >> 31) | (w20 << 33) & 0x7ffffffffff)); out[0*64+30] = (start += zigzagdec64((w20 >> 10) & 0x7ffffffffff)); w21 = *(uint32_t *)(in+(0*43+21)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w20 >> 53) | (w21 << 11) & 0x7ffffffffff));;}; out += 32; in += 43*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_44(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*44)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec64((w0 ) & 0xfffffffffff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*16+ 1] = (start += zigzagdec64((w0 >> 44) | (w1 << 20) & 0xfffffffffff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*16+ 2] = (start += zigzagdec64((w1 >> 24) | (w2 << 40) & 0xfffffffffff)); out[0*16+ 3] = (start += zigzagdec64((w2 >> 4) & 0xfffffffffff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*16+ 4] = (start += zigzagdec64((w2 >> 48) | (w3 << 16) & 0xfffffffffff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*16+ 5] = (start += zigzagdec64((w3 >> 28) | (w4 << 36) & 0xfffffffffff)); out[0*16+ 6] = (start += zigzagdec64((w4 >> 8) & 0xfffffffffff)); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*16+ 7] = (start += zigzagdec64((w4 >> 52) | (w5 << 12) & 0xfffffffffff)); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*16+ 8] = (start += zigzagdec64((w5 >> 32) | (w6 << 32) & 0xfffffffffff)); out[0*16+ 9] = (start += zigzagdec64((w6 >> 12) & 0xfffffffffff)); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*16+10] = (start += zigzagdec64((w6 >> 56) | (w7 << 8) & 0xfffffffffff)); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*16+11] = (start += zigzagdec64((w7 >> 36) | (w8 << 28) & 0xfffffffffff)); out[0*16+12] = (start += zigzagdec64((w8 >> 16) & 0xfffffffffff)); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*16+13] = (start += zigzagdec64((w8 >> 60) | (w9 << 4) & 0xfffffffffff)); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*16+14] = (start += zigzagdec64((w9 >> 40) | (w10 << 24) & 0xfffffffffff)); out[0*16+15] = (start += zigzagdec64((w10 >> 20)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(1*11+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec64((w0 ) & 0xfffffffffff)); w1 = *(uint64_t *)(in+(1*11+1)*8/sizeof(in[0])); out[1*16+ 1] = (start += zigzagdec64((w0 >> 44) | (w1 << 20) & 0xfffffffffff)); w2 = *(uint64_t *)(in+(1*11+2)*8/sizeof(in[0])); out[1*16+ 2] = (start += zigzagdec64((w1 >> 24) | (w2 << 40) & 0xfffffffffff)); out[1*16+ 3] = (start += zigzagdec64((w2 >> 4) & 0xfffffffffff)); w3 = *(uint64_t *)(in+(1*11+3)*8/sizeof(in[0])); out[1*16+ 4] = (start += zigzagdec64((w2 >> 48) | (w3 << 16) & 0xfffffffffff)); w4 = *(uint64_t *)(in+(1*11+4)*8/sizeof(in[0])); out[1*16+ 5] = (start += zigzagdec64((w3 >> 28) | (w4 << 36) & 0xfffffffffff)); out[1*16+ 6] = (start += zigzagdec64((w4 >> 8) & 0xfffffffffff)); w5 = *(uint64_t *)(in+(1*11+5)*8/sizeof(in[0])); out[1*16+ 7] = (start += zigzagdec64((w4 >> 52) | (w5 << 12) & 0xfffffffffff)); w6 = *(uint64_t *)(in+(1*11+6)*8/sizeof(in[0])); out[1*16+ 8] = (start += zigzagdec64((w5 >> 32) | (w6 << 32) & 0xfffffffffff)); out[1*16+ 9] = (start += zigzagdec64((w6 >> 12) & 0xfffffffffff)); w7 = *(uint64_t *)(in+(1*11+7)*8/sizeof(in[0])); out[1*16+10] = (start += zigzagdec64((w6 >> 56) | (w7 << 8) & 0xfffffffffff)); w8 = *(uint64_t *)(in+(1*11+8)*8/sizeof(in[0])); out[1*16+11] = (start += zigzagdec64((w7 >> 36) | (w8 << 28) & 0xfffffffffff)); out[1*16+12] = (start += zigzagdec64((w8 >> 16) & 0xfffffffffff)); w9 = *(uint64_t *)(in+(1*11+9)*8/sizeof(in[0])); out[1*16+13] = (start += zigzagdec64((w8 >> 60) | (w9 << 4) & 0xfffffffffff)); w10 = *(uint64_t *)(in+(1*11+10)*8/sizeof(in[0])); out[1*16+14] = (start += zigzagdec64((w9 >> 40) | (w10 << 24) & 0xfffffffffff)); out[1*16+15] = (start += zigzagdec64((w10 >> 20)));;}; out += 32; in += 44*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_45(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*45)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22; w0 = *(uint64_t *)(in+(0*45+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1fffffffffff)); w1 = *(uint64_t *)(in+(0*45+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 45) | (w1 << 19) & 0x1fffffffffff)); w2 = *(uint64_t *)(in+(0*45+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w1 >> 26) | (w2 << 38) & 0x1fffffffffff)); out[0*64+ 3] = (start += zigzagdec64((w2 >> 7) & 0x1fffffffffff)); w3 = *(uint64_t *)(in+(0*45+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w2 >> 52) | (w3 << 12) & 0x1fffffffffff)); w4 = *(uint64_t *)(in+(0*45+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w3 >> 33) | (w4 << 31) & 0x1fffffffffff)); out[0*64+ 6] = (start += zigzagdec64((w4 >> 14) & 0x1fffffffffff)); w5 = *(uint64_t *)(in+(0*45+5)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w4 >> 59) | (w5 << 5) & 0x1fffffffffff)); w6 = *(uint64_t *)(in+(0*45+6)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w5 >> 40) | (w6 << 24) & 0x1fffffffffff)); w7 = *(uint64_t *)(in+(0*45+7)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w6 >> 21) | (w7 << 43) & 0x1fffffffffff)); out[0*64+10] = (start += zigzagdec64((w7 >> 2) & 0x1fffffffffff)); w8 = *(uint64_t *)(in+(0*45+8)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w7 >> 47) | (w8 << 17) & 0x1fffffffffff)); w9 = *(uint64_t *)(in+(0*45+9)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w8 >> 28) | (w9 << 36) & 0x1fffffffffff)); out[0*64+13] = (start += zigzagdec64((w9 >> 9) & 0x1fffffffffff)); w10 = *(uint64_t *)(in+(0*45+10)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w9 >> 54) | (w10 << 10) & 0x1fffffffffff)); w11 = *(uint64_t *)(in+(0*45+11)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w10 >> 35) | (w11 << 29) & 0x1fffffffffff)); out[0*64+16] = (start += zigzagdec64((w11 >> 16) & 0x1fffffffffff)); w12 = *(uint64_t *)(in+(0*45+12)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w11 >> 61) | (w12 << 3) & 0x1fffffffffff)); w13 = *(uint64_t *)(in+(0*45+13)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w12 >> 42) | (w13 << 22) & 0x1fffffffffff)); w14 = *(uint64_t *)(in+(0*45+14)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w13 >> 23) | (w14 << 41) & 0x1fffffffffff)); out[0*64+20] = (start += zigzagdec64((w14 >> 4) & 0x1fffffffffff)); w15 = *(uint64_t *)(in+(0*45+15)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w14 >> 49) | (w15 << 15) & 0x1fffffffffff)); w16 = *(uint64_t *)(in+(0*45+16)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w15 >> 30) | (w16 << 34) & 0x1fffffffffff)); out[0*64+23] = (start += zigzagdec64((w16 >> 11) & 0x1fffffffffff)); w17 = *(uint64_t *)(in+(0*45+17)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w16 >> 56) | (w17 << 8) & 0x1fffffffffff)); w18 = *(uint64_t *)(in+(0*45+18)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w17 >> 37) | (w18 << 27) & 0x1fffffffffff)); out[0*64+26] = (start += zigzagdec64((w18 >> 18) & 0x1fffffffffff)); w19 = *(uint64_t *)(in+(0*45+19)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w18 >> 63) | (w19 << 1) & 0x1fffffffffff)); w20 = *(uint64_t *)(in+(0*45+20)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w19 >> 44) | (w20 << 20) & 0x1fffffffffff)); w21 = *(uint64_t *)(in+(0*45+21)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w20 >> 25) | (w21 << 39) & 0x1fffffffffff)); out[0*64+30] = (start += zigzagdec64((w21 >> 6) & 0x1fffffffffff)); w22 = *(uint32_t *)(in+(0*45+22)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w21 >> 51) | (w22 << 13) & 0x1fffffffffff));;}; out += 32; in += 45*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_46(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*46)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3fffffffffff)); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += zigzagdec64((w0 >> 46) | (w1 << 18) & 0x3fffffffffff)); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += zigzagdec64((w1 >> 28) | (w2 << 36) & 0x3fffffffffff)); out[0*32+ 3] = (start += zigzagdec64((w2 >> 10) & 0x3fffffffffff)); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*32+ 4] = (start += zigzagdec64((w2 >> 56) | (w3 << 8) & 0x3fffffffffff)); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*32+ 5] = (start += zigzagdec64((w3 >> 38) | (w4 << 26) & 0x3fffffffffff)); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*32+ 6] = (start += zigzagdec64((w4 >> 20) | (w5 << 44) & 0x3fffffffffff)); out[0*32+ 7] = (start += zigzagdec64((w5 >> 2) & 0x3fffffffffff)); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*32+ 8] = (start += zigzagdec64((w5 >> 48) | (w6 << 16) & 0x3fffffffffff)); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*32+ 9] = (start += zigzagdec64((w6 >> 30) | (w7 << 34) & 0x3fffffffffff)); out[0*32+10] = (start += zigzagdec64((w7 >> 12) & 0x3fffffffffff)); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*32+11] = (start += zigzagdec64((w7 >> 58) | (w8 << 6) & 0x3fffffffffff)); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*32+12] = (start += zigzagdec64((w8 >> 40) | (w9 << 24) & 0x3fffffffffff)); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*32+13] = (start += zigzagdec64((w9 >> 22) | (w10 << 42) & 0x3fffffffffff)); out[0*32+14] = (start += zigzagdec64((w10 >> 4) & 0x3fffffffffff)); w11 = *(uint64_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*32+15] = (start += zigzagdec64((w10 >> 50) | (w11 << 14) & 0x3fffffffffff)); w12 = *(uint64_t *)(in+(0*23+12)*8/sizeof(in[0])); out[0*32+16] = (start += zigzagdec64((w11 >> 32) | (w12 << 32) & 0x3fffffffffff)); out[0*32+17] = (start += zigzagdec64((w12 >> 14) & 0x3fffffffffff)); w13 = *(uint64_t *)(in+(0*23+13)*8/sizeof(in[0])); out[0*32+18] = (start += zigzagdec64((w12 >> 60) | (w13 << 4) & 0x3fffffffffff)); w14 = *(uint64_t *)(in+(0*23+14)*8/sizeof(in[0])); out[0*32+19] = (start += zigzagdec64((w13 >> 42) | (w14 << 22) & 0x3fffffffffff)); w15 = *(uint64_t *)(in+(0*23+15)*8/sizeof(in[0])); out[0*32+20] = (start += zigzagdec64((w14 >> 24) | (w15 << 40) & 0x3fffffffffff)); out[0*32+21] = (start += zigzagdec64((w15 >> 6) & 0x3fffffffffff)); w16 = *(uint64_t *)(in+(0*23+16)*8/sizeof(in[0])); out[0*32+22] = (start += zigzagdec64((w15 >> 52) | (w16 << 12) & 0x3fffffffffff)); w17 = *(uint64_t *)(in+(0*23+17)*8/sizeof(in[0])); out[0*32+23] = (start += zigzagdec64((w16 >> 34) | (w17 << 30) & 0x3fffffffffff)); out[0*32+24] = (start += zigzagdec64((w17 >> 16) & 0x3fffffffffff)); w18 = *(uint64_t *)(in+(0*23+18)*8/sizeof(in[0])); out[0*32+25] = (start += zigzagdec64((w17 >> 62) | (w18 << 2) & 0x3fffffffffff)); w19 = *(uint64_t *)(in+(0*23+19)*8/sizeof(in[0])); out[0*32+26] = (start += zigzagdec64((w18 >> 44) | (w19 << 20) & 0x3fffffffffff)); w20 = *(uint64_t *)(in+(0*23+20)*8/sizeof(in[0])); out[0*32+27] = (start += zigzagdec64((w19 >> 26) | (w20 << 38) & 0x3fffffffffff)); out[0*32+28] = (start += zigzagdec64((w20 >> 8) & 0x3fffffffffff)); w21 = *(uint64_t *)(in+(0*23+21)*8/sizeof(in[0])); out[0*32+29] = (start += zigzagdec64((w20 >> 54) | (w21 << 10) & 0x3fffffffffff)); w22 = *(uint64_t *)(in+(0*23+22)*8/sizeof(in[0])); out[0*32+30] = (start += zigzagdec64((w21 >> 36) | (w22 << 28) & 0x3fffffffffff)); out[0*32+31] = (start += zigzagdec64((w22 >> 18)));;}; out += 32; in += 46*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_47(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*47)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(0*47+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7fffffffffff)); w1 = *(uint64_t *)(in+(0*47+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 47) | (w1 << 17) & 0x7fffffffffff)); w2 = *(uint64_t *)(in+(0*47+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w1 >> 30) | (w2 << 34) & 0x7fffffffffff)); out[0*64+ 3] = (start += zigzagdec64((w2 >> 13) & 0x7fffffffffff)); w3 = *(uint64_t *)(in+(0*47+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w2 >> 60) | (w3 << 4) & 0x7fffffffffff)); w4 = *(uint64_t *)(in+(0*47+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w3 >> 43) | (w4 << 21) & 0x7fffffffffff)); w5 = *(uint64_t *)(in+(0*47+5)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w4 >> 26) | (w5 << 38) & 0x7fffffffffff)); out[0*64+ 7] = (start += zigzagdec64((w5 >> 9) & 0x7fffffffffff)); w6 = *(uint64_t *)(in+(0*47+6)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w5 >> 56) | (w6 << 8) & 0x7fffffffffff)); w7 = *(uint64_t *)(in+(0*47+7)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w6 >> 39) | (w7 << 25) & 0x7fffffffffff)); w8 = *(uint64_t *)(in+(0*47+8)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w7 >> 22) | (w8 << 42) & 0x7fffffffffff)); out[0*64+11] = (start += zigzagdec64((w8 >> 5) & 0x7fffffffffff)); w9 = *(uint64_t *)(in+(0*47+9)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w8 >> 52) | (w9 << 12) & 0x7fffffffffff)); w10 = *(uint64_t *)(in+(0*47+10)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w9 >> 35) | (w10 << 29) & 0x7fffffffffff)); w11 = *(uint64_t *)(in+(0*47+11)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w10 >> 18) | (w11 << 46) & 0x7fffffffffff)); out[0*64+15] = (start += zigzagdec64((w11 >> 1) & 0x7fffffffffff)); w12 = *(uint64_t *)(in+(0*47+12)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w11 >> 48) | (w12 << 16) & 0x7fffffffffff)); w13 = *(uint64_t *)(in+(0*47+13)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w12 >> 31) | (w13 << 33) & 0x7fffffffffff)); out[0*64+18] = (start += zigzagdec64((w13 >> 14) & 0x7fffffffffff)); w14 = *(uint64_t *)(in+(0*47+14)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w13 >> 61) | (w14 << 3) & 0x7fffffffffff)); w15 = *(uint64_t *)(in+(0*47+15)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w14 >> 44) | (w15 << 20) & 0x7fffffffffff)); w16 = *(uint64_t *)(in+(0*47+16)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w15 >> 27) | (w16 << 37) & 0x7fffffffffff)); out[0*64+22] = (start += zigzagdec64((w16 >> 10) & 0x7fffffffffff)); w17 = *(uint64_t *)(in+(0*47+17)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w16 >> 57) | (w17 << 7) & 0x7fffffffffff)); w18 = *(uint64_t *)(in+(0*47+18)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w17 >> 40) | (w18 << 24) & 0x7fffffffffff)); w19 = *(uint64_t *)(in+(0*47+19)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w18 >> 23) | (w19 << 41) & 0x7fffffffffff)); out[0*64+26] = (start += zigzagdec64((w19 >> 6) & 0x7fffffffffff)); w20 = *(uint64_t *)(in+(0*47+20)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w19 >> 53) | (w20 << 11) & 0x7fffffffffff)); w21 = *(uint64_t *)(in+(0*47+21)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w20 >> 36) | (w21 << 28) & 0x7fffffffffff)); w22 = *(uint64_t *)(in+(0*47+22)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w21 >> 19) | (w22 << 45) & 0x7fffffffffff)); out[0*64+30] = (start += zigzagdec64((w22 >> 2) & 0x7fffffffffff)); w23 = *(uint32_t *)(in+(0*47+23)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w22 >> 49) | (w23 << 15) & 0x7fffffffffff));;}; out += 32; in += 47*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_48(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*48)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*4+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*4+ 1] = (start += zigzagdec64((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*4+ 2] = (start += zigzagdec64((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[0*4+ 3] = (start += zigzagdec64((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*4+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*4+ 1] = (start += zigzagdec64((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*4+ 2] = (start += zigzagdec64((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[1*4+ 3] = (start += zigzagdec64((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*4+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*4+ 1] = (start += zigzagdec64((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*4+ 2] = (start += zigzagdec64((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[2*4+ 3] = (start += zigzagdec64((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*4+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*4+ 1] = (start += zigzagdec64((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*4+ 2] = (start += zigzagdec64((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[3*4+ 3] = (start += zigzagdec64((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(4*3+0)*8/sizeof(in[0])); out[4*4+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(4*3+1)*8/sizeof(in[0])); out[4*4+ 1] = (start += zigzagdec64((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(4*3+2)*8/sizeof(in[0])); out[4*4+ 2] = (start += zigzagdec64((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[4*4+ 3] = (start += zigzagdec64((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(5*3+0)*8/sizeof(in[0])); out[5*4+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(5*3+1)*8/sizeof(in[0])); out[5*4+ 1] = (start += zigzagdec64((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(5*3+2)*8/sizeof(in[0])); out[5*4+ 2] = (start += zigzagdec64((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[5*4+ 3] = (start += zigzagdec64((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(6*3+0)*8/sizeof(in[0])); out[6*4+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(6*3+1)*8/sizeof(in[0])); out[6*4+ 1] = (start += zigzagdec64((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(6*3+2)*8/sizeof(in[0])); out[6*4+ 2] = (start += zigzagdec64((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[6*4+ 3] = (start += zigzagdec64((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(7*3+0)*8/sizeof(in[0])); out[7*4+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(7*3+1)*8/sizeof(in[0])); out[7*4+ 1] = (start += zigzagdec64((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(7*3+2)*8/sizeof(in[0])); out[7*4+ 2] = (start += zigzagdec64((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[7*4+ 3] = (start += zigzagdec64((w2 >> 16)));;}; out += 32; in += 48*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_49(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*49)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24; w0 = *(uint64_t *)(in+(0*49+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1ffffffffffff)); w1 = *(uint64_t *)(in+(0*49+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 49) | (w1 << 15) & 0x1ffffffffffff)); w2 = *(uint64_t *)(in+(0*49+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w1 >> 34) | (w2 << 30) & 0x1ffffffffffff)); w3 = *(uint64_t *)(in+(0*49+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w2 >> 19) | (w3 << 45) & 0x1ffffffffffff)); out[0*64+ 4] = (start += zigzagdec64((w3 >> 4) & 0x1ffffffffffff)); w4 = *(uint64_t *)(in+(0*49+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w3 >> 53) | (w4 << 11) & 0x1ffffffffffff)); w5 = *(uint64_t *)(in+(0*49+5)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w4 >> 38) | (w5 << 26) & 0x1ffffffffffff)); w6 = *(uint64_t *)(in+(0*49+6)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w5 >> 23) | (w6 << 41) & 0x1ffffffffffff)); out[0*64+ 8] = (start += zigzagdec64((w6 >> 8) & 0x1ffffffffffff)); w7 = *(uint64_t *)(in+(0*49+7)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w6 >> 57) | (w7 << 7) & 0x1ffffffffffff)); w8 = *(uint64_t *)(in+(0*49+8)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w7 >> 42) | (w8 << 22) & 0x1ffffffffffff)); w9 = *(uint64_t *)(in+(0*49+9)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w8 >> 27) | (w9 << 37) & 0x1ffffffffffff)); out[0*64+12] = (start += zigzagdec64((w9 >> 12) & 0x1ffffffffffff)); w10 = *(uint64_t *)(in+(0*49+10)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w9 >> 61) | (w10 << 3) & 0x1ffffffffffff)); w11 = *(uint64_t *)(in+(0*49+11)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w10 >> 46) | (w11 << 18) & 0x1ffffffffffff)); w12 = *(uint64_t *)(in+(0*49+12)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w11 >> 31) | (w12 << 33) & 0x1ffffffffffff)); w13 = *(uint64_t *)(in+(0*49+13)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w12 >> 16) | (w13 << 48) & 0x1ffffffffffff)); out[0*64+17] = (start += zigzagdec64((w13 >> 1) & 0x1ffffffffffff)); w14 = *(uint64_t *)(in+(0*49+14)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w13 >> 50) | (w14 << 14) & 0x1ffffffffffff)); w15 = *(uint64_t *)(in+(0*49+15)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w14 >> 35) | (w15 << 29) & 0x1ffffffffffff)); w16 = *(uint64_t *)(in+(0*49+16)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w15 >> 20) | (w16 << 44) & 0x1ffffffffffff)); out[0*64+21] = (start += zigzagdec64((w16 >> 5) & 0x1ffffffffffff)); w17 = *(uint64_t *)(in+(0*49+17)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w16 >> 54) | (w17 << 10) & 0x1ffffffffffff)); w18 = *(uint64_t *)(in+(0*49+18)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w17 >> 39) | (w18 << 25) & 0x1ffffffffffff)); w19 = *(uint64_t *)(in+(0*49+19)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w18 >> 24) | (w19 << 40) & 0x1ffffffffffff)); out[0*64+25] = (start += zigzagdec64((w19 >> 9) & 0x1ffffffffffff)); w20 = *(uint64_t *)(in+(0*49+20)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w19 >> 58) | (w20 << 6) & 0x1ffffffffffff)); w21 = *(uint64_t *)(in+(0*49+21)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w20 >> 43) | (w21 << 21) & 0x1ffffffffffff)); w22 = *(uint64_t *)(in+(0*49+22)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w21 >> 28) | (w22 << 36) & 0x1ffffffffffff)); out[0*64+29] = (start += zigzagdec64((w22 >> 13) & 0x1ffffffffffff)); w23 = *(uint64_t *)(in+(0*49+23)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w22 >> 62) | (w23 << 2) & 0x1ffffffffffff)); w24 = *(uint32_t *)(in+(0*49+24)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w23 >> 47) | (w24 << 17) & 0x1ffffffffffff));;}; out += 32; in += 49*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_50(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*50)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3ffffffffffff)); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += zigzagdec64((w0 >> 50) | (w1 << 14) & 0x3ffffffffffff)); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += zigzagdec64((w1 >> 36) | (w2 << 28) & 0x3ffffffffffff)); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*32+ 3] = (start += zigzagdec64((w2 >> 22) | (w3 << 42) & 0x3ffffffffffff)); out[0*32+ 4] = (start += zigzagdec64((w3 >> 8) & 0x3ffffffffffff)); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*32+ 5] = (start += zigzagdec64((w3 >> 58) | (w4 << 6) & 0x3ffffffffffff)); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*32+ 6] = (start += zigzagdec64((w4 >> 44) | (w5 << 20) & 0x3ffffffffffff)); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*32+ 7] = (start += zigzagdec64((w5 >> 30) | (w6 << 34) & 0x3ffffffffffff)); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*32+ 8] = (start += zigzagdec64((w6 >> 16) | (w7 << 48) & 0x3ffffffffffff)); out[0*32+ 9] = (start += zigzagdec64((w7 >> 2) & 0x3ffffffffffff)); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*32+10] = (start += zigzagdec64((w7 >> 52) | (w8 << 12) & 0x3ffffffffffff)); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*32+11] = (start += zigzagdec64((w8 >> 38) | (w9 << 26) & 0x3ffffffffffff)); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*32+12] = (start += zigzagdec64((w9 >> 24) | (w10 << 40) & 0x3ffffffffffff)); out[0*32+13] = (start += zigzagdec64((w10 >> 10) & 0x3ffffffffffff)); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*32+14] = (start += zigzagdec64((w10 >> 60) | (w11 << 4) & 0x3ffffffffffff)); w12 = *(uint64_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*32+15] = (start += zigzagdec64((w11 >> 46) | (w12 << 18) & 0x3ffffffffffff)); w13 = *(uint64_t *)(in+(0*25+13)*8/sizeof(in[0])); out[0*32+16] = (start += zigzagdec64((w12 >> 32) | (w13 << 32) & 0x3ffffffffffff)); w14 = *(uint64_t *)(in+(0*25+14)*8/sizeof(in[0])); out[0*32+17] = (start += zigzagdec64((w13 >> 18) | (w14 << 46) & 0x3ffffffffffff)); out[0*32+18] = (start += zigzagdec64((w14 >> 4) & 0x3ffffffffffff)); w15 = *(uint64_t *)(in+(0*25+15)*8/sizeof(in[0])); out[0*32+19] = (start += zigzagdec64((w14 >> 54) | (w15 << 10) & 0x3ffffffffffff)); w16 = *(uint64_t *)(in+(0*25+16)*8/sizeof(in[0])); out[0*32+20] = (start += zigzagdec64((w15 >> 40) | (w16 << 24) & 0x3ffffffffffff)); w17 = *(uint64_t *)(in+(0*25+17)*8/sizeof(in[0])); out[0*32+21] = (start += zigzagdec64((w16 >> 26) | (w17 << 38) & 0x3ffffffffffff)); out[0*32+22] = (start += zigzagdec64((w17 >> 12) & 0x3ffffffffffff)); w18 = *(uint64_t *)(in+(0*25+18)*8/sizeof(in[0])); out[0*32+23] = (start += zigzagdec64((w17 >> 62) | (w18 << 2) & 0x3ffffffffffff)); w19 = *(uint64_t *)(in+(0*25+19)*8/sizeof(in[0])); out[0*32+24] = (start += zigzagdec64((w18 >> 48) | (w19 << 16) & 0x3ffffffffffff)); w20 = *(uint64_t *)(in+(0*25+20)*8/sizeof(in[0])); out[0*32+25] = (start += zigzagdec64((w19 >> 34) | (w20 << 30) & 0x3ffffffffffff)); w21 = *(uint64_t *)(in+(0*25+21)*8/sizeof(in[0])); out[0*32+26] = (start += zigzagdec64((w20 >> 20) | (w21 << 44) & 0x3ffffffffffff)); out[0*32+27] = (start += zigzagdec64((w21 >> 6) & 0x3ffffffffffff)); w22 = *(uint64_t *)(in+(0*25+22)*8/sizeof(in[0])); out[0*32+28] = (start += zigzagdec64((w21 >> 56) | (w22 << 8) & 0x3ffffffffffff)); w23 = *(uint64_t *)(in+(0*25+23)*8/sizeof(in[0])); out[0*32+29] = (start += zigzagdec64((w22 >> 42) | (w23 << 22) & 0x3ffffffffffff)); w24 = *(uint64_t *)(in+(0*25+24)*8/sizeof(in[0])); out[0*32+30] = (start += zigzagdec64((w23 >> 28) | (w24 << 36) & 0x3ffffffffffff)); out[0*32+31] = (start += zigzagdec64((w24 >> 14)));;}; out += 32; in += 50*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_51(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*51)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(0*51+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7ffffffffffff)); w1 = *(uint64_t *)(in+(0*51+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 51) | (w1 << 13) & 0x7ffffffffffff)); w2 = *(uint64_t *)(in+(0*51+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w1 >> 38) | (w2 << 26) & 0x7ffffffffffff)); w3 = *(uint64_t *)(in+(0*51+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w2 >> 25) | (w3 << 39) & 0x7ffffffffffff)); out[0*64+ 4] = (start += zigzagdec64((w3 >> 12) & 0x7ffffffffffff)); w4 = *(uint64_t *)(in+(0*51+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w3 >> 63) | (w4 << 1) & 0x7ffffffffffff)); w5 = *(uint64_t *)(in+(0*51+5)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w4 >> 50) | (w5 << 14) & 0x7ffffffffffff)); w6 = *(uint64_t *)(in+(0*51+6)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w5 >> 37) | (w6 << 27) & 0x7ffffffffffff)); w7 = *(uint64_t *)(in+(0*51+7)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w6 >> 24) | (w7 << 40) & 0x7ffffffffffff)); out[0*64+ 9] = (start += zigzagdec64((w7 >> 11) & 0x7ffffffffffff)); w8 = *(uint64_t *)(in+(0*51+8)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w7 >> 62) | (w8 << 2) & 0x7ffffffffffff)); w9 = *(uint64_t *)(in+(0*51+9)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w8 >> 49) | (w9 << 15) & 0x7ffffffffffff)); w10 = *(uint64_t *)(in+(0*51+10)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w9 >> 36) | (w10 << 28) & 0x7ffffffffffff)); w11 = *(uint64_t *)(in+(0*51+11)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w10 >> 23) | (w11 << 41) & 0x7ffffffffffff)); out[0*64+14] = (start += zigzagdec64((w11 >> 10) & 0x7ffffffffffff)); w12 = *(uint64_t *)(in+(0*51+12)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w11 >> 61) | (w12 << 3) & 0x7ffffffffffff)); w13 = *(uint64_t *)(in+(0*51+13)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w12 >> 48) | (w13 << 16) & 0x7ffffffffffff)); w14 = *(uint64_t *)(in+(0*51+14)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w13 >> 35) | (w14 << 29) & 0x7ffffffffffff)); w15 = *(uint64_t *)(in+(0*51+15)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w14 >> 22) | (w15 << 42) & 0x7ffffffffffff)); out[0*64+19] = (start += zigzagdec64((w15 >> 9) & 0x7ffffffffffff)); w16 = *(uint64_t *)(in+(0*51+16)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w15 >> 60) | (w16 << 4) & 0x7ffffffffffff)); w17 = *(uint64_t *)(in+(0*51+17)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w16 >> 47) | (w17 << 17) & 0x7ffffffffffff)); w18 = *(uint64_t *)(in+(0*51+18)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w17 >> 34) | (w18 << 30) & 0x7ffffffffffff)); w19 = *(uint64_t *)(in+(0*51+19)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w18 >> 21) | (w19 << 43) & 0x7ffffffffffff)); out[0*64+24] = (start += zigzagdec64((w19 >> 8) & 0x7ffffffffffff)); w20 = *(uint64_t *)(in+(0*51+20)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w19 >> 59) | (w20 << 5) & 0x7ffffffffffff)); w21 = *(uint64_t *)(in+(0*51+21)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w20 >> 46) | (w21 << 18) & 0x7ffffffffffff)); w22 = *(uint64_t *)(in+(0*51+22)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w21 >> 33) | (w22 << 31) & 0x7ffffffffffff)); w23 = *(uint64_t *)(in+(0*51+23)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w22 >> 20) | (w23 << 44) & 0x7ffffffffffff)); out[0*64+29] = (start += zigzagdec64((w23 >> 7) & 0x7ffffffffffff)); w24 = *(uint64_t *)(in+(0*51+24)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w23 >> 58) | (w24 << 6) & 0x7ffffffffffff)); w25 = *(uint32_t *)(in+(0*51+25)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w24 >> 45) | (w25 << 19) & 0x7ffffffffffff));;}; out += 32; in += 51*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_52(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*52)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec64((w0 ) & 0xfffffffffffff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*16+ 1] = (start += zigzagdec64((w0 >> 52) | (w1 << 12) & 0xfffffffffffff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*16+ 2] = (start += zigzagdec64((w1 >> 40) | (w2 << 24) & 0xfffffffffffff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*16+ 3] = (start += zigzagdec64((w2 >> 28) | (w3 << 36) & 0xfffffffffffff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*16+ 4] = (start += zigzagdec64((w3 >> 16) | (w4 << 48) & 0xfffffffffffff)); out[0*16+ 5] = (start += zigzagdec64((w4 >> 4) & 0xfffffffffffff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*16+ 6] = (start += zigzagdec64((w4 >> 56) | (w5 << 8) & 0xfffffffffffff)); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*16+ 7] = (start += zigzagdec64((w5 >> 44) | (w6 << 20) & 0xfffffffffffff)); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*16+ 8] = (start += zigzagdec64((w6 >> 32) | (w7 << 32) & 0xfffffffffffff)); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*16+ 9] = (start += zigzagdec64((w7 >> 20) | (w8 << 44) & 0xfffffffffffff)); out[0*16+10] = (start += zigzagdec64((w8 >> 8) & 0xfffffffffffff)); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*16+11] = (start += zigzagdec64((w8 >> 60) | (w9 << 4) & 0xfffffffffffff)); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*16+12] = (start += zigzagdec64((w9 >> 48) | (w10 << 16) & 0xfffffffffffff)); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*16+13] = (start += zigzagdec64((w10 >> 36) | (w11 << 28) & 0xfffffffffffff)); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*16+14] = (start += zigzagdec64((w11 >> 24) | (w12 << 40) & 0xfffffffffffff)); out[0*16+15] = (start += zigzagdec64((w12 >> 12)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(1*13+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec64((w0 ) & 0xfffffffffffff)); w1 = *(uint64_t *)(in+(1*13+1)*8/sizeof(in[0])); out[1*16+ 1] = (start += zigzagdec64((w0 >> 52) | (w1 << 12) & 0xfffffffffffff)); w2 = *(uint64_t *)(in+(1*13+2)*8/sizeof(in[0])); out[1*16+ 2] = (start += zigzagdec64((w1 >> 40) | (w2 << 24) & 0xfffffffffffff)); w3 = *(uint64_t *)(in+(1*13+3)*8/sizeof(in[0])); out[1*16+ 3] = (start += zigzagdec64((w2 >> 28) | (w3 << 36) & 0xfffffffffffff)); w4 = *(uint64_t *)(in+(1*13+4)*8/sizeof(in[0])); out[1*16+ 4] = (start += zigzagdec64((w3 >> 16) | (w4 << 48) & 0xfffffffffffff)); out[1*16+ 5] = (start += zigzagdec64((w4 >> 4) & 0xfffffffffffff)); w5 = *(uint64_t *)(in+(1*13+5)*8/sizeof(in[0])); out[1*16+ 6] = (start += zigzagdec64((w4 >> 56) | (w5 << 8) & 0xfffffffffffff)); w6 = *(uint64_t *)(in+(1*13+6)*8/sizeof(in[0])); out[1*16+ 7] = (start += zigzagdec64((w5 >> 44) | (w6 << 20) & 0xfffffffffffff)); w7 = *(uint64_t *)(in+(1*13+7)*8/sizeof(in[0])); out[1*16+ 8] = (start += zigzagdec64((w6 >> 32) | (w7 << 32) & 0xfffffffffffff)); w8 = *(uint64_t *)(in+(1*13+8)*8/sizeof(in[0])); out[1*16+ 9] = (start += zigzagdec64((w7 >> 20) | (w8 << 44) & 0xfffffffffffff)); out[1*16+10] = (start += zigzagdec64((w8 >> 8) & 0xfffffffffffff)); w9 = *(uint64_t *)(in+(1*13+9)*8/sizeof(in[0])); out[1*16+11] = (start += zigzagdec64((w8 >> 60) | (w9 << 4) & 0xfffffffffffff)); w10 = *(uint64_t *)(in+(1*13+10)*8/sizeof(in[0])); out[1*16+12] = (start += zigzagdec64((w9 >> 48) | (w10 << 16) & 0xfffffffffffff)); w11 = *(uint64_t *)(in+(1*13+11)*8/sizeof(in[0])); out[1*16+13] = (start += zigzagdec64((w10 >> 36) | (w11 << 28) & 0xfffffffffffff)); w12 = *(uint64_t *)(in+(1*13+12)*8/sizeof(in[0])); out[1*16+14] = (start += zigzagdec64((w11 >> 24) | (w12 << 40) & 0xfffffffffffff)); out[1*16+15] = (start += zigzagdec64((w12 >> 12)));;}; out += 32; in += 52*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_53(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*53)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26; w0 = *(uint64_t *)(in+(0*53+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1fffffffffffff)); w1 = *(uint64_t *)(in+(0*53+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 53) | (w1 << 11) & 0x1fffffffffffff)); w2 = *(uint64_t *)(in+(0*53+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w1 >> 42) | (w2 << 22) & 0x1fffffffffffff)); w3 = *(uint64_t *)(in+(0*53+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w2 >> 31) | (w3 << 33) & 0x1fffffffffffff)); w4 = *(uint64_t *)(in+(0*53+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w3 >> 20) | (w4 << 44) & 0x1fffffffffffff)); out[0*64+ 5] = (start += zigzagdec64((w4 >> 9) & 0x1fffffffffffff)); w5 = *(uint64_t *)(in+(0*53+5)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w4 >> 62) | (w5 << 2) & 0x1fffffffffffff)); w6 = *(uint64_t *)(in+(0*53+6)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w5 >> 51) | (w6 << 13) & 0x1fffffffffffff)); w7 = *(uint64_t *)(in+(0*53+7)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w6 >> 40) | (w7 << 24) & 0x1fffffffffffff)); w8 = *(uint64_t *)(in+(0*53+8)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w7 >> 29) | (w8 << 35) & 0x1fffffffffffff)); w9 = *(uint64_t *)(in+(0*53+9)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w8 >> 18) | (w9 << 46) & 0x1fffffffffffff)); out[0*64+11] = (start += zigzagdec64((w9 >> 7) & 0x1fffffffffffff)); w10 = *(uint64_t *)(in+(0*53+10)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w9 >> 60) | (w10 << 4) & 0x1fffffffffffff)); w11 = *(uint64_t *)(in+(0*53+11)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w10 >> 49) | (w11 << 15) & 0x1fffffffffffff)); w12 = *(uint64_t *)(in+(0*53+12)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w11 >> 38) | (w12 << 26) & 0x1fffffffffffff)); w13 = *(uint64_t *)(in+(0*53+13)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w12 >> 27) | (w13 << 37) & 0x1fffffffffffff)); w14 = *(uint64_t *)(in+(0*53+14)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w13 >> 16) | (w14 << 48) & 0x1fffffffffffff)); out[0*64+17] = (start += zigzagdec64((w14 >> 5) & 0x1fffffffffffff)); w15 = *(uint64_t *)(in+(0*53+15)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w14 >> 58) | (w15 << 6) & 0x1fffffffffffff)); w16 = *(uint64_t *)(in+(0*53+16)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w15 >> 47) | (w16 << 17) & 0x1fffffffffffff)); w17 = *(uint64_t *)(in+(0*53+17)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w16 >> 36) | (w17 << 28) & 0x1fffffffffffff)); w18 = *(uint64_t *)(in+(0*53+18)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w17 >> 25) | (w18 << 39) & 0x1fffffffffffff)); w19 = *(uint64_t *)(in+(0*53+19)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w18 >> 14) | (w19 << 50) & 0x1fffffffffffff)); out[0*64+23] = (start += zigzagdec64((w19 >> 3) & 0x1fffffffffffff)); w20 = *(uint64_t *)(in+(0*53+20)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w19 >> 56) | (w20 << 8) & 0x1fffffffffffff)); w21 = *(uint64_t *)(in+(0*53+21)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w20 >> 45) | (w21 << 19) & 0x1fffffffffffff)); w22 = *(uint64_t *)(in+(0*53+22)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w21 >> 34) | (w22 << 30) & 0x1fffffffffffff)); w23 = *(uint64_t *)(in+(0*53+23)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w22 >> 23) | (w23 << 41) & 0x1fffffffffffff)); w24 = *(uint64_t *)(in+(0*53+24)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w23 >> 12) | (w24 << 52) & 0x1fffffffffffff)); out[0*64+29] = (start += zigzagdec64((w24 >> 1) & 0x1fffffffffffff)); w25 = *(uint64_t *)(in+(0*53+25)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w24 >> 54) | (w25 << 10) & 0x1fffffffffffff)); w26 = *(uint32_t *)(in+(0*53+26)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w25 >> 43) | (w26 << 21) & 0x1fffffffffffff));;}; out += 32; in += 53*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_54(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*54)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3fffffffffffff)); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += zigzagdec64((w0 >> 54) | (w1 << 10) & 0x3fffffffffffff)); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += zigzagdec64((w1 >> 44) | (w2 << 20) & 0x3fffffffffffff)); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*32+ 3] = (start += zigzagdec64((w2 >> 34) | (w3 << 30) & 0x3fffffffffffff)); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*32+ 4] = (start += zigzagdec64((w3 >> 24) | (w4 << 40) & 0x3fffffffffffff)); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*32+ 5] = (start += zigzagdec64((w4 >> 14) | (w5 << 50) & 0x3fffffffffffff)); out[0*32+ 6] = (start += zigzagdec64((w5 >> 4) & 0x3fffffffffffff)); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*32+ 7] = (start += zigzagdec64((w5 >> 58) | (w6 << 6) & 0x3fffffffffffff)); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*32+ 8] = (start += zigzagdec64((w6 >> 48) | (w7 << 16) & 0x3fffffffffffff)); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*32+ 9] = (start += zigzagdec64((w7 >> 38) | (w8 << 26) & 0x3fffffffffffff)); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*32+10] = (start += zigzagdec64((w8 >> 28) | (w9 << 36) & 0x3fffffffffffff)); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*32+11] = (start += zigzagdec64((w9 >> 18) | (w10 << 46) & 0x3fffffffffffff)); out[0*32+12] = (start += zigzagdec64((w10 >> 8) & 0x3fffffffffffff)); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*32+13] = (start += zigzagdec64((w10 >> 62) | (w11 << 2) & 0x3fffffffffffff)); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*32+14] = (start += zigzagdec64((w11 >> 52) | (w12 << 12) & 0x3fffffffffffff)); w13 = *(uint64_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*32+15] = (start += zigzagdec64((w12 >> 42) | (w13 << 22) & 0x3fffffffffffff)); w14 = *(uint64_t *)(in+(0*27+14)*8/sizeof(in[0])); out[0*32+16] = (start += zigzagdec64((w13 >> 32) | (w14 << 32) & 0x3fffffffffffff)); w15 = *(uint64_t *)(in+(0*27+15)*8/sizeof(in[0])); out[0*32+17] = (start += zigzagdec64((w14 >> 22) | (w15 << 42) & 0x3fffffffffffff)); w16 = *(uint64_t *)(in+(0*27+16)*8/sizeof(in[0])); out[0*32+18] = (start += zigzagdec64((w15 >> 12) | (w16 << 52) & 0x3fffffffffffff)); out[0*32+19] = (start += zigzagdec64((w16 >> 2) & 0x3fffffffffffff)); w17 = *(uint64_t *)(in+(0*27+17)*8/sizeof(in[0])); out[0*32+20] = (start += zigzagdec64((w16 >> 56) | (w17 << 8) & 0x3fffffffffffff)); w18 = *(uint64_t *)(in+(0*27+18)*8/sizeof(in[0])); out[0*32+21] = (start += zigzagdec64((w17 >> 46) | (w18 << 18) & 0x3fffffffffffff)); w19 = *(uint64_t *)(in+(0*27+19)*8/sizeof(in[0])); out[0*32+22] = (start += zigzagdec64((w18 >> 36) | (w19 << 28) & 0x3fffffffffffff)); w20 = *(uint64_t *)(in+(0*27+20)*8/sizeof(in[0])); out[0*32+23] = (start += zigzagdec64((w19 >> 26) | (w20 << 38) & 0x3fffffffffffff)); w21 = *(uint64_t *)(in+(0*27+21)*8/sizeof(in[0])); out[0*32+24] = (start += zigzagdec64((w20 >> 16) | (w21 << 48) & 0x3fffffffffffff)); out[0*32+25] = (start += zigzagdec64((w21 >> 6) & 0x3fffffffffffff)); w22 = *(uint64_t *)(in+(0*27+22)*8/sizeof(in[0])); out[0*32+26] = (start += zigzagdec64((w21 >> 60) | (w22 << 4) & 0x3fffffffffffff)); w23 = *(uint64_t *)(in+(0*27+23)*8/sizeof(in[0])); out[0*32+27] = (start += zigzagdec64((w22 >> 50) | (w23 << 14) & 0x3fffffffffffff)); w24 = *(uint64_t *)(in+(0*27+24)*8/sizeof(in[0])); out[0*32+28] = (start += zigzagdec64((w23 >> 40) | (w24 << 24) & 0x3fffffffffffff)); w25 = *(uint64_t *)(in+(0*27+25)*8/sizeof(in[0])); out[0*32+29] = (start += zigzagdec64((w24 >> 30) | (w25 << 34) & 0x3fffffffffffff)); w26 = *(uint64_t *)(in+(0*27+26)*8/sizeof(in[0])); out[0*32+30] = (start += zigzagdec64((w25 >> 20) | (w26 << 44) & 0x3fffffffffffff)); out[0*32+31] = (start += zigzagdec64((w26 >> 10)));;}; out += 32; in += 54*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_55(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*55)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(0*55+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7fffffffffffff)); w1 = *(uint64_t *)(in+(0*55+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 55) | (w1 << 9) & 0x7fffffffffffff)); w2 = *(uint64_t *)(in+(0*55+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w1 >> 46) | (w2 << 18) & 0x7fffffffffffff)); w3 = *(uint64_t *)(in+(0*55+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w2 >> 37) | (w3 << 27) & 0x7fffffffffffff)); w4 = *(uint64_t *)(in+(0*55+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w3 >> 28) | (w4 << 36) & 0x7fffffffffffff)); w5 = *(uint64_t *)(in+(0*55+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w4 >> 19) | (w5 << 45) & 0x7fffffffffffff)); w6 = *(uint64_t *)(in+(0*55+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w5 >> 10) | (w6 << 54) & 0x7fffffffffffff)); out[0*64+ 7] = (start += zigzagdec64((w6 >> 1) & 0x7fffffffffffff)); w7 = *(uint64_t *)(in+(0*55+7)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w6 >> 56) | (w7 << 8) & 0x7fffffffffffff)); w8 = *(uint64_t *)(in+(0*55+8)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w7 >> 47) | (w8 << 17) & 0x7fffffffffffff)); w9 = *(uint64_t *)(in+(0*55+9)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w8 >> 38) | (w9 << 26) & 0x7fffffffffffff)); w10 = *(uint64_t *)(in+(0*55+10)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w9 >> 29) | (w10 << 35) & 0x7fffffffffffff)); w11 = *(uint64_t *)(in+(0*55+11)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w10 >> 20) | (w11 << 44) & 0x7fffffffffffff)); w12 = *(uint64_t *)(in+(0*55+12)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w11 >> 11) | (w12 << 53) & 0x7fffffffffffff)); out[0*64+14] = (start += zigzagdec64((w12 >> 2) & 0x7fffffffffffff)); w13 = *(uint64_t *)(in+(0*55+13)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w12 >> 57) | (w13 << 7) & 0x7fffffffffffff)); w14 = *(uint64_t *)(in+(0*55+14)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w13 >> 48) | (w14 << 16) & 0x7fffffffffffff)); w15 = *(uint64_t *)(in+(0*55+15)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w14 >> 39) | (w15 << 25) & 0x7fffffffffffff)); w16 = *(uint64_t *)(in+(0*55+16)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w15 >> 30) | (w16 << 34) & 0x7fffffffffffff)); w17 = *(uint64_t *)(in+(0*55+17)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w16 >> 21) | (w17 << 43) & 0x7fffffffffffff)); w18 = *(uint64_t *)(in+(0*55+18)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w17 >> 12) | (w18 << 52) & 0x7fffffffffffff)); out[0*64+21] = (start += zigzagdec64((w18 >> 3) & 0x7fffffffffffff)); w19 = *(uint64_t *)(in+(0*55+19)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w18 >> 58) | (w19 << 6) & 0x7fffffffffffff)); w20 = *(uint64_t *)(in+(0*55+20)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w19 >> 49) | (w20 << 15) & 0x7fffffffffffff)); w21 = *(uint64_t *)(in+(0*55+21)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w20 >> 40) | (w21 << 24) & 0x7fffffffffffff)); w22 = *(uint64_t *)(in+(0*55+22)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w21 >> 31) | (w22 << 33) & 0x7fffffffffffff)); w23 = *(uint64_t *)(in+(0*55+23)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w22 >> 22) | (w23 << 42) & 0x7fffffffffffff)); w24 = *(uint64_t *)(in+(0*55+24)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w23 >> 13) | (w24 << 51) & 0x7fffffffffffff)); out[0*64+28] = (start += zigzagdec64((w24 >> 4) & 0x7fffffffffffff)); w25 = *(uint64_t *)(in+(0*55+25)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w24 >> 59) | (w25 << 5) & 0x7fffffffffffff)); w26 = *(uint64_t *)(in+(0*55+26)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w25 >> 50) | (w26 << 14) & 0x7fffffffffffff)); w27 = *(uint32_t *)(in+(0*55+27)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w26 >> 41) | (w27 << 23) & 0x7fffffffffffff));;}; out += 32; in += 55*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_56(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*56)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffffffff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*8+ 1] = (start += zigzagdec64((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*8+ 2] = (start += zigzagdec64((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*8+ 3] = (start += zigzagdec64((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*8+ 4] = (start += zigzagdec64((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*8+ 5] = (start += zigzagdec64((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*8+ 6] = (start += zigzagdec64((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)); out[0*8+ 7] = (start += zigzagdec64((w6 >> 8)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffffffff)); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*8+ 1] = (start += zigzagdec64((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*8+ 2] = (start += zigzagdec64((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*8+ 3] = (start += zigzagdec64((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*8+ 4] = (start += zigzagdec64((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*8+ 5] = (start += zigzagdec64((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*8+ 6] = (start += zigzagdec64((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)); out[1*8+ 7] = (start += zigzagdec64((w6 >> 8)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(2*7+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffffffff)); w1 = *(uint64_t *)(in+(2*7+1)*8/sizeof(in[0])); out[2*8+ 1] = (start += zigzagdec64((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)); w2 = *(uint64_t *)(in+(2*7+2)*8/sizeof(in[0])); out[2*8+ 2] = (start += zigzagdec64((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)); w3 = *(uint64_t *)(in+(2*7+3)*8/sizeof(in[0])); out[2*8+ 3] = (start += zigzagdec64((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)); w4 = *(uint64_t *)(in+(2*7+4)*8/sizeof(in[0])); out[2*8+ 4] = (start += zigzagdec64((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)); w5 = *(uint64_t *)(in+(2*7+5)*8/sizeof(in[0])); out[2*8+ 5] = (start += zigzagdec64((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)); w6 = *(uint64_t *)(in+(2*7+6)*8/sizeof(in[0])); out[2*8+ 6] = (start += zigzagdec64((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)); out[2*8+ 7] = (start += zigzagdec64((w6 >> 8)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(3*7+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += zigzagdec64((w0 ) & 0xffffffffffffff)); w1 = *(uint64_t *)(in+(3*7+1)*8/sizeof(in[0])); out[3*8+ 1] = (start += zigzagdec64((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)); w2 = *(uint64_t *)(in+(3*7+2)*8/sizeof(in[0])); out[3*8+ 2] = (start += zigzagdec64((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)); w3 = *(uint64_t *)(in+(3*7+3)*8/sizeof(in[0])); out[3*8+ 3] = (start += zigzagdec64((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)); w4 = *(uint64_t *)(in+(3*7+4)*8/sizeof(in[0])); out[3*8+ 4] = (start += zigzagdec64((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)); w5 = *(uint64_t *)(in+(3*7+5)*8/sizeof(in[0])); out[3*8+ 5] = (start += zigzagdec64((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)); w6 = *(uint64_t *)(in+(3*7+6)*8/sizeof(in[0])); out[3*8+ 6] = (start += zigzagdec64((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)); out[3*8+ 7] = (start += zigzagdec64((w6 >> 8)));;}; out += 32; in += 56*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_57(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*57)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28; w0 = *(uint64_t *)(in+(0*57+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1ffffffffffffff)); w1 = *(uint64_t *)(in+(0*57+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 57) | (w1 << 7) & 0x1ffffffffffffff)); w2 = *(uint64_t *)(in+(0*57+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w1 >> 50) | (w2 << 14) & 0x1ffffffffffffff)); w3 = *(uint64_t *)(in+(0*57+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w2 >> 43) | (w3 << 21) & 0x1ffffffffffffff)); w4 = *(uint64_t *)(in+(0*57+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w3 >> 36) | (w4 << 28) & 0x1ffffffffffffff)); w5 = *(uint64_t *)(in+(0*57+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w4 >> 29) | (w5 << 35) & 0x1ffffffffffffff)); w6 = *(uint64_t *)(in+(0*57+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w5 >> 22) | (w6 << 42) & 0x1ffffffffffffff)); w7 = *(uint64_t *)(in+(0*57+7)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w6 >> 15) | (w7 << 49) & 0x1ffffffffffffff)); w8 = *(uint64_t *)(in+(0*57+8)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w7 >> 8) | (w8 << 56) & 0x1ffffffffffffff)); out[0*64+ 9] = (start += zigzagdec64((w8 >> 1) & 0x1ffffffffffffff)); w9 = *(uint64_t *)(in+(0*57+9)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w8 >> 58) | (w9 << 6) & 0x1ffffffffffffff)); w10 = *(uint64_t *)(in+(0*57+10)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w9 >> 51) | (w10 << 13) & 0x1ffffffffffffff)); w11 = *(uint64_t *)(in+(0*57+11)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w10 >> 44) | (w11 << 20) & 0x1ffffffffffffff)); w12 = *(uint64_t *)(in+(0*57+12)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w11 >> 37) | (w12 << 27) & 0x1ffffffffffffff)); w13 = *(uint64_t *)(in+(0*57+13)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w12 >> 30) | (w13 << 34) & 0x1ffffffffffffff)); w14 = *(uint64_t *)(in+(0*57+14)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w13 >> 23) | (w14 << 41) & 0x1ffffffffffffff)); w15 = *(uint64_t *)(in+(0*57+15)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w14 >> 16) | (w15 << 48) & 0x1ffffffffffffff)); w16 = *(uint64_t *)(in+(0*57+16)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w15 >> 9) | (w16 << 55) & 0x1ffffffffffffff)); out[0*64+18] = (start += zigzagdec64((w16 >> 2) & 0x1ffffffffffffff)); w17 = *(uint64_t *)(in+(0*57+17)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w16 >> 59) | (w17 << 5) & 0x1ffffffffffffff)); w18 = *(uint64_t *)(in+(0*57+18)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w17 >> 52) | (w18 << 12) & 0x1ffffffffffffff)); w19 = *(uint64_t *)(in+(0*57+19)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w18 >> 45) | (w19 << 19) & 0x1ffffffffffffff)); w20 = *(uint64_t *)(in+(0*57+20)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w19 >> 38) | (w20 << 26) & 0x1ffffffffffffff)); w21 = *(uint64_t *)(in+(0*57+21)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w20 >> 31) | (w21 << 33) & 0x1ffffffffffffff)); w22 = *(uint64_t *)(in+(0*57+22)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w21 >> 24) | (w22 << 40) & 0x1ffffffffffffff)); w23 = *(uint64_t *)(in+(0*57+23)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w22 >> 17) | (w23 << 47) & 0x1ffffffffffffff)); w24 = *(uint64_t *)(in+(0*57+24)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w23 >> 10) | (w24 << 54) & 0x1ffffffffffffff)); out[0*64+27] = (start += zigzagdec64((w24 >> 3) & 0x1ffffffffffffff)); w25 = *(uint64_t *)(in+(0*57+25)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w24 >> 60) | (w25 << 4) & 0x1ffffffffffffff)); w26 = *(uint64_t *)(in+(0*57+26)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w25 >> 53) | (w26 << 11) & 0x1ffffffffffffff)); w27 = *(uint64_t *)(in+(0*57+27)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w26 >> 46) | (w27 << 18) & 0x1ffffffffffffff)); w28 = *(uint32_t *)(in+(0*57+28)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w27 >> 39) | (w28 << 25) & 0x1ffffffffffffff));;}; out += 32; in += 57*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_58(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*58)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3ffffffffffffff)); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += zigzagdec64((w0 >> 58) | (w1 << 6) & 0x3ffffffffffffff)); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += zigzagdec64((w1 >> 52) | (w2 << 12) & 0x3ffffffffffffff)); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*32+ 3] = (start += zigzagdec64((w2 >> 46) | (w3 << 18) & 0x3ffffffffffffff)); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*32+ 4] = (start += zigzagdec64((w3 >> 40) | (w4 << 24) & 0x3ffffffffffffff)); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*32+ 5] = (start += zigzagdec64((w4 >> 34) | (w5 << 30) & 0x3ffffffffffffff)); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*32+ 6] = (start += zigzagdec64((w5 >> 28) | (w6 << 36) & 0x3ffffffffffffff)); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*32+ 7] = (start += zigzagdec64((w6 >> 22) | (w7 << 42) & 0x3ffffffffffffff)); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*32+ 8] = (start += zigzagdec64((w7 >> 16) | (w8 << 48) & 0x3ffffffffffffff)); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*32+ 9] = (start += zigzagdec64((w8 >> 10) | (w9 << 54) & 0x3ffffffffffffff)); out[0*32+10] = (start += zigzagdec64((w9 >> 4) & 0x3ffffffffffffff)); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*32+11] = (start += zigzagdec64((w9 >> 62) | (w10 << 2) & 0x3ffffffffffffff)); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*32+12] = (start += zigzagdec64((w10 >> 56) | (w11 << 8) & 0x3ffffffffffffff)); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*32+13] = (start += zigzagdec64((w11 >> 50) | (w12 << 14) & 0x3ffffffffffffff)); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*32+14] = (start += zigzagdec64((w12 >> 44) | (w13 << 20) & 0x3ffffffffffffff)); w14 = *(uint64_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*32+15] = (start += zigzagdec64((w13 >> 38) | (w14 << 26) & 0x3ffffffffffffff)); w15 = *(uint64_t *)(in+(0*29+15)*8/sizeof(in[0])); out[0*32+16] = (start += zigzagdec64((w14 >> 32) | (w15 << 32) & 0x3ffffffffffffff)); w16 = *(uint64_t *)(in+(0*29+16)*8/sizeof(in[0])); out[0*32+17] = (start += zigzagdec64((w15 >> 26) | (w16 << 38) & 0x3ffffffffffffff)); w17 = *(uint64_t *)(in+(0*29+17)*8/sizeof(in[0])); out[0*32+18] = (start += zigzagdec64((w16 >> 20) | (w17 << 44) & 0x3ffffffffffffff)); w18 = *(uint64_t *)(in+(0*29+18)*8/sizeof(in[0])); out[0*32+19] = (start += zigzagdec64((w17 >> 14) | (w18 << 50) & 0x3ffffffffffffff)); w19 = *(uint64_t *)(in+(0*29+19)*8/sizeof(in[0])); out[0*32+20] = (start += zigzagdec64((w18 >> 8) | (w19 << 56) & 0x3ffffffffffffff)); out[0*32+21] = (start += zigzagdec64((w19 >> 2) & 0x3ffffffffffffff)); w20 = *(uint64_t *)(in+(0*29+20)*8/sizeof(in[0])); out[0*32+22] = (start += zigzagdec64((w19 >> 60) | (w20 << 4) & 0x3ffffffffffffff)); w21 = *(uint64_t *)(in+(0*29+21)*8/sizeof(in[0])); out[0*32+23] = (start += zigzagdec64((w20 >> 54) | (w21 << 10) & 0x3ffffffffffffff)); w22 = *(uint64_t *)(in+(0*29+22)*8/sizeof(in[0])); out[0*32+24] = (start += zigzagdec64((w21 >> 48) | (w22 << 16) & 0x3ffffffffffffff)); w23 = *(uint64_t *)(in+(0*29+23)*8/sizeof(in[0])); out[0*32+25] = (start += zigzagdec64((w22 >> 42) | (w23 << 22) & 0x3ffffffffffffff)); w24 = *(uint64_t *)(in+(0*29+24)*8/sizeof(in[0])); out[0*32+26] = (start += zigzagdec64((w23 >> 36) | (w24 << 28) & 0x3ffffffffffffff)); w25 = *(uint64_t *)(in+(0*29+25)*8/sizeof(in[0])); out[0*32+27] = (start += zigzagdec64((w24 >> 30) | (w25 << 34) & 0x3ffffffffffffff)); w26 = *(uint64_t *)(in+(0*29+26)*8/sizeof(in[0])); out[0*32+28] = (start += zigzagdec64((w25 >> 24) | (w26 << 40) & 0x3ffffffffffffff)); w27 = *(uint64_t *)(in+(0*29+27)*8/sizeof(in[0])); out[0*32+29] = (start += zigzagdec64((w26 >> 18) | (w27 << 46) & 0x3ffffffffffffff)); w28 = *(uint64_t *)(in+(0*29+28)*8/sizeof(in[0])); out[0*32+30] = (start += zigzagdec64((w27 >> 12) | (w28 << 52) & 0x3ffffffffffffff)); out[0*32+31] = (start += zigzagdec64((w28 >> 6)));;}; out += 32; in += 58*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_59(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*59)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(0*59+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7ffffffffffffff)); w1 = *(uint64_t *)(in+(0*59+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 59) | (w1 << 5) & 0x7ffffffffffffff)); w2 = *(uint64_t *)(in+(0*59+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w1 >> 54) | (w2 << 10) & 0x7ffffffffffffff)); w3 = *(uint64_t *)(in+(0*59+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w2 >> 49) | (w3 << 15) & 0x7ffffffffffffff)); w4 = *(uint64_t *)(in+(0*59+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w3 >> 44) | (w4 << 20) & 0x7ffffffffffffff)); w5 = *(uint64_t *)(in+(0*59+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w4 >> 39) | (w5 << 25) & 0x7ffffffffffffff)); w6 = *(uint64_t *)(in+(0*59+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w5 >> 34) | (w6 << 30) & 0x7ffffffffffffff)); w7 = *(uint64_t *)(in+(0*59+7)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w6 >> 29) | (w7 << 35) & 0x7ffffffffffffff)); w8 = *(uint64_t *)(in+(0*59+8)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w7 >> 24) | (w8 << 40) & 0x7ffffffffffffff)); w9 = *(uint64_t *)(in+(0*59+9)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w8 >> 19) | (w9 << 45) & 0x7ffffffffffffff)); w10 = *(uint64_t *)(in+(0*59+10)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w9 >> 14) | (w10 << 50) & 0x7ffffffffffffff)); w11 = *(uint64_t *)(in+(0*59+11)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w10 >> 9) | (w11 << 55) & 0x7ffffffffffffff)); out[0*64+12] = (start += zigzagdec64((w11 >> 4) & 0x7ffffffffffffff)); w12 = *(uint64_t *)(in+(0*59+12)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w11 >> 63) | (w12 << 1) & 0x7ffffffffffffff)); w13 = *(uint64_t *)(in+(0*59+13)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w12 >> 58) | (w13 << 6) & 0x7ffffffffffffff)); w14 = *(uint64_t *)(in+(0*59+14)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w13 >> 53) | (w14 << 11) & 0x7ffffffffffffff)); w15 = *(uint64_t *)(in+(0*59+15)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w14 >> 48) | (w15 << 16) & 0x7ffffffffffffff)); w16 = *(uint64_t *)(in+(0*59+16)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w15 >> 43) | (w16 << 21) & 0x7ffffffffffffff)); w17 = *(uint64_t *)(in+(0*59+17)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w16 >> 38) | (w17 << 26) & 0x7ffffffffffffff)); w18 = *(uint64_t *)(in+(0*59+18)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w17 >> 33) | (w18 << 31) & 0x7ffffffffffffff)); w19 = *(uint64_t *)(in+(0*59+19)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w18 >> 28) | (w19 << 36) & 0x7ffffffffffffff)); w20 = *(uint64_t *)(in+(0*59+20)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w19 >> 23) | (w20 << 41) & 0x7ffffffffffffff)); w21 = *(uint64_t *)(in+(0*59+21)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w20 >> 18) | (w21 << 46) & 0x7ffffffffffffff)); w22 = *(uint64_t *)(in+(0*59+22)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w21 >> 13) | (w22 << 51) & 0x7ffffffffffffff)); w23 = *(uint64_t *)(in+(0*59+23)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w22 >> 8) | (w23 << 56) & 0x7ffffffffffffff)); out[0*64+25] = (start += zigzagdec64((w23 >> 3) & 0x7ffffffffffffff)); w24 = *(uint64_t *)(in+(0*59+24)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w23 >> 62) | (w24 << 2) & 0x7ffffffffffffff)); w25 = *(uint64_t *)(in+(0*59+25)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w24 >> 57) | (w25 << 7) & 0x7ffffffffffffff)); w26 = *(uint64_t *)(in+(0*59+26)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w25 >> 52) | (w26 << 12) & 0x7ffffffffffffff)); w27 = *(uint64_t *)(in+(0*59+27)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w26 >> 47) | (w27 << 17) & 0x7ffffffffffffff)); w28 = *(uint64_t *)(in+(0*59+28)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w27 >> 42) | (w28 << 22) & 0x7ffffffffffffff)); w29 = *(uint32_t *)(in+(0*59+29)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w28 >> 37) | (w29 << 27) & 0x7ffffffffffffff));;}; out += 32; in += 59*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_60(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*60)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += zigzagdec64((w0 ) & 0xfffffffffffffff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*16+ 1] = (start += zigzagdec64((w0 >> 60) | (w1 << 4) & 0xfffffffffffffff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*16+ 2] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0xfffffffffffffff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*16+ 3] = (start += zigzagdec64((w2 >> 52) | (w3 << 12) & 0xfffffffffffffff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*16+ 4] = (start += zigzagdec64((w3 >> 48) | (w4 << 16) & 0xfffffffffffffff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*16+ 5] = (start += zigzagdec64((w4 >> 44) | (w5 << 20) & 0xfffffffffffffff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*16+ 6] = (start += zigzagdec64((w5 >> 40) | (w6 << 24) & 0xfffffffffffffff)); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*16+ 7] = (start += zigzagdec64((w6 >> 36) | (w7 << 28) & 0xfffffffffffffff)); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*16+ 8] = (start += zigzagdec64((w7 >> 32) | (w8 << 32) & 0xfffffffffffffff)); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*16+ 9] = (start += zigzagdec64((w8 >> 28) | (w9 << 36) & 0xfffffffffffffff)); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*16+10] = (start += zigzagdec64((w9 >> 24) | (w10 << 40) & 0xfffffffffffffff)); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*16+11] = (start += zigzagdec64((w10 >> 20) | (w11 << 44) & 0xfffffffffffffff)); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*16+12] = (start += zigzagdec64((w11 >> 16) | (w12 << 48) & 0xfffffffffffffff)); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*16+13] = (start += zigzagdec64((w12 >> 12) | (w13 << 52) & 0xfffffffffffffff)); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*16+14] = (start += zigzagdec64((w13 >> 8) | (w14 << 56) & 0xfffffffffffffff)); out[0*16+15] = (start += zigzagdec64((w14 >> 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(1*15+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += zigzagdec64((w0 ) & 0xfffffffffffffff)); w1 = *(uint64_t *)(in+(1*15+1)*8/sizeof(in[0])); out[1*16+ 1] = (start += zigzagdec64((w0 >> 60) | (w1 << 4) & 0xfffffffffffffff)); w2 = *(uint64_t *)(in+(1*15+2)*8/sizeof(in[0])); out[1*16+ 2] = (start += zigzagdec64((w1 >> 56) | (w2 << 8) & 0xfffffffffffffff)); w3 = *(uint64_t *)(in+(1*15+3)*8/sizeof(in[0])); out[1*16+ 3] = (start += zigzagdec64((w2 >> 52) | (w3 << 12) & 0xfffffffffffffff)); w4 = *(uint64_t *)(in+(1*15+4)*8/sizeof(in[0])); out[1*16+ 4] = (start += zigzagdec64((w3 >> 48) | (w4 << 16) & 0xfffffffffffffff)); w5 = *(uint64_t *)(in+(1*15+5)*8/sizeof(in[0])); out[1*16+ 5] = (start += zigzagdec64((w4 >> 44) | (w5 << 20) & 0xfffffffffffffff)); w6 = *(uint64_t *)(in+(1*15+6)*8/sizeof(in[0])); out[1*16+ 6] = (start += zigzagdec64((w5 >> 40) | (w6 << 24) & 0xfffffffffffffff)); w7 = *(uint64_t *)(in+(1*15+7)*8/sizeof(in[0])); out[1*16+ 7] = (start += zigzagdec64((w6 >> 36) | (w7 << 28) & 0xfffffffffffffff)); w8 = *(uint64_t *)(in+(1*15+8)*8/sizeof(in[0])); out[1*16+ 8] = (start += zigzagdec64((w7 >> 32) | (w8 << 32) & 0xfffffffffffffff)); w9 = *(uint64_t *)(in+(1*15+9)*8/sizeof(in[0])); out[1*16+ 9] = (start += zigzagdec64((w8 >> 28) | (w9 << 36) & 0xfffffffffffffff)); w10 = *(uint64_t *)(in+(1*15+10)*8/sizeof(in[0])); out[1*16+10] = (start += zigzagdec64((w9 >> 24) | (w10 << 40) & 0xfffffffffffffff)); w11 = *(uint64_t *)(in+(1*15+11)*8/sizeof(in[0])); out[1*16+11] = (start += zigzagdec64((w10 >> 20) | (w11 << 44) & 0xfffffffffffffff)); w12 = *(uint64_t *)(in+(1*15+12)*8/sizeof(in[0])); out[1*16+12] = (start += zigzagdec64((w11 >> 16) | (w12 << 48) & 0xfffffffffffffff)); w13 = *(uint64_t *)(in+(1*15+13)*8/sizeof(in[0])); out[1*16+13] = (start += zigzagdec64((w12 >> 12) | (w13 << 52) & 0xfffffffffffffff)); w14 = *(uint64_t *)(in+(1*15+14)*8/sizeof(in[0])); out[1*16+14] = (start += zigzagdec64((w13 >> 8) | (w14 << 56) & 0xfffffffffffffff)); out[1*16+15] = (start += zigzagdec64((w14 >> 4)));;}; out += 32; in += 60*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_61(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*61)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30; w0 = *(uint64_t *)(in+(0*61+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x1fffffffffffffff)); w1 = *(uint64_t *)(in+(0*61+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 61) | (w1 << 3) & 0x1fffffffffffffff)); w2 = *(uint64_t *)(in+(0*61+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w1 >> 58) | (w2 << 6) & 0x1fffffffffffffff)); w3 = *(uint64_t *)(in+(0*61+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w2 >> 55) | (w3 << 9) & 0x1fffffffffffffff)); w4 = *(uint64_t *)(in+(0*61+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w3 >> 52) | (w4 << 12) & 0x1fffffffffffffff)); w5 = *(uint64_t *)(in+(0*61+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w4 >> 49) | (w5 << 15) & 0x1fffffffffffffff)); w6 = *(uint64_t *)(in+(0*61+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w5 >> 46) | (w6 << 18) & 0x1fffffffffffffff)); w7 = *(uint64_t *)(in+(0*61+7)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w6 >> 43) | (w7 << 21) & 0x1fffffffffffffff)); w8 = *(uint64_t *)(in+(0*61+8)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w7 >> 40) | (w8 << 24) & 0x1fffffffffffffff)); w9 = *(uint64_t *)(in+(0*61+9)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w8 >> 37) | (w9 << 27) & 0x1fffffffffffffff)); w10 = *(uint64_t *)(in+(0*61+10)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w9 >> 34) | (w10 << 30) & 0x1fffffffffffffff)); w11 = *(uint64_t *)(in+(0*61+11)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w10 >> 31) | (w11 << 33) & 0x1fffffffffffffff)); w12 = *(uint64_t *)(in+(0*61+12)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w11 >> 28) | (w12 << 36) & 0x1fffffffffffffff)); w13 = *(uint64_t *)(in+(0*61+13)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w12 >> 25) | (w13 << 39) & 0x1fffffffffffffff)); w14 = *(uint64_t *)(in+(0*61+14)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w13 >> 22) | (w14 << 42) & 0x1fffffffffffffff)); w15 = *(uint64_t *)(in+(0*61+15)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w14 >> 19) | (w15 << 45) & 0x1fffffffffffffff)); w16 = *(uint64_t *)(in+(0*61+16)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w15 >> 16) | (w16 << 48) & 0x1fffffffffffffff)); w17 = *(uint64_t *)(in+(0*61+17)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w16 >> 13) | (w17 << 51) & 0x1fffffffffffffff)); w18 = *(uint64_t *)(in+(0*61+18)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w17 >> 10) | (w18 << 54) & 0x1fffffffffffffff)); w19 = *(uint64_t *)(in+(0*61+19)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w18 >> 7) | (w19 << 57) & 0x1fffffffffffffff)); w20 = *(uint64_t *)(in+(0*61+20)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w19 >> 4) | (w20 << 60) & 0x1fffffffffffffff)); out[0*64+21] = (start += zigzagdec64((w20 >> 1) & 0x1fffffffffffffff)); w21 = *(uint64_t *)(in+(0*61+21)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w20 >> 62) | (w21 << 2) & 0x1fffffffffffffff)); w22 = *(uint64_t *)(in+(0*61+22)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w21 >> 59) | (w22 << 5) & 0x1fffffffffffffff)); w23 = *(uint64_t *)(in+(0*61+23)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w22 >> 56) | (w23 << 8) & 0x1fffffffffffffff)); w24 = *(uint64_t *)(in+(0*61+24)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w23 >> 53) | (w24 << 11) & 0x1fffffffffffffff)); w25 = *(uint64_t *)(in+(0*61+25)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w24 >> 50) | (w25 << 14) & 0x1fffffffffffffff)); w26 = *(uint64_t *)(in+(0*61+26)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w25 >> 47) | (w26 << 17) & 0x1fffffffffffffff)); w27 = *(uint64_t *)(in+(0*61+27)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w26 >> 44) | (w27 << 20) & 0x1fffffffffffffff)); w28 = *(uint64_t *)(in+(0*61+28)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w27 >> 41) | (w28 << 23) & 0x1fffffffffffffff)); w29 = *(uint64_t *)(in+(0*61+29)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w28 >> 38) | (w29 << 26) & 0x1fffffffffffffff)); w30 = *(uint32_t *)(in+(0*61+30)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w29 >> 35) | (w30 << 29) & 0x1fffffffffffffff));;}; out += 32; in += 61*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_62(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*62)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += zigzagdec64((w0 ) & 0x3fffffffffffffff)); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += zigzagdec64((w0 >> 62) | (w1 << 2) & 0x3fffffffffffffff)); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += zigzagdec64((w1 >> 60) | (w2 << 4) & 0x3fffffffffffffff)); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*32+ 3] = (start += zigzagdec64((w2 >> 58) | (w3 << 6) & 0x3fffffffffffffff)); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*32+ 4] = (start += zigzagdec64((w3 >> 56) | (w4 << 8) & 0x3fffffffffffffff)); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*32+ 5] = (start += zigzagdec64((w4 >> 54) | (w5 << 10) & 0x3fffffffffffffff)); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*32+ 6] = (start += zigzagdec64((w5 >> 52) | (w6 << 12) & 0x3fffffffffffffff)); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*32+ 7] = (start += zigzagdec64((w6 >> 50) | (w7 << 14) & 0x3fffffffffffffff)); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*32+ 8] = (start += zigzagdec64((w7 >> 48) | (w8 << 16) & 0x3fffffffffffffff)); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*32+ 9] = (start += zigzagdec64((w8 >> 46) | (w9 << 18) & 0x3fffffffffffffff)); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*32+10] = (start += zigzagdec64((w9 >> 44) | (w10 << 20) & 0x3fffffffffffffff)); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*32+11] = (start += zigzagdec64((w10 >> 42) | (w11 << 22) & 0x3fffffffffffffff)); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*32+12] = (start += zigzagdec64((w11 >> 40) | (w12 << 24) & 0x3fffffffffffffff)); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*32+13] = (start += zigzagdec64((w12 >> 38) | (w13 << 26) & 0x3fffffffffffffff)); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*32+14] = (start += zigzagdec64((w13 >> 36) | (w14 << 28) & 0x3fffffffffffffff)); w15 = *(uint64_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*32+15] = (start += zigzagdec64((w14 >> 34) | (w15 << 30) & 0x3fffffffffffffff)); w16 = *(uint64_t *)(in+(0*31+16)*8/sizeof(in[0])); out[0*32+16] = (start += zigzagdec64((w15 >> 32) | (w16 << 32) & 0x3fffffffffffffff)); w17 = *(uint64_t *)(in+(0*31+17)*8/sizeof(in[0])); out[0*32+17] = (start += zigzagdec64((w16 >> 30) | (w17 << 34) & 0x3fffffffffffffff)); w18 = *(uint64_t *)(in+(0*31+18)*8/sizeof(in[0])); out[0*32+18] = (start += zigzagdec64((w17 >> 28) | (w18 << 36) & 0x3fffffffffffffff)); w19 = *(uint64_t *)(in+(0*31+19)*8/sizeof(in[0])); out[0*32+19] = (start += zigzagdec64((w18 >> 26) | (w19 << 38) & 0x3fffffffffffffff)); w20 = *(uint64_t *)(in+(0*31+20)*8/sizeof(in[0])); out[0*32+20] = (start += zigzagdec64((w19 >> 24) | (w20 << 40) & 0x3fffffffffffffff)); w21 = *(uint64_t *)(in+(0*31+21)*8/sizeof(in[0])); out[0*32+21] = (start += zigzagdec64((w20 >> 22) | (w21 << 42) & 0x3fffffffffffffff)); w22 = *(uint64_t *)(in+(0*31+22)*8/sizeof(in[0])); out[0*32+22] = (start += zigzagdec64((w21 >> 20) | (w22 << 44) & 0x3fffffffffffffff)); w23 = *(uint64_t *)(in+(0*31+23)*8/sizeof(in[0])); out[0*32+23] = (start += zigzagdec64((w22 >> 18) | (w23 << 46) & 0x3fffffffffffffff)); w24 = *(uint64_t *)(in+(0*31+24)*8/sizeof(in[0])); out[0*32+24] = (start += zigzagdec64((w23 >> 16) | (w24 << 48) & 0x3fffffffffffffff)); w25 = *(uint64_t *)(in+(0*31+25)*8/sizeof(in[0])); out[0*32+25] = (start += zigzagdec64((w24 >> 14) | (w25 << 50) & 0x3fffffffffffffff)); w26 = *(uint64_t *)(in+(0*31+26)*8/sizeof(in[0])); out[0*32+26] = (start += zigzagdec64((w25 >> 12) | (w26 << 52) & 0x3fffffffffffffff)); w27 = *(uint64_t *)(in+(0*31+27)*8/sizeof(in[0])); out[0*32+27] = (start += zigzagdec64((w26 >> 10) | (w27 << 54) & 0x3fffffffffffffff)); w28 = *(uint64_t *)(in+(0*31+28)*8/sizeof(in[0])); out[0*32+28] = (start += zigzagdec64((w27 >> 8) | (w28 << 56) & 0x3fffffffffffffff)); w29 = *(uint64_t *)(in+(0*31+29)*8/sizeof(in[0])); out[0*32+29] = (start += zigzagdec64((w28 >> 6) | (w29 << 58) & 0x3fffffffffffffff)); w30 = *(uint64_t *)(in+(0*31+30)*8/sizeof(in[0])); out[0*32+30] = (start += zigzagdec64((w29 >> 4) | (w30 << 60) & 0x3fffffffffffffff)); out[0*32+31] = (start += zigzagdec64((w30 >> 2)));;}; out += 32; in += 62*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_63(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*63)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(0*63+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += zigzagdec64((w0 ) & 0x7fffffffffffffff)); w1 = *(uint64_t *)(in+(0*63+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += zigzagdec64((w0 >> 63) | (w1 << 1) & 0x7fffffffffffffff)); w2 = *(uint64_t *)(in+(0*63+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += zigzagdec64((w1 >> 62) | (w2 << 2) & 0x7fffffffffffffff)); w3 = *(uint64_t *)(in+(0*63+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += zigzagdec64((w2 >> 61) | (w3 << 3) & 0x7fffffffffffffff)); w4 = *(uint64_t *)(in+(0*63+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += zigzagdec64((w3 >> 60) | (w4 << 4) & 0x7fffffffffffffff)); w5 = *(uint64_t *)(in+(0*63+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += zigzagdec64((w4 >> 59) | (w5 << 5) & 0x7fffffffffffffff)); w6 = *(uint64_t *)(in+(0*63+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += zigzagdec64((w5 >> 58) | (w6 << 6) & 0x7fffffffffffffff)); w7 = *(uint64_t *)(in+(0*63+7)*8/sizeof(in[0])); out[0*64+ 7] = (start += zigzagdec64((w6 >> 57) | (w7 << 7) & 0x7fffffffffffffff)); w8 = *(uint64_t *)(in+(0*63+8)*8/sizeof(in[0])); out[0*64+ 8] = (start += zigzagdec64((w7 >> 56) | (w8 << 8) & 0x7fffffffffffffff)); w9 = *(uint64_t *)(in+(0*63+9)*8/sizeof(in[0])); out[0*64+ 9] = (start += zigzagdec64((w8 >> 55) | (w9 << 9) & 0x7fffffffffffffff)); w10 = *(uint64_t *)(in+(0*63+10)*8/sizeof(in[0])); out[0*64+10] = (start += zigzagdec64((w9 >> 54) | (w10 << 10) & 0x7fffffffffffffff)); w11 = *(uint64_t *)(in+(0*63+11)*8/sizeof(in[0])); out[0*64+11] = (start += zigzagdec64((w10 >> 53) | (w11 << 11) & 0x7fffffffffffffff)); w12 = *(uint64_t *)(in+(0*63+12)*8/sizeof(in[0])); out[0*64+12] = (start += zigzagdec64((w11 >> 52) | (w12 << 12) & 0x7fffffffffffffff)); w13 = *(uint64_t *)(in+(0*63+13)*8/sizeof(in[0])); out[0*64+13] = (start += zigzagdec64((w12 >> 51) | (w13 << 13) & 0x7fffffffffffffff)); w14 = *(uint64_t *)(in+(0*63+14)*8/sizeof(in[0])); out[0*64+14] = (start += zigzagdec64((w13 >> 50) | (w14 << 14) & 0x7fffffffffffffff)); w15 = *(uint64_t *)(in+(0*63+15)*8/sizeof(in[0])); out[0*64+15] = (start += zigzagdec64((w14 >> 49) | (w15 << 15) & 0x7fffffffffffffff)); w16 = *(uint64_t *)(in+(0*63+16)*8/sizeof(in[0])); out[0*64+16] = (start += zigzagdec64((w15 >> 48) | (w16 << 16) & 0x7fffffffffffffff)); w17 = *(uint64_t *)(in+(0*63+17)*8/sizeof(in[0])); out[0*64+17] = (start += zigzagdec64((w16 >> 47) | (w17 << 17) & 0x7fffffffffffffff)); w18 = *(uint64_t *)(in+(0*63+18)*8/sizeof(in[0])); out[0*64+18] = (start += zigzagdec64((w17 >> 46) | (w18 << 18) & 0x7fffffffffffffff)); w19 = *(uint64_t *)(in+(0*63+19)*8/sizeof(in[0])); out[0*64+19] = (start += zigzagdec64((w18 >> 45) | (w19 << 19) & 0x7fffffffffffffff)); w20 = *(uint64_t *)(in+(0*63+20)*8/sizeof(in[0])); out[0*64+20] = (start += zigzagdec64((w19 >> 44) | (w20 << 20) & 0x7fffffffffffffff)); w21 = *(uint64_t *)(in+(0*63+21)*8/sizeof(in[0])); out[0*64+21] = (start += zigzagdec64((w20 >> 43) | (w21 << 21) & 0x7fffffffffffffff)); w22 = *(uint64_t *)(in+(0*63+22)*8/sizeof(in[0])); out[0*64+22] = (start += zigzagdec64((w21 >> 42) | (w22 << 22) & 0x7fffffffffffffff)); w23 = *(uint64_t *)(in+(0*63+23)*8/sizeof(in[0])); out[0*64+23] = (start += zigzagdec64((w22 >> 41) | (w23 << 23) & 0x7fffffffffffffff)); w24 = *(uint64_t *)(in+(0*63+24)*8/sizeof(in[0])); out[0*64+24] = (start += zigzagdec64((w23 >> 40) | (w24 << 24) & 0x7fffffffffffffff)); w25 = *(uint64_t *)(in+(0*63+25)*8/sizeof(in[0])); out[0*64+25] = (start += zigzagdec64((w24 >> 39) | (w25 << 25) & 0x7fffffffffffffff)); w26 = *(uint64_t *)(in+(0*63+26)*8/sizeof(in[0])); out[0*64+26] = (start += zigzagdec64((w25 >> 38) | (w26 << 26) & 0x7fffffffffffffff)); w27 = *(uint64_t *)(in+(0*63+27)*8/sizeof(in[0])); out[0*64+27] = (start += zigzagdec64((w26 >> 37) | (w27 << 27) & 0x7fffffffffffffff)); w28 = *(uint64_t *)(in+(0*63+28)*8/sizeof(in[0])); out[0*64+28] = (start += zigzagdec64((w27 >> 36) | (w28 << 28) & 0x7fffffffffffffff)); w29 = *(uint64_t *)(in+(0*63+29)*8/sizeof(in[0])); out[0*64+29] = (start += zigzagdec64((w28 >> 35) | (w29 << 29) & 0x7fffffffffffffff)); w30 = *(uint64_t *)(in+(0*63+30)*8/sizeof(in[0])); out[0*64+30] = (start += zigzagdec64((w29 >> 34) | (w30 << 30) & 0x7fffffffffffffff)); w31 = *(uint32_t *)(in+(0*63+31)*8/sizeof(in[0])); out[0*64+31] = (start += zigzagdec64((w30 >> 33) | (w31 << 31) & 0x7fffffffffffffff));;}; out += 32; in += 63*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitzunpack64_64(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*64)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(4*1+0)*8/sizeof(in[0])); out[4*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(5*1+0)*8/sizeof(in[0])); out[5*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(6*1+0)*8/sizeof(in[0])); out[6*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(7*1+0)*8/sizeof(in[0])); out[7*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(8*1+0)*8/sizeof(in[0])); out[8*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(9*1+0)*8/sizeof(in[0])); out[9*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(10*1+0)*8/sizeof(in[0])); out[10*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(11*1+0)*8/sizeof(in[0])); out[11*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(12*1+0)*8/sizeof(in[0])); out[12*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(13*1+0)*8/sizeof(in[0])); out[13*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(14*1+0)*8/sizeof(in[0])); out[14*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(15*1+0)*8/sizeof(in[0])); out[15*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(16*1+0)*8/sizeof(in[0])); out[16*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(17*1+0)*8/sizeof(in[0])); out[17*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(18*1+0)*8/sizeof(in[0])); out[18*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(19*1+0)*8/sizeof(in[0])); out[19*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(20*1+0)*8/sizeof(in[0])); out[20*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(21*1+0)*8/sizeof(in[0])); out[21*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(22*1+0)*8/sizeof(in[0])); out[22*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(23*1+0)*8/sizeof(in[0])); out[23*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(24*1+0)*8/sizeof(in[0])); out[24*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(25*1+0)*8/sizeof(in[0])); out[25*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(26*1+0)*8/sizeof(in[0])); out[26*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(27*1+0)*8/sizeof(in[0])); out[27*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(28*1+0)*8/sizeof(in[0])); out[28*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(29*1+0)*8/sizeof(in[0])); out[29*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(30*1+0)*8/sizeof(in[0])); out[30*1+ 0] = (start += zigzagdec64((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(31*1+0)*8/sizeof(in[0])); out[31*1+ 0] = (start += zigzagdec64((w0 )));;}; out += 32; in += 64*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D64 bitzunpacka64[] = {
  &bitzunpack64_0,
  &bitzunpack64_1,
  &bitzunpack64_2,
  &bitzunpack64_3,
  &bitzunpack64_4,
  &bitzunpack64_5,
  &bitzunpack64_6,
  &bitzunpack64_7,
  &bitzunpack64_8,
  &bitzunpack64_9,
  &bitzunpack64_10,
  &bitzunpack64_11,
  &bitzunpack64_12,
  &bitzunpack64_13,
  &bitzunpack64_14,
  &bitzunpack64_15,
  &bitzunpack64_16,
  &bitzunpack64_17,
  &bitzunpack64_18,
  &bitzunpack64_19,
  &bitzunpack64_20,
  &bitzunpack64_21,
  &bitzunpack64_22,
  &bitzunpack64_23,
  &bitzunpack64_24,
  &bitzunpack64_25,
  &bitzunpack64_26,
  &bitzunpack64_27,
  &bitzunpack64_28,
  &bitzunpack64_29,
  &bitzunpack64_30,
  &bitzunpack64_31,
  &bitzunpack64_32,
  &bitzunpack64_33,
  &bitzunpack64_34,
  &bitzunpack64_35,
  &bitzunpack64_36,
  &bitzunpack64_37,
  &bitzunpack64_38,
  &bitzunpack64_39,
  &bitzunpack64_40,
  &bitzunpack64_41,
  &bitzunpack64_42,
  &bitzunpack64_43,
  &bitzunpack64_44,
  &bitzunpack64_45,
  &bitzunpack64_46,
  &bitzunpack64_47,
  &bitzunpack64_48,
  &bitzunpack64_49,
  &bitzunpack64_50,
  &bitzunpack64_51,
  &bitzunpack64_52,
  &bitzunpack64_53,
  &bitzunpack64_54,
  &bitzunpack64_55,
  &bitzunpack64_56,
  &bitzunpack64_57,
  &bitzunpack64_58,
  &bitzunpack64_59,
  &bitzunpack64_60,
  &bitzunpack64_61,
  &bitzunpack64_62,
  &bitzunpack64_63,
  &bitzunpack64_64
};
unsigned char *bitzunpack64( const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start, unsigned b) { return bitzunpacka64[ b](in, n, out, start); }
unsigned char *bitfunpack8_0(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint8_t *out_ = out+n; do { { { out[0*0+ 0] = (start + (0)); out[0*0+ 1] = (start + (0)); out[0*0+ 2] = (start + (0)); out[0*0+ 3] = (start + (0)); out[0*0+ 4] = (start + (0)); out[0*0+ 5] = (start + (0)); out[0*0+ 6] = (start + (0)); out[0*0+ 7] = (start + (0)); out[0*0+ 8] = (start + (0)); out[0*0+ 9] = (start + (0)); out[0*0+10] = (start + (0)); out[0*0+11] = (start + (0)); out[0*0+12] = (start + (0)); out[0*0+13] = (start + (0)); out[0*0+14] = (start + (0)); out[0*0+15] = (start + (0)); out[0*0+16] = (start + (0)); out[0*0+17] = (start + (0)); out[0*0+18] = (start + (0)); out[0*0+19] = (start + (0)); out[0*0+20] = (start + (0)); out[0*0+21] = (start + (0)); out[0*0+22] = (start + (0)); out[0*0+23] = (start + (0)); out[0*0+24] = (start + (0)); out[0*0+25] = (start + (0)); out[0*0+26] = (start + (0)); out[0*0+27] = (start + (0)); out[0*0+28] = (start + (0)); out[0*0+29] = (start + (0)); out[0*0+30] = (start + (0)); out[0*0+31] = (start + (0));;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitfunpack8_1(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x1)); out[0*32+ 1] = (start + ((w0 >> 1) & 0x1)); out[0*32+ 2] = (start + ((w0 >> 2) & 0x1)); out[0*32+ 3] = (start + ((w0 >> 3) & 0x1)); out[0*32+ 4] = (start + ((w0 >> 4) & 0x1)); out[0*32+ 5] = (start + ((w0 >> 5) & 0x1)); out[0*32+ 6] = (start + ((w0 >> 6) & 0x1)); out[0*32+ 7] = (start + ((w0 >> 7) & 0x1)); out[0*32+ 8] = (start + ((w0 >> 8) & 0x1)); out[0*32+ 9] = (start + ((w0 >> 9) & 0x1)); out[0*32+10] = (start + ((w0 >> 10) & 0x1)); out[0*32+11] = (start + ((w0 >> 11) & 0x1)); out[0*32+12] = (start + ((w0 >> 12) & 0x1)); out[0*32+13] = (start + ((w0 >> 13) & 0x1)); out[0*32+14] = (start + ((w0 >> 14) & 0x1)); out[0*32+15] = (start + ((w0 >> 15) & 0x1)); out[0*32+16] = (start + ((w0 >> 16) & 0x1)); out[0*32+17] = (start + ((w0 >> 17) & 0x1)); out[0*32+18] = (start + ((w0 >> 18) & 0x1)); out[0*32+19] = (start + ((w0 >> 19) & 0x1)); out[0*32+20] = (start + ((w0 >> 20) & 0x1)); out[0*32+21] = (start + ((w0 >> 21) & 0x1)); out[0*32+22] = (start + ((w0 >> 22) & 0x1)); out[0*32+23] = (start + ((w0 >> 23) & 0x1)); out[0*32+24] = (start + ((w0 >> 24) & 0x1)); out[0*32+25] = (start + ((w0 >> 25) & 0x1)); out[0*32+26] = (start + ((w0 >> 26) & 0x1)); out[0*32+27] = (start + ((w0 >> 27) & 0x1)); out[0*32+28] = (start + ((w0 >> 28) & 0x1)); out[0*32+29] = (start + ((w0 >> 29) & 0x1)); out[0*32+30] = (start + ((w0 >> 30) & 0x1)); out[0*32+31] = (start + ((w0 >> 31)));;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack8_2(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3)); out[0*32+ 1] = (start + ((w0 >> 2) & 0x3)); out[0*32+ 2] = (start + ((w0 >> 4) & 0x3)); out[0*32+ 3] = (start + ((w0 >> 6) & 0x3)); out[0*32+ 4] = (start + ((w0 >> 8) & 0x3)); out[0*32+ 5] = (start + ((w0 >> 10) & 0x3)); out[0*32+ 6] = (start + ((w0 >> 12) & 0x3)); out[0*32+ 7] = (start + ((w0 >> 14) & 0x3)); out[0*32+ 8] = (start + ((w0 >> 16) & 0x3)); out[0*32+ 9] = (start + ((w0 >> 18) & 0x3)); out[0*32+10] = (start + ((w0 >> 20) & 0x3)); out[0*32+11] = (start + ((w0 >> 22) & 0x3)); out[0*32+12] = (start + ((w0 >> 24) & 0x3)); out[0*32+13] = (start + ((w0 >> 26) & 0x3)); out[0*32+14] = (start + ((w0 >> 28) & 0x3)); out[0*32+15] = (start + ((w0 >> 30) & 0x3)); out[0*32+16] = (start + ((w0 >> 32) & 0x3)); out[0*32+17] = (start + ((w0 >> 34) & 0x3)); out[0*32+18] = (start + ((w0 >> 36) & 0x3)); out[0*32+19] = (start + ((w0 >> 38) & 0x3)); out[0*32+20] = (start + ((w0 >> 40) & 0x3)); out[0*32+21] = (start + ((w0 >> 42) & 0x3)); out[0*32+22] = (start + ((w0 >> 44) & 0x3)); out[0*32+23] = (start + ((w0 >> 46) & 0x3)); out[0*32+24] = (start + ((w0 >> 48) & 0x3)); out[0*32+25] = (start + ((w0 >> 50) & 0x3)); out[0*32+26] = (start + ((w0 >> 52) & 0x3)); out[0*32+27] = (start + ((w0 >> 54) & 0x3)); out[0*32+28] = (start + ((w0 >> 56) & 0x3)); out[0*32+29] = (start + ((w0 >> 58) & 0x3)); out[0*32+30] = (start + ((w0 >> 60) & 0x3)); out[0*32+31] = (start + ((w0 >> 62)));;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack8_3(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7)); out[0*64+ 1] = (start + ((w0 >> 3) & 0x7)); out[0*64+ 2] = (start + ((w0 >> 6) & 0x7)); out[0*64+ 3] = (start + ((w0 >> 9) & 0x7)); out[0*64+ 4] = (start + ((w0 >> 12) & 0x7)); out[0*64+ 5] = (start + ((w0 >> 15) & 0x7)); out[0*64+ 6] = (start + ((w0 >> 18) & 0x7)); out[0*64+ 7] = (start + ((w0 >> 21) & 0x7)); out[0*64+ 8] = (start + ((w0 >> 24) & 0x7)); out[0*64+ 9] = (start + ((w0 >> 27) & 0x7)); out[0*64+10] = (start + ((w0 >> 30) & 0x7)); out[0*64+11] = (start + ((w0 >> 33) & 0x7)); out[0*64+12] = (start + ((w0 >> 36) & 0x7)); out[0*64+13] = (start + ((w0 >> 39) & 0x7)); out[0*64+14] = (start + ((w0 >> 42) & 0x7)); out[0*64+15] = (start + ((w0 >> 45) & 0x7)); out[0*64+16] = (start + ((w0 >> 48) & 0x7)); out[0*64+17] = (start + ((w0 >> 51) & 0x7)); out[0*64+18] = (start + ((w0 >> 54) & 0x7)); out[0*64+19] = (start + ((w0 >> 57) & 0x7)); out[0*64+20] = (start + ((w0 >> 60) & 0x7)); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start + ((w0 >> 63) | (w1 << 1) & 0x7)); out[0*64+22] = (start + ((w1 >> 2) & 0x7)); out[0*64+23] = (start + ((w1 >> 5) & 0x7)); out[0*64+24] = (start + ((w1 >> 8) & 0x7)); out[0*64+25] = (start + ((w1 >> 11) & 0x7)); out[0*64+26] = (start + ((w1 >> 14) & 0x7)); out[0*64+27] = (start + ((w1 >> 17) & 0x7)); out[0*64+28] = (start + ((w1 >> 20) & 0x7)); out[0*64+29] = (start + ((w1 >> 23) & 0x7)); out[0*64+30] = (start + ((w1 >> 26) & 0x7)); out[0*64+31] = (start + ((w1 >> 29) & 0x7));;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack8_4(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xf)); out[0*16+ 1] = (start + ((w0 >> 4) & 0xf)); out[0*16+ 2] = (start + ((w0 >> 8) & 0xf)); out[0*16+ 3] = (start + ((w0 >> 12) & 0xf)); out[0*16+ 4] = (start + ((w0 >> 16) & 0xf)); out[0*16+ 5] = (start + ((w0 >> 20) & 0xf)); out[0*16+ 6] = (start + ((w0 >> 24) & 0xf)); out[0*16+ 7] = (start + ((w0 >> 28) & 0xf)); out[0*16+ 8] = (start + ((w0 >> 32) & 0xf)); out[0*16+ 9] = (start + ((w0 >> 36) & 0xf)); out[0*16+10] = (start + ((w0 >> 40) & 0xf)); out[0*16+11] = (start + ((w0 >> 44) & 0xf)); out[0*16+12] = (start + ((w0 >> 48) & 0xf)); out[0*16+13] = (start + ((w0 >> 52) & 0xf)); out[0*16+14] = (start + ((w0 >> 56) & 0xf)); out[0*16+15] = (start + ((w0 >> 60)));;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xf)); out[1*16+ 1] = (start + ((w0 >> 4) & 0xf)); out[1*16+ 2] = (start + ((w0 >> 8) & 0xf)); out[1*16+ 3] = (start + ((w0 >> 12) & 0xf)); out[1*16+ 4] = (start + ((w0 >> 16) & 0xf)); out[1*16+ 5] = (start + ((w0 >> 20) & 0xf)); out[1*16+ 6] = (start + ((w0 >> 24) & 0xf)); out[1*16+ 7] = (start + ((w0 >> 28) & 0xf)); out[1*16+ 8] = (start + ((w0 >> 32) & 0xf)); out[1*16+ 9] = (start + ((w0 >> 36) & 0xf)); out[1*16+10] = (start + ((w0 >> 40) & 0xf)); out[1*16+11] = (start + ((w0 >> 44) & 0xf)); out[1*16+12] = (start + ((w0 >> 48) & 0xf)); out[1*16+13] = (start + ((w0 >> 52) & 0xf)); out[1*16+14] = (start + ((w0 >> 56) & 0xf)); out[1*16+15] = (start + ((w0 >> 60)));;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack8_5(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1f)); out[0*64+ 1] = (start + ((w0 >> 5) & 0x1f)); out[0*64+ 2] = (start + ((w0 >> 10) & 0x1f)); out[0*64+ 3] = (start + ((w0 >> 15) & 0x1f)); out[0*64+ 4] = (start + ((w0 >> 20) & 0x1f)); out[0*64+ 5] = (start + ((w0 >> 25) & 0x1f)); out[0*64+ 6] = (start + ((w0 >> 30) & 0x1f)); out[0*64+ 7] = (start + ((w0 >> 35) & 0x1f)); out[0*64+ 8] = (start + ((w0 >> 40) & 0x1f)); out[0*64+ 9] = (start + ((w0 >> 45) & 0x1f)); out[0*64+10] = (start + ((w0 >> 50) & 0x1f)); out[0*64+11] = (start + ((w0 >> 55) & 0x1f)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start + ((w0 >> 60) | (w1 << 4) & 0x1f)); out[0*64+13] = (start + ((w1 >> 1) & 0x1f)); out[0*64+14] = (start + ((w1 >> 6) & 0x1f)); out[0*64+15] = (start + ((w1 >> 11) & 0x1f)); out[0*64+16] = (start + ((w1 >> 16) & 0x1f)); out[0*64+17] = (start + ((w1 >> 21) & 0x1f)); out[0*64+18] = (start + ((w1 >> 26) & 0x1f)); out[0*64+19] = (start + ((w1 >> 31) & 0x1f)); out[0*64+20] = (start + ((w1 >> 36) & 0x1f)); out[0*64+21] = (start + ((w1 >> 41) & 0x1f)); out[0*64+22] = (start + ((w1 >> 46) & 0x1f)); out[0*64+23] = (start + ((w1 >> 51) & 0x1f)); out[0*64+24] = (start + ((w1 >> 56) & 0x1f)); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start + ((w1 >> 61) | (w2 << 3) & 0x1f)); out[0*64+26] = (start + ((w2 >> 2) & 0x1f)); out[0*64+27] = (start + ((w2 >> 7) & 0x1f)); out[0*64+28] = (start + ((w2 >> 12) & 0x1f)); out[0*64+29] = (start + ((w2 >> 17) & 0x1f)); out[0*64+30] = (start + ((w2 >> 22) & 0x1f)); out[0*64+31] = (start + ((w2 >> 27) & 0x1f));;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack8_6(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3f)); out[0*32+ 1] = (start + ((w0 >> 6) & 0x3f)); out[0*32+ 2] = (start + ((w0 >> 12) & 0x3f)); out[0*32+ 3] = (start + ((w0 >> 18) & 0x3f)); out[0*32+ 4] = (start + ((w0 >> 24) & 0x3f)); out[0*32+ 5] = (start + ((w0 >> 30) & 0x3f)); out[0*32+ 6] = (start + ((w0 >> 36) & 0x3f)); out[0*32+ 7] = (start + ((w0 >> 42) & 0x3f)); out[0*32+ 8] = (start + ((w0 >> 48) & 0x3f)); out[0*32+ 9] = (start + ((w0 >> 54) & 0x3f)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start + ((w0 >> 60) | (w1 << 4) & 0x3f)); out[0*32+11] = (start + ((w1 >> 2) & 0x3f)); out[0*32+12] = (start + ((w1 >> 8) & 0x3f)); out[0*32+13] = (start + ((w1 >> 14) & 0x3f)); out[0*32+14] = (start + ((w1 >> 20) & 0x3f)); out[0*32+15] = (start + ((w1 >> 26) & 0x3f)); out[0*32+16] = (start + ((w1 >> 32) & 0x3f)); out[0*32+17] = (start + ((w1 >> 38) & 0x3f)); out[0*32+18] = (start + ((w1 >> 44) & 0x3f)); out[0*32+19] = (start + ((w1 >> 50) & 0x3f)); out[0*32+20] = (start + ((w1 >> 56) & 0x3f)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start + ((w1 >> 62) | (w2 << 2) & 0x3f)); out[0*32+22] = (start + ((w2 >> 4) & 0x3f)); out[0*32+23] = (start + ((w2 >> 10) & 0x3f)); out[0*32+24] = (start + ((w2 >> 16) & 0x3f)); out[0*32+25] = (start + ((w2 >> 22) & 0x3f)); out[0*32+26] = (start + ((w2 >> 28) & 0x3f)); out[0*32+27] = (start + ((w2 >> 34) & 0x3f)); out[0*32+28] = (start + ((w2 >> 40) & 0x3f)); out[0*32+29] = (start + ((w2 >> 46) & 0x3f)); out[0*32+30] = (start + ((w2 >> 52) & 0x3f)); out[0*32+31] = (start + ((w2 >> 58)));;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack8_7(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7f)); out[0*64+ 1] = (start + ((w0 >> 7) & 0x7f)); out[0*64+ 2] = (start + ((w0 >> 14) & 0x7f)); out[0*64+ 3] = (start + ((w0 >> 21) & 0x7f)); out[0*64+ 4] = (start + ((w0 >> 28) & 0x7f)); out[0*64+ 5] = (start + ((w0 >> 35) & 0x7f)); out[0*64+ 6] = (start + ((w0 >> 42) & 0x7f)); out[0*64+ 7] = (start + ((w0 >> 49) & 0x7f)); out[0*64+ 8] = (start + ((w0 >> 56) & 0x7f)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w0 >> 63) | (w1 << 1) & 0x7f)); out[0*64+10] = (start + ((w1 >> 6) & 0x7f)); out[0*64+11] = (start + ((w1 >> 13) & 0x7f)); out[0*64+12] = (start + ((w1 >> 20) & 0x7f)); out[0*64+13] = (start + ((w1 >> 27) & 0x7f)); out[0*64+14] = (start + ((w1 >> 34) & 0x7f)); out[0*64+15] = (start + ((w1 >> 41) & 0x7f)); out[0*64+16] = (start + ((w1 >> 48) & 0x7f)); out[0*64+17] = (start + ((w1 >> 55) & 0x7f)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start + ((w1 >> 62) | (w2 << 2) & 0x7f)); out[0*64+19] = (start + ((w2 >> 5) & 0x7f)); out[0*64+20] = (start + ((w2 >> 12) & 0x7f)); out[0*64+21] = (start + ((w2 >> 19) & 0x7f)); out[0*64+22] = (start + ((w2 >> 26) & 0x7f)); out[0*64+23] = (start + ((w2 >> 33) & 0x7f)); out[0*64+24] = (start + ((w2 >> 40) & 0x7f)); out[0*64+25] = (start + ((w2 >> 47) & 0x7f)); out[0*64+26] = (start + ((w2 >> 54) & 0x7f)); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start + ((w2 >> 61) | (w3 << 3) & 0x7f)); out[0*64+28] = (start + ((w3 >> 4) & 0x7f)); out[0*64+29] = (start + ((w3 >> 11) & 0x7f)); out[0*64+30] = (start + ((w3 >> 18) & 0x7f)); out[0*64+31] = (start + ((w3 >> 25) & 0x7f));;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack8_8(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start + ((w0 ) & 0xff)); out[0*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[0*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[0*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[0*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[0*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[0*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[0*8+ 7] = (start + ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start + ((w0 ) & 0xff)); out[1*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[1*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[1*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[1*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[1*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[1*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[1*8+ 7] = (start + ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start + ((w0 ) & 0xff)); out[2*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[2*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[2*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[2*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[2*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[2*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[2*8+ 7] = (start + ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start + ((w0 ) & 0xff)); out[3*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[3*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[3*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[3*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[3*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[3*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[3*8+ 7] = (start + ((w0 >> 56)));;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D8 bitfunpacka8[] = {
  &bitfunpack8_0,
  &bitfunpack8_1,
  &bitfunpack8_2,
  &bitfunpack8_3,
  &bitfunpack8_4,
  &bitfunpack8_5,
  &bitfunpack8_6,
  &bitfunpack8_7,
  &bitfunpack8_8
};
unsigned char *bitfunpack8( const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start, unsigned b) { return bitfunpacka8[ b](in, n, out, start); }
unsigned char *bitfunpack16_0(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint16_t *out_ = out+n; do { { { out[0*0+ 0] = (start + (0)); out[0*0+ 1] = (start + (0)); out[0*0+ 2] = (start + (0)); out[0*0+ 3] = (start + (0)); out[0*0+ 4] = (start + (0)); out[0*0+ 5] = (start + (0)); out[0*0+ 6] = (start + (0)); out[0*0+ 7] = (start + (0)); out[0*0+ 8] = (start + (0)); out[0*0+ 9] = (start + (0)); out[0*0+10] = (start + (0)); out[0*0+11] = (start + (0)); out[0*0+12] = (start + (0)); out[0*0+13] = (start + (0)); out[0*0+14] = (start + (0)); out[0*0+15] = (start + (0)); out[0*0+16] = (start + (0)); out[0*0+17] = (start + (0)); out[0*0+18] = (start + (0)); out[0*0+19] = (start + (0)); out[0*0+20] = (start + (0)); out[0*0+21] = (start + (0)); out[0*0+22] = (start + (0)); out[0*0+23] = (start + (0)); out[0*0+24] = (start + (0)); out[0*0+25] = (start + (0)); out[0*0+26] = (start + (0)); out[0*0+27] = (start + (0)); out[0*0+28] = (start + (0)); out[0*0+29] = (start + (0)); out[0*0+30] = (start + (0)); out[0*0+31] = (start + (0));;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitfunpack16_1(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x1)); out[0*32+ 1] = (start + ((w0 >> 1) & 0x1)); out[0*32+ 2] = (start + ((w0 >> 2) & 0x1)); out[0*32+ 3] = (start + ((w0 >> 3) & 0x1)); out[0*32+ 4] = (start + ((w0 >> 4) & 0x1)); out[0*32+ 5] = (start + ((w0 >> 5) & 0x1)); out[0*32+ 6] = (start + ((w0 >> 6) & 0x1)); out[0*32+ 7] = (start + ((w0 >> 7) & 0x1)); out[0*32+ 8] = (start + ((w0 >> 8) & 0x1)); out[0*32+ 9] = (start + ((w0 >> 9) & 0x1)); out[0*32+10] = (start + ((w0 >> 10) & 0x1)); out[0*32+11] = (start + ((w0 >> 11) & 0x1)); out[0*32+12] = (start + ((w0 >> 12) & 0x1)); out[0*32+13] = (start + ((w0 >> 13) & 0x1)); out[0*32+14] = (start + ((w0 >> 14) & 0x1)); out[0*32+15] = (start + ((w0 >> 15) & 0x1)); out[0*32+16] = (start + ((w0 >> 16) & 0x1)); out[0*32+17] = (start + ((w0 >> 17) & 0x1)); out[0*32+18] = (start + ((w0 >> 18) & 0x1)); out[0*32+19] = (start + ((w0 >> 19) & 0x1)); out[0*32+20] = (start + ((w0 >> 20) & 0x1)); out[0*32+21] = (start + ((w0 >> 21) & 0x1)); out[0*32+22] = (start + ((w0 >> 22) & 0x1)); out[0*32+23] = (start + ((w0 >> 23) & 0x1)); out[0*32+24] = (start + ((w0 >> 24) & 0x1)); out[0*32+25] = (start + ((w0 >> 25) & 0x1)); out[0*32+26] = (start + ((w0 >> 26) & 0x1)); out[0*32+27] = (start + ((w0 >> 27) & 0x1)); out[0*32+28] = (start + ((w0 >> 28) & 0x1)); out[0*32+29] = (start + ((w0 >> 29) & 0x1)); out[0*32+30] = (start + ((w0 >> 30) & 0x1)); out[0*32+31] = (start + ((w0 >> 31)));;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_2(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3)); out[0*32+ 1] = (start + ((w0 >> 2) & 0x3)); out[0*32+ 2] = (start + ((w0 >> 4) & 0x3)); out[0*32+ 3] = (start + ((w0 >> 6) & 0x3)); out[0*32+ 4] = (start + ((w0 >> 8) & 0x3)); out[0*32+ 5] = (start + ((w0 >> 10) & 0x3)); out[0*32+ 6] = (start + ((w0 >> 12) & 0x3)); out[0*32+ 7] = (start + ((w0 >> 14) & 0x3)); out[0*32+ 8] = (start + ((w0 >> 16) & 0x3)); out[0*32+ 9] = (start + ((w0 >> 18) & 0x3)); out[0*32+10] = (start + ((w0 >> 20) & 0x3)); out[0*32+11] = (start + ((w0 >> 22) & 0x3)); out[0*32+12] = (start + ((w0 >> 24) & 0x3)); out[0*32+13] = (start + ((w0 >> 26) & 0x3)); out[0*32+14] = (start + ((w0 >> 28) & 0x3)); out[0*32+15] = (start + ((w0 >> 30) & 0x3)); out[0*32+16] = (start + ((w0 >> 32) & 0x3)); out[0*32+17] = (start + ((w0 >> 34) & 0x3)); out[0*32+18] = (start + ((w0 >> 36) & 0x3)); out[0*32+19] = (start + ((w0 >> 38) & 0x3)); out[0*32+20] = (start + ((w0 >> 40) & 0x3)); out[0*32+21] = (start + ((w0 >> 42) & 0x3)); out[0*32+22] = (start + ((w0 >> 44) & 0x3)); out[0*32+23] = (start + ((w0 >> 46) & 0x3)); out[0*32+24] = (start + ((w0 >> 48) & 0x3)); out[0*32+25] = (start + ((w0 >> 50) & 0x3)); out[0*32+26] = (start + ((w0 >> 52) & 0x3)); out[0*32+27] = (start + ((w0 >> 54) & 0x3)); out[0*32+28] = (start + ((w0 >> 56) & 0x3)); out[0*32+29] = (start + ((w0 >> 58) & 0x3)); out[0*32+30] = (start + ((w0 >> 60) & 0x3)); out[0*32+31] = (start + ((w0 >> 62)));;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_3(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7)); out[0*64+ 1] = (start + ((w0 >> 3) & 0x7)); out[0*64+ 2] = (start + ((w0 >> 6) & 0x7)); out[0*64+ 3] = (start + ((w0 >> 9) & 0x7)); out[0*64+ 4] = (start + ((w0 >> 12) & 0x7)); out[0*64+ 5] = (start + ((w0 >> 15) & 0x7)); out[0*64+ 6] = (start + ((w0 >> 18) & 0x7)); out[0*64+ 7] = (start + ((w0 >> 21) & 0x7)); out[0*64+ 8] = (start + ((w0 >> 24) & 0x7)); out[0*64+ 9] = (start + ((w0 >> 27) & 0x7)); out[0*64+10] = (start + ((w0 >> 30) & 0x7)); out[0*64+11] = (start + ((w0 >> 33) & 0x7)); out[0*64+12] = (start + ((w0 >> 36) & 0x7)); out[0*64+13] = (start + ((w0 >> 39) & 0x7)); out[0*64+14] = (start + ((w0 >> 42) & 0x7)); out[0*64+15] = (start + ((w0 >> 45) & 0x7)); out[0*64+16] = (start + ((w0 >> 48) & 0x7)); out[0*64+17] = (start + ((w0 >> 51) & 0x7)); out[0*64+18] = (start + ((w0 >> 54) & 0x7)); out[0*64+19] = (start + ((w0 >> 57) & 0x7)); out[0*64+20] = (start + ((w0 >> 60) & 0x7)); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start + ((w0 >> 63) | (w1 << 1) & 0x7)); out[0*64+22] = (start + ((w1 >> 2) & 0x7)); out[0*64+23] = (start + ((w1 >> 5) & 0x7)); out[0*64+24] = (start + ((w1 >> 8) & 0x7)); out[0*64+25] = (start + ((w1 >> 11) & 0x7)); out[0*64+26] = (start + ((w1 >> 14) & 0x7)); out[0*64+27] = (start + ((w1 >> 17) & 0x7)); out[0*64+28] = (start + ((w1 >> 20) & 0x7)); out[0*64+29] = (start + ((w1 >> 23) & 0x7)); out[0*64+30] = (start + ((w1 >> 26) & 0x7)); out[0*64+31] = (start + ((w1 >> 29) & 0x7));;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_4(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xf)); out[0*16+ 1] = (start + ((w0 >> 4) & 0xf)); out[0*16+ 2] = (start + ((w0 >> 8) & 0xf)); out[0*16+ 3] = (start + ((w0 >> 12) & 0xf)); out[0*16+ 4] = (start + ((w0 >> 16) & 0xf)); out[0*16+ 5] = (start + ((w0 >> 20) & 0xf)); out[0*16+ 6] = (start + ((w0 >> 24) & 0xf)); out[0*16+ 7] = (start + ((w0 >> 28) & 0xf)); out[0*16+ 8] = (start + ((w0 >> 32) & 0xf)); out[0*16+ 9] = (start + ((w0 >> 36) & 0xf)); out[0*16+10] = (start + ((w0 >> 40) & 0xf)); out[0*16+11] = (start + ((w0 >> 44) & 0xf)); out[0*16+12] = (start + ((w0 >> 48) & 0xf)); out[0*16+13] = (start + ((w0 >> 52) & 0xf)); out[0*16+14] = (start + ((w0 >> 56) & 0xf)); out[0*16+15] = (start + ((w0 >> 60)));;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xf)); out[1*16+ 1] = (start + ((w0 >> 4) & 0xf)); out[1*16+ 2] = (start + ((w0 >> 8) & 0xf)); out[1*16+ 3] = (start + ((w0 >> 12) & 0xf)); out[1*16+ 4] = (start + ((w0 >> 16) & 0xf)); out[1*16+ 5] = (start + ((w0 >> 20) & 0xf)); out[1*16+ 6] = (start + ((w0 >> 24) & 0xf)); out[1*16+ 7] = (start + ((w0 >> 28) & 0xf)); out[1*16+ 8] = (start + ((w0 >> 32) & 0xf)); out[1*16+ 9] = (start + ((w0 >> 36) & 0xf)); out[1*16+10] = (start + ((w0 >> 40) & 0xf)); out[1*16+11] = (start + ((w0 >> 44) & 0xf)); out[1*16+12] = (start + ((w0 >> 48) & 0xf)); out[1*16+13] = (start + ((w0 >> 52) & 0xf)); out[1*16+14] = (start + ((w0 >> 56) & 0xf)); out[1*16+15] = (start + ((w0 >> 60)));;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_5(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1f)); out[0*64+ 1] = (start + ((w0 >> 5) & 0x1f)); out[0*64+ 2] = (start + ((w0 >> 10) & 0x1f)); out[0*64+ 3] = (start + ((w0 >> 15) & 0x1f)); out[0*64+ 4] = (start + ((w0 >> 20) & 0x1f)); out[0*64+ 5] = (start + ((w0 >> 25) & 0x1f)); out[0*64+ 6] = (start + ((w0 >> 30) & 0x1f)); out[0*64+ 7] = (start + ((w0 >> 35) & 0x1f)); out[0*64+ 8] = (start + ((w0 >> 40) & 0x1f)); out[0*64+ 9] = (start + ((w0 >> 45) & 0x1f)); out[0*64+10] = (start + ((w0 >> 50) & 0x1f)); out[0*64+11] = (start + ((w0 >> 55) & 0x1f)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start + ((w0 >> 60) | (w1 << 4) & 0x1f)); out[0*64+13] = (start + ((w1 >> 1) & 0x1f)); out[0*64+14] = (start + ((w1 >> 6) & 0x1f)); out[0*64+15] = (start + ((w1 >> 11) & 0x1f)); out[0*64+16] = (start + ((w1 >> 16) & 0x1f)); out[0*64+17] = (start + ((w1 >> 21) & 0x1f)); out[0*64+18] = (start + ((w1 >> 26) & 0x1f)); out[0*64+19] = (start + ((w1 >> 31) & 0x1f)); out[0*64+20] = (start + ((w1 >> 36) & 0x1f)); out[0*64+21] = (start + ((w1 >> 41) & 0x1f)); out[0*64+22] = (start + ((w1 >> 46) & 0x1f)); out[0*64+23] = (start + ((w1 >> 51) & 0x1f)); out[0*64+24] = (start + ((w1 >> 56) & 0x1f)); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start + ((w1 >> 61) | (w2 << 3) & 0x1f)); out[0*64+26] = (start + ((w2 >> 2) & 0x1f)); out[0*64+27] = (start + ((w2 >> 7) & 0x1f)); out[0*64+28] = (start + ((w2 >> 12) & 0x1f)); out[0*64+29] = (start + ((w2 >> 17) & 0x1f)); out[0*64+30] = (start + ((w2 >> 22) & 0x1f)); out[0*64+31] = (start + ((w2 >> 27) & 0x1f));;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_6(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3f)); out[0*32+ 1] = (start + ((w0 >> 6) & 0x3f)); out[0*32+ 2] = (start + ((w0 >> 12) & 0x3f)); out[0*32+ 3] = (start + ((w0 >> 18) & 0x3f)); out[0*32+ 4] = (start + ((w0 >> 24) & 0x3f)); out[0*32+ 5] = (start + ((w0 >> 30) & 0x3f)); out[0*32+ 6] = (start + ((w0 >> 36) & 0x3f)); out[0*32+ 7] = (start + ((w0 >> 42) & 0x3f)); out[0*32+ 8] = (start + ((w0 >> 48) & 0x3f)); out[0*32+ 9] = (start + ((w0 >> 54) & 0x3f)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start + ((w0 >> 60) | (w1 << 4) & 0x3f)); out[0*32+11] = (start + ((w1 >> 2) & 0x3f)); out[0*32+12] = (start + ((w1 >> 8) & 0x3f)); out[0*32+13] = (start + ((w1 >> 14) & 0x3f)); out[0*32+14] = (start + ((w1 >> 20) & 0x3f)); out[0*32+15] = (start + ((w1 >> 26) & 0x3f)); out[0*32+16] = (start + ((w1 >> 32) & 0x3f)); out[0*32+17] = (start + ((w1 >> 38) & 0x3f)); out[0*32+18] = (start + ((w1 >> 44) & 0x3f)); out[0*32+19] = (start + ((w1 >> 50) & 0x3f)); out[0*32+20] = (start + ((w1 >> 56) & 0x3f)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start + ((w1 >> 62) | (w2 << 2) & 0x3f)); out[0*32+22] = (start + ((w2 >> 4) & 0x3f)); out[0*32+23] = (start + ((w2 >> 10) & 0x3f)); out[0*32+24] = (start + ((w2 >> 16) & 0x3f)); out[0*32+25] = (start + ((w2 >> 22) & 0x3f)); out[0*32+26] = (start + ((w2 >> 28) & 0x3f)); out[0*32+27] = (start + ((w2 >> 34) & 0x3f)); out[0*32+28] = (start + ((w2 >> 40) & 0x3f)); out[0*32+29] = (start + ((w2 >> 46) & 0x3f)); out[0*32+30] = (start + ((w2 >> 52) & 0x3f)); out[0*32+31] = (start + ((w2 >> 58)));;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_7(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7f)); out[0*64+ 1] = (start + ((w0 >> 7) & 0x7f)); out[0*64+ 2] = (start + ((w0 >> 14) & 0x7f)); out[0*64+ 3] = (start + ((w0 >> 21) & 0x7f)); out[0*64+ 4] = (start + ((w0 >> 28) & 0x7f)); out[0*64+ 5] = (start + ((w0 >> 35) & 0x7f)); out[0*64+ 6] = (start + ((w0 >> 42) & 0x7f)); out[0*64+ 7] = (start + ((w0 >> 49) & 0x7f)); out[0*64+ 8] = (start + ((w0 >> 56) & 0x7f)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w0 >> 63) | (w1 << 1) & 0x7f)); out[0*64+10] = (start + ((w1 >> 6) & 0x7f)); out[0*64+11] = (start + ((w1 >> 13) & 0x7f)); out[0*64+12] = (start + ((w1 >> 20) & 0x7f)); out[0*64+13] = (start + ((w1 >> 27) & 0x7f)); out[0*64+14] = (start + ((w1 >> 34) & 0x7f)); out[0*64+15] = (start + ((w1 >> 41) & 0x7f)); out[0*64+16] = (start + ((w1 >> 48) & 0x7f)); out[0*64+17] = (start + ((w1 >> 55) & 0x7f)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start + ((w1 >> 62) | (w2 << 2) & 0x7f)); out[0*64+19] = (start + ((w2 >> 5) & 0x7f)); out[0*64+20] = (start + ((w2 >> 12) & 0x7f)); out[0*64+21] = (start + ((w2 >> 19) & 0x7f)); out[0*64+22] = (start + ((w2 >> 26) & 0x7f)); out[0*64+23] = (start + ((w2 >> 33) & 0x7f)); out[0*64+24] = (start + ((w2 >> 40) & 0x7f)); out[0*64+25] = (start + ((w2 >> 47) & 0x7f)); out[0*64+26] = (start + ((w2 >> 54) & 0x7f)); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start + ((w2 >> 61) | (w3 << 3) & 0x7f)); out[0*64+28] = (start + ((w3 >> 4) & 0x7f)); out[0*64+29] = (start + ((w3 >> 11) & 0x7f)); out[0*64+30] = (start + ((w3 >> 18) & 0x7f)); out[0*64+31] = (start + ((w3 >> 25) & 0x7f));;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_8(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start + ((w0 ) & 0xff)); out[0*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[0*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[0*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[0*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[0*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[0*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[0*8+ 7] = (start + ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start + ((w0 ) & 0xff)); out[1*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[1*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[1*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[1*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[1*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[1*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[1*8+ 7] = (start + ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start + ((w0 ) & 0xff)); out[2*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[2*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[2*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[2*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[2*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[2*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[2*8+ 7] = (start + ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start + ((w0 ) & 0xff)); out[3*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[3*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[3*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[3*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[3*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[3*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[3*8+ 7] = (start + ((w0 >> 56)));;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_9(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1ff)); out[0*64+ 1] = (start + ((w0 >> 9) & 0x1ff)); out[0*64+ 2] = (start + ((w0 >> 18) & 0x1ff)); out[0*64+ 3] = (start + ((w0 >> 27) & 0x1ff)); out[0*64+ 4] = (start + ((w0 >> 36) & 0x1ff)); out[0*64+ 5] = (start + ((w0 >> 45) & 0x1ff)); out[0*64+ 6] = (start + ((w0 >> 54) & 0x1ff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w0 >> 63) | (w1 << 1) & 0x1ff)); out[0*64+ 8] = (start + ((w1 >> 8) & 0x1ff)); out[0*64+ 9] = (start + ((w1 >> 17) & 0x1ff)); out[0*64+10] = (start + ((w1 >> 26) & 0x1ff)); out[0*64+11] = (start + ((w1 >> 35) & 0x1ff)); out[0*64+12] = (start + ((w1 >> 44) & 0x1ff)); out[0*64+13] = (start + ((w1 >> 53) & 0x1ff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (start + ((w1 >> 62) | (w2 << 2) & 0x1ff)); out[0*64+15] = (start + ((w2 >> 7) & 0x1ff)); out[0*64+16] = (start + ((w2 >> 16) & 0x1ff)); out[0*64+17] = (start + ((w2 >> 25) & 0x1ff)); out[0*64+18] = (start + ((w2 >> 34) & 0x1ff)); out[0*64+19] = (start + ((w2 >> 43) & 0x1ff)); out[0*64+20] = (start + ((w2 >> 52) & 0x1ff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (start + ((w2 >> 61) | (w3 << 3) & 0x1ff)); out[0*64+22] = (start + ((w3 >> 6) & 0x1ff)); out[0*64+23] = (start + ((w3 >> 15) & 0x1ff)); out[0*64+24] = (start + ((w3 >> 24) & 0x1ff)); out[0*64+25] = (start + ((w3 >> 33) & 0x1ff)); out[0*64+26] = (start + ((w3 >> 42) & 0x1ff)); out[0*64+27] = (start + ((w3 >> 51) & 0x1ff)); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (start + ((w3 >> 60) | (w4 << 4) & 0x1ff)); out[0*64+29] = (start + ((w4 >> 5) & 0x1ff)); out[0*64+30] = (start + ((w4 >> 14) & 0x1ff)); out[0*64+31] = (start + ((w4 >> 23) & 0x1ff));;}; out += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_10(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3ff)); out[0*32+ 1] = (start + ((w0 >> 10) & 0x3ff)); out[0*32+ 2] = (start + ((w0 >> 20) & 0x3ff)); out[0*32+ 3] = (start + ((w0 >> 30) & 0x3ff)); out[0*32+ 4] = (start + ((w0 >> 40) & 0x3ff)); out[0*32+ 5] = (start + ((w0 >> 50) & 0x3ff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (start + ((w0 >> 60) | (w1 << 4) & 0x3ff)); out[0*32+ 7] = (start + ((w1 >> 6) & 0x3ff)); out[0*32+ 8] = (start + ((w1 >> 16) & 0x3ff)); out[0*32+ 9] = (start + ((w1 >> 26) & 0x3ff)); out[0*32+10] = (start + ((w1 >> 36) & 0x3ff)); out[0*32+11] = (start + ((w1 >> 46) & 0x3ff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (start + ((w1 >> 56) | (w2 << 8) & 0x3ff)); out[0*32+13] = (start + ((w2 >> 2) & 0x3ff)); out[0*32+14] = (start + ((w2 >> 12) & 0x3ff)); out[0*32+15] = (start + ((w2 >> 22) & 0x3ff)); out[0*32+16] = (start + ((w2 >> 32) & 0x3ff)); out[0*32+17] = (start + ((w2 >> 42) & 0x3ff)); out[0*32+18] = (start + ((w2 >> 52) & 0x3ff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (start + ((w2 >> 62) | (w3 << 2) & 0x3ff)); out[0*32+20] = (start + ((w3 >> 8) & 0x3ff)); out[0*32+21] = (start + ((w3 >> 18) & 0x3ff)); out[0*32+22] = (start + ((w3 >> 28) & 0x3ff)); out[0*32+23] = (start + ((w3 >> 38) & 0x3ff)); out[0*32+24] = (start + ((w3 >> 48) & 0x3ff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (start + ((w3 >> 58) | (w4 << 6) & 0x3ff)); out[0*32+26] = (start + ((w4 >> 4) & 0x3ff)); out[0*32+27] = (start + ((w4 >> 14) & 0x3ff)); out[0*32+28] = (start + ((w4 >> 24) & 0x3ff)); out[0*32+29] = (start + ((w4 >> 34) & 0x3ff)); out[0*32+30] = (start + ((w4 >> 44) & 0x3ff)); out[0*32+31] = (start + ((w4 >> 54)));;}; out += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_11(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7ff)); out[0*64+ 1] = (start + ((w0 >> 11) & 0x7ff)); out[0*64+ 2] = (start + ((w0 >> 22) & 0x7ff)); out[0*64+ 3] = (start + ((w0 >> 33) & 0x7ff)); out[0*64+ 4] = (start + ((w0 >> 44) & 0x7ff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w0 >> 55) | (w1 << 9) & 0x7ff)); out[0*64+ 6] = (start + ((w1 >> 2) & 0x7ff)); out[0*64+ 7] = (start + ((w1 >> 13) & 0x7ff)); out[0*64+ 8] = (start + ((w1 >> 24) & 0x7ff)); out[0*64+ 9] = (start + ((w1 >> 35) & 0x7ff)); out[0*64+10] = (start + ((w1 >> 46) & 0x7ff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (start + ((w1 >> 57) | (w2 << 7) & 0x7ff)); out[0*64+12] = (start + ((w2 >> 4) & 0x7ff)); out[0*64+13] = (start + ((w2 >> 15) & 0x7ff)); out[0*64+14] = (start + ((w2 >> 26) & 0x7ff)); out[0*64+15] = (start + ((w2 >> 37) & 0x7ff)); out[0*64+16] = (start + ((w2 >> 48) & 0x7ff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (start + ((w2 >> 59) | (w3 << 5) & 0x7ff)); out[0*64+18] = (start + ((w3 >> 6) & 0x7ff)); out[0*64+19] = (start + ((w3 >> 17) & 0x7ff)); out[0*64+20] = (start + ((w3 >> 28) & 0x7ff)); out[0*64+21] = (start + ((w3 >> 39) & 0x7ff)); out[0*64+22] = (start + ((w3 >> 50) & 0x7ff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (start + ((w3 >> 61) | (w4 << 3) & 0x7ff)); out[0*64+24] = (start + ((w4 >> 8) & 0x7ff)); out[0*64+25] = (start + ((w4 >> 19) & 0x7ff)); out[0*64+26] = (start + ((w4 >> 30) & 0x7ff)); out[0*64+27] = (start + ((w4 >> 41) & 0x7ff)); out[0*64+28] = (start + ((w4 >> 52) & 0x7ff)); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (start + ((w4 >> 63) | (w5 << 1) & 0x7ff)); out[0*64+30] = (start + ((w5 >> 10) & 0x7ff)); out[0*64+31] = (start + ((w5 >> 21) & 0x7ff));;}; out += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_12(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xfff)); out[0*16+ 1] = (start + ((w0 >> 12) & 0xfff)); out[0*16+ 2] = (start + ((w0 >> 24) & 0xfff)); out[0*16+ 3] = (start + ((w0 >> 36) & 0xfff)); out[0*16+ 4] = (start + ((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (start + ((w0 >> 60) | (w1 << 4) & 0xfff)); out[0*16+ 6] = (start + ((w1 >> 8) & 0xfff)); out[0*16+ 7] = (start + ((w1 >> 20) & 0xfff)); out[0*16+ 8] = (start + ((w1 >> 32) & 0xfff)); out[0*16+ 9] = (start + ((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (start + ((w1 >> 56) | (w2 << 8) & 0xfff)); out[0*16+11] = (start + ((w2 >> 4) & 0xfff)); out[0*16+12] = (start + ((w2 >> 16) & 0xfff)); out[0*16+13] = (start + ((w2 >> 28) & 0xfff)); out[0*16+14] = (start + ((w2 >> 40) & 0xfff)); out[0*16+15] = (start + ((w2 >> 52)));;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xfff)); out[1*16+ 1] = (start + ((w0 >> 12) & 0xfff)); out[1*16+ 2] = (start + ((w0 >> 24) & 0xfff)); out[1*16+ 3] = (start + ((w0 >> 36) & 0xfff)); out[1*16+ 4] = (start + ((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (start + ((w0 >> 60) | (w1 << 4) & 0xfff)); out[1*16+ 6] = (start + ((w1 >> 8) & 0xfff)); out[1*16+ 7] = (start + ((w1 >> 20) & 0xfff)); out[1*16+ 8] = (start + ((w1 >> 32) & 0xfff)); out[1*16+ 9] = (start + ((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (start + ((w1 >> 56) | (w2 << 8) & 0xfff)); out[1*16+11] = (start + ((w2 >> 4) & 0xfff)); out[1*16+12] = (start + ((w2 >> 16) & 0xfff)); out[1*16+13] = (start + ((w2 >> 28) & 0xfff)); out[1*16+14] = (start + ((w2 >> 40) & 0xfff)); out[1*16+15] = (start + ((w2 >> 52)));;}; out += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_13(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1fff)); out[0*64+ 1] = (start + ((w0 >> 13) & 0x1fff)); out[0*64+ 2] = (start + ((w0 >> 26) & 0x1fff)); out[0*64+ 3] = (start + ((w0 >> 39) & 0x1fff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w0 >> 52) | (w1 << 12) & 0x1fff)); out[0*64+ 5] = (start + ((w1 >> 1) & 0x1fff)); out[0*64+ 6] = (start + ((w1 >> 14) & 0x1fff)); out[0*64+ 7] = (start + ((w1 >> 27) & 0x1fff)); out[0*64+ 8] = (start + ((w1 >> 40) & 0x1fff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w1 >> 53) | (w2 << 11) & 0x1fff)); out[0*64+10] = (start + ((w2 >> 2) & 0x1fff)); out[0*64+11] = (start + ((w2 >> 15) & 0x1fff)); out[0*64+12] = (start + ((w2 >> 28) & 0x1fff)); out[0*64+13] = (start + ((w2 >> 41) & 0x1fff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (start + ((w2 >> 54) | (w3 << 10) & 0x1fff)); out[0*64+15] = (start + ((w3 >> 3) & 0x1fff)); out[0*64+16] = (start + ((w3 >> 16) & 0x1fff)); out[0*64+17] = (start + ((w3 >> 29) & 0x1fff)); out[0*64+18] = (start + ((w3 >> 42) & 0x1fff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (start + ((w3 >> 55) | (w4 << 9) & 0x1fff)); out[0*64+20] = (start + ((w4 >> 4) & 0x1fff)); out[0*64+21] = (start + ((w4 >> 17) & 0x1fff)); out[0*64+22] = (start + ((w4 >> 30) & 0x1fff)); out[0*64+23] = (start + ((w4 >> 43) & 0x1fff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (start + ((w4 >> 56) | (w5 << 8) & 0x1fff)); out[0*64+25] = (start + ((w5 >> 5) & 0x1fff)); out[0*64+26] = (start + ((w5 >> 18) & 0x1fff)); out[0*64+27] = (start + ((w5 >> 31) & 0x1fff)); out[0*64+28] = (start + ((w5 >> 44) & 0x1fff)); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (start + ((w5 >> 57) | (w6 << 7) & 0x1fff)); out[0*64+30] = (start + ((w6 >> 6) & 0x1fff)); out[0*64+31] = (start + ((w6 >> 19) & 0x1fff));;}; out += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_14(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3fff)); out[0*32+ 1] = (start + ((w0 >> 14) & 0x3fff)); out[0*32+ 2] = (start + ((w0 >> 28) & 0x3fff)); out[0*32+ 3] = (start + ((w0 >> 42) & 0x3fff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (start + ((w0 >> 56) | (w1 << 8) & 0x3fff)); out[0*32+ 5] = (start + ((w1 >> 6) & 0x3fff)); out[0*32+ 6] = (start + ((w1 >> 20) & 0x3fff)); out[0*32+ 7] = (start + ((w1 >> 34) & 0x3fff)); out[0*32+ 8] = (start + ((w1 >> 48) & 0x3fff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (start + ((w1 >> 62) | (w2 << 2) & 0x3fff)); out[0*32+10] = (start + ((w2 >> 12) & 0x3fff)); out[0*32+11] = (start + ((w2 >> 26) & 0x3fff)); out[0*32+12] = (start + ((w2 >> 40) & 0x3fff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (start + ((w2 >> 54) | (w3 << 10) & 0x3fff)); out[0*32+14] = (start + ((w3 >> 4) & 0x3fff)); out[0*32+15] = (start + ((w3 >> 18) & 0x3fff)); out[0*32+16] = (start + ((w3 >> 32) & 0x3fff)); out[0*32+17] = (start + ((w3 >> 46) & 0x3fff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (start + ((w3 >> 60) | (w4 << 4) & 0x3fff)); out[0*32+19] = (start + ((w4 >> 10) & 0x3fff)); out[0*32+20] = (start + ((w4 >> 24) & 0x3fff)); out[0*32+21] = (start + ((w4 >> 38) & 0x3fff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (start + ((w4 >> 52) | (w5 << 12) & 0x3fff)); out[0*32+23] = (start + ((w5 >> 2) & 0x3fff)); out[0*32+24] = (start + ((w5 >> 16) & 0x3fff)); out[0*32+25] = (start + ((w5 >> 30) & 0x3fff)); out[0*32+26] = (start + ((w5 >> 44) & 0x3fff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (start + ((w5 >> 58) | (w6 << 6) & 0x3fff)); out[0*32+28] = (start + ((w6 >> 8) & 0x3fff)); out[0*32+29] = (start + ((w6 >> 22) & 0x3fff)); out[0*32+30] = (start + ((w6 >> 36) & 0x3fff)); out[0*32+31] = (start + ((w6 >> 50)));;}; out += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_15(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7fff)); out[0*64+ 1] = (start + ((w0 >> 15) & 0x7fff)); out[0*64+ 2] = (start + ((w0 >> 30) & 0x7fff)); out[0*64+ 3] = (start + ((w0 >> 45) & 0x7fff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w0 >> 60) | (w1 << 4) & 0x7fff)); out[0*64+ 5] = (start + ((w1 >> 11) & 0x7fff)); out[0*64+ 6] = (start + ((w1 >> 26) & 0x7fff)); out[0*64+ 7] = (start + ((w1 >> 41) & 0x7fff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w1 >> 56) | (w2 << 8) & 0x7fff)); out[0*64+ 9] = (start + ((w2 >> 7) & 0x7fff)); out[0*64+10] = (start + ((w2 >> 22) & 0x7fff)); out[0*64+11] = (start + ((w2 >> 37) & 0x7fff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (start + ((w2 >> 52) | (w3 << 12) & 0x7fff)); out[0*64+13] = (start + ((w3 >> 3) & 0x7fff)); out[0*64+14] = (start + ((w3 >> 18) & 0x7fff)); out[0*64+15] = (start + ((w3 >> 33) & 0x7fff)); out[0*64+16] = (start + ((w3 >> 48) & 0x7fff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (start + ((w3 >> 63) | (w4 << 1) & 0x7fff)); out[0*64+18] = (start + ((w4 >> 14) & 0x7fff)); out[0*64+19] = (start + ((w4 >> 29) & 0x7fff)); out[0*64+20] = (start + ((w4 >> 44) & 0x7fff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (start + ((w4 >> 59) | (w5 << 5) & 0x7fff)); out[0*64+22] = (start + ((w5 >> 10) & 0x7fff)); out[0*64+23] = (start + ((w5 >> 25) & 0x7fff)); out[0*64+24] = (start + ((w5 >> 40) & 0x7fff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (start + ((w5 >> 55) | (w6 << 9) & 0x7fff)); out[0*64+26] = (start + ((w6 >> 6) & 0x7fff)); out[0*64+27] = (start + ((w6 >> 21) & 0x7fff)); out[0*64+28] = (start + ((w6 >> 36) & 0x7fff)); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (start + ((w6 >> 51) | (w7 << 13) & 0x7fff)); out[0*64+30] = (start + ((w7 >> 2) & 0x7fff)); out[0*64+31] = (start + ((w7 >> 17) & 0x7fff));;}; out += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack16_16(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = (start + (*(uint16_t *)(in+0*8+ 0))); out[0*4+ 1] = (start + (*(uint16_t *)(in+0*8+ 2))); out[0*4+ 2] = (start + (*(uint16_t *)(in+0*8+ 4))); out[0*4+ 3] = (start + (*(uint16_t *)(in+0*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = (start + (*(uint16_t *)(in+1*8+ 0))); out[1*4+ 1] = (start + (*(uint16_t *)(in+1*8+ 2))); out[1*4+ 2] = (start + (*(uint16_t *)(in+1*8+ 4))); out[1*4+ 3] = (start + (*(uint16_t *)(in+1*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = (start + (*(uint16_t *)(in+2*8+ 0))); out[2*4+ 1] = (start + (*(uint16_t *)(in+2*8+ 2))); out[2*4+ 2] = (start + (*(uint16_t *)(in+2*8+ 4))); out[2*4+ 3] = (start + (*(uint16_t *)(in+2*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = (start + (*(uint16_t *)(in+3*8+ 0))); out[3*4+ 1] = (start + (*(uint16_t *)(in+3*8+ 2))); out[3*4+ 2] = (start + (*(uint16_t *)(in+3*8+ 4))); out[3*4+ 3] = (start + (*(uint16_t *)(in+3*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = (start + (*(uint16_t *)(in+4*8+ 0))); out[4*4+ 1] = (start + (*(uint16_t *)(in+4*8+ 2))); out[4*4+ 2] = (start + (*(uint16_t *)(in+4*8+ 4))); out[4*4+ 3] = (start + (*(uint16_t *)(in+4*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = (start + (*(uint16_t *)(in+5*8+ 0))); out[5*4+ 1] = (start + (*(uint16_t *)(in+5*8+ 2))); out[5*4+ 2] = (start + (*(uint16_t *)(in+5*8+ 4))); out[5*4+ 3] = (start + (*(uint16_t *)(in+5*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = (start + (*(uint16_t *)(in+6*8+ 0))); out[6*4+ 1] = (start + (*(uint16_t *)(in+6*8+ 2))); out[6*4+ 2] = (start + (*(uint16_t *)(in+6*8+ 4))); out[6*4+ 3] = (start + (*(uint16_t *)(in+6*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = (start + (*(uint16_t *)(in+7*8+ 0))); out[7*4+ 1] = (start + (*(uint16_t *)(in+7*8+ 2))); out[7*4+ 2] = (start + (*(uint16_t *)(in+7*8+ 4))); out[7*4+ 3] = (start + (*(uint16_t *)(in+7*8+ 6)));;}; out += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D16 bitfunpacka16[] = {
  &bitfunpack16_0,
  &bitfunpack16_1,
  &bitfunpack16_2,
  &bitfunpack16_3,
  &bitfunpack16_4,
  &bitfunpack16_5,
  &bitfunpack16_6,
  &bitfunpack16_7,
  &bitfunpack16_8,
  &bitfunpack16_9,
  &bitfunpack16_10,
  &bitfunpack16_11,
  &bitfunpack16_12,
  &bitfunpack16_13,
  &bitfunpack16_14,
  &bitfunpack16_15,
  &bitfunpack16_16
};
unsigned char *bitfunpack16( const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start, unsigned b) { return bitfunpacka16[ b](in, n, out, start); }
unsigned char *bitfunpack32_0(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint32_t *out_ = out+n; do { { { out[0*0+ 0] = (start + (0)); out[0*0+ 1] = (start + (0)); out[0*0+ 2] = (start + (0)); out[0*0+ 3] = (start + (0)); out[0*0+ 4] = (start + (0)); out[0*0+ 5] = (start + (0)); out[0*0+ 6] = (start + (0)); out[0*0+ 7] = (start + (0)); out[0*0+ 8] = (start + (0)); out[0*0+ 9] = (start + (0)); out[0*0+10] = (start + (0)); out[0*0+11] = (start + (0)); out[0*0+12] = (start + (0)); out[0*0+13] = (start + (0)); out[0*0+14] = (start + (0)); out[0*0+15] = (start + (0)); out[0*0+16] = (start + (0)); out[0*0+17] = (start + (0)); out[0*0+18] = (start + (0)); out[0*0+19] = (start + (0)); out[0*0+20] = (start + (0)); out[0*0+21] = (start + (0)); out[0*0+22] = (start + (0)); out[0*0+23] = (start + (0)); out[0*0+24] = (start + (0)); out[0*0+25] = (start + (0)); out[0*0+26] = (start + (0)); out[0*0+27] = (start + (0)); out[0*0+28] = (start + (0)); out[0*0+29] = (start + (0)); out[0*0+30] = (start + (0)); out[0*0+31] = (start + (0));;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitfunpack32_1(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x1)); out[0*32+ 1] = (start + ((w0 >> 1) & 0x1)); out[0*32+ 2] = (start + ((w0 >> 2) & 0x1)); out[0*32+ 3] = (start + ((w0 >> 3) & 0x1)); out[0*32+ 4] = (start + ((w0 >> 4) & 0x1)); out[0*32+ 5] = (start + ((w0 >> 5) & 0x1)); out[0*32+ 6] = (start + ((w0 >> 6) & 0x1)); out[0*32+ 7] = (start + ((w0 >> 7) & 0x1)); out[0*32+ 8] = (start + ((w0 >> 8) & 0x1)); out[0*32+ 9] = (start + ((w0 >> 9) & 0x1)); out[0*32+10] = (start + ((w0 >> 10) & 0x1)); out[0*32+11] = (start + ((w0 >> 11) & 0x1)); out[0*32+12] = (start + ((w0 >> 12) & 0x1)); out[0*32+13] = (start + ((w0 >> 13) & 0x1)); out[0*32+14] = (start + ((w0 >> 14) & 0x1)); out[0*32+15] = (start + ((w0 >> 15) & 0x1)); out[0*32+16] = (start + ((w0 >> 16) & 0x1)); out[0*32+17] = (start + ((w0 >> 17) & 0x1)); out[0*32+18] = (start + ((w0 >> 18) & 0x1)); out[0*32+19] = (start + ((w0 >> 19) & 0x1)); out[0*32+20] = (start + ((w0 >> 20) & 0x1)); out[0*32+21] = (start + ((w0 >> 21) & 0x1)); out[0*32+22] = (start + ((w0 >> 22) & 0x1)); out[0*32+23] = (start + ((w0 >> 23) & 0x1)); out[0*32+24] = (start + ((w0 >> 24) & 0x1)); out[0*32+25] = (start + ((w0 >> 25) & 0x1)); out[0*32+26] = (start + ((w0 >> 26) & 0x1)); out[0*32+27] = (start + ((w0 >> 27) & 0x1)); out[0*32+28] = (start + ((w0 >> 28) & 0x1)); out[0*32+29] = (start + ((w0 >> 29) & 0x1)); out[0*32+30] = (start + ((w0 >> 30) & 0x1)); out[0*32+31] = (start + ((w0 >> 31)));;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_2(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3)); out[0*32+ 1] = (start + ((w0 >> 2) & 0x3)); out[0*32+ 2] = (start + ((w0 >> 4) & 0x3)); out[0*32+ 3] = (start + ((w0 >> 6) & 0x3)); out[0*32+ 4] = (start + ((w0 >> 8) & 0x3)); out[0*32+ 5] = (start + ((w0 >> 10) & 0x3)); out[0*32+ 6] = (start + ((w0 >> 12) & 0x3)); out[0*32+ 7] = (start + ((w0 >> 14) & 0x3)); out[0*32+ 8] = (start + ((w0 >> 16) & 0x3)); out[0*32+ 9] = (start + ((w0 >> 18) & 0x3)); out[0*32+10] = (start + ((w0 >> 20) & 0x3)); out[0*32+11] = (start + ((w0 >> 22) & 0x3)); out[0*32+12] = (start + ((w0 >> 24) & 0x3)); out[0*32+13] = (start + ((w0 >> 26) & 0x3)); out[0*32+14] = (start + ((w0 >> 28) & 0x3)); out[0*32+15] = (start + ((w0 >> 30) & 0x3)); out[0*32+16] = (start + ((w0 >> 32) & 0x3)); out[0*32+17] = (start + ((w0 >> 34) & 0x3)); out[0*32+18] = (start + ((w0 >> 36) & 0x3)); out[0*32+19] = (start + ((w0 >> 38) & 0x3)); out[0*32+20] = (start + ((w0 >> 40) & 0x3)); out[0*32+21] = (start + ((w0 >> 42) & 0x3)); out[0*32+22] = (start + ((w0 >> 44) & 0x3)); out[0*32+23] = (start + ((w0 >> 46) & 0x3)); out[0*32+24] = (start + ((w0 >> 48) & 0x3)); out[0*32+25] = (start + ((w0 >> 50) & 0x3)); out[0*32+26] = (start + ((w0 >> 52) & 0x3)); out[0*32+27] = (start + ((w0 >> 54) & 0x3)); out[0*32+28] = (start + ((w0 >> 56) & 0x3)); out[0*32+29] = (start + ((w0 >> 58) & 0x3)); out[0*32+30] = (start + ((w0 >> 60) & 0x3)); out[0*32+31] = (start + ((w0 >> 62)));;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_3(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7)); out[0*64+ 1] = (start + ((w0 >> 3) & 0x7)); out[0*64+ 2] = (start + ((w0 >> 6) & 0x7)); out[0*64+ 3] = (start + ((w0 >> 9) & 0x7)); out[0*64+ 4] = (start + ((w0 >> 12) & 0x7)); out[0*64+ 5] = (start + ((w0 >> 15) & 0x7)); out[0*64+ 6] = (start + ((w0 >> 18) & 0x7)); out[0*64+ 7] = (start + ((w0 >> 21) & 0x7)); out[0*64+ 8] = (start + ((w0 >> 24) & 0x7)); out[0*64+ 9] = (start + ((w0 >> 27) & 0x7)); out[0*64+10] = (start + ((w0 >> 30) & 0x7)); out[0*64+11] = (start + ((w0 >> 33) & 0x7)); out[0*64+12] = (start + ((w0 >> 36) & 0x7)); out[0*64+13] = (start + ((w0 >> 39) & 0x7)); out[0*64+14] = (start + ((w0 >> 42) & 0x7)); out[0*64+15] = (start + ((w0 >> 45) & 0x7)); out[0*64+16] = (start + ((w0 >> 48) & 0x7)); out[0*64+17] = (start + ((w0 >> 51) & 0x7)); out[0*64+18] = (start + ((w0 >> 54) & 0x7)); out[0*64+19] = (start + ((w0 >> 57) & 0x7)); out[0*64+20] = (start + ((w0 >> 60) & 0x7)); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start + ((w0 >> 63) | (w1 << 1) & 0x7)); out[0*64+22] = (start + ((w1 >> 2) & 0x7)); out[0*64+23] = (start + ((w1 >> 5) & 0x7)); out[0*64+24] = (start + ((w1 >> 8) & 0x7)); out[0*64+25] = (start + ((w1 >> 11) & 0x7)); out[0*64+26] = (start + ((w1 >> 14) & 0x7)); out[0*64+27] = (start + ((w1 >> 17) & 0x7)); out[0*64+28] = (start + ((w1 >> 20) & 0x7)); out[0*64+29] = (start + ((w1 >> 23) & 0x7)); out[0*64+30] = (start + ((w1 >> 26) & 0x7)); out[0*64+31] = (start + ((w1 >> 29) & 0x7));;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_4(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xf)); out[0*16+ 1] = (start + ((w0 >> 4) & 0xf)); out[0*16+ 2] = (start + ((w0 >> 8) & 0xf)); out[0*16+ 3] = (start + ((w0 >> 12) & 0xf)); out[0*16+ 4] = (start + ((w0 >> 16) & 0xf)); out[0*16+ 5] = (start + ((w0 >> 20) & 0xf)); out[0*16+ 6] = (start + ((w0 >> 24) & 0xf)); out[0*16+ 7] = (start + ((w0 >> 28) & 0xf)); out[0*16+ 8] = (start + ((w0 >> 32) & 0xf)); out[0*16+ 9] = (start + ((w0 >> 36) & 0xf)); out[0*16+10] = (start + ((w0 >> 40) & 0xf)); out[0*16+11] = (start + ((w0 >> 44) & 0xf)); out[0*16+12] = (start + ((w0 >> 48) & 0xf)); out[0*16+13] = (start + ((w0 >> 52) & 0xf)); out[0*16+14] = (start + ((w0 >> 56) & 0xf)); out[0*16+15] = (start + ((w0 >> 60)));;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xf)); out[1*16+ 1] = (start + ((w0 >> 4) & 0xf)); out[1*16+ 2] = (start + ((w0 >> 8) & 0xf)); out[1*16+ 3] = (start + ((w0 >> 12) & 0xf)); out[1*16+ 4] = (start + ((w0 >> 16) & 0xf)); out[1*16+ 5] = (start + ((w0 >> 20) & 0xf)); out[1*16+ 6] = (start + ((w0 >> 24) & 0xf)); out[1*16+ 7] = (start + ((w0 >> 28) & 0xf)); out[1*16+ 8] = (start + ((w0 >> 32) & 0xf)); out[1*16+ 9] = (start + ((w0 >> 36) & 0xf)); out[1*16+10] = (start + ((w0 >> 40) & 0xf)); out[1*16+11] = (start + ((w0 >> 44) & 0xf)); out[1*16+12] = (start + ((w0 >> 48) & 0xf)); out[1*16+13] = (start + ((w0 >> 52) & 0xf)); out[1*16+14] = (start + ((w0 >> 56) & 0xf)); out[1*16+15] = (start + ((w0 >> 60)));;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_5(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1f)); out[0*64+ 1] = (start + ((w0 >> 5) & 0x1f)); out[0*64+ 2] = (start + ((w0 >> 10) & 0x1f)); out[0*64+ 3] = (start + ((w0 >> 15) & 0x1f)); out[0*64+ 4] = (start + ((w0 >> 20) & 0x1f)); out[0*64+ 5] = (start + ((w0 >> 25) & 0x1f)); out[0*64+ 6] = (start + ((w0 >> 30) & 0x1f)); out[0*64+ 7] = (start + ((w0 >> 35) & 0x1f)); out[0*64+ 8] = (start + ((w0 >> 40) & 0x1f)); out[0*64+ 9] = (start + ((w0 >> 45) & 0x1f)); out[0*64+10] = (start + ((w0 >> 50) & 0x1f)); out[0*64+11] = (start + ((w0 >> 55) & 0x1f)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start + ((w0 >> 60) | (w1 << 4) & 0x1f)); out[0*64+13] = (start + ((w1 >> 1) & 0x1f)); out[0*64+14] = (start + ((w1 >> 6) & 0x1f)); out[0*64+15] = (start + ((w1 >> 11) & 0x1f)); out[0*64+16] = (start + ((w1 >> 16) & 0x1f)); out[0*64+17] = (start + ((w1 >> 21) & 0x1f)); out[0*64+18] = (start + ((w1 >> 26) & 0x1f)); out[0*64+19] = (start + ((w1 >> 31) & 0x1f)); out[0*64+20] = (start + ((w1 >> 36) & 0x1f)); out[0*64+21] = (start + ((w1 >> 41) & 0x1f)); out[0*64+22] = (start + ((w1 >> 46) & 0x1f)); out[0*64+23] = (start + ((w1 >> 51) & 0x1f)); out[0*64+24] = (start + ((w1 >> 56) & 0x1f)); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start + ((w1 >> 61) | (w2 << 3) & 0x1f)); out[0*64+26] = (start + ((w2 >> 2) & 0x1f)); out[0*64+27] = (start + ((w2 >> 7) & 0x1f)); out[0*64+28] = (start + ((w2 >> 12) & 0x1f)); out[0*64+29] = (start + ((w2 >> 17) & 0x1f)); out[0*64+30] = (start + ((w2 >> 22) & 0x1f)); out[0*64+31] = (start + ((w2 >> 27) & 0x1f));;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_6(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3f)); out[0*32+ 1] = (start + ((w0 >> 6) & 0x3f)); out[0*32+ 2] = (start + ((w0 >> 12) & 0x3f)); out[0*32+ 3] = (start + ((w0 >> 18) & 0x3f)); out[0*32+ 4] = (start + ((w0 >> 24) & 0x3f)); out[0*32+ 5] = (start + ((w0 >> 30) & 0x3f)); out[0*32+ 6] = (start + ((w0 >> 36) & 0x3f)); out[0*32+ 7] = (start + ((w0 >> 42) & 0x3f)); out[0*32+ 8] = (start + ((w0 >> 48) & 0x3f)); out[0*32+ 9] = (start + ((w0 >> 54) & 0x3f)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start + ((w0 >> 60) | (w1 << 4) & 0x3f)); out[0*32+11] = (start + ((w1 >> 2) & 0x3f)); out[0*32+12] = (start + ((w1 >> 8) & 0x3f)); out[0*32+13] = (start + ((w1 >> 14) & 0x3f)); out[0*32+14] = (start + ((w1 >> 20) & 0x3f)); out[0*32+15] = (start + ((w1 >> 26) & 0x3f)); out[0*32+16] = (start + ((w1 >> 32) & 0x3f)); out[0*32+17] = (start + ((w1 >> 38) & 0x3f)); out[0*32+18] = (start + ((w1 >> 44) & 0x3f)); out[0*32+19] = (start + ((w1 >> 50) & 0x3f)); out[0*32+20] = (start + ((w1 >> 56) & 0x3f)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start + ((w1 >> 62) | (w2 << 2) & 0x3f)); out[0*32+22] = (start + ((w2 >> 4) & 0x3f)); out[0*32+23] = (start + ((w2 >> 10) & 0x3f)); out[0*32+24] = (start + ((w2 >> 16) & 0x3f)); out[0*32+25] = (start + ((w2 >> 22) & 0x3f)); out[0*32+26] = (start + ((w2 >> 28) & 0x3f)); out[0*32+27] = (start + ((w2 >> 34) & 0x3f)); out[0*32+28] = (start + ((w2 >> 40) & 0x3f)); out[0*32+29] = (start + ((w2 >> 46) & 0x3f)); out[0*32+30] = (start + ((w2 >> 52) & 0x3f)); out[0*32+31] = (start + ((w2 >> 58)));;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_7(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7f)); out[0*64+ 1] = (start + ((w0 >> 7) & 0x7f)); out[0*64+ 2] = (start + ((w0 >> 14) & 0x7f)); out[0*64+ 3] = (start + ((w0 >> 21) & 0x7f)); out[0*64+ 4] = (start + ((w0 >> 28) & 0x7f)); out[0*64+ 5] = (start + ((w0 >> 35) & 0x7f)); out[0*64+ 6] = (start + ((w0 >> 42) & 0x7f)); out[0*64+ 7] = (start + ((w0 >> 49) & 0x7f)); out[0*64+ 8] = (start + ((w0 >> 56) & 0x7f)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w0 >> 63) | (w1 << 1) & 0x7f)); out[0*64+10] = (start + ((w1 >> 6) & 0x7f)); out[0*64+11] = (start + ((w1 >> 13) & 0x7f)); out[0*64+12] = (start + ((w1 >> 20) & 0x7f)); out[0*64+13] = (start + ((w1 >> 27) & 0x7f)); out[0*64+14] = (start + ((w1 >> 34) & 0x7f)); out[0*64+15] = (start + ((w1 >> 41) & 0x7f)); out[0*64+16] = (start + ((w1 >> 48) & 0x7f)); out[0*64+17] = (start + ((w1 >> 55) & 0x7f)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start + ((w1 >> 62) | (w2 << 2) & 0x7f)); out[0*64+19] = (start + ((w2 >> 5) & 0x7f)); out[0*64+20] = (start + ((w2 >> 12) & 0x7f)); out[0*64+21] = (start + ((w2 >> 19) & 0x7f)); out[0*64+22] = (start + ((w2 >> 26) & 0x7f)); out[0*64+23] = (start + ((w2 >> 33) & 0x7f)); out[0*64+24] = (start + ((w2 >> 40) & 0x7f)); out[0*64+25] = (start + ((w2 >> 47) & 0x7f)); out[0*64+26] = (start + ((w2 >> 54) & 0x7f)); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start + ((w2 >> 61) | (w3 << 3) & 0x7f)); out[0*64+28] = (start + ((w3 >> 4) & 0x7f)); out[0*64+29] = (start + ((w3 >> 11) & 0x7f)); out[0*64+30] = (start + ((w3 >> 18) & 0x7f)); out[0*64+31] = (start + ((w3 >> 25) & 0x7f));;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_8(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start + ((w0 ) & 0xff)); out[0*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[0*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[0*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[0*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[0*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[0*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[0*8+ 7] = (start + ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start + ((w0 ) & 0xff)); out[1*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[1*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[1*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[1*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[1*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[1*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[1*8+ 7] = (start + ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start + ((w0 ) & 0xff)); out[2*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[2*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[2*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[2*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[2*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[2*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[2*8+ 7] = (start + ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start + ((w0 ) & 0xff)); out[3*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[3*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[3*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[3*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[3*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[3*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[3*8+ 7] = (start + ((w0 >> 56)));;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_9(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1ff)); out[0*64+ 1] = (start + ((w0 >> 9) & 0x1ff)); out[0*64+ 2] = (start + ((w0 >> 18) & 0x1ff)); out[0*64+ 3] = (start + ((w0 >> 27) & 0x1ff)); out[0*64+ 4] = (start + ((w0 >> 36) & 0x1ff)); out[0*64+ 5] = (start + ((w0 >> 45) & 0x1ff)); out[0*64+ 6] = (start + ((w0 >> 54) & 0x1ff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w0 >> 63) | (w1 << 1) & 0x1ff)); out[0*64+ 8] = (start + ((w1 >> 8) & 0x1ff)); out[0*64+ 9] = (start + ((w1 >> 17) & 0x1ff)); out[0*64+10] = (start + ((w1 >> 26) & 0x1ff)); out[0*64+11] = (start + ((w1 >> 35) & 0x1ff)); out[0*64+12] = (start + ((w1 >> 44) & 0x1ff)); out[0*64+13] = (start + ((w1 >> 53) & 0x1ff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (start + ((w1 >> 62) | (w2 << 2) & 0x1ff)); out[0*64+15] = (start + ((w2 >> 7) & 0x1ff)); out[0*64+16] = (start + ((w2 >> 16) & 0x1ff)); out[0*64+17] = (start + ((w2 >> 25) & 0x1ff)); out[0*64+18] = (start + ((w2 >> 34) & 0x1ff)); out[0*64+19] = (start + ((w2 >> 43) & 0x1ff)); out[0*64+20] = (start + ((w2 >> 52) & 0x1ff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (start + ((w2 >> 61) | (w3 << 3) & 0x1ff)); out[0*64+22] = (start + ((w3 >> 6) & 0x1ff)); out[0*64+23] = (start + ((w3 >> 15) & 0x1ff)); out[0*64+24] = (start + ((w3 >> 24) & 0x1ff)); out[0*64+25] = (start + ((w3 >> 33) & 0x1ff)); out[0*64+26] = (start + ((w3 >> 42) & 0x1ff)); out[0*64+27] = (start + ((w3 >> 51) & 0x1ff)); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (start + ((w3 >> 60) | (w4 << 4) & 0x1ff)); out[0*64+29] = (start + ((w4 >> 5) & 0x1ff)); out[0*64+30] = (start + ((w4 >> 14) & 0x1ff)); out[0*64+31] = (start + ((w4 >> 23) & 0x1ff));;}; out += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_10(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3ff)); out[0*32+ 1] = (start + ((w0 >> 10) & 0x3ff)); out[0*32+ 2] = (start + ((w0 >> 20) & 0x3ff)); out[0*32+ 3] = (start + ((w0 >> 30) & 0x3ff)); out[0*32+ 4] = (start + ((w0 >> 40) & 0x3ff)); out[0*32+ 5] = (start + ((w0 >> 50) & 0x3ff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (start + ((w0 >> 60) | (w1 << 4) & 0x3ff)); out[0*32+ 7] = (start + ((w1 >> 6) & 0x3ff)); out[0*32+ 8] = (start + ((w1 >> 16) & 0x3ff)); out[0*32+ 9] = (start + ((w1 >> 26) & 0x3ff)); out[0*32+10] = (start + ((w1 >> 36) & 0x3ff)); out[0*32+11] = (start + ((w1 >> 46) & 0x3ff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (start + ((w1 >> 56) | (w2 << 8) & 0x3ff)); out[0*32+13] = (start + ((w2 >> 2) & 0x3ff)); out[0*32+14] = (start + ((w2 >> 12) & 0x3ff)); out[0*32+15] = (start + ((w2 >> 22) & 0x3ff)); out[0*32+16] = (start + ((w2 >> 32) & 0x3ff)); out[0*32+17] = (start + ((w2 >> 42) & 0x3ff)); out[0*32+18] = (start + ((w2 >> 52) & 0x3ff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (start + ((w2 >> 62) | (w3 << 2) & 0x3ff)); out[0*32+20] = (start + ((w3 >> 8) & 0x3ff)); out[0*32+21] = (start + ((w3 >> 18) & 0x3ff)); out[0*32+22] = (start + ((w3 >> 28) & 0x3ff)); out[0*32+23] = (start + ((w3 >> 38) & 0x3ff)); out[0*32+24] = (start + ((w3 >> 48) & 0x3ff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (start + ((w3 >> 58) | (w4 << 6) & 0x3ff)); out[0*32+26] = (start + ((w4 >> 4) & 0x3ff)); out[0*32+27] = (start + ((w4 >> 14) & 0x3ff)); out[0*32+28] = (start + ((w4 >> 24) & 0x3ff)); out[0*32+29] = (start + ((w4 >> 34) & 0x3ff)); out[0*32+30] = (start + ((w4 >> 44) & 0x3ff)); out[0*32+31] = (start + ((w4 >> 54)));;}; out += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_11(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7ff)); out[0*64+ 1] = (start + ((w0 >> 11) & 0x7ff)); out[0*64+ 2] = (start + ((w0 >> 22) & 0x7ff)); out[0*64+ 3] = (start + ((w0 >> 33) & 0x7ff)); out[0*64+ 4] = (start + ((w0 >> 44) & 0x7ff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w0 >> 55) | (w1 << 9) & 0x7ff)); out[0*64+ 6] = (start + ((w1 >> 2) & 0x7ff)); out[0*64+ 7] = (start + ((w1 >> 13) & 0x7ff)); out[0*64+ 8] = (start + ((w1 >> 24) & 0x7ff)); out[0*64+ 9] = (start + ((w1 >> 35) & 0x7ff)); out[0*64+10] = (start + ((w1 >> 46) & 0x7ff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (start + ((w1 >> 57) | (w2 << 7) & 0x7ff)); out[0*64+12] = (start + ((w2 >> 4) & 0x7ff)); out[0*64+13] = (start + ((w2 >> 15) & 0x7ff)); out[0*64+14] = (start + ((w2 >> 26) & 0x7ff)); out[0*64+15] = (start + ((w2 >> 37) & 0x7ff)); out[0*64+16] = (start + ((w2 >> 48) & 0x7ff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (start + ((w2 >> 59) | (w3 << 5) & 0x7ff)); out[0*64+18] = (start + ((w3 >> 6) & 0x7ff)); out[0*64+19] = (start + ((w3 >> 17) & 0x7ff)); out[0*64+20] = (start + ((w3 >> 28) & 0x7ff)); out[0*64+21] = (start + ((w3 >> 39) & 0x7ff)); out[0*64+22] = (start + ((w3 >> 50) & 0x7ff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (start + ((w3 >> 61) | (w4 << 3) & 0x7ff)); out[0*64+24] = (start + ((w4 >> 8) & 0x7ff)); out[0*64+25] = (start + ((w4 >> 19) & 0x7ff)); out[0*64+26] = (start + ((w4 >> 30) & 0x7ff)); out[0*64+27] = (start + ((w4 >> 41) & 0x7ff)); out[0*64+28] = (start + ((w4 >> 52) & 0x7ff)); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (start + ((w4 >> 63) | (w5 << 1) & 0x7ff)); out[0*64+30] = (start + ((w5 >> 10) & 0x7ff)); out[0*64+31] = (start + ((w5 >> 21) & 0x7ff));;}; out += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_12(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xfff)); out[0*16+ 1] = (start + ((w0 >> 12) & 0xfff)); out[0*16+ 2] = (start + ((w0 >> 24) & 0xfff)); out[0*16+ 3] = (start + ((w0 >> 36) & 0xfff)); out[0*16+ 4] = (start + ((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (start + ((w0 >> 60) | (w1 << 4) & 0xfff)); out[0*16+ 6] = (start + ((w1 >> 8) & 0xfff)); out[0*16+ 7] = (start + ((w1 >> 20) & 0xfff)); out[0*16+ 8] = (start + ((w1 >> 32) & 0xfff)); out[0*16+ 9] = (start + ((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (start + ((w1 >> 56) | (w2 << 8) & 0xfff)); out[0*16+11] = (start + ((w2 >> 4) & 0xfff)); out[0*16+12] = (start + ((w2 >> 16) & 0xfff)); out[0*16+13] = (start + ((w2 >> 28) & 0xfff)); out[0*16+14] = (start + ((w2 >> 40) & 0xfff)); out[0*16+15] = (start + ((w2 >> 52)));;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xfff)); out[1*16+ 1] = (start + ((w0 >> 12) & 0xfff)); out[1*16+ 2] = (start + ((w0 >> 24) & 0xfff)); out[1*16+ 3] = (start + ((w0 >> 36) & 0xfff)); out[1*16+ 4] = (start + ((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (start + ((w0 >> 60) | (w1 << 4) & 0xfff)); out[1*16+ 6] = (start + ((w1 >> 8) & 0xfff)); out[1*16+ 7] = (start + ((w1 >> 20) & 0xfff)); out[1*16+ 8] = (start + ((w1 >> 32) & 0xfff)); out[1*16+ 9] = (start + ((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (start + ((w1 >> 56) | (w2 << 8) & 0xfff)); out[1*16+11] = (start + ((w2 >> 4) & 0xfff)); out[1*16+12] = (start + ((w2 >> 16) & 0xfff)); out[1*16+13] = (start + ((w2 >> 28) & 0xfff)); out[1*16+14] = (start + ((w2 >> 40) & 0xfff)); out[1*16+15] = (start + ((w2 >> 52)));;}; out += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_13(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1fff)); out[0*64+ 1] = (start + ((w0 >> 13) & 0x1fff)); out[0*64+ 2] = (start + ((w0 >> 26) & 0x1fff)); out[0*64+ 3] = (start + ((w0 >> 39) & 0x1fff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w0 >> 52) | (w1 << 12) & 0x1fff)); out[0*64+ 5] = (start + ((w1 >> 1) & 0x1fff)); out[0*64+ 6] = (start + ((w1 >> 14) & 0x1fff)); out[0*64+ 7] = (start + ((w1 >> 27) & 0x1fff)); out[0*64+ 8] = (start + ((w1 >> 40) & 0x1fff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w1 >> 53) | (w2 << 11) & 0x1fff)); out[0*64+10] = (start + ((w2 >> 2) & 0x1fff)); out[0*64+11] = (start + ((w2 >> 15) & 0x1fff)); out[0*64+12] = (start + ((w2 >> 28) & 0x1fff)); out[0*64+13] = (start + ((w2 >> 41) & 0x1fff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (start + ((w2 >> 54) | (w3 << 10) & 0x1fff)); out[0*64+15] = (start + ((w3 >> 3) & 0x1fff)); out[0*64+16] = (start + ((w3 >> 16) & 0x1fff)); out[0*64+17] = (start + ((w3 >> 29) & 0x1fff)); out[0*64+18] = (start + ((w3 >> 42) & 0x1fff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (start + ((w3 >> 55) | (w4 << 9) & 0x1fff)); out[0*64+20] = (start + ((w4 >> 4) & 0x1fff)); out[0*64+21] = (start + ((w4 >> 17) & 0x1fff)); out[0*64+22] = (start + ((w4 >> 30) & 0x1fff)); out[0*64+23] = (start + ((w4 >> 43) & 0x1fff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (start + ((w4 >> 56) | (w5 << 8) & 0x1fff)); out[0*64+25] = (start + ((w5 >> 5) & 0x1fff)); out[0*64+26] = (start + ((w5 >> 18) & 0x1fff)); out[0*64+27] = (start + ((w5 >> 31) & 0x1fff)); out[0*64+28] = (start + ((w5 >> 44) & 0x1fff)); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (start + ((w5 >> 57) | (w6 << 7) & 0x1fff)); out[0*64+30] = (start + ((w6 >> 6) & 0x1fff)); out[0*64+31] = (start + ((w6 >> 19) & 0x1fff));;}; out += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_14(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3fff)); out[0*32+ 1] = (start + ((w0 >> 14) & 0x3fff)); out[0*32+ 2] = (start + ((w0 >> 28) & 0x3fff)); out[0*32+ 3] = (start + ((w0 >> 42) & 0x3fff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (start + ((w0 >> 56) | (w1 << 8) & 0x3fff)); out[0*32+ 5] = (start + ((w1 >> 6) & 0x3fff)); out[0*32+ 6] = (start + ((w1 >> 20) & 0x3fff)); out[0*32+ 7] = (start + ((w1 >> 34) & 0x3fff)); out[0*32+ 8] = (start + ((w1 >> 48) & 0x3fff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (start + ((w1 >> 62) | (w2 << 2) & 0x3fff)); out[0*32+10] = (start + ((w2 >> 12) & 0x3fff)); out[0*32+11] = (start + ((w2 >> 26) & 0x3fff)); out[0*32+12] = (start + ((w2 >> 40) & 0x3fff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (start + ((w2 >> 54) | (w3 << 10) & 0x3fff)); out[0*32+14] = (start + ((w3 >> 4) & 0x3fff)); out[0*32+15] = (start + ((w3 >> 18) & 0x3fff)); out[0*32+16] = (start + ((w3 >> 32) & 0x3fff)); out[0*32+17] = (start + ((w3 >> 46) & 0x3fff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (start + ((w3 >> 60) | (w4 << 4) & 0x3fff)); out[0*32+19] = (start + ((w4 >> 10) & 0x3fff)); out[0*32+20] = (start + ((w4 >> 24) & 0x3fff)); out[0*32+21] = (start + ((w4 >> 38) & 0x3fff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (start + ((w4 >> 52) | (w5 << 12) & 0x3fff)); out[0*32+23] = (start + ((w5 >> 2) & 0x3fff)); out[0*32+24] = (start + ((w5 >> 16) & 0x3fff)); out[0*32+25] = (start + ((w5 >> 30) & 0x3fff)); out[0*32+26] = (start + ((w5 >> 44) & 0x3fff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (start + ((w5 >> 58) | (w6 << 6) & 0x3fff)); out[0*32+28] = (start + ((w6 >> 8) & 0x3fff)); out[0*32+29] = (start + ((w6 >> 22) & 0x3fff)); out[0*32+30] = (start + ((w6 >> 36) & 0x3fff)); out[0*32+31] = (start + ((w6 >> 50)));;}; out += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_15(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7fff)); out[0*64+ 1] = (start + ((w0 >> 15) & 0x7fff)); out[0*64+ 2] = (start + ((w0 >> 30) & 0x7fff)); out[0*64+ 3] = (start + ((w0 >> 45) & 0x7fff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w0 >> 60) | (w1 << 4) & 0x7fff)); out[0*64+ 5] = (start + ((w1 >> 11) & 0x7fff)); out[0*64+ 6] = (start + ((w1 >> 26) & 0x7fff)); out[0*64+ 7] = (start + ((w1 >> 41) & 0x7fff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w1 >> 56) | (w2 << 8) & 0x7fff)); out[0*64+ 9] = (start + ((w2 >> 7) & 0x7fff)); out[0*64+10] = (start + ((w2 >> 22) & 0x7fff)); out[0*64+11] = (start + ((w2 >> 37) & 0x7fff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (start + ((w2 >> 52) | (w3 << 12) & 0x7fff)); out[0*64+13] = (start + ((w3 >> 3) & 0x7fff)); out[0*64+14] = (start + ((w3 >> 18) & 0x7fff)); out[0*64+15] = (start + ((w3 >> 33) & 0x7fff)); out[0*64+16] = (start + ((w3 >> 48) & 0x7fff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (start + ((w3 >> 63) | (w4 << 1) & 0x7fff)); out[0*64+18] = (start + ((w4 >> 14) & 0x7fff)); out[0*64+19] = (start + ((w4 >> 29) & 0x7fff)); out[0*64+20] = (start + ((w4 >> 44) & 0x7fff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (start + ((w4 >> 59) | (w5 << 5) & 0x7fff)); out[0*64+22] = (start + ((w5 >> 10) & 0x7fff)); out[0*64+23] = (start + ((w5 >> 25) & 0x7fff)); out[0*64+24] = (start + ((w5 >> 40) & 0x7fff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (start + ((w5 >> 55) | (w6 << 9) & 0x7fff)); out[0*64+26] = (start + ((w6 >> 6) & 0x7fff)); out[0*64+27] = (start + ((w6 >> 21) & 0x7fff)); out[0*64+28] = (start + ((w6 >> 36) & 0x7fff)); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (start + ((w6 >> 51) | (w7 << 13) & 0x7fff)); out[0*64+30] = (start + ((w7 >> 2) & 0x7fff)); out[0*64+31] = (start + ((w7 >> 17) & 0x7fff));;}; out += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_16(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = (start + (*(uint16_t *)(in+0*8+ 0))); out[0*4+ 1] = (start + (*(uint16_t *)(in+0*8+ 2))); out[0*4+ 2] = (start + (*(uint16_t *)(in+0*8+ 4))); out[0*4+ 3] = (start + (*(uint16_t *)(in+0*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = (start + (*(uint16_t *)(in+1*8+ 0))); out[1*4+ 1] = (start + (*(uint16_t *)(in+1*8+ 2))); out[1*4+ 2] = (start + (*(uint16_t *)(in+1*8+ 4))); out[1*4+ 3] = (start + (*(uint16_t *)(in+1*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = (start + (*(uint16_t *)(in+2*8+ 0))); out[2*4+ 1] = (start + (*(uint16_t *)(in+2*8+ 2))); out[2*4+ 2] = (start + (*(uint16_t *)(in+2*8+ 4))); out[2*4+ 3] = (start + (*(uint16_t *)(in+2*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = (start + (*(uint16_t *)(in+3*8+ 0))); out[3*4+ 1] = (start + (*(uint16_t *)(in+3*8+ 2))); out[3*4+ 2] = (start + (*(uint16_t *)(in+3*8+ 4))); out[3*4+ 3] = (start + (*(uint16_t *)(in+3*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = (start + (*(uint16_t *)(in+4*8+ 0))); out[4*4+ 1] = (start + (*(uint16_t *)(in+4*8+ 2))); out[4*4+ 2] = (start + (*(uint16_t *)(in+4*8+ 4))); out[4*4+ 3] = (start + (*(uint16_t *)(in+4*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = (start + (*(uint16_t *)(in+5*8+ 0))); out[5*4+ 1] = (start + (*(uint16_t *)(in+5*8+ 2))); out[5*4+ 2] = (start + (*(uint16_t *)(in+5*8+ 4))); out[5*4+ 3] = (start + (*(uint16_t *)(in+5*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = (start + (*(uint16_t *)(in+6*8+ 0))); out[6*4+ 1] = (start + (*(uint16_t *)(in+6*8+ 2))); out[6*4+ 2] = (start + (*(uint16_t *)(in+6*8+ 4))); out[6*4+ 3] = (start + (*(uint16_t *)(in+6*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = (start + (*(uint16_t *)(in+7*8+ 0))); out[7*4+ 1] = (start + (*(uint16_t *)(in+7*8+ 2))); out[7*4+ 2] = (start + (*(uint16_t *)(in+7*8+ 4))); out[7*4+ 3] = (start + (*(uint16_t *)(in+7*8+ 6)));;}; out += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_17(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*17)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1ffff)); out[0*64+ 1] = (start + ((w0 >> 17) & 0x1ffff)); out[0*64+ 2] = (start + ((w0 >> 34) & 0x1ffff)); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w0 >> 51) | (w1 << 13) & 0x1ffff)); out[0*64+ 4] = (start + ((w1 >> 4) & 0x1ffff)); out[0*64+ 5] = (start + ((w1 >> 21) & 0x1ffff)); out[0*64+ 6] = (start + ((w1 >> 38) & 0x1ffff)); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w1 >> 55) | (w2 << 9) & 0x1ffff)); out[0*64+ 8] = (start + ((w2 >> 8) & 0x1ffff)); out[0*64+ 9] = (start + ((w2 >> 25) & 0x1ffff)); out[0*64+10] = (start + ((w2 >> 42) & 0x1ffff)); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*64+11] = (start + ((w2 >> 59) | (w3 << 5) & 0x1ffff)); out[0*64+12] = (start + ((w3 >> 12) & 0x1ffff)); out[0*64+13] = (start + ((w3 >> 29) & 0x1ffff)); out[0*64+14] = (start + ((w3 >> 46) & 0x1ffff)); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*64+15] = (start + ((w3 >> 63) | (w4 << 1) & 0x1ffff)); out[0*64+16] = (start + ((w4 >> 16) & 0x1ffff)); out[0*64+17] = (start + ((w4 >> 33) & 0x1ffff)); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*64+18] = (start + ((w4 >> 50) | (w5 << 14) & 0x1ffff)); out[0*64+19] = (start + ((w5 >> 3) & 0x1ffff)); out[0*64+20] = (start + ((w5 >> 20) & 0x1ffff)); out[0*64+21] = (start + ((w5 >> 37) & 0x1ffff)); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*64+22] = (start + ((w5 >> 54) | (w6 << 10) & 0x1ffff)); out[0*64+23] = (start + ((w6 >> 7) & 0x1ffff)); out[0*64+24] = (start + ((w6 >> 24) & 0x1ffff)); out[0*64+25] = (start + ((w6 >> 41) & 0x1ffff)); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*64+26] = (start + ((w6 >> 58) | (w7 << 6) & 0x1ffff)); out[0*64+27] = (start + ((w7 >> 11) & 0x1ffff)); out[0*64+28] = (start + ((w7 >> 28) & 0x1ffff)); out[0*64+29] = (start + ((w7 >> 45) & 0x1ffff)); w8 = *(uint32_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*64+30] = (start + ((w7 >> 62) | (w8 << 2) & 0x1ffff)); out[0*64+31] = (start + ((w8 >> 15) & 0x1ffff));;}; out += 32; in += 17*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_18(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*18)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3ffff)); out[0*32+ 1] = (start + ((w0 >> 18) & 0x3ffff)); out[0*32+ 2] = (start + ((w0 >> 36) & 0x3ffff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*32+ 3] = (start + ((w0 >> 54) | (w1 << 10) & 0x3ffff)); out[0*32+ 4] = (start + ((w1 >> 8) & 0x3ffff)); out[0*32+ 5] = (start + ((w1 >> 26) & 0x3ffff)); out[0*32+ 6] = (start + ((w1 >> 44) & 0x3ffff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*32+ 7] = (start + ((w1 >> 62) | (w2 << 2) & 0x3ffff)); out[0*32+ 8] = (start + ((w2 >> 16) & 0x3ffff)); out[0*32+ 9] = (start + ((w2 >> 34) & 0x3ffff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*32+10] = (start + ((w2 >> 52) | (w3 << 12) & 0x3ffff)); out[0*32+11] = (start + ((w3 >> 6) & 0x3ffff)); out[0*32+12] = (start + ((w3 >> 24) & 0x3ffff)); out[0*32+13] = (start + ((w3 >> 42) & 0x3ffff)); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*32+14] = (start + ((w3 >> 60) | (w4 << 4) & 0x3ffff)); out[0*32+15] = (start + ((w4 >> 14) & 0x3ffff)); out[0*32+16] = (start + ((w4 >> 32) & 0x3ffff)); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*32+17] = (start + ((w4 >> 50) | (w5 << 14) & 0x3ffff)); out[0*32+18] = (start + ((w5 >> 4) & 0x3ffff)); out[0*32+19] = (start + ((w5 >> 22) & 0x3ffff)); out[0*32+20] = (start + ((w5 >> 40) & 0x3ffff)); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*32+21] = (start + ((w5 >> 58) | (w6 << 6) & 0x3ffff)); out[0*32+22] = (start + ((w6 >> 12) & 0x3ffff)); out[0*32+23] = (start + ((w6 >> 30) & 0x3ffff)); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*32+24] = (start + ((w6 >> 48) | (w7 << 16) & 0x3ffff)); out[0*32+25] = (start + ((w7 >> 2) & 0x3ffff)); out[0*32+26] = (start + ((w7 >> 20) & 0x3ffff)); out[0*32+27] = (start + ((w7 >> 38) & 0x3ffff)); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*32+28] = (start + ((w7 >> 56) | (w8 << 8) & 0x3ffff)); out[0*32+29] = (start + ((w8 >> 10) & 0x3ffff)); out[0*32+30] = (start + ((w8 >> 28) & 0x3ffff)); out[0*32+31] = (start + ((w8 >> 46)));;}; out += 32; in += 18*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_19(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*19)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7ffff)); out[0*64+ 1] = (start + ((w0 >> 19) & 0x7ffff)); out[0*64+ 2] = (start + ((w0 >> 38) & 0x7ffff)); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w0 >> 57) | (w1 << 7) & 0x7ffff)); out[0*64+ 4] = (start + ((w1 >> 12) & 0x7ffff)); out[0*64+ 5] = (start + ((w1 >> 31) & 0x7ffff)); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w1 >> 50) | (w2 << 14) & 0x7ffff)); out[0*64+ 7] = (start + ((w2 >> 5) & 0x7ffff)); out[0*64+ 8] = (start + ((w2 >> 24) & 0x7ffff)); out[0*64+ 9] = (start + ((w2 >> 43) & 0x7ffff)); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*64+10] = (start + ((w2 >> 62) | (w3 << 2) & 0x7ffff)); out[0*64+11] = (start + ((w3 >> 17) & 0x7ffff)); out[0*64+12] = (start + ((w3 >> 36) & 0x7ffff)); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*64+13] = (start + ((w3 >> 55) | (w4 << 9) & 0x7ffff)); out[0*64+14] = (start + ((w4 >> 10) & 0x7ffff)); out[0*64+15] = (start + ((w4 >> 29) & 0x7ffff)); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*64+16] = (start + ((w4 >> 48) | (w5 << 16) & 0x7ffff)); out[0*64+17] = (start + ((w5 >> 3) & 0x7ffff)); out[0*64+18] = (start + ((w5 >> 22) & 0x7ffff)); out[0*64+19] = (start + ((w5 >> 41) & 0x7ffff)); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*64+20] = (start + ((w5 >> 60) | (w6 << 4) & 0x7ffff)); out[0*64+21] = (start + ((w6 >> 15) & 0x7ffff)); out[0*64+22] = (start + ((w6 >> 34) & 0x7ffff)); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*64+23] = (start + ((w6 >> 53) | (w7 << 11) & 0x7ffff)); out[0*64+24] = (start + ((w7 >> 8) & 0x7ffff)); out[0*64+25] = (start + ((w7 >> 27) & 0x7ffff)); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*64+26] = (start + ((w7 >> 46) | (w8 << 18) & 0x7ffff)); out[0*64+27] = (start + ((w8 >> 1) & 0x7ffff)); out[0*64+28] = (start + ((w8 >> 20) & 0x7ffff)); out[0*64+29] = (start + ((w8 >> 39) & 0x7ffff)); w9 = *(uint32_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*64+30] = (start + ((w8 >> 58) | (w9 << 6) & 0x7ffff)); out[0*64+31] = (start + ((w9 >> 13) & 0x7ffff));;}; out += 32; in += 19*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_20(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*20)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xfffff)); out[0*16+ 1] = (start + ((w0 >> 20) & 0xfffff)); out[0*16+ 2] = (start + ((w0 >> 40) & 0xfffff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*16+ 3] = (start + ((w0 >> 60) | (w1 << 4) & 0xfffff)); out[0*16+ 4] = (start + ((w1 >> 16) & 0xfffff)); out[0*16+ 5] = (start + ((w1 >> 36) & 0xfffff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*16+ 6] = (start + ((w1 >> 56) | (w2 << 8) & 0xfffff)); out[0*16+ 7] = (start + ((w2 >> 12) & 0xfffff)); out[0*16+ 8] = (start + ((w2 >> 32) & 0xfffff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*16+ 9] = (start + ((w2 >> 52) | (w3 << 12) & 0xfffff)); out[0*16+10] = (start + ((w3 >> 8) & 0xfffff)); out[0*16+11] = (start + ((w3 >> 28) & 0xfffff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*16+12] = (start + ((w3 >> 48) | (w4 << 16) & 0xfffff)); out[0*16+13] = (start + ((w4 >> 4) & 0xfffff)); out[0*16+14] = (start + ((w4 >> 24) & 0xfffff)); out[0*16+15] = (start + ((w4 >> 44)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xfffff)); out[1*16+ 1] = (start + ((w0 >> 20) & 0xfffff)); out[1*16+ 2] = (start + ((w0 >> 40) & 0xfffff)); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*16+ 3] = (start + ((w0 >> 60) | (w1 << 4) & 0xfffff)); out[1*16+ 4] = (start + ((w1 >> 16) & 0xfffff)); out[1*16+ 5] = (start + ((w1 >> 36) & 0xfffff)); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*16+ 6] = (start + ((w1 >> 56) | (w2 << 8) & 0xfffff)); out[1*16+ 7] = (start + ((w2 >> 12) & 0xfffff)); out[1*16+ 8] = (start + ((w2 >> 32) & 0xfffff)); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*16+ 9] = (start + ((w2 >> 52) | (w3 << 12) & 0xfffff)); out[1*16+10] = (start + ((w3 >> 8) & 0xfffff)); out[1*16+11] = (start + ((w3 >> 28) & 0xfffff)); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*16+12] = (start + ((w3 >> 48) | (w4 << 16) & 0xfffff)); out[1*16+13] = (start + ((w4 >> 4) & 0xfffff)); out[1*16+14] = (start + ((w4 >> 24) & 0xfffff)); out[1*16+15] = (start + ((w4 >> 44)));;}; out += 32; in += 20*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_21(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*21)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1fffff)); out[0*64+ 1] = (start + ((w0 >> 21) & 0x1fffff)); out[0*64+ 2] = (start + ((w0 >> 42) & 0x1fffff)); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w0 >> 63) | (w1 << 1) & 0x1fffff)); out[0*64+ 4] = (start + ((w1 >> 20) & 0x1fffff)); out[0*64+ 5] = (start + ((w1 >> 41) & 0x1fffff)); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w1 >> 62) | (w2 << 2) & 0x1fffff)); out[0*64+ 7] = (start + ((w2 >> 19) & 0x1fffff)); out[0*64+ 8] = (start + ((w2 >> 40) & 0x1fffff)); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w2 >> 61) | (w3 << 3) & 0x1fffff)); out[0*64+10] = (start + ((w3 >> 18) & 0x1fffff)); out[0*64+11] = (start + ((w3 >> 39) & 0x1fffff)); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*64+12] = (start + ((w3 >> 60) | (w4 << 4) & 0x1fffff)); out[0*64+13] = (start + ((w4 >> 17) & 0x1fffff)); out[0*64+14] = (start + ((w4 >> 38) & 0x1fffff)); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*64+15] = (start + ((w4 >> 59) | (w5 << 5) & 0x1fffff)); out[0*64+16] = (start + ((w5 >> 16) & 0x1fffff)); out[0*64+17] = (start + ((w5 >> 37) & 0x1fffff)); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*64+18] = (start + ((w5 >> 58) | (w6 << 6) & 0x1fffff)); out[0*64+19] = (start + ((w6 >> 15) & 0x1fffff)); out[0*64+20] = (start + ((w6 >> 36) & 0x1fffff)); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*64+21] = (start + ((w6 >> 57) | (w7 << 7) & 0x1fffff)); out[0*64+22] = (start + ((w7 >> 14) & 0x1fffff)); out[0*64+23] = (start + ((w7 >> 35) & 0x1fffff)); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*64+24] = (start + ((w7 >> 56) | (w8 << 8) & 0x1fffff)); out[0*64+25] = (start + ((w8 >> 13) & 0x1fffff)); out[0*64+26] = (start + ((w8 >> 34) & 0x1fffff)); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*64+27] = (start + ((w8 >> 55) | (w9 << 9) & 0x1fffff)); out[0*64+28] = (start + ((w9 >> 12) & 0x1fffff)); out[0*64+29] = (start + ((w9 >> 33) & 0x1fffff)); w10 = *(uint32_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*64+30] = (start + ((w9 >> 54) | (w10 << 10) & 0x1fffff)); out[0*64+31] = (start + ((w10 >> 11) & 0x1fffff));;}; out += 32; in += 21*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_22(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*22)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3fffff)); out[0*32+ 1] = (start + ((w0 >> 22) & 0x3fffff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*32+ 2] = (start + ((w0 >> 44) | (w1 << 20) & 0x3fffff)); out[0*32+ 3] = (start + ((w1 >> 2) & 0x3fffff)); out[0*32+ 4] = (start + ((w1 >> 24) & 0x3fffff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*32+ 5] = (start + ((w1 >> 46) | (w2 << 18) & 0x3fffff)); out[0*32+ 6] = (start + ((w2 >> 4) & 0x3fffff)); out[0*32+ 7] = (start + ((w2 >> 26) & 0x3fffff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*32+ 8] = (start + ((w2 >> 48) | (w3 << 16) & 0x3fffff)); out[0*32+ 9] = (start + ((w3 >> 6) & 0x3fffff)); out[0*32+10] = (start + ((w3 >> 28) & 0x3fffff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*32+11] = (start + ((w3 >> 50) | (w4 << 14) & 0x3fffff)); out[0*32+12] = (start + ((w4 >> 8) & 0x3fffff)); out[0*32+13] = (start + ((w4 >> 30) & 0x3fffff)); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*32+14] = (start + ((w4 >> 52) | (w5 << 12) & 0x3fffff)); out[0*32+15] = (start + ((w5 >> 10) & 0x3fffff)); out[0*32+16] = (start + ((w5 >> 32) & 0x3fffff)); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*32+17] = (start + ((w5 >> 54) | (w6 << 10) & 0x3fffff)); out[0*32+18] = (start + ((w6 >> 12) & 0x3fffff)); out[0*32+19] = (start + ((w6 >> 34) & 0x3fffff)); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*32+20] = (start + ((w6 >> 56) | (w7 << 8) & 0x3fffff)); out[0*32+21] = (start + ((w7 >> 14) & 0x3fffff)); out[0*32+22] = (start + ((w7 >> 36) & 0x3fffff)); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*32+23] = (start + ((w7 >> 58) | (w8 << 6) & 0x3fffff)); out[0*32+24] = (start + ((w8 >> 16) & 0x3fffff)); out[0*32+25] = (start + ((w8 >> 38) & 0x3fffff)); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*32+26] = (start + ((w8 >> 60) | (w9 << 4) & 0x3fffff)); out[0*32+27] = (start + ((w9 >> 18) & 0x3fffff)); out[0*32+28] = (start + ((w9 >> 40) & 0x3fffff)); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*32+29] = (start + ((w9 >> 62) | (w10 << 2) & 0x3fffff)); out[0*32+30] = (start + ((w10 >> 20) & 0x3fffff)); out[0*32+31] = (start + ((w10 >> 42)));;}; out += 32; in += 22*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_23(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*23)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7fffff)); out[0*64+ 1] = (start + ((w0 >> 23) & 0x7fffff)); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w0 >> 46) | (w1 << 18) & 0x7fffff)); out[0*64+ 3] = (start + ((w1 >> 5) & 0x7fffff)); out[0*64+ 4] = (start + ((w1 >> 28) & 0x7fffff)); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w1 >> 51) | (w2 << 13) & 0x7fffff)); out[0*64+ 6] = (start + ((w2 >> 10) & 0x7fffff)); out[0*64+ 7] = (start + ((w2 >> 33) & 0x7fffff)); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w2 >> 56) | (w3 << 8) & 0x7fffff)); out[0*64+ 9] = (start + ((w3 >> 15) & 0x7fffff)); out[0*64+10] = (start + ((w3 >> 38) & 0x7fffff)); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*64+11] = (start + ((w3 >> 61) | (w4 << 3) & 0x7fffff)); out[0*64+12] = (start + ((w4 >> 20) & 0x7fffff)); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*64+13] = (start + ((w4 >> 43) | (w5 << 21) & 0x7fffff)); out[0*64+14] = (start + ((w5 >> 2) & 0x7fffff)); out[0*64+15] = (start + ((w5 >> 25) & 0x7fffff)); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*64+16] = (start + ((w5 >> 48) | (w6 << 16) & 0x7fffff)); out[0*64+17] = (start + ((w6 >> 7) & 0x7fffff)); out[0*64+18] = (start + ((w6 >> 30) & 0x7fffff)); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*64+19] = (start + ((w6 >> 53) | (w7 << 11) & 0x7fffff)); out[0*64+20] = (start + ((w7 >> 12) & 0x7fffff)); out[0*64+21] = (start + ((w7 >> 35) & 0x7fffff)); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*64+22] = (start + ((w7 >> 58) | (w8 << 6) & 0x7fffff)); out[0*64+23] = (start + ((w8 >> 17) & 0x7fffff)); out[0*64+24] = (start + ((w8 >> 40) & 0x7fffff)); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*64+25] = (start + ((w8 >> 63) | (w9 << 1) & 0x7fffff)); out[0*64+26] = (start + ((w9 >> 22) & 0x7fffff)); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*64+27] = (start + ((w9 >> 45) | (w10 << 19) & 0x7fffff)); out[0*64+28] = (start + ((w10 >> 4) & 0x7fffff)); out[0*64+29] = (start + ((w10 >> 27) & 0x7fffff)); w11 = *(uint32_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*64+30] = (start + ((w10 >> 50) | (w11 << 14) & 0x7fffff)); out[0*64+31] = (start + ((w11 >> 9) & 0x7fffff));;}; out += 32; in += 23*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_24(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*24)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*8+ 0] = (start + ((w0 ) & 0xffffff)); out[0*8+ 1] = (start + ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*8+ 2] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[0*8+ 3] = (start + ((w1 >> 8) & 0xffffff)); out[0*8+ 4] = (start + ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*8+ 5] = (start + ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[0*8+ 6] = (start + ((w2 >> 16) & 0xffffff)); out[0*8+ 7] = (start + ((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*8+ 0] = (start + ((w0 ) & 0xffffff)); out[1*8+ 1] = (start + ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*8+ 2] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[1*8+ 3] = (start + ((w1 >> 8) & 0xffffff)); out[1*8+ 4] = (start + ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*8+ 5] = (start + ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[1*8+ 6] = (start + ((w2 >> 16) & 0xffffff)); out[1*8+ 7] = (start + ((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*8+ 0] = (start + ((w0 ) & 0xffffff)); out[2*8+ 1] = (start + ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*8+ 2] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[2*8+ 3] = (start + ((w1 >> 8) & 0xffffff)); out[2*8+ 4] = (start + ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*8+ 5] = (start + ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[2*8+ 6] = (start + ((w2 >> 16) & 0xffffff)); out[2*8+ 7] = (start + ((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*8+ 0] = (start + ((w0 ) & 0xffffff)); out[3*8+ 1] = (start + ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*8+ 2] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[3*8+ 3] = (start + ((w1 >> 8) & 0xffffff)); out[3*8+ 4] = (start + ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*8+ 5] = (start + ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[3*8+ 6] = (start + ((w2 >> 16) & 0xffffff)); out[3*8+ 7] = (start + ((w2 >> 40)));;}; out += 32; in += 24*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_25(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*25)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1ffffff)); out[0*64+ 1] = (start + ((w0 >> 25) & 0x1ffffff)); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w0 >> 50) | (w1 << 14) & 0x1ffffff)); out[0*64+ 3] = (start + ((w1 >> 11) & 0x1ffffff)); out[0*64+ 4] = (start + ((w1 >> 36) & 0x1ffffff)); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w1 >> 61) | (w2 << 3) & 0x1ffffff)); out[0*64+ 6] = (start + ((w2 >> 22) & 0x1ffffff)); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w2 >> 47) | (w3 << 17) & 0x1ffffff)); out[0*64+ 8] = (start + ((w3 >> 8) & 0x1ffffff)); out[0*64+ 9] = (start + ((w3 >> 33) & 0x1ffffff)); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*64+10] = (start + ((w3 >> 58) | (w4 << 6) & 0x1ffffff)); out[0*64+11] = (start + ((w4 >> 19) & 0x1ffffff)); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*64+12] = (start + ((w4 >> 44) | (w5 << 20) & 0x1ffffff)); out[0*64+13] = (start + ((w5 >> 5) & 0x1ffffff)); out[0*64+14] = (start + ((w5 >> 30) & 0x1ffffff)); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*64+15] = (start + ((w5 >> 55) | (w6 << 9) & 0x1ffffff)); out[0*64+16] = (start + ((w6 >> 16) & 0x1ffffff)); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*64+17] = (start + ((w6 >> 41) | (w7 << 23) & 0x1ffffff)); out[0*64+18] = (start + ((w7 >> 2) & 0x1ffffff)); out[0*64+19] = (start + ((w7 >> 27) & 0x1ffffff)); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*64+20] = (start + ((w7 >> 52) | (w8 << 12) & 0x1ffffff)); out[0*64+21] = (start + ((w8 >> 13) & 0x1ffffff)); out[0*64+22] = (start + ((w8 >> 38) & 0x1ffffff)); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*64+23] = (start + ((w8 >> 63) | (w9 << 1) & 0x1ffffff)); out[0*64+24] = (start + ((w9 >> 24) & 0x1ffffff)); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*64+25] = (start + ((w9 >> 49) | (w10 << 15) & 0x1ffffff)); out[0*64+26] = (start + ((w10 >> 10) & 0x1ffffff)); out[0*64+27] = (start + ((w10 >> 35) & 0x1ffffff)); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*64+28] = (start + ((w10 >> 60) | (w11 << 4) & 0x1ffffff)); out[0*64+29] = (start + ((w11 >> 21) & 0x1ffffff)); w12 = *(uint32_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*64+30] = (start + ((w11 >> 46) | (w12 << 18) & 0x1ffffff)); out[0*64+31] = (start + ((w12 >> 7) & 0x1ffffff));;}; out += 32; in += 25*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_26(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*26)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3ffffff)); out[0*32+ 1] = (start + ((w0 >> 26) & 0x3ffffff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*32+ 2] = (start + ((w0 >> 52) | (w1 << 12) & 0x3ffffff)); out[0*32+ 3] = (start + ((w1 >> 14) & 0x3ffffff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*32+ 4] = (start + ((w1 >> 40) | (w2 << 24) & 0x3ffffff)); out[0*32+ 5] = (start + ((w2 >> 2) & 0x3ffffff)); out[0*32+ 6] = (start + ((w2 >> 28) & 0x3ffffff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*32+ 7] = (start + ((w2 >> 54) | (w3 << 10) & 0x3ffffff)); out[0*32+ 8] = (start + ((w3 >> 16) & 0x3ffffff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*32+ 9] = (start + ((w3 >> 42) | (w4 << 22) & 0x3ffffff)); out[0*32+10] = (start + ((w4 >> 4) & 0x3ffffff)); out[0*32+11] = (start + ((w4 >> 30) & 0x3ffffff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*32+12] = (start + ((w4 >> 56) | (w5 << 8) & 0x3ffffff)); out[0*32+13] = (start + ((w5 >> 18) & 0x3ffffff)); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*32+14] = (start + ((w5 >> 44) | (w6 << 20) & 0x3ffffff)); out[0*32+15] = (start + ((w6 >> 6) & 0x3ffffff)); out[0*32+16] = (start + ((w6 >> 32) & 0x3ffffff)); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*32+17] = (start + ((w6 >> 58) | (w7 << 6) & 0x3ffffff)); out[0*32+18] = (start + ((w7 >> 20) & 0x3ffffff)); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*32+19] = (start + ((w7 >> 46) | (w8 << 18) & 0x3ffffff)); out[0*32+20] = (start + ((w8 >> 8) & 0x3ffffff)); out[0*32+21] = (start + ((w8 >> 34) & 0x3ffffff)); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*32+22] = (start + ((w8 >> 60) | (w9 << 4) & 0x3ffffff)); out[0*32+23] = (start + ((w9 >> 22) & 0x3ffffff)); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*32+24] = (start + ((w9 >> 48) | (w10 << 16) & 0x3ffffff)); out[0*32+25] = (start + ((w10 >> 10) & 0x3ffffff)); out[0*32+26] = (start + ((w10 >> 36) & 0x3ffffff)); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*32+27] = (start + ((w10 >> 62) | (w11 << 2) & 0x3ffffff)); out[0*32+28] = (start + ((w11 >> 24) & 0x3ffffff)); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*32+29] = (start + ((w11 >> 50) | (w12 << 14) & 0x3ffffff)); out[0*32+30] = (start + ((w12 >> 12) & 0x3ffffff)); out[0*32+31] = (start + ((w12 >> 38)));;}; out += 32; in += 26*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_27(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*27)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7ffffff)); out[0*64+ 1] = (start + ((w0 >> 27) & 0x7ffffff)); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w0 >> 54) | (w1 << 10) & 0x7ffffff)); out[0*64+ 3] = (start + ((w1 >> 17) & 0x7ffffff)); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w1 >> 44) | (w2 << 20) & 0x7ffffff)); out[0*64+ 5] = (start + ((w2 >> 7) & 0x7ffffff)); out[0*64+ 6] = (start + ((w2 >> 34) & 0x7ffffff)); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w2 >> 61) | (w3 << 3) & 0x7ffffff)); out[0*64+ 8] = (start + ((w3 >> 24) & 0x7ffffff)); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w3 >> 51) | (w4 << 13) & 0x7ffffff)); out[0*64+10] = (start + ((w4 >> 14) & 0x7ffffff)); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*64+11] = (start + ((w4 >> 41) | (w5 << 23) & 0x7ffffff)); out[0*64+12] = (start + ((w5 >> 4) & 0x7ffffff)); out[0*64+13] = (start + ((w5 >> 31) & 0x7ffffff)); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*64+14] = (start + ((w5 >> 58) | (w6 << 6) & 0x7ffffff)); out[0*64+15] = (start + ((w6 >> 21) & 0x7ffffff)); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*64+16] = (start + ((w6 >> 48) | (w7 << 16) & 0x7ffffff)); out[0*64+17] = (start + ((w7 >> 11) & 0x7ffffff)); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*64+18] = (start + ((w7 >> 38) | (w8 << 26) & 0x7ffffff)); out[0*64+19] = (start + ((w8 >> 1) & 0x7ffffff)); out[0*64+20] = (start + ((w8 >> 28) & 0x7ffffff)); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*64+21] = (start + ((w8 >> 55) | (w9 << 9) & 0x7ffffff)); out[0*64+22] = (start + ((w9 >> 18) & 0x7ffffff)); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*64+23] = (start + ((w9 >> 45) | (w10 << 19) & 0x7ffffff)); out[0*64+24] = (start + ((w10 >> 8) & 0x7ffffff)); out[0*64+25] = (start + ((w10 >> 35) & 0x7ffffff)); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*64+26] = (start + ((w10 >> 62) | (w11 << 2) & 0x7ffffff)); out[0*64+27] = (start + ((w11 >> 25) & 0x7ffffff)); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*64+28] = (start + ((w11 >> 52) | (w12 << 12) & 0x7ffffff)); out[0*64+29] = (start + ((w12 >> 15) & 0x7ffffff)); w13 = *(uint32_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*64+30] = (start + ((w12 >> 42) | (w13 << 22) & 0x7ffffff)); out[0*64+31] = (start + ((w13 >> 5) & 0x7ffffff));;}; out += 32; in += 27*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_28(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*28)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xfffffff)); out[0*16+ 1] = (start + ((w0 >> 28) & 0xfffffff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*16+ 2] = (start + ((w0 >> 56) | (w1 << 8) & 0xfffffff)); out[0*16+ 3] = (start + ((w1 >> 20) & 0xfffffff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*16+ 4] = (start + ((w1 >> 48) | (w2 << 16) & 0xfffffff)); out[0*16+ 5] = (start + ((w2 >> 12) & 0xfffffff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*16+ 6] = (start + ((w2 >> 40) | (w3 << 24) & 0xfffffff)); out[0*16+ 7] = (start + ((w3 >> 4) & 0xfffffff)); out[0*16+ 8] = (start + ((w3 >> 32) & 0xfffffff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*16+ 9] = (start + ((w3 >> 60) | (w4 << 4) & 0xfffffff)); out[0*16+10] = (start + ((w4 >> 24) & 0xfffffff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*16+11] = (start + ((w4 >> 52) | (w5 << 12) & 0xfffffff)); out[0*16+12] = (start + ((w5 >> 16) & 0xfffffff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*16+13] = (start + ((w5 >> 44) | (w6 << 20) & 0xfffffff)); out[0*16+14] = (start + ((w6 >> 8) & 0xfffffff)); out[0*16+15] = (start + ((w6 >> 36)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xfffffff)); out[1*16+ 1] = (start + ((w0 >> 28) & 0xfffffff)); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*16+ 2] = (start + ((w0 >> 56) | (w1 << 8) & 0xfffffff)); out[1*16+ 3] = (start + ((w1 >> 20) & 0xfffffff)); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*16+ 4] = (start + ((w1 >> 48) | (w2 << 16) & 0xfffffff)); out[1*16+ 5] = (start + ((w2 >> 12) & 0xfffffff)); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*16+ 6] = (start + ((w2 >> 40) | (w3 << 24) & 0xfffffff)); out[1*16+ 7] = (start + ((w3 >> 4) & 0xfffffff)); out[1*16+ 8] = (start + ((w3 >> 32) & 0xfffffff)); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*16+ 9] = (start + ((w3 >> 60) | (w4 << 4) & 0xfffffff)); out[1*16+10] = (start + ((w4 >> 24) & 0xfffffff)); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*16+11] = (start + ((w4 >> 52) | (w5 << 12) & 0xfffffff)); out[1*16+12] = (start + ((w5 >> 16) & 0xfffffff)); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*16+13] = (start + ((w5 >> 44) | (w6 << 20) & 0xfffffff)); out[1*16+14] = (start + ((w6 >> 8) & 0xfffffff)); out[1*16+15] = (start + ((w6 >> 36)));;}; out += 32; in += 28*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_29(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*29)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1fffffff)); out[0*64+ 1] = (start + ((w0 >> 29) & 0x1fffffff)); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w0 >> 58) | (w1 << 6) & 0x1fffffff)); out[0*64+ 3] = (start + ((w1 >> 23) & 0x1fffffff)); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w1 >> 52) | (w2 << 12) & 0x1fffffff)); out[0*64+ 5] = (start + ((w2 >> 17) & 0x1fffffff)); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w2 >> 46) | (w3 << 18) & 0x1fffffff)); out[0*64+ 7] = (start + ((w3 >> 11) & 0x1fffffff)); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w3 >> 40) | (w4 << 24) & 0x1fffffff)); out[0*64+ 9] = (start + ((w4 >> 5) & 0x1fffffff)); out[0*64+10] = (start + ((w4 >> 34) & 0x1fffffff)); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*64+11] = (start + ((w4 >> 63) | (w5 << 1) & 0x1fffffff)); out[0*64+12] = (start + ((w5 >> 28) & 0x1fffffff)); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*64+13] = (start + ((w5 >> 57) | (w6 << 7) & 0x1fffffff)); out[0*64+14] = (start + ((w6 >> 22) & 0x1fffffff)); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*64+15] = (start + ((w6 >> 51) | (w7 << 13) & 0x1fffffff)); out[0*64+16] = (start + ((w7 >> 16) & 0x1fffffff)); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*64+17] = (start + ((w7 >> 45) | (w8 << 19) & 0x1fffffff)); out[0*64+18] = (start + ((w8 >> 10) & 0x1fffffff)); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*64+19] = (start + ((w8 >> 39) | (w9 << 25) & 0x1fffffff)); out[0*64+20] = (start + ((w9 >> 4) & 0x1fffffff)); out[0*64+21] = (start + ((w9 >> 33) & 0x1fffffff)); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*64+22] = (start + ((w9 >> 62) | (w10 << 2) & 0x1fffffff)); out[0*64+23] = (start + ((w10 >> 27) & 0x1fffffff)); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*64+24] = (start + ((w10 >> 56) | (w11 << 8) & 0x1fffffff)); out[0*64+25] = (start + ((w11 >> 21) & 0x1fffffff)); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*64+26] = (start + ((w11 >> 50) | (w12 << 14) & 0x1fffffff)); out[0*64+27] = (start + ((w12 >> 15) & 0x1fffffff)); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*64+28] = (start + ((w12 >> 44) | (w13 << 20) & 0x1fffffff)); out[0*64+29] = (start + ((w13 >> 9) & 0x1fffffff)); w14 = *(uint32_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*64+30] = (start + ((w13 >> 38) | (w14 << 26) & 0x1fffffff)); out[0*64+31] = (start + ((w14 >> 3) & 0x1fffffff));;}; out += 32; in += 29*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_30(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*30)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3fffffff)); out[0*32+ 1] = (start + ((w0 >> 30) & 0x3fffffff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*32+ 2] = (start + ((w0 >> 60) | (w1 << 4) & 0x3fffffff)); out[0*32+ 3] = (start + ((w1 >> 26) & 0x3fffffff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*32+ 4] = (start + ((w1 >> 56) | (w2 << 8) & 0x3fffffff)); out[0*32+ 5] = (start + ((w2 >> 22) & 0x3fffffff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*32+ 6] = (start + ((w2 >> 52) | (w3 << 12) & 0x3fffffff)); out[0*32+ 7] = (start + ((w3 >> 18) & 0x3fffffff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*32+ 8] = (start + ((w3 >> 48) | (w4 << 16) & 0x3fffffff)); out[0*32+ 9] = (start + ((w4 >> 14) & 0x3fffffff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*32+10] = (start + ((w4 >> 44) | (w5 << 20) & 0x3fffffff)); out[0*32+11] = (start + ((w5 >> 10) & 0x3fffffff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*32+12] = (start + ((w5 >> 40) | (w6 << 24) & 0x3fffffff)); out[0*32+13] = (start + ((w6 >> 6) & 0x3fffffff)); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*32+14] = (start + ((w6 >> 36) | (w7 << 28) & 0x3fffffff)); out[0*32+15] = (start + ((w7 >> 2) & 0x3fffffff)); out[0*32+16] = (start + ((w7 >> 32) & 0x3fffffff)); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*32+17] = (start + ((w7 >> 62) | (w8 << 2) & 0x3fffffff)); out[0*32+18] = (start + ((w8 >> 28) & 0x3fffffff)); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*32+19] = (start + ((w8 >> 58) | (w9 << 6) & 0x3fffffff)); out[0*32+20] = (start + ((w9 >> 24) & 0x3fffffff)); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*32+21] = (start + ((w9 >> 54) | (w10 << 10) & 0x3fffffff)); out[0*32+22] = (start + ((w10 >> 20) & 0x3fffffff)); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*32+23] = (start + ((w10 >> 50) | (w11 << 14) & 0x3fffffff)); out[0*32+24] = (start + ((w11 >> 16) & 0x3fffffff)); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*32+25] = (start + ((w11 >> 46) | (w12 << 18) & 0x3fffffff)); out[0*32+26] = (start + ((w12 >> 12) & 0x3fffffff)); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*32+27] = (start + ((w12 >> 42) | (w13 << 22) & 0x3fffffff)); out[0*32+28] = (start + ((w13 >> 8) & 0x3fffffff)); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*32+29] = (start + ((w13 >> 38) | (w14 << 26) & 0x3fffffff)); out[0*32+30] = (start + ((w14 >> 4) & 0x3fffffff)); out[0*32+31] = (start + ((w14 >> 34)));;}; out += 32; in += 30*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_31(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*31)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7fffffff)); out[0*64+ 1] = (start + ((w0 >> 31) & 0x7fffffff)); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w0 >> 62) | (w1 << 2) & 0x7fffffff)); out[0*64+ 3] = (start + ((w1 >> 29) & 0x7fffffff)); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w1 >> 60) | (w2 << 4) & 0x7fffffff)); out[0*64+ 5] = (start + ((w2 >> 27) & 0x7fffffff)); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w2 >> 58) | (w3 << 6) & 0x7fffffff)); out[0*64+ 7] = (start + ((w3 >> 25) & 0x7fffffff)); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w3 >> 56) | (w4 << 8) & 0x7fffffff)); out[0*64+ 9] = (start + ((w4 >> 23) & 0x7fffffff)); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*64+10] = (start + ((w4 >> 54) | (w5 << 10) & 0x7fffffff)); out[0*64+11] = (start + ((w5 >> 21) & 0x7fffffff)); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*64+12] = (start + ((w5 >> 52) | (w6 << 12) & 0x7fffffff)); out[0*64+13] = (start + ((w6 >> 19) & 0x7fffffff)); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*64+14] = (start + ((w6 >> 50) | (w7 << 14) & 0x7fffffff)); out[0*64+15] = (start + ((w7 >> 17) & 0x7fffffff)); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*64+16] = (start + ((w7 >> 48) | (w8 << 16) & 0x7fffffff)); out[0*64+17] = (start + ((w8 >> 15) & 0x7fffffff)); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*64+18] = (start + ((w8 >> 46) | (w9 << 18) & 0x7fffffff)); out[0*64+19] = (start + ((w9 >> 13) & 0x7fffffff)); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*64+20] = (start + ((w9 >> 44) | (w10 << 20) & 0x7fffffff)); out[0*64+21] = (start + ((w10 >> 11) & 0x7fffffff)); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*64+22] = (start + ((w10 >> 42) | (w11 << 22) & 0x7fffffff)); out[0*64+23] = (start + ((w11 >> 9) & 0x7fffffff)); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*64+24] = (start + ((w11 >> 40) | (w12 << 24) & 0x7fffffff)); out[0*64+25] = (start + ((w12 >> 7) & 0x7fffffff)); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*64+26] = (start + ((w12 >> 38) | (w13 << 26) & 0x7fffffff)); out[0*64+27] = (start + ((w13 >> 5) & 0x7fffffff)); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*64+28] = (start + ((w13 >> 36) | (w14 << 28) & 0x7fffffff)); out[0*64+29] = (start + ((w14 >> 3) & 0x7fffffff)); w15 = *(uint32_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*64+30] = (start + ((w14 >> 34) | (w15 << 30) & 0x7fffffff)); out[0*64+31] = (start + ((w15 >> 1) & 0x7fffffff));;}; out += 32; in += 31*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack32_32(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*32)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[0*2+ 0] = (start + (*(uint32_t *)(in+0*8+ 0))); out[0*2+ 1] = (start + (*(uint32_t *)(in+0*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[1*2+ 0] = (start + (*(uint32_t *)(in+1*8+ 0))); out[1*2+ 1] = (start + (*(uint32_t *)(in+1*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[2*2+ 0] = (start + (*(uint32_t *)(in+2*8+ 0))); out[2*2+ 1] = (start + (*(uint32_t *)(in+2*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[3*2+ 0] = (start + (*(uint32_t *)(in+3*8+ 0))); out[3*2+ 1] = (start + (*(uint32_t *)(in+3*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[4*2+ 0] = (start + (*(uint32_t *)(in+4*8+ 0))); out[4*2+ 1] = (start + (*(uint32_t *)(in+4*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[5*2+ 0] = (start + (*(uint32_t *)(in+5*8+ 0))); out[5*2+ 1] = (start + (*(uint32_t *)(in+5*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[6*2+ 0] = (start + (*(uint32_t *)(in+6*8+ 0))); out[6*2+ 1] = (start + (*(uint32_t *)(in+6*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[7*2+ 0] = (start + (*(uint32_t *)(in+7*8+ 0))); out[7*2+ 1] = (start + (*(uint32_t *)(in+7*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[8*2+ 0] = (start + (*(uint32_t *)(in+8*8+ 0))); out[8*2+ 1] = (start + (*(uint32_t *)(in+8*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[9*2+ 0] = (start + (*(uint32_t *)(in+9*8+ 0))); out[9*2+ 1] = (start + (*(uint32_t *)(in+9*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[10*2+ 0] = (start + (*(uint32_t *)(in+10*8+ 0))); out[10*2+ 1] = (start + (*(uint32_t *)(in+10*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[11*2+ 0] = (start + (*(uint32_t *)(in+11*8+ 0))); out[11*2+ 1] = (start + (*(uint32_t *)(in+11*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[12*2+ 0] = (start + (*(uint32_t *)(in+12*8+ 0))); out[12*2+ 1] = (start + (*(uint32_t *)(in+12*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[13*2+ 0] = (start + (*(uint32_t *)(in+13*8+ 0))); out[13*2+ 1] = (start + (*(uint32_t *)(in+13*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[14*2+ 0] = (start + (*(uint32_t *)(in+14*8+ 0))); out[14*2+ 1] = (start + (*(uint32_t *)(in+14*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[15*2+ 0] = (start + (*(uint32_t *)(in+15*8+ 0))); out[15*2+ 1] = (start + (*(uint32_t *)(in+15*8+ 4)));;}; out += 32; in += 32*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D32 bitfunpacka32[] = {
  &bitfunpack32_0,
  &bitfunpack32_1,
  &bitfunpack32_2,
  &bitfunpack32_3,
  &bitfunpack32_4,
  &bitfunpack32_5,
  &bitfunpack32_6,
  &bitfunpack32_7,
  &bitfunpack32_8,
  &bitfunpack32_9,
  &bitfunpack32_10,
  &bitfunpack32_11,
  &bitfunpack32_12,
  &bitfunpack32_13,
  &bitfunpack32_14,
  &bitfunpack32_15,
  &bitfunpack32_16,
  &bitfunpack32_17,
  &bitfunpack32_18,
  &bitfunpack32_19,
  &bitfunpack32_20,
  &bitfunpack32_21,
  &bitfunpack32_22,
  &bitfunpack32_23,
  &bitfunpack32_24,
  &bitfunpack32_25,
  &bitfunpack32_26,
  &bitfunpack32_27,
  &bitfunpack32_28,
  &bitfunpack32_29,
  &bitfunpack32_30,
  &bitfunpack32_31,
  &bitfunpack32_32
};
unsigned char *bitfunpack32( const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start, unsigned b) { return bitfunpacka32[ b](in, n, out, start); }
unsigned char *bitfunpack64_0(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint64_t *out_ = out+n; do { { { out[0*0+ 0] = (start + (0)); out[0*0+ 1] = (start + (0)); out[0*0+ 2] = (start + (0)); out[0*0+ 3] = (start + (0)); out[0*0+ 4] = (start + (0)); out[0*0+ 5] = (start + (0)); out[0*0+ 6] = (start + (0)); out[0*0+ 7] = (start + (0)); out[0*0+ 8] = (start + (0)); out[0*0+ 9] = (start + (0)); out[0*0+10] = (start + (0)); out[0*0+11] = (start + (0)); out[0*0+12] = (start + (0)); out[0*0+13] = (start + (0)); out[0*0+14] = (start + (0)); out[0*0+15] = (start + (0)); out[0*0+16] = (start + (0)); out[0*0+17] = (start + (0)); out[0*0+18] = (start + (0)); out[0*0+19] = (start + (0)); out[0*0+20] = (start + (0)); out[0*0+21] = (start + (0)); out[0*0+22] = (start + (0)); out[0*0+23] = (start + (0)); out[0*0+24] = (start + (0)); out[0*0+25] = (start + (0)); out[0*0+26] = (start + (0)); out[0*0+27] = (start + (0)); out[0*0+28] = (start + (0)); out[0*0+29] = (start + (0)); out[0*0+30] = (start + (0)); out[0*0+31] = (start + (0));;}; out += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitfunpack64_1(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x1)); out[0*32+ 1] = (start + ((w0 >> 1) & 0x1)); out[0*32+ 2] = (start + ((w0 >> 2) & 0x1)); out[0*32+ 3] = (start + ((w0 >> 3) & 0x1)); out[0*32+ 4] = (start + ((w0 >> 4) & 0x1)); out[0*32+ 5] = (start + ((w0 >> 5) & 0x1)); out[0*32+ 6] = (start + ((w0 >> 6) & 0x1)); out[0*32+ 7] = (start + ((w0 >> 7) & 0x1)); out[0*32+ 8] = (start + ((w0 >> 8) & 0x1)); out[0*32+ 9] = (start + ((w0 >> 9) & 0x1)); out[0*32+10] = (start + ((w0 >> 10) & 0x1)); out[0*32+11] = (start + ((w0 >> 11) & 0x1)); out[0*32+12] = (start + ((w0 >> 12) & 0x1)); out[0*32+13] = (start + ((w0 >> 13) & 0x1)); out[0*32+14] = (start + ((w0 >> 14) & 0x1)); out[0*32+15] = (start + ((w0 >> 15) & 0x1)); out[0*32+16] = (start + ((w0 >> 16) & 0x1)); out[0*32+17] = (start + ((w0 >> 17) & 0x1)); out[0*32+18] = (start + ((w0 >> 18) & 0x1)); out[0*32+19] = (start + ((w0 >> 19) & 0x1)); out[0*32+20] = (start + ((w0 >> 20) & 0x1)); out[0*32+21] = (start + ((w0 >> 21) & 0x1)); out[0*32+22] = (start + ((w0 >> 22) & 0x1)); out[0*32+23] = (start + ((w0 >> 23) & 0x1)); out[0*32+24] = (start + ((w0 >> 24) & 0x1)); out[0*32+25] = (start + ((w0 >> 25) & 0x1)); out[0*32+26] = (start + ((w0 >> 26) & 0x1)); out[0*32+27] = (start + ((w0 >> 27) & 0x1)); out[0*32+28] = (start + ((w0 >> 28) & 0x1)); out[0*32+29] = (start + ((w0 >> 29) & 0x1)); out[0*32+30] = (start + ((w0 >> 30) & 0x1)); out[0*32+31] = (start + ((w0 >> 31)));;}; out += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_2(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3)); out[0*32+ 1] = (start + ((w0 >> 2) & 0x3)); out[0*32+ 2] = (start + ((w0 >> 4) & 0x3)); out[0*32+ 3] = (start + ((w0 >> 6) & 0x3)); out[0*32+ 4] = (start + ((w0 >> 8) & 0x3)); out[0*32+ 5] = (start + ((w0 >> 10) & 0x3)); out[0*32+ 6] = (start + ((w0 >> 12) & 0x3)); out[0*32+ 7] = (start + ((w0 >> 14) & 0x3)); out[0*32+ 8] = (start + ((w0 >> 16) & 0x3)); out[0*32+ 9] = (start + ((w0 >> 18) & 0x3)); out[0*32+10] = (start + ((w0 >> 20) & 0x3)); out[0*32+11] = (start + ((w0 >> 22) & 0x3)); out[0*32+12] = (start + ((w0 >> 24) & 0x3)); out[0*32+13] = (start + ((w0 >> 26) & 0x3)); out[0*32+14] = (start + ((w0 >> 28) & 0x3)); out[0*32+15] = (start + ((w0 >> 30) & 0x3)); out[0*32+16] = (start + ((w0 >> 32) & 0x3)); out[0*32+17] = (start + ((w0 >> 34) & 0x3)); out[0*32+18] = (start + ((w0 >> 36) & 0x3)); out[0*32+19] = (start + ((w0 >> 38) & 0x3)); out[0*32+20] = (start + ((w0 >> 40) & 0x3)); out[0*32+21] = (start + ((w0 >> 42) & 0x3)); out[0*32+22] = (start + ((w0 >> 44) & 0x3)); out[0*32+23] = (start + ((w0 >> 46) & 0x3)); out[0*32+24] = (start + ((w0 >> 48) & 0x3)); out[0*32+25] = (start + ((w0 >> 50) & 0x3)); out[0*32+26] = (start + ((w0 >> 52) & 0x3)); out[0*32+27] = (start + ((w0 >> 54) & 0x3)); out[0*32+28] = (start + ((w0 >> 56) & 0x3)); out[0*32+29] = (start + ((w0 >> 58) & 0x3)); out[0*32+30] = (start + ((w0 >> 60) & 0x3)); out[0*32+31] = (start + ((w0 >> 62)));;}; out += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_3(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7)); out[0*64+ 1] = (start + ((w0 >> 3) & 0x7)); out[0*64+ 2] = (start + ((w0 >> 6) & 0x7)); out[0*64+ 3] = (start + ((w0 >> 9) & 0x7)); out[0*64+ 4] = (start + ((w0 >> 12) & 0x7)); out[0*64+ 5] = (start + ((w0 >> 15) & 0x7)); out[0*64+ 6] = (start + ((w0 >> 18) & 0x7)); out[0*64+ 7] = (start + ((w0 >> 21) & 0x7)); out[0*64+ 8] = (start + ((w0 >> 24) & 0x7)); out[0*64+ 9] = (start + ((w0 >> 27) & 0x7)); out[0*64+10] = (start + ((w0 >> 30) & 0x7)); out[0*64+11] = (start + ((w0 >> 33) & 0x7)); out[0*64+12] = (start + ((w0 >> 36) & 0x7)); out[0*64+13] = (start + ((w0 >> 39) & 0x7)); out[0*64+14] = (start + ((w0 >> 42) & 0x7)); out[0*64+15] = (start + ((w0 >> 45) & 0x7)); out[0*64+16] = (start + ((w0 >> 48) & 0x7)); out[0*64+17] = (start + ((w0 >> 51) & 0x7)); out[0*64+18] = (start + ((w0 >> 54) & 0x7)); out[0*64+19] = (start + ((w0 >> 57) & 0x7)); out[0*64+20] = (start + ((w0 >> 60) & 0x7)); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start + ((w0 >> 63) | (w1 << 1) & 0x7)); out[0*64+22] = (start + ((w1 >> 2) & 0x7)); out[0*64+23] = (start + ((w1 >> 5) & 0x7)); out[0*64+24] = (start + ((w1 >> 8) & 0x7)); out[0*64+25] = (start + ((w1 >> 11) & 0x7)); out[0*64+26] = (start + ((w1 >> 14) & 0x7)); out[0*64+27] = (start + ((w1 >> 17) & 0x7)); out[0*64+28] = (start + ((w1 >> 20) & 0x7)); out[0*64+29] = (start + ((w1 >> 23) & 0x7)); out[0*64+30] = (start + ((w1 >> 26) & 0x7)); out[0*64+31] = (start + ((w1 >> 29) & 0x7));;}; out += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_4(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xf)); out[0*16+ 1] = (start + ((w0 >> 4) & 0xf)); out[0*16+ 2] = (start + ((w0 >> 8) & 0xf)); out[0*16+ 3] = (start + ((w0 >> 12) & 0xf)); out[0*16+ 4] = (start + ((w0 >> 16) & 0xf)); out[0*16+ 5] = (start + ((w0 >> 20) & 0xf)); out[0*16+ 6] = (start + ((w0 >> 24) & 0xf)); out[0*16+ 7] = (start + ((w0 >> 28) & 0xf)); out[0*16+ 8] = (start + ((w0 >> 32) & 0xf)); out[0*16+ 9] = (start + ((w0 >> 36) & 0xf)); out[0*16+10] = (start + ((w0 >> 40) & 0xf)); out[0*16+11] = (start + ((w0 >> 44) & 0xf)); out[0*16+12] = (start + ((w0 >> 48) & 0xf)); out[0*16+13] = (start + ((w0 >> 52) & 0xf)); out[0*16+14] = (start + ((w0 >> 56) & 0xf)); out[0*16+15] = (start + ((w0 >> 60)));;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xf)); out[1*16+ 1] = (start + ((w0 >> 4) & 0xf)); out[1*16+ 2] = (start + ((w0 >> 8) & 0xf)); out[1*16+ 3] = (start + ((w0 >> 12) & 0xf)); out[1*16+ 4] = (start + ((w0 >> 16) & 0xf)); out[1*16+ 5] = (start + ((w0 >> 20) & 0xf)); out[1*16+ 6] = (start + ((w0 >> 24) & 0xf)); out[1*16+ 7] = (start + ((w0 >> 28) & 0xf)); out[1*16+ 8] = (start + ((w0 >> 32) & 0xf)); out[1*16+ 9] = (start + ((w0 >> 36) & 0xf)); out[1*16+10] = (start + ((w0 >> 40) & 0xf)); out[1*16+11] = (start + ((w0 >> 44) & 0xf)); out[1*16+12] = (start + ((w0 >> 48) & 0xf)); out[1*16+13] = (start + ((w0 >> 52) & 0xf)); out[1*16+14] = (start + ((w0 >> 56) & 0xf)); out[1*16+15] = (start + ((w0 >> 60)));;}; out += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_5(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1f)); out[0*64+ 1] = (start + ((w0 >> 5) & 0x1f)); out[0*64+ 2] = (start + ((w0 >> 10) & 0x1f)); out[0*64+ 3] = (start + ((w0 >> 15) & 0x1f)); out[0*64+ 4] = (start + ((w0 >> 20) & 0x1f)); out[0*64+ 5] = (start + ((w0 >> 25) & 0x1f)); out[0*64+ 6] = (start + ((w0 >> 30) & 0x1f)); out[0*64+ 7] = (start + ((w0 >> 35) & 0x1f)); out[0*64+ 8] = (start + ((w0 >> 40) & 0x1f)); out[0*64+ 9] = (start + ((w0 >> 45) & 0x1f)); out[0*64+10] = (start + ((w0 >> 50) & 0x1f)); out[0*64+11] = (start + ((w0 >> 55) & 0x1f)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start + ((w0 >> 60) | (w1 << 4) & 0x1f)); out[0*64+13] = (start + ((w1 >> 1) & 0x1f)); out[0*64+14] = (start + ((w1 >> 6) & 0x1f)); out[0*64+15] = (start + ((w1 >> 11) & 0x1f)); out[0*64+16] = (start + ((w1 >> 16) & 0x1f)); out[0*64+17] = (start + ((w1 >> 21) & 0x1f)); out[0*64+18] = (start + ((w1 >> 26) & 0x1f)); out[0*64+19] = (start + ((w1 >> 31) & 0x1f)); out[0*64+20] = (start + ((w1 >> 36) & 0x1f)); out[0*64+21] = (start + ((w1 >> 41) & 0x1f)); out[0*64+22] = (start + ((w1 >> 46) & 0x1f)); out[0*64+23] = (start + ((w1 >> 51) & 0x1f)); out[0*64+24] = (start + ((w1 >> 56) & 0x1f)); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start + ((w1 >> 61) | (w2 << 3) & 0x1f)); out[0*64+26] = (start + ((w2 >> 2) & 0x1f)); out[0*64+27] = (start + ((w2 >> 7) & 0x1f)); out[0*64+28] = (start + ((w2 >> 12) & 0x1f)); out[0*64+29] = (start + ((w2 >> 17) & 0x1f)); out[0*64+30] = (start + ((w2 >> 22) & 0x1f)); out[0*64+31] = (start + ((w2 >> 27) & 0x1f));;}; out += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_6(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3f)); out[0*32+ 1] = (start + ((w0 >> 6) & 0x3f)); out[0*32+ 2] = (start + ((w0 >> 12) & 0x3f)); out[0*32+ 3] = (start + ((w0 >> 18) & 0x3f)); out[0*32+ 4] = (start + ((w0 >> 24) & 0x3f)); out[0*32+ 5] = (start + ((w0 >> 30) & 0x3f)); out[0*32+ 6] = (start + ((w0 >> 36) & 0x3f)); out[0*32+ 7] = (start + ((w0 >> 42) & 0x3f)); out[0*32+ 8] = (start + ((w0 >> 48) & 0x3f)); out[0*32+ 9] = (start + ((w0 >> 54) & 0x3f)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start + ((w0 >> 60) | (w1 << 4) & 0x3f)); out[0*32+11] = (start + ((w1 >> 2) & 0x3f)); out[0*32+12] = (start + ((w1 >> 8) & 0x3f)); out[0*32+13] = (start + ((w1 >> 14) & 0x3f)); out[0*32+14] = (start + ((w1 >> 20) & 0x3f)); out[0*32+15] = (start + ((w1 >> 26) & 0x3f)); out[0*32+16] = (start + ((w1 >> 32) & 0x3f)); out[0*32+17] = (start + ((w1 >> 38) & 0x3f)); out[0*32+18] = (start + ((w1 >> 44) & 0x3f)); out[0*32+19] = (start + ((w1 >> 50) & 0x3f)); out[0*32+20] = (start + ((w1 >> 56) & 0x3f)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start + ((w1 >> 62) | (w2 << 2) & 0x3f)); out[0*32+22] = (start + ((w2 >> 4) & 0x3f)); out[0*32+23] = (start + ((w2 >> 10) & 0x3f)); out[0*32+24] = (start + ((w2 >> 16) & 0x3f)); out[0*32+25] = (start + ((w2 >> 22) & 0x3f)); out[0*32+26] = (start + ((w2 >> 28) & 0x3f)); out[0*32+27] = (start + ((w2 >> 34) & 0x3f)); out[0*32+28] = (start + ((w2 >> 40) & 0x3f)); out[0*32+29] = (start + ((w2 >> 46) & 0x3f)); out[0*32+30] = (start + ((w2 >> 52) & 0x3f)); out[0*32+31] = (start + ((w2 >> 58)));;}; out += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_7(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7f)); out[0*64+ 1] = (start + ((w0 >> 7) & 0x7f)); out[0*64+ 2] = (start + ((w0 >> 14) & 0x7f)); out[0*64+ 3] = (start + ((w0 >> 21) & 0x7f)); out[0*64+ 4] = (start + ((w0 >> 28) & 0x7f)); out[0*64+ 5] = (start + ((w0 >> 35) & 0x7f)); out[0*64+ 6] = (start + ((w0 >> 42) & 0x7f)); out[0*64+ 7] = (start + ((w0 >> 49) & 0x7f)); out[0*64+ 8] = (start + ((w0 >> 56) & 0x7f)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w0 >> 63) | (w1 << 1) & 0x7f)); out[0*64+10] = (start + ((w1 >> 6) & 0x7f)); out[0*64+11] = (start + ((w1 >> 13) & 0x7f)); out[0*64+12] = (start + ((w1 >> 20) & 0x7f)); out[0*64+13] = (start + ((w1 >> 27) & 0x7f)); out[0*64+14] = (start + ((w1 >> 34) & 0x7f)); out[0*64+15] = (start + ((w1 >> 41) & 0x7f)); out[0*64+16] = (start + ((w1 >> 48) & 0x7f)); out[0*64+17] = (start + ((w1 >> 55) & 0x7f)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start + ((w1 >> 62) | (w2 << 2) & 0x7f)); out[0*64+19] = (start + ((w2 >> 5) & 0x7f)); out[0*64+20] = (start + ((w2 >> 12) & 0x7f)); out[0*64+21] = (start + ((w2 >> 19) & 0x7f)); out[0*64+22] = (start + ((w2 >> 26) & 0x7f)); out[0*64+23] = (start + ((w2 >> 33) & 0x7f)); out[0*64+24] = (start + ((w2 >> 40) & 0x7f)); out[0*64+25] = (start + ((w2 >> 47) & 0x7f)); out[0*64+26] = (start + ((w2 >> 54) & 0x7f)); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start + ((w2 >> 61) | (w3 << 3) & 0x7f)); out[0*64+28] = (start + ((w3 >> 4) & 0x7f)); out[0*64+29] = (start + ((w3 >> 11) & 0x7f)); out[0*64+30] = (start + ((w3 >> 18) & 0x7f)); out[0*64+31] = (start + ((w3 >> 25) & 0x7f));;}; out += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_8(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start + ((w0 ) & 0xff)); out[0*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[0*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[0*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[0*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[0*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[0*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[0*8+ 7] = (start + ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start + ((w0 ) & 0xff)); out[1*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[1*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[1*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[1*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[1*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[1*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[1*8+ 7] = (start + ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start + ((w0 ) & 0xff)); out[2*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[2*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[2*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[2*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[2*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[2*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[2*8+ 7] = (start + ((w0 >> 56)));;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start + ((w0 ) & 0xff)); out[3*8+ 1] = (start + ((w0 >> 8) & 0xff)); out[3*8+ 2] = (start + ((w0 >> 16) & 0xff)); out[3*8+ 3] = (start + ((w0 >> 24) & 0xff)); out[3*8+ 4] = (start + ((w0 >> 32) & 0xff)); out[3*8+ 5] = (start + ((w0 >> 40) & 0xff)); out[3*8+ 6] = (start + ((w0 >> 48) & 0xff)); out[3*8+ 7] = (start + ((w0 >> 56)));;}; out += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_9(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1ff)); out[0*64+ 1] = (start + ((w0 >> 9) & 0x1ff)); out[0*64+ 2] = (start + ((w0 >> 18) & 0x1ff)); out[0*64+ 3] = (start + ((w0 >> 27) & 0x1ff)); out[0*64+ 4] = (start + ((w0 >> 36) & 0x1ff)); out[0*64+ 5] = (start + ((w0 >> 45) & 0x1ff)); out[0*64+ 6] = (start + ((w0 >> 54) & 0x1ff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w0 >> 63) | (w1 << 1) & 0x1ff)); out[0*64+ 8] = (start + ((w1 >> 8) & 0x1ff)); out[0*64+ 9] = (start + ((w1 >> 17) & 0x1ff)); out[0*64+10] = (start + ((w1 >> 26) & 0x1ff)); out[0*64+11] = (start + ((w1 >> 35) & 0x1ff)); out[0*64+12] = (start + ((w1 >> 44) & 0x1ff)); out[0*64+13] = (start + ((w1 >> 53) & 0x1ff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (start + ((w1 >> 62) | (w2 << 2) & 0x1ff)); out[0*64+15] = (start + ((w2 >> 7) & 0x1ff)); out[0*64+16] = (start + ((w2 >> 16) & 0x1ff)); out[0*64+17] = (start + ((w2 >> 25) & 0x1ff)); out[0*64+18] = (start + ((w2 >> 34) & 0x1ff)); out[0*64+19] = (start + ((w2 >> 43) & 0x1ff)); out[0*64+20] = (start + ((w2 >> 52) & 0x1ff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (start + ((w2 >> 61) | (w3 << 3) & 0x1ff)); out[0*64+22] = (start + ((w3 >> 6) & 0x1ff)); out[0*64+23] = (start + ((w3 >> 15) & 0x1ff)); out[0*64+24] = (start + ((w3 >> 24) & 0x1ff)); out[0*64+25] = (start + ((w3 >> 33) & 0x1ff)); out[0*64+26] = (start + ((w3 >> 42) & 0x1ff)); out[0*64+27] = (start + ((w3 >> 51) & 0x1ff)); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (start + ((w3 >> 60) | (w4 << 4) & 0x1ff)); out[0*64+29] = (start + ((w4 >> 5) & 0x1ff)); out[0*64+30] = (start + ((w4 >> 14) & 0x1ff)); out[0*64+31] = (start + ((w4 >> 23) & 0x1ff));;}; out += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_10(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3ff)); out[0*32+ 1] = (start + ((w0 >> 10) & 0x3ff)); out[0*32+ 2] = (start + ((w0 >> 20) & 0x3ff)); out[0*32+ 3] = (start + ((w0 >> 30) & 0x3ff)); out[0*32+ 4] = (start + ((w0 >> 40) & 0x3ff)); out[0*32+ 5] = (start + ((w0 >> 50) & 0x3ff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (start + ((w0 >> 60) | (w1 << 4) & 0x3ff)); out[0*32+ 7] = (start + ((w1 >> 6) & 0x3ff)); out[0*32+ 8] = (start + ((w1 >> 16) & 0x3ff)); out[0*32+ 9] = (start + ((w1 >> 26) & 0x3ff)); out[0*32+10] = (start + ((w1 >> 36) & 0x3ff)); out[0*32+11] = (start + ((w1 >> 46) & 0x3ff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (start + ((w1 >> 56) | (w2 << 8) & 0x3ff)); out[0*32+13] = (start + ((w2 >> 2) & 0x3ff)); out[0*32+14] = (start + ((w2 >> 12) & 0x3ff)); out[0*32+15] = (start + ((w2 >> 22) & 0x3ff)); out[0*32+16] = (start + ((w2 >> 32) & 0x3ff)); out[0*32+17] = (start + ((w2 >> 42) & 0x3ff)); out[0*32+18] = (start + ((w2 >> 52) & 0x3ff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (start + ((w2 >> 62) | (w3 << 2) & 0x3ff)); out[0*32+20] = (start + ((w3 >> 8) & 0x3ff)); out[0*32+21] = (start + ((w3 >> 18) & 0x3ff)); out[0*32+22] = (start + ((w3 >> 28) & 0x3ff)); out[0*32+23] = (start + ((w3 >> 38) & 0x3ff)); out[0*32+24] = (start + ((w3 >> 48) & 0x3ff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (start + ((w3 >> 58) | (w4 << 6) & 0x3ff)); out[0*32+26] = (start + ((w4 >> 4) & 0x3ff)); out[0*32+27] = (start + ((w4 >> 14) & 0x3ff)); out[0*32+28] = (start + ((w4 >> 24) & 0x3ff)); out[0*32+29] = (start + ((w4 >> 34) & 0x3ff)); out[0*32+30] = (start + ((w4 >> 44) & 0x3ff)); out[0*32+31] = (start + ((w4 >> 54)));;}; out += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_11(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7ff)); out[0*64+ 1] = (start + ((w0 >> 11) & 0x7ff)); out[0*64+ 2] = (start + ((w0 >> 22) & 0x7ff)); out[0*64+ 3] = (start + ((w0 >> 33) & 0x7ff)); out[0*64+ 4] = (start + ((w0 >> 44) & 0x7ff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w0 >> 55) | (w1 << 9) & 0x7ff)); out[0*64+ 6] = (start + ((w1 >> 2) & 0x7ff)); out[0*64+ 7] = (start + ((w1 >> 13) & 0x7ff)); out[0*64+ 8] = (start + ((w1 >> 24) & 0x7ff)); out[0*64+ 9] = (start + ((w1 >> 35) & 0x7ff)); out[0*64+10] = (start + ((w1 >> 46) & 0x7ff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (start + ((w1 >> 57) | (w2 << 7) & 0x7ff)); out[0*64+12] = (start + ((w2 >> 4) & 0x7ff)); out[0*64+13] = (start + ((w2 >> 15) & 0x7ff)); out[0*64+14] = (start + ((w2 >> 26) & 0x7ff)); out[0*64+15] = (start + ((w2 >> 37) & 0x7ff)); out[0*64+16] = (start + ((w2 >> 48) & 0x7ff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (start + ((w2 >> 59) | (w3 << 5) & 0x7ff)); out[0*64+18] = (start + ((w3 >> 6) & 0x7ff)); out[0*64+19] = (start + ((w3 >> 17) & 0x7ff)); out[0*64+20] = (start + ((w3 >> 28) & 0x7ff)); out[0*64+21] = (start + ((w3 >> 39) & 0x7ff)); out[0*64+22] = (start + ((w3 >> 50) & 0x7ff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (start + ((w3 >> 61) | (w4 << 3) & 0x7ff)); out[0*64+24] = (start + ((w4 >> 8) & 0x7ff)); out[0*64+25] = (start + ((w4 >> 19) & 0x7ff)); out[0*64+26] = (start + ((w4 >> 30) & 0x7ff)); out[0*64+27] = (start + ((w4 >> 41) & 0x7ff)); out[0*64+28] = (start + ((w4 >> 52) & 0x7ff)); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (start + ((w4 >> 63) | (w5 << 1) & 0x7ff)); out[0*64+30] = (start + ((w5 >> 10) & 0x7ff)); out[0*64+31] = (start + ((w5 >> 21) & 0x7ff));;}; out += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_12(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xfff)); out[0*16+ 1] = (start + ((w0 >> 12) & 0xfff)); out[0*16+ 2] = (start + ((w0 >> 24) & 0xfff)); out[0*16+ 3] = (start + ((w0 >> 36) & 0xfff)); out[0*16+ 4] = (start + ((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (start + ((w0 >> 60) | (w1 << 4) & 0xfff)); out[0*16+ 6] = (start + ((w1 >> 8) & 0xfff)); out[0*16+ 7] = (start + ((w1 >> 20) & 0xfff)); out[0*16+ 8] = (start + ((w1 >> 32) & 0xfff)); out[0*16+ 9] = (start + ((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (start + ((w1 >> 56) | (w2 << 8) & 0xfff)); out[0*16+11] = (start + ((w2 >> 4) & 0xfff)); out[0*16+12] = (start + ((w2 >> 16) & 0xfff)); out[0*16+13] = (start + ((w2 >> 28) & 0xfff)); out[0*16+14] = (start + ((w2 >> 40) & 0xfff)); out[0*16+15] = (start + ((w2 >> 52)));;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xfff)); out[1*16+ 1] = (start + ((w0 >> 12) & 0xfff)); out[1*16+ 2] = (start + ((w0 >> 24) & 0xfff)); out[1*16+ 3] = (start + ((w0 >> 36) & 0xfff)); out[1*16+ 4] = (start + ((w0 >> 48) & 0xfff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (start + ((w0 >> 60) | (w1 << 4) & 0xfff)); out[1*16+ 6] = (start + ((w1 >> 8) & 0xfff)); out[1*16+ 7] = (start + ((w1 >> 20) & 0xfff)); out[1*16+ 8] = (start + ((w1 >> 32) & 0xfff)); out[1*16+ 9] = (start + ((w1 >> 44) & 0xfff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (start + ((w1 >> 56) | (w2 << 8) & 0xfff)); out[1*16+11] = (start + ((w2 >> 4) & 0xfff)); out[1*16+12] = (start + ((w2 >> 16) & 0xfff)); out[1*16+13] = (start + ((w2 >> 28) & 0xfff)); out[1*16+14] = (start + ((w2 >> 40) & 0xfff)); out[1*16+15] = (start + ((w2 >> 52)));;}; out += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_13(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1fff)); out[0*64+ 1] = (start + ((w0 >> 13) & 0x1fff)); out[0*64+ 2] = (start + ((w0 >> 26) & 0x1fff)); out[0*64+ 3] = (start + ((w0 >> 39) & 0x1fff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w0 >> 52) | (w1 << 12) & 0x1fff)); out[0*64+ 5] = (start + ((w1 >> 1) & 0x1fff)); out[0*64+ 6] = (start + ((w1 >> 14) & 0x1fff)); out[0*64+ 7] = (start + ((w1 >> 27) & 0x1fff)); out[0*64+ 8] = (start + ((w1 >> 40) & 0x1fff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w1 >> 53) | (w2 << 11) & 0x1fff)); out[0*64+10] = (start + ((w2 >> 2) & 0x1fff)); out[0*64+11] = (start + ((w2 >> 15) & 0x1fff)); out[0*64+12] = (start + ((w2 >> 28) & 0x1fff)); out[0*64+13] = (start + ((w2 >> 41) & 0x1fff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (start + ((w2 >> 54) | (w3 << 10) & 0x1fff)); out[0*64+15] = (start + ((w3 >> 3) & 0x1fff)); out[0*64+16] = (start + ((w3 >> 16) & 0x1fff)); out[0*64+17] = (start + ((w3 >> 29) & 0x1fff)); out[0*64+18] = (start + ((w3 >> 42) & 0x1fff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (start + ((w3 >> 55) | (w4 << 9) & 0x1fff)); out[0*64+20] = (start + ((w4 >> 4) & 0x1fff)); out[0*64+21] = (start + ((w4 >> 17) & 0x1fff)); out[0*64+22] = (start + ((w4 >> 30) & 0x1fff)); out[0*64+23] = (start + ((w4 >> 43) & 0x1fff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (start + ((w4 >> 56) | (w5 << 8) & 0x1fff)); out[0*64+25] = (start + ((w5 >> 5) & 0x1fff)); out[0*64+26] = (start + ((w5 >> 18) & 0x1fff)); out[0*64+27] = (start + ((w5 >> 31) & 0x1fff)); out[0*64+28] = (start + ((w5 >> 44) & 0x1fff)); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (start + ((w5 >> 57) | (w6 << 7) & 0x1fff)); out[0*64+30] = (start + ((w6 >> 6) & 0x1fff)); out[0*64+31] = (start + ((w6 >> 19) & 0x1fff));;}; out += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_14(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3fff)); out[0*32+ 1] = (start + ((w0 >> 14) & 0x3fff)); out[0*32+ 2] = (start + ((w0 >> 28) & 0x3fff)); out[0*32+ 3] = (start + ((w0 >> 42) & 0x3fff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (start + ((w0 >> 56) | (w1 << 8) & 0x3fff)); out[0*32+ 5] = (start + ((w1 >> 6) & 0x3fff)); out[0*32+ 6] = (start + ((w1 >> 20) & 0x3fff)); out[0*32+ 7] = (start + ((w1 >> 34) & 0x3fff)); out[0*32+ 8] = (start + ((w1 >> 48) & 0x3fff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (start + ((w1 >> 62) | (w2 << 2) & 0x3fff)); out[0*32+10] = (start + ((w2 >> 12) & 0x3fff)); out[0*32+11] = (start + ((w2 >> 26) & 0x3fff)); out[0*32+12] = (start + ((w2 >> 40) & 0x3fff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (start + ((w2 >> 54) | (w3 << 10) & 0x3fff)); out[0*32+14] = (start + ((w3 >> 4) & 0x3fff)); out[0*32+15] = (start + ((w3 >> 18) & 0x3fff)); out[0*32+16] = (start + ((w3 >> 32) & 0x3fff)); out[0*32+17] = (start + ((w3 >> 46) & 0x3fff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (start + ((w3 >> 60) | (w4 << 4) & 0x3fff)); out[0*32+19] = (start + ((w4 >> 10) & 0x3fff)); out[0*32+20] = (start + ((w4 >> 24) & 0x3fff)); out[0*32+21] = (start + ((w4 >> 38) & 0x3fff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (start + ((w4 >> 52) | (w5 << 12) & 0x3fff)); out[0*32+23] = (start + ((w5 >> 2) & 0x3fff)); out[0*32+24] = (start + ((w5 >> 16) & 0x3fff)); out[0*32+25] = (start + ((w5 >> 30) & 0x3fff)); out[0*32+26] = (start + ((w5 >> 44) & 0x3fff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (start + ((w5 >> 58) | (w6 << 6) & 0x3fff)); out[0*32+28] = (start + ((w6 >> 8) & 0x3fff)); out[0*32+29] = (start + ((w6 >> 22) & 0x3fff)); out[0*32+30] = (start + ((w6 >> 36) & 0x3fff)); out[0*32+31] = (start + ((w6 >> 50)));;}; out += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_15(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7fff)); out[0*64+ 1] = (start + ((w0 >> 15) & 0x7fff)); out[0*64+ 2] = (start + ((w0 >> 30) & 0x7fff)); out[0*64+ 3] = (start + ((w0 >> 45) & 0x7fff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w0 >> 60) | (w1 << 4) & 0x7fff)); out[0*64+ 5] = (start + ((w1 >> 11) & 0x7fff)); out[0*64+ 6] = (start + ((w1 >> 26) & 0x7fff)); out[0*64+ 7] = (start + ((w1 >> 41) & 0x7fff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w1 >> 56) | (w2 << 8) & 0x7fff)); out[0*64+ 9] = (start + ((w2 >> 7) & 0x7fff)); out[0*64+10] = (start + ((w2 >> 22) & 0x7fff)); out[0*64+11] = (start + ((w2 >> 37) & 0x7fff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (start + ((w2 >> 52) | (w3 << 12) & 0x7fff)); out[0*64+13] = (start + ((w3 >> 3) & 0x7fff)); out[0*64+14] = (start + ((w3 >> 18) & 0x7fff)); out[0*64+15] = (start + ((w3 >> 33) & 0x7fff)); out[0*64+16] = (start + ((w3 >> 48) & 0x7fff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (start + ((w3 >> 63) | (w4 << 1) & 0x7fff)); out[0*64+18] = (start + ((w4 >> 14) & 0x7fff)); out[0*64+19] = (start + ((w4 >> 29) & 0x7fff)); out[0*64+20] = (start + ((w4 >> 44) & 0x7fff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (start + ((w4 >> 59) | (w5 << 5) & 0x7fff)); out[0*64+22] = (start + ((w5 >> 10) & 0x7fff)); out[0*64+23] = (start + ((w5 >> 25) & 0x7fff)); out[0*64+24] = (start + ((w5 >> 40) & 0x7fff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (start + ((w5 >> 55) | (w6 << 9) & 0x7fff)); out[0*64+26] = (start + ((w6 >> 6) & 0x7fff)); out[0*64+27] = (start + ((w6 >> 21) & 0x7fff)); out[0*64+28] = (start + ((w6 >> 36) & 0x7fff)); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (start + ((w6 >> 51) | (w7 << 13) & 0x7fff)); out[0*64+30] = (start + ((w7 >> 2) & 0x7fff)); out[0*64+31] = (start + ((w7 >> 17) & 0x7fff));;}; out += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_16(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = (start + (*(uint16_t *)(in+0*8+ 0))); out[0*4+ 1] = (start + (*(uint16_t *)(in+0*8+ 2))); out[0*4+ 2] = (start + (*(uint16_t *)(in+0*8+ 4))); out[0*4+ 3] = (start + (*(uint16_t *)(in+0*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = (start + (*(uint16_t *)(in+1*8+ 0))); out[1*4+ 1] = (start + (*(uint16_t *)(in+1*8+ 2))); out[1*4+ 2] = (start + (*(uint16_t *)(in+1*8+ 4))); out[1*4+ 3] = (start + (*(uint16_t *)(in+1*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = (start + (*(uint16_t *)(in+2*8+ 0))); out[2*4+ 1] = (start + (*(uint16_t *)(in+2*8+ 2))); out[2*4+ 2] = (start + (*(uint16_t *)(in+2*8+ 4))); out[2*4+ 3] = (start + (*(uint16_t *)(in+2*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = (start + (*(uint16_t *)(in+3*8+ 0))); out[3*4+ 1] = (start + (*(uint16_t *)(in+3*8+ 2))); out[3*4+ 2] = (start + (*(uint16_t *)(in+3*8+ 4))); out[3*4+ 3] = (start + (*(uint16_t *)(in+3*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = (start + (*(uint16_t *)(in+4*8+ 0))); out[4*4+ 1] = (start + (*(uint16_t *)(in+4*8+ 2))); out[4*4+ 2] = (start + (*(uint16_t *)(in+4*8+ 4))); out[4*4+ 3] = (start + (*(uint16_t *)(in+4*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = (start + (*(uint16_t *)(in+5*8+ 0))); out[5*4+ 1] = (start + (*(uint16_t *)(in+5*8+ 2))); out[5*4+ 2] = (start + (*(uint16_t *)(in+5*8+ 4))); out[5*4+ 3] = (start + (*(uint16_t *)(in+5*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = (start + (*(uint16_t *)(in+6*8+ 0))); out[6*4+ 1] = (start + (*(uint16_t *)(in+6*8+ 2))); out[6*4+ 2] = (start + (*(uint16_t *)(in+6*8+ 4))); out[6*4+ 3] = (start + (*(uint16_t *)(in+6*8+ 6)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = (start + (*(uint16_t *)(in+7*8+ 0))); out[7*4+ 1] = (start + (*(uint16_t *)(in+7*8+ 2))); out[7*4+ 2] = (start + (*(uint16_t *)(in+7*8+ 4))); out[7*4+ 3] = (start + (*(uint16_t *)(in+7*8+ 6)));;}; out += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_17(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*17)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1ffff)); out[0*64+ 1] = (start + ((w0 >> 17) & 0x1ffff)); out[0*64+ 2] = (start + ((w0 >> 34) & 0x1ffff)); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w0 >> 51) | (w1 << 13) & 0x1ffff)); out[0*64+ 4] = (start + ((w1 >> 4) & 0x1ffff)); out[0*64+ 5] = (start + ((w1 >> 21) & 0x1ffff)); out[0*64+ 6] = (start + ((w1 >> 38) & 0x1ffff)); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w1 >> 55) | (w2 << 9) & 0x1ffff)); out[0*64+ 8] = (start + ((w2 >> 8) & 0x1ffff)); out[0*64+ 9] = (start + ((w2 >> 25) & 0x1ffff)); out[0*64+10] = (start + ((w2 >> 42) & 0x1ffff)); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*64+11] = (start + ((w2 >> 59) | (w3 << 5) & 0x1ffff)); out[0*64+12] = (start + ((w3 >> 12) & 0x1ffff)); out[0*64+13] = (start + ((w3 >> 29) & 0x1ffff)); out[0*64+14] = (start + ((w3 >> 46) & 0x1ffff)); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*64+15] = (start + ((w3 >> 63) | (w4 << 1) & 0x1ffff)); out[0*64+16] = (start + ((w4 >> 16) & 0x1ffff)); out[0*64+17] = (start + ((w4 >> 33) & 0x1ffff)); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*64+18] = (start + ((w4 >> 50) | (w5 << 14) & 0x1ffff)); out[0*64+19] = (start + ((w5 >> 3) & 0x1ffff)); out[0*64+20] = (start + ((w5 >> 20) & 0x1ffff)); out[0*64+21] = (start + ((w5 >> 37) & 0x1ffff)); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*64+22] = (start + ((w5 >> 54) | (w6 << 10) & 0x1ffff)); out[0*64+23] = (start + ((w6 >> 7) & 0x1ffff)); out[0*64+24] = (start + ((w6 >> 24) & 0x1ffff)); out[0*64+25] = (start + ((w6 >> 41) & 0x1ffff)); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*64+26] = (start + ((w6 >> 58) | (w7 << 6) & 0x1ffff)); out[0*64+27] = (start + ((w7 >> 11) & 0x1ffff)); out[0*64+28] = (start + ((w7 >> 28) & 0x1ffff)); out[0*64+29] = (start + ((w7 >> 45) & 0x1ffff)); w8 = *(uint32_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*64+30] = (start + ((w7 >> 62) | (w8 << 2) & 0x1ffff)); out[0*64+31] = (start + ((w8 >> 15) & 0x1ffff));;}; out += 32; in += 17*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_18(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*18)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3ffff)); out[0*32+ 1] = (start + ((w0 >> 18) & 0x3ffff)); out[0*32+ 2] = (start + ((w0 >> 36) & 0x3ffff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*32+ 3] = (start + ((w0 >> 54) | (w1 << 10) & 0x3ffff)); out[0*32+ 4] = (start + ((w1 >> 8) & 0x3ffff)); out[0*32+ 5] = (start + ((w1 >> 26) & 0x3ffff)); out[0*32+ 6] = (start + ((w1 >> 44) & 0x3ffff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*32+ 7] = (start + ((w1 >> 62) | (w2 << 2) & 0x3ffff)); out[0*32+ 8] = (start + ((w2 >> 16) & 0x3ffff)); out[0*32+ 9] = (start + ((w2 >> 34) & 0x3ffff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*32+10] = (start + ((w2 >> 52) | (w3 << 12) & 0x3ffff)); out[0*32+11] = (start + ((w3 >> 6) & 0x3ffff)); out[0*32+12] = (start + ((w3 >> 24) & 0x3ffff)); out[0*32+13] = (start + ((w3 >> 42) & 0x3ffff)); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*32+14] = (start + ((w3 >> 60) | (w4 << 4) & 0x3ffff)); out[0*32+15] = (start + ((w4 >> 14) & 0x3ffff)); out[0*32+16] = (start + ((w4 >> 32) & 0x3ffff)); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*32+17] = (start + ((w4 >> 50) | (w5 << 14) & 0x3ffff)); out[0*32+18] = (start + ((w5 >> 4) & 0x3ffff)); out[0*32+19] = (start + ((w5 >> 22) & 0x3ffff)); out[0*32+20] = (start + ((w5 >> 40) & 0x3ffff)); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*32+21] = (start + ((w5 >> 58) | (w6 << 6) & 0x3ffff)); out[0*32+22] = (start + ((w6 >> 12) & 0x3ffff)); out[0*32+23] = (start + ((w6 >> 30) & 0x3ffff)); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*32+24] = (start + ((w6 >> 48) | (w7 << 16) & 0x3ffff)); out[0*32+25] = (start + ((w7 >> 2) & 0x3ffff)); out[0*32+26] = (start + ((w7 >> 20) & 0x3ffff)); out[0*32+27] = (start + ((w7 >> 38) & 0x3ffff)); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*32+28] = (start + ((w7 >> 56) | (w8 << 8) & 0x3ffff)); out[0*32+29] = (start + ((w8 >> 10) & 0x3ffff)); out[0*32+30] = (start + ((w8 >> 28) & 0x3ffff)); out[0*32+31] = (start + ((w8 >> 46)));;}; out += 32; in += 18*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_19(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*19)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7ffff)); out[0*64+ 1] = (start + ((w0 >> 19) & 0x7ffff)); out[0*64+ 2] = (start + ((w0 >> 38) & 0x7ffff)); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w0 >> 57) | (w1 << 7) & 0x7ffff)); out[0*64+ 4] = (start + ((w1 >> 12) & 0x7ffff)); out[0*64+ 5] = (start + ((w1 >> 31) & 0x7ffff)); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w1 >> 50) | (w2 << 14) & 0x7ffff)); out[0*64+ 7] = (start + ((w2 >> 5) & 0x7ffff)); out[0*64+ 8] = (start + ((w2 >> 24) & 0x7ffff)); out[0*64+ 9] = (start + ((w2 >> 43) & 0x7ffff)); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*64+10] = (start + ((w2 >> 62) | (w3 << 2) & 0x7ffff)); out[0*64+11] = (start + ((w3 >> 17) & 0x7ffff)); out[0*64+12] = (start + ((w3 >> 36) & 0x7ffff)); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*64+13] = (start + ((w3 >> 55) | (w4 << 9) & 0x7ffff)); out[0*64+14] = (start + ((w4 >> 10) & 0x7ffff)); out[0*64+15] = (start + ((w4 >> 29) & 0x7ffff)); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*64+16] = (start + ((w4 >> 48) | (w5 << 16) & 0x7ffff)); out[0*64+17] = (start + ((w5 >> 3) & 0x7ffff)); out[0*64+18] = (start + ((w5 >> 22) & 0x7ffff)); out[0*64+19] = (start + ((w5 >> 41) & 0x7ffff)); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*64+20] = (start + ((w5 >> 60) | (w6 << 4) & 0x7ffff)); out[0*64+21] = (start + ((w6 >> 15) & 0x7ffff)); out[0*64+22] = (start + ((w6 >> 34) & 0x7ffff)); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*64+23] = (start + ((w6 >> 53) | (w7 << 11) & 0x7ffff)); out[0*64+24] = (start + ((w7 >> 8) & 0x7ffff)); out[0*64+25] = (start + ((w7 >> 27) & 0x7ffff)); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*64+26] = (start + ((w7 >> 46) | (w8 << 18) & 0x7ffff)); out[0*64+27] = (start + ((w8 >> 1) & 0x7ffff)); out[0*64+28] = (start + ((w8 >> 20) & 0x7ffff)); out[0*64+29] = (start + ((w8 >> 39) & 0x7ffff)); w9 = *(uint32_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*64+30] = (start + ((w8 >> 58) | (w9 << 6) & 0x7ffff)); out[0*64+31] = (start + ((w9 >> 13) & 0x7ffff));;}; out += 32; in += 19*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_20(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*20)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xfffff)); out[0*16+ 1] = (start + ((w0 >> 20) & 0xfffff)); out[0*16+ 2] = (start + ((w0 >> 40) & 0xfffff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*16+ 3] = (start + ((w0 >> 60) | (w1 << 4) & 0xfffff)); out[0*16+ 4] = (start + ((w1 >> 16) & 0xfffff)); out[0*16+ 5] = (start + ((w1 >> 36) & 0xfffff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*16+ 6] = (start + ((w1 >> 56) | (w2 << 8) & 0xfffff)); out[0*16+ 7] = (start + ((w2 >> 12) & 0xfffff)); out[0*16+ 8] = (start + ((w2 >> 32) & 0xfffff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*16+ 9] = (start + ((w2 >> 52) | (w3 << 12) & 0xfffff)); out[0*16+10] = (start + ((w3 >> 8) & 0xfffff)); out[0*16+11] = (start + ((w3 >> 28) & 0xfffff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*16+12] = (start + ((w3 >> 48) | (w4 << 16) & 0xfffff)); out[0*16+13] = (start + ((w4 >> 4) & 0xfffff)); out[0*16+14] = (start + ((w4 >> 24) & 0xfffff)); out[0*16+15] = (start + ((w4 >> 44)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xfffff)); out[1*16+ 1] = (start + ((w0 >> 20) & 0xfffff)); out[1*16+ 2] = (start + ((w0 >> 40) & 0xfffff)); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*16+ 3] = (start + ((w0 >> 60) | (w1 << 4) & 0xfffff)); out[1*16+ 4] = (start + ((w1 >> 16) & 0xfffff)); out[1*16+ 5] = (start + ((w1 >> 36) & 0xfffff)); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*16+ 6] = (start + ((w1 >> 56) | (w2 << 8) & 0xfffff)); out[1*16+ 7] = (start + ((w2 >> 12) & 0xfffff)); out[1*16+ 8] = (start + ((w2 >> 32) & 0xfffff)); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*16+ 9] = (start + ((w2 >> 52) | (w3 << 12) & 0xfffff)); out[1*16+10] = (start + ((w3 >> 8) & 0xfffff)); out[1*16+11] = (start + ((w3 >> 28) & 0xfffff)); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*16+12] = (start + ((w3 >> 48) | (w4 << 16) & 0xfffff)); out[1*16+13] = (start + ((w4 >> 4) & 0xfffff)); out[1*16+14] = (start + ((w4 >> 24) & 0xfffff)); out[1*16+15] = (start + ((w4 >> 44)));;}; out += 32; in += 20*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_21(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*21)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1fffff)); out[0*64+ 1] = (start + ((w0 >> 21) & 0x1fffff)); out[0*64+ 2] = (start + ((w0 >> 42) & 0x1fffff)); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w0 >> 63) | (w1 << 1) & 0x1fffff)); out[0*64+ 4] = (start + ((w1 >> 20) & 0x1fffff)); out[0*64+ 5] = (start + ((w1 >> 41) & 0x1fffff)); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w1 >> 62) | (w2 << 2) & 0x1fffff)); out[0*64+ 7] = (start + ((w2 >> 19) & 0x1fffff)); out[0*64+ 8] = (start + ((w2 >> 40) & 0x1fffff)); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w2 >> 61) | (w3 << 3) & 0x1fffff)); out[0*64+10] = (start + ((w3 >> 18) & 0x1fffff)); out[0*64+11] = (start + ((w3 >> 39) & 0x1fffff)); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*64+12] = (start + ((w3 >> 60) | (w4 << 4) & 0x1fffff)); out[0*64+13] = (start + ((w4 >> 17) & 0x1fffff)); out[0*64+14] = (start + ((w4 >> 38) & 0x1fffff)); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*64+15] = (start + ((w4 >> 59) | (w5 << 5) & 0x1fffff)); out[0*64+16] = (start + ((w5 >> 16) & 0x1fffff)); out[0*64+17] = (start + ((w5 >> 37) & 0x1fffff)); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*64+18] = (start + ((w5 >> 58) | (w6 << 6) & 0x1fffff)); out[0*64+19] = (start + ((w6 >> 15) & 0x1fffff)); out[0*64+20] = (start + ((w6 >> 36) & 0x1fffff)); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*64+21] = (start + ((w6 >> 57) | (w7 << 7) & 0x1fffff)); out[0*64+22] = (start + ((w7 >> 14) & 0x1fffff)); out[0*64+23] = (start + ((w7 >> 35) & 0x1fffff)); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*64+24] = (start + ((w7 >> 56) | (w8 << 8) & 0x1fffff)); out[0*64+25] = (start + ((w8 >> 13) & 0x1fffff)); out[0*64+26] = (start + ((w8 >> 34) & 0x1fffff)); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*64+27] = (start + ((w8 >> 55) | (w9 << 9) & 0x1fffff)); out[0*64+28] = (start + ((w9 >> 12) & 0x1fffff)); out[0*64+29] = (start + ((w9 >> 33) & 0x1fffff)); w10 = *(uint32_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*64+30] = (start + ((w9 >> 54) | (w10 << 10) & 0x1fffff)); out[0*64+31] = (start + ((w10 >> 11) & 0x1fffff));;}; out += 32; in += 21*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_22(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*22)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3fffff)); out[0*32+ 1] = (start + ((w0 >> 22) & 0x3fffff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*32+ 2] = (start + ((w0 >> 44) | (w1 << 20) & 0x3fffff)); out[0*32+ 3] = (start + ((w1 >> 2) & 0x3fffff)); out[0*32+ 4] = (start + ((w1 >> 24) & 0x3fffff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*32+ 5] = (start + ((w1 >> 46) | (w2 << 18) & 0x3fffff)); out[0*32+ 6] = (start + ((w2 >> 4) & 0x3fffff)); out[0*32+ 7] = (start + ((w2 >> 26) & 0x3fffff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*32+ 8] = (start + ((w2 >> 48) | (w3 << 16) & 0x3fffff)); out[0*32+ 9] = (start + ((w3 >> 6) & 0x3fffff)); out[0*32+10] = (start + ((w3 >> 28) & 0x3fffff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*32+11] = (start + ((w3 >> 50) | (w4 << 14) & 0x3fffff)); out[0*32+12] = (start + ((w4 >> 8) & 0x3fffff)); out[0*32+13] = (start + ((w4 >> 30) & 0x3fffff)); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*32+14] = (start + ((w4 >> 52) | (w5 << 12) & 0x3fffff)); out[0*32+15] = (start + ((w5 >> 10) & 0x3fffff)); out[0*32+16] = (start + ((w5 >> 32) & 0x3fffff)); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*32+17] = (start + ((w5 >> 54) | (w6 << 10) & 0x3fffff)); out[0*32+18] = (start + ((w6 >> 12) & 0x3fffff)); out[0*32+19] = (start + ((w6 >> 34) & 0x3fffff)); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*32+20] = (start + ((w6 >> 56) | (w7 << 8) & 0x3fffff)); out[0*32+21] = (start + ((w7 >> 14) & 0x3fffff)); out[0*32+22] = (start + ((w7 >> 36) & 0x3fffff)); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*32+23] = (start + ((w7 >> 58) | (w8 << 6) & 0x3fffff)); out[0*32+24] = (start + ((w8 >> 16) & 0x3fffff)); out[0*32+25] = (start + ((w8 >> 38) & 0x3fffff)); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*32+26] = (start + ((w8 >> 60) | (w9 << 4) & 0x3fffff)); out[0*32+27] = (start + ((w9 >> 18) & 0x3fffff)); out[0*32+28] = (start + ((w9 >> 40) & 0x3fffff)); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*32+29] = (start + ((w9 >> 62) | (w10 << 2) & 0x3fffff)); out[0*32+30] = (start + ((w10 >> 20) & 0x3fffff)); out[0*32+31] = (start + ((w10 >> 42)));;}; out += 32; in += 22*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_23(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*23)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7fffff)); out[0*64+ 1] = (start + ((w0 >> 23) & 0x7fffff)); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w0 >> 46) | (w1 << 18) & 0x7fffff)); out[0*64+ 3] = (start + ((w1 >> 5) & 0x7fffff)); out[0*64+ 4] = (start + ((w1 >> 28) & 0x7fffff)); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w1 >> 51) | (w2 << 13) & 0x7fffff)); out[0*64+ 6] = (start + ((w2 >> 10) & 0x7fffff)); out[0*64+ 7] = (start + ((w2 >> 33) & 0x7fffff)); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w2 >> 56) | (w3 << 8) & 0x7fffff)); out[0*64+ 9] = (start + ((w3 >> 15) & 0x7fffff)); out[0*64+10] = (start + ((w3 >> 38) & 0x7fffff)); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*64+11] = (start + ((w3 >> 61) | (w4 << 3) & 0x7fffff)); out[0*64+12] = (start + ((w4 >> 20) & 0x7fffff)); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*64+13] = (start + ((w4 >> 43) | (w5 << 21) & 0x7fffff)); out[0*64+14] = (start + ((w5 >> 2) & 0x7fffff)); out[0*64+15] = (start + ((w5 >> 25) & 0x7fffff)); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*64+16] = (start + ((w5 >> 48) | (w6 << 16) & 0x7fffff)); out[0*64+17] = (start + ((w6 >> 7) & 0x7fffff)); out[0*64+18] = (start + ((w6 >> 30) & 0x7fffff)); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*64+19] = (start + ((w6 >> 53) | (w7 << 11) & 0x7fffff)); out[0*64+20] = (start + ((w7 >> 12) & 0x7fffff)); out[0*64+21] = (start + ((w7 >> 35) & 0x7fffff)); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*64+22] = (start + ((w7 >> 58) | (w8 << 6) & 0x7fffff)); out[0*64+23] = (start + ((w8 >> 17) & 0x7fffff)); out[0*64+24] = (start + ((w8 >> 40) & 0x7fffff)); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*64+25] = (start + ((w8 >> 63) | (w9 << 1) & 0x7fffff)); out[0*64+26] = (start + ((w9 >> 22) & 0x7fffff)); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*64+27] = (start + ((w9 >> 45) | (w10 << 19) & 0x7fffff)); out[0*64+28] = (start + ((w10 >> 4) & 0x7fffff)); out[0*64+29] = (start + ((w10 >> 27) & 0x7fffff)); w11 = *(uint32_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*64+30] = (start + ((w10 >> 50) | (w11 << 14) & 0x7fffff)); out[0*64+31] = (start + ((w11 >> 9) & 0x7fffff));;}; out += 32; in += 23*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_24(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*24)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*8+ 0] = (start + ((w0 ) & 0xffffff)); out[0*8+ 1] = (start + ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*8+ 2] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[0*8+ 3] = (start + ((w1 >> 8) & 0xffffff)); out[0*8+ 4] = (start + ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*8+ 5] = (start + ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[0*8+ 6] = (start + ((w2 >> 16) & 0xffffff)); out[0*8+ 7] = (start + ((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*8+ 0] = (start + ((w0 ) & 0xffffff)); out[1*8+ 1] = (start + ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*8+ 2] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[1*8+ 3] = (start + ((w1 >> 8) & 0xffffff)); out[1*8+ 4] = (start + ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*8+ 5] = (start + ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[1*8+ 6] = (start + ((w2 >> 16) & 0xffffff)); out[1*8+ 7] = (start + ((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*8+ 0] = (start + ((w0 ) & 0xffffff)); out[2*8+ 1] = (start + ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*8+ 2] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[2*8+ 3] = (start + ((w1 >> 8) & 0xffffff)); out[2*8+ 4] = (start + ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*8+ 5] = (start + ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[2*8+ 6] = (start + ((w2 >> 16) & 0xffffff)); out[2*8+ 7] = (start + ((w2 >> 40)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*8+ 0] = (start + ((w0 ) & 0xffffff)); out[3*8+ 1] = (start + ((w0 >> 24) & 0xffffff)); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*8+ 2] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffff)); out[3*8+ 3] = (start + ((w1 >> 8) & 0xffffff)); out[3*8+ 4] = (start + ((w1 >> 32) & 0xffffff)); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*8+ 5] = (start + ((w1 >> 56) | (w2 << 8) & 0xffffff)); out[3*8+ 6] = (start + ((w2 >> 16) & 0xffffff)); out[3*8+ 7] = (start + ((w2 >> 40)));;}; out += 32; in += 24*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_25(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*25)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1ffffff)); out[0*64+ 1] = (start + ((w0 >> 25) & 0x1ffffff)); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w0 >> 50) | (w1 << 14) & 0x1ffffff)); out[0*64+ 3] = (start + ((w1 >> 11) & 0x1ffffff)); out[0*64+ 4] = (start + ((w1 >> 36) & 0x1ffffff)); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w1 >> 61) | (w2 << 3) & 0x1ffffff)); out[0*64+ 6] = (start + ((w2 >> 22) & 0x1ffffff)); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w2 >> 47) | (w3 << 17) & 0x1ffffff)); out[0*64+ 8] = (start + ((w3 >> 8) & 0x1ffffff)); out[0*64+ 9] = (start + ((w3 >> 33) & 0x1ffffff)); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*64+10] = (start + ((w3 >> 58) | (w4 << 6) & 0x1ffffff)); out[0*64+11] = (start + ((w4 >> 19) & 0x1ffffff)); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*64+12] = (start + ((w4 >> 44) | (w5 << 20) & 0x1ffffff)); out[0*64+13] = (start + ((w5 >> 5) & 0x1ffffff)); out[0*64+14] = (start + ((w5 >> 30) & 0x1ffffff)); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*64+15] = (start + ((w5 >> 55) | (w6 << 9) & 0x1ffffff)); out[0*64+16] = (start + ((w6 >> 16) & 0x1ffffff)); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*64+17] = (start + ((w6 >> 41) | (w7 << 23) & 0x1ffffff)); out[0*64+18] = (start + ((w7 >> 2) & 0x1ffffff)); out[0*64+19] = (start + ((w7 >> 27) & 0x1ffffff)); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*64+20] = (start + ((w7 >> 52) | (w8 << 12) & 0x1ffffff)); out[0*64+21] = (start + ((w8 >> 13) & 0x1ffffff)); out[0*64+22] = (start + ((w8 >> 38) & 0x1ffffff)); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*64+23] = (start + ((w8 >> 63) | (w9 << 1) & 0x1ffffff)); out[0*64+24] = (start + ((w9 >> 24) & 0x1ffffff)); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*64+25] = (start + ((w9 >> 49) | (w10 << 15) & 0x1ffffff)); out[0*64+26] = (start + ((w10 >> 10) & 0x1ffffff)); out[0*64+27] = (start + ((w10 >> 35) & 0x1ffffff)); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*64+28] = (start + ((w10 >> 60) | (w11 << 4) & 0x1ffffff)); out[0*64+29] = (start + ((w11 >> 21) & 0x1ffffff)); w12 = *(uint32_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*64+30] = (start + ((w11 >> 46) | (w12 << 18) & 0x1ffffff)); out[0*64+31] = (start + ((w12 >> 7) & 0x1ffffff));;}; out += 32; in += 25*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_26(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*26)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3ffffff)); out[0*32+ 1] = (start + ((w0 >> 26) & 0x3ffffff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*32+ 2] = (start + ((w0 >> 52) | (w1 << 12) & 0x3ffffff)); out[0*32+ 3] = (start + ((w1 >> 14) & 0x3ffffff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*32+ 4] = (start + ((w1 >> 40) | (w2 << 24) & 0x3ffffff)); out[0*32+ 5] = (start + ((w2 >> 2) & 0x3ffffff)); out[0*32+ 6] = (start + ((w2 >> 28) & 0x3ffffff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*32+ 7] = (start + ((w2 >> 54) | (w3 << 10) & 0x3ffffff)); out[0*32+ 8] = (start + ((w3 >> 16) & 0x3ffffff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*32+ 9] = (start + ((w3 >> 42) | (w4 << 22) & 0x3ffffff)); out[0*32+10] = (start + ((w4 >> 4) & 0x3ffffff)); out[0*32+11] = (start + ((w4 >> 30) & 0x3ffffff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*32+12] = (start + ((w4 >> 56) | (w5 << 8) & 0x3ffffff)); out[0*32+13] = (start + ((w5 >> 18) & 0x3ffffff)); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*32+14] = (start + ((w5 >> 44) | (w6 << 20) & 0x3ffffff)); out[0*32+15] = (start + ((w6 >> 6) & 0x3ffffff)); out[0*32+16] = (start + ((w6 >> 32) & 0x3ffffff)); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*32+17] = (start + ((w6 >> 58) | (w7 << 6) & 0x3ffffff)); out[0*32+18] = (start + ((w7 >> 20) & 0x3ffffff)); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*32+19] = (start + ((w7 >> 46) | (w8 << 18) & 0x3ffffff)); out[0*32+20] = (start + ((w8 >> 8) & 0x3ffffff)); out[0*32+21] = (start + ((w8 >> 34) & 0x3ffffff)); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*32+22] = (start + ((w8 >> 60) | (w9 << 4) & 0x3ffffff)); out[0*32+23] = (start + ((w9 >> 22) & 0x3ffffff)); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*32+24] = (start + ((w9 >> 48) | (w10 << 16) & 0x3ffffff)); out[0*32+25] = (start + ((w10 >> 10) & 0x3ffffff)); out[0*32+26] = (start + ((w10 >> 36) & 0x3ffffff)); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*32+27] = (start + ((w10 >> 62) | (w11 << 2) & 0x3ffffff)); out[0*32+28] = (start + ((w11 >> 24) & 0x3ffffff)); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*32+29] = (start + ((w11 >> 50) | (w12 << 14) & 0x3ffffff)); out[0*32+30] = (start + ((w12 >> 12) & 0x3ffffff)); out[0*32+31] = (start + ((w12 >> 38)));;}; out += 32; in += 26*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_27(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*27)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7ffffff)); out[0*64+ 1] = (start + ((w0 >> 27) & 0x7ffffff)); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w0 >> 54) | (w1 << 10) & 0x7ffffff)); out[0*64+ 3] = (start + ((w1 >> 17) & 0x7ffffff)); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w1 >> 44) | (w2 << 20) & 0x7ffffff)); out[0*64+ 5] = (start + ((w2 >> 7) & 0x7ffffff)); out[0*64+ 6] = (start + ((w2 >> 34) & 0x7ffffff)); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w2 >> 61) | (w3 << 3) & 0x7ffffff)); out[0*64+ 8] = (start + ((w3 >> 24) & 0x7ffffff)); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w3 >> 51) | (w4 << 13) & 0x7ffffff)); out[0*64+10] = (start + ((w4 >> 14) & 0x7ffffff)); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*64+11] = (start + ((w4 >> 41) | (w5 << 23) & 0x7ffffff)); out[0*64+12] = (start + ((w5 >> 4) & 0x7ffffff)); out[0*64+13] = (start + ((w5 >> 31) & 0x7ffffff)); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*64+14] = (start + ((w5 >> 58) | (w6 << 6) & 0x7ffffff)); out[0*64+15] = (start + ((w6 >> 21) & 0x7ffffff)); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*64+16] = (start + ((w6 >> 48) | (w7 << 16) & 0x7ffffff)); out[0*64+17] = (start + ((w7 >> 11) & 0x7ffffff)); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*64+18] = (start + ((w7 >> 38) | (w8 << 26) & 0x7ffffff)); out[0*64+19] = (start + ((w8 >> 1) & 0x7ffffff)); out[0*64+20] = (start + ((w8 >> 28) & 0x7ffffff)); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*64+21] = (start + ((w8 >> 55) | (w9 << 9) & 0x7ffffff)); out[0*64+22] = (start + ((w9 >> 18) & 0x7ffffff)); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*64+23] = (start + ((w9 >> 45) | (w10 << 19) & 0x7ffffff)); out[0*64+24] = (start + ((w10 >> 8) & 0x7ffffff)); out[0*64+25] = (start + ((w10 >> 35) & 0x7ffffff)); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*64+26] = (start + ((w10 >> 62) | (w11 << 2) & 0x7ffffff)); out[0*64+27] = (start + ((w11 >> 25) & 0x7ffffff)); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*64+28] = (start + ((w11 >> 52) | (w12 << 12) & 0x7ffffff)); out[0*64+29] = (start + ((w12 >> 15) & 0x7ffffff)); w13 = *(uint32_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*64+30] = (start + ((w12 >> 42) | (w13 << 22) & 0x7ffffff)); out[0*64+31] = (start + ((w13 >> 5) & 0x7ffffff));;}; out += 32; in += 27*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_28(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*28)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xfffffff)); out[0*16+ 1] = (start + ((w0 >> 28) & 0xfffffff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*16+ 2] = (start + ((w0 >> 56) | (w1 << 8) & 0xfffffff)); out[0*16+ 3] = (start + ((w1 >> 20) & 0xfffffff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*16+ 4] = (start + ((w1 >> 48) | (w2 << 16) & 0xfffffff)); out[0*16+ 5] = (start + ((w2 >> 12) & 0xfffffff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*16+ 6] = (start + ((w2 >> 40) | (w3 << 24) & 0xfffffff)); out[0*16+ 7] = (start + ((w3 >> 4) & 0xfffffff)); out[0*16+ 8] = (start + ((w3 >> 32) & 0xfffffff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*16+ 9] = (start + ((w3 >> 60) | (w4 << 4) & 0xfffffff)); out[0*16+10] = (start + ((w4 >> 24) & 0xfffffff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*16+11] = (start + ((w4 >> 52) | (w5 << 12) & 0xfffffff)); out[0*16+12] = (start + ((w5 >> 16) & 0xfffffff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*16+13] = (start + ((w5 >> 44) | (w6 << 20) & 0xfffffff)); out[0*16+14] = (start + ((w6 >> 8) & 0xfffffff)); out[0*16+15] = (start + ((w6 >> 36)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xfffffff)); out[1*16+ 1] = (start + ((w0 >> 28) & 0xfffffff)); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*16+ 2] = (start + ((w0 >> 56) | (w1 << 8) & 0xfffffff)); out[1*16+ 3] = (start + ((w1 >> 20) & 0xfffffff)); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*16+ 4] = (start + ((w1 >> 48) | (w2 << 16) & 0xfffffff)); out[1*16+ 5] = (start + ((w2 >> 12) & 0xfffffff)); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*16+ 6] = (start + ((w2 >> 40) | (w3 << 24) & 0xfffffff)); out[1*16+ 7] = (start + ((w3 >> 4) & 0xfffffff)); out[1*16+ 8] = (start + ((w3 >> 32) & 0xfffffff)); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*16+ 9] = (start + ((w3 >> 60) | (w4 << 4) & 0xfffffff)); out[1*16+10] = (start + ((w4 >> 24) & 0xfffffff)); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*16+11] = (start + ((w4 >> 52) | (w5 << 12) & 0xfffffff)); out[1*16+12] = (start + ((w5 >> 16) & 0xfffffff)); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*16+13] = (start + ((w5 >> 44) | (w6 << 20) & 0xfffffff)); out[1*16+14] = (start + ((w6 >> 8) & 0xfffffff)); out[1*16+15] = (start + ((w6 >> 36)));;}; out += 32; in += 28*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_29(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*29)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1fffffff)); out[0*64+ 1] = (start + ((w0 >> 29) & 0x1fffffff)); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w0 >> 58) | (w1 << 6) & 0x1fffffff)); out[0*64+ 3] = (start + ((w1 >> 23) & 0x1fffffff)); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w1 >> 52) | (w2 << 12) & 0x1fffffff)); out[0*64+ 5] = (start + ((w2 >> 17) & 0x1fffffff)); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w2 >> 46) | (w3 << 18) & 0x1fffffff)); out[0*64+ 7] = (start + ((w3 >> 11) & 0x1fffffff)); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w3 >> 40) | (w4 << 24) & 0x1fffffff)); out[0*64+ 9] = (start + ((w4 >> 5) & 0x1fffffff)); out[0*64+10] = (start + ((w4 >> 34) & 0x1fffffff)); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*64+11] = (start + ((w4 >> 63) | (w5 << 1) & 0x1fffffff)); out[0*64+12] = (start + ((w5 >> 28) & 0x1fffffff)); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*64+13] = (start + ((w5 >> 57) | (w6 << 7) & 0x1fffffff)); out[0*64+14] = (start + ((w6 >> 22) & 0x1fffffff)); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*64+15] = (start + ((w6 >> 51) | (w7 << 13) & 0x1fffffff)); out[0*64+16] = (start + ((w7 >> 16) & 0x1fffffff)); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*64+17] = (start + ((w7 >> 45) | (w8 << 19) & 0x1fffffff)); out[0*64+18] = (start + ((w8 >> 10) & 0x1fffffff)); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*64+19] = (start + ((w8 >> 39) | (w9 << 25) & 0x1fffffff)); out[0*64+20] = (start + ((w9 >> 4) & 0x1fffffff)); out[0*64+21] = (start + ((w9 >> 33) & 0x1fffffff)); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*64+22] = (start + ((w9 >> 62) | (w10 << 2) & 0x1fffffff)); out[0*64+23] = (start + ((w10 >> 27) & 0x1fffffff)); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*64+24] = (start + ((w10 >> 56) | (w11 << 8) & 0x1fffffff)); out[0*64+25] = (start + ((w11 >> 21) & 0x1fffffff)); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*64+26] = (start + ((w11 >> 50) | (w12 << 14) & 0x1fffffff)); out[0*64+27] = (start + ((w12 >> 15) & 0x1fffffff)); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*64+28] = (start + ((w12 >> 44) | (w13 << 20) & 0x1fffffff)); out[0*64+29] = (start + ((w13 >> 9) & 0x1fffffff)); w14 = *(uint32_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*64+30] = (start + ((w13 >> 38) | (w14 << 26) & 0x1fffffff)); out[0*64+31] = (start + ((w14 >> 3) & 0x1fffffff));;}; out += 32; in += 29*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_30(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*30)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3fffffff)); out[0*32+ 1] = (start + ((w0 >> 30) & 0x3fffffff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*32+ 2] = (start + ((w0 >> 60) | (w1 << 4) & 0x3fffffff)); out[0*32+ 3] = (start + ((w1 >> 26) & 0x3fffffff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*32+ 4] = (start + ((w1 >> 56) | (w2 << 8) & 0x3fffffff)); out[0*32+ 5] = (start + ((w2 >> 22) & 0x3fffffff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*32+ 6] = (start + ((w2 >> 52) | (w3 << 12) & 0x3fffffff)); out[0*32+ 7] = (start + ((w3 >> 18) & 0x3fffffff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*32+ 8] = (start + ((w3 >> 48) | (w4 << 16) & 0x3fffffff)); out[0*32+ 9] = (start + ((w4 >> 14) & 0x3fffffff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*32+10] = (start + ((w4 >> 44) | (w5 << 20) & 0x3fffffff)); out[0*32+11] = (start + ((w5 >> 10) & 0x3fffffff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*32+12] = (start + ((w5 >> 40) | (w6 << 24) & 0x3fffffff)); out[0*32+13] = (start + ((w6 >> 6) & 0x3fffffff)); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*32+14] = (start + ((w6 >> 36) | (w7 << 28) & 0x3fffffff)); out[0*32+15] = (start + ((w7 >> 2) & 0x3fffffff)); out[0*32+16] = (start + ((w7 >> 32) & 0x3fffffff)); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*32+17] = (start + ((w7 >> 62) | (w8 << 2) & 0x3fffffff)); out[0*32+18] = (start + ((w8 >> 28) & 0x3fffffff)); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*32+19] = (start + ((w8 >> 58) | (w9 << 6) & 0x3fffffff)); out[0*32+20] = (start + ((w9 >> 24) & 0x3fffffff)); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*32+21] = (start + ((w9 >> 54) | (w10 << 10) & 0x3fffffff)); out[0*32+22] = (start + ((w10 >> 20) & 0x3fffffff)); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*32+23] = (start + ((w10 >> 50) | (w11 << 14) & 0x3fffffff)); out[0*32+24] = (start + ((w11 >> 16) & 0x3fffffff)); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*32+25] = (start + ((w11 >> 46) | (w12 << 18) & 0x3fffffff)); out[0*32+26] = (start + ((w12 >> 12) & 0x3fffffff)); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*32+27] = (start + ((w12 >> 42) | (w13 << 22) & 0x3fffffff)); out[0*32+28] = (start + ((w13 >> 8) & 0x3fffffff)); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*32+29] = (start + ((w13 >> 38) | (w14 << 26) & 0x3fffffff)); out[0*32+30] = (start + ((w14 >> 4) & 0x3fffffff)); out[0*32+31] = (start + ((w14 >> 34)));;}; out += 32; in += 30*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_31(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*31)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7fffffff)); out[0*64+ 1] = (start + ((w0 >> 31) & 0x7fffffff)); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w0 >> 62) | (w1 << 2) & 0x7fffffff)); out[0*64+ 3] = (start + ((w1 >> 29) & 0x7fffffff)); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w1 >> 60) | (w2 << 4) & 0x7fffffff)); out[0*64+ 5] = (start + ((w2 >> 27) & 0x7fffffff)); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w2 >> 58) | (w3 << 6) & 0x7fffffff)); out[0*64+ 7] = (start + ((w3 >> 25) & 0x7fffffff)); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w3 >> 56) | (w4 << 8) & 0x7fffffff)); out[0*64+ 9] = (start + ((w4 >> 23) & 0x7fffffff)); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*64+10] = (start + ((w4 >> 54) | (w5 << 10) & 0x7fffffff)); out[0*64+11] = (start + ((w5 >> 21) & 0x7fffffff)); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*64+12] = (start + ((w5 >> 52) | (w6 << 12) & 0x7fffffff)); out[0*64+13] = (start + ((w6 >> 19) & 0x7fffffff)); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*64+14] = (start + ((w6 >> 50) | (w7 << 14) & 0x7fffffff)); out[0*64+15] = (start + ((w7 >> 17) & 0x7fffffff)); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*64+16] = (start + ((w7 >> 48) | (w8 << 16) & 0x7fffffff)); out[0*64+17] = (start + ((w8 >> 15) & 0x7fffffff)); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*64+18] = (start + ((w8 >> 46) | (w9 << 18) & 0x7fffffff)); out[0*64+19] = (start + ((w9 >> 13) & 0x7fffffff)); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*64+20] = (start + ((w9 >> 44) | (w10 << 20) & 0x7fffffff)); out[0*64+21] = (start + ((w10 >> 11) & 0x7fffffff)); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*64+22] = (start + ((w10 >> 42) | (w11 << 22) & 0x7fffffff)); out[0*64+23] = (start + ((w11 >> 9) & 0x7fffffff)); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*64+24] = (start + ((w11 >> 40) | (w12 << 24) & 0x7fffffff)); out[0*64+25] = (start + ((w12 >> 7) & 0x7fffffff)); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*64+26] = (start + ((w12 >> 38) | (w13 << 26) & 0x7fffffff)); out[0*64+27] = (start + ((w13 >> 5) & 0x7fffffff)); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*64+28] = (start + ((w13 >> 36) | (w14 << 28) & 0x7fffffff)); out[0*64+29] = (start + ((w14 >> 3) & 0x7fffffff)); w15 = *(uint32_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*64+30] = (start + ((w14 >> 34) | (w15 << 30) & 0x7fffffff)); out[0*64+31] = (start + ((w15 >> 1) & 0x7fffffff));;}; out += 32; in += 31*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_32(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*32)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[0*2+ 0] = (start + (*(uint32_t *)(in+0*8+ 0))); out[0*2+ 1] = (start + (*(uint32_t *)(in+0*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[1*2+ 0] = (start + (*(uint32_t *)(in+1*8+ 0))); out[1*2+ 1] = (start + (*(uint32_t *)(in+1*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[2*2+ 0] = (start + (*(uint32_t *)(in+2*8+ 0))); out[2*2+ 1] = (start + (*(uint32_t *)(in+2*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[3*2+ 0] = (start + (*(uint32_t *)(in+3*8+ 0))); out[3*2+ 1] = (start + (*(uint32_t *)(in+3*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[4*2+ 0] = (start + (*(uint32_t *)(in+4*8+ 0))); out[4*2+ 1] = (start + (*(uint32_t *)(in+4*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[5*2+ 0] = (start + (*(uint32_t *)(in+5*8+ 0))); out[5*2+ 1] = (start + (*(uint32_t *)(in+5*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[6*2+ 0] = (start + (*(uint32_t *)(in+6*8+ 0))); out[6*2+ 1] = (start + (*(uint32_t *)(in+6*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[7*2+ 0] = (start + (*(uint32_t *)(in+7*8+ 0))); out[7*2+ 1] = (start + (*(uint32_t *)(in+7*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[8*2+ 0] = (start + (*(uint32_t *)(in+8*8+ 0))); out[8*2+ 1] = (start + (*(uint32_t *)(in+8*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[9*2+ 0] = (start + (*(uint32_t *)(in+9*8+ 0))); out[9*2+ 1] = (start + (*(uint32_t *)(in+9*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[10*2+ 0] = (start + (*(uint32_t *)(in+10*8+ 0))); out[10*2+ 1] = (start + (*(uint32_t *)(in+10*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[11*2+ 0] = (start + (*(uint32_t *)(in+11*8+ 0))); out[11*2+ 1] = (start + (*(uint32_t *)(in+11*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[12*2+ 0] = (start + (*(uint32_t *)(in+12*8+ 0))); out[12*2+ 1] = (start + (*(uint32_t *)(in+12*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[13*2+ 0] = (start + (*(uint32_t *)(in+13*8+ 0))); out[13*2+ 1] = (start + (*(uint32_t *)(in+13*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[14*2+ 0] = (start + (*(uint32_t *)(in+14*8+ 0))); out[14*2+ 1] = (start + (*(uint32_t *)(in+14*8+ 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[15*2+ 0] = (start + (*(uint32_t *)(in+15*8+ 0))); out[15*2+ 1] = (start + (*(uint32_t *)(in+15*8+ 4)));;}; out += 32; in += 32*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_33(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*33)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16; w0 = *(uint64_t *)(in+(0*33+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1ffffffff)); w1 = *(uint64_t *)(in+(0*33+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 33) | (w1 << 31) & 0x1ffffffff)); out[0*64+ 2] = (start + ((w1 >> 2) & 0x1ffffffff)); w2 = *(uint64_t *)(in+(0*33+2)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w1 >> 35) | (w2 << 29) & 0x1ffffffff)); out[0*64+ 4] = (start + ((w2 >> 4) & 0x1ffffffff)); w3 = *(uint64_t *)(in+(0*33+3)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w2 >> 37) | (w3 << 27) & 0x1ffffffff)); out[0*64+ 6] = (start + ((w3 >> 6) & 0x1ffffffff)); w4 = *(uint64_t *)(in+(0*33+4)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w3 >> 39) | (w4 << 25) & 0x1ffffffff)); out[0*64+ 8] = (start + ((w4 >> 8) & 0x1ffffffff)); w5 = *(uint64_t *)(in+(0*33+5)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w4 >> 41) | (w5 << 23) & 0x1ffffffff)); out[0*64+10] = (start + ((w5 >> 10) & 0x1ffffffff)); w6 = *(uint64_t *)(in+(0*33+6)*8/sizeof(in[0])); out[0*64+11] = (start + ((w5 >> 43) | (w6 << 21) & 0x1ffffffff)); out[0*64+12] = (start + ((w6 >> 12) & 0x1ffffffff)); w7 = *(uint64_t *)(in+(0*33+7)*8/sizeof(in[0])); out[0*64+13] = (start + ((w6 >> 45) | (w7 << 19) & 0x1ffffffff)); out[0*64+14] = (start + ((w7 >> 14) & 0x1ffffffff)); w8 = *(uint64_t *)(in+(0*33+8)*8/sizeof(in[0])); out[0*64+15] = (start + ((w7 >> 47) | (w8 << 17) & 0x1ffffffff)); out[0*64+16] = (start + ((w8 >> 16) & 0x1ffffffff)); w9 = *(uint64_t *)(in+(0*33+9)*8/sizeof(in[0])); out[0*64+17] = (start + ((w8 >> 49) | (w9 << 15) & 0x1ffffffff)); out[0*64+18] = (start + ((w9 >> 18) & 0x1ffffffff)); w10 = *(uint64_t *)(in+(0*33+10)*8/sizeof(in[0])); out[0*64+19] = (start + ((w9 >> 51) | (w10 << 13) & 0x1ffffffff)); out[0*64+20] = (start + ((w10 >> 20) & 0x1ffffffff)); w11 = *(uint64_t *)(in+(0*33+11)*8/sizeof(in[0])); out[0*64+21] = (start + ((w10 >> 53) | (w11 << 11) & 0x1ffffffff)); out[0*64+22] = (start + ((w11 >> 22) & 0x1ffffffff)); w12 = *(uint64_t *)(in+(0*33+12)*8/sizeof(in[0])); out[0*64+23] = (start + ((w11 >> 55) | (w12 << 9) & 0x1ffffffff)); out[0*64+24] = (start + ((w12 >> 24) & 0x1ffffffff)); w13 = *(uint64_t *)(in+(0*33+13)*8/sizeof(in[0])); out[0*64+25] = (start + ((w12 >> 57) | (w13 << 7) & 0x1ffffffff)); out[0*64+26] = (start + ((w13 >> 26) & 0x1ffffffff)); w14 = *(uint64_t *)(in+(0*33+14)*8/sizeof(in[0])); out[0*64+27] = (start + ((w13 >> 59) | (w14 << 5) & 0x1ffffffff)); out[0*64+28] = (start + ((w14 >> 28) & 0x1ffffffff)); w15 = *(uint64_t *)(in+(0*33+15)*8/sizeof(in[0])); out[0*64+29] = (start + ((w14 >> 61) | (w15 << 3) & 0x1ffffffff)); out[0*64+30] = (start + ((w15 >> 30) & 0x1ffffffff)); w16 = *(uint32_t *)(in+(0*33+16)*8/sizeof(in[0])); out[0*64+31] = (start + ((w15 >> 63) | (w16 << 1) & 0x1ffffffff));;}; out += 32; in += 33*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_34(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*34)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3ffffffff)); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*32+ 1] = (start + ((w0 >> 34) | (w1 << 30) & 0x3ffffffff)); out[0*32+ 2] = (start + ((w1 >> 4) & 0x3ffffffff)); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*32+ 3] = (start + ((w1 >> 38) | (w2 << 26) & 0x3ffffffff)); out[0*32+ 4] = (start + ((w2 >> 8) & 0x3ffffffff)); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*32+ 5] = (start + ((w2 >> 42) | (w3 << 22) & 0x3ffffffff)); out[0*32+ 6] = (start + ((w3 >> 12) & 0x3ffffffff)); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*32+ 7] = (start + ((w3 >> 46) | (w4 << 18) & 0x3ffffffff)); out[0*32+ 8] = (start + ((w4 >> 16) & 0x3ffffffff)); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*32+ 9] = (start + ((w4 >> 50) | (w5 << 14) & 0x3ffffffff)); out[0*32+10] = (start + ((w5 >> 20) & 0x3ffffffff)); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*32+11] = (start + ((w5 >> 54) | (w6 << 10) & 0x3ffffffff)); out[0*32+12] = (start + ((w6 >> 24) & 0x3ffffffff)); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*32+13] = (start + ((w6 >> 58) | (w7 << 6) & 0x3ffffffff)); out[0*32+14] = (start + ((w7 >> 28) & 0x3ffffffff)); w8 = *(uint64_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*32+15] = (start + ((w7 >> 62) | (w8 << 2) & 0x3ffffffff)); w9 = *(uint64_t *)(in+(0*17+9)*8/sizeof(in[0])); out[0*32+16] = (start + ((w8 >> 32) | (w9 << 32) & 0x3ffffffff)); out[0*32+17] = (start + ((w9 >> 2) & 0x3ffffffff)); w10 = *(uint64_t *)(in+(0*17+10)*8/sizeof(in[0])); out[0*32+18] = (start + ((w9 >> 36) | (w10 << 28) & 0x3ffffffff)); out[0*32+19] = (start + ((w10 >> 6) & 0x3ffffffff)); w11 = *(uint64_t *)(in+(0*17+11)*8/sizeof(in[0])); out[0*32+20] = (start + ((w10 >> 40) | (w11 << 24) & 0x3ffffffff)); out[0*32+21] = (start + ((w11 >> 10) & 0x3ffffffff)); w12 = *(uint64_t *)(in+(0*17+12)*8/sizeof(in[0])); out[0*32+22] = (start + ((w11 >> 44) | (w12 << 20) & 0x3ffffffff)); out[0*32+23] = (start + ((w12 >> 14) & 0x3ffffffff)); w13 = *(uint64_t *)(in+(0*17+13)*8/sizeof(in[0])); out[0*32+24] = (start + ((w12 >> 48) | (w13 << 16) & 0x3ffffffff)); out[0*32+25] = (start + ((w13 >> 18) & 0x3ffffffff)); w14 = *(uint64_t *)(in+(0*17+14)*8/sizeof(in[0])); out[0*32+26] = (start + ((w13 >> 52) | (w14 << 12) & 0x3ffffffff)); out[0*32+27] = (start + ((w14 >> 22) & 0x3ffffffff)); w15 = *(uint64_t *)(in+(0*17+15)*8/sizeof(in[0])); out[0*32+28] = (start + ((w14 >> 56) | (w15 << 8) & 0x3ffffffff)); out[0*32+29] = (start + ((w15 >> 26) & 0x3ffffffff)); w16 = *(uint64_t *)(in+(0*17+16)*8/sizeof(in[0])); out[0*32+30] = (start + ((w15 >> 60) | (w16 << 4) & 0x3ffffffff)); out[0*32+31] = (start + ((w16 >> 30)));;}; out += 32; in += 34*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_35(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*35)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(0*35+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7ffffffff)); w1 = *(uint64_t *)(in+(0*35+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 35) | (w1 << 29) & 0x7ffffffff)); out[0*64+ 2] = (start + ((w1 >> 6) & 0x7ffffffff)); w2 = *(uint64_t *)(in+(0*35+2)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w1 >> 41) | (w2 << 23) & 0x7ffffffff)); out[0*64+ 4] = (start + ((w2 >> 12) & 0x7ffffffff)); w3 = *(uint64_t *)(in+(0*35+3)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w2 >> 47) | (w3 << 17) & 0x7ffffffff)); out[0*64+ 6] = (start + ((w3 >> 18) & 0x7ffffffff)); w4 = *(uint64_t *)(in+(0*35+4)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w3 >> 53) | (w4 << 11) & 0x7ffffffff)); out[0*64+ 8] = (start + ((w4 >> 24) & 0x7ffffffff)); w5 = *(uint64_t *)(in+(0*35+5)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w4 >> 59) | (w5 << 5) & 0x7ffffffff)); w6 = *(uint64_t *)(in+(0*35+6)*8/sizeof(in[0])); out[0*64+10] = (start + ((w5 >> 30) | (w6 << 34) & 0x7ffffffff)); out[0*64+11] = (start + ((w6 >> 1) & 0x7ffffffff)); w7 = *(uint64_t *)(in+(0*35+7)*8/sizeof(in[0])); out[0*64+12] = (start + ((w6 >> 36) | (w7 << 28) & 0x7ffffffff)); out[0*64+13] = (start + ((w7 >> 7) & 0x7ffffffff)); w8 = *(uint64_t *)(in+(0*35+8)*8/sizeof(in[0])); out[0*64+14] = (start + ((w7 >> 42) | (w8 << 22) & 0x7ffffffff)); out[0*64+15] = (start + ((w8 >> 13) & 0x7ffffffff)); w9 = *(uint64_t *)(in+(0*35+9)*8/sizeof(in[0])); out[0*64+16] = (start + ((w8 >> 48) | (w9 << 16) & 0x7ffffffff)); out[0*64+17] = (start + ((w9 >> 19) & 0x7ffffffff)); w10 = *(uint64_t *)(in+(0*35+10)*8/sizeof(in[0])); out[0*64+18] = (start + ((w9 >> 54) | (w10 << 10) & 0x7ffffffff)); out[0*64+19] = (start + ((w10 >> 25) & 0x7ffffffff)); w11 = *(uint64_t *)(in+(0*35+11)*8/sizeof(in[0])); out[0*64+20] = (start + ((w10 >> 60) | (w11 << 4) & 0x7ffffffff)); w12 = *(uint64_t *)(in+(0*35+12)*8/sizeof(in[0])); out[0*64+21] = (start + ((w11 >> 31) | (w12 << 33) & 0x7ffffffff)); out[0*64+22] = (start + ((w12 >> 2) & 0x7ffffffff)); w13 = *(uint64_t *)(in+(0*35+13)*8/sizeof(in[0])); out[0*64+23] = (start + ((w12 >> 37) | (w13 << 27) & 0x7ffffffff)); out[0*64+24] = (start + ((w13 >> 8) & 0x7ffffffff)); w14 = *(uint64_t *)(in+(0*35+14)*8/sizeof(in[0])); out[0*64+25] = (start + ((w13 >> 43) | (w14 << 21) & 0x7ffffffff)); out[0*64+26] = (start + ((w14 >> 14) & 0x7ffffffff)); w15 = *(uint64_t *)(in+(0*35+15)*8/sizeof(in[0])); out[0*64+27] = (start + ((w14 >> 49) | (w15 << 15) & 0x7ffffffff)); out[0*64+28] = (start + ((w15 >> 20) & 0x7ffffffff)); w16 = *(uint64_t *)(in+(0*35+16)*8/sizeof(in[0])); out[0*64+29] = (start + ((w15 >> 55) | (w16 << 9) & 0x7ffffffff)); out[0*64+30] = (start + ((w16 >> 26) & 0x7ffffffff)); w17 = *(uint32_t *)(in+(0*35+17)*8/sizeof(in[0])); out[0*64+31] = (start + ((w16 >> 61) | (w17 << 3) & 0x7ffffffff));;}; out += 32; in += 35*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_36(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*36)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xfffffffff)); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*16+ 1] = (start + ((w0 >> 36) | (w1 << 28) & 0xfffffffff)); out[0*16+ 2] = (start + ((w1 >> 8) & 0xfffffffff)); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*16+ 3] = (start + ((w1 >> 44) | (w2 << 20) & 0xfffffffff)); out[0*16+ 4] = (start + ((w2 >> 16) & 0xfffffffff)); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*16+ 5] = (start + ((w2 >> 52) | (w3 << 12) & 0xfffffffff)); out[0*16+ 6] = (start + ((w3 >> 24) & 0xfffffffff)); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*16+ 7] = (start + ((w3 >> 60) | (w4 << 4) & 0xfffffffff)); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*16+ 8] = (start + ((w4 >> 32) | (w5 << 32) & 0xfffffffff)); out[0*16+ 9] = (start + ((w5 >> 4) & 0xfffffffff)); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*16+10] = (start + ((w5 >> 40) | (w6 << 24) & 0xfffffffff)); out[0*16+11] = (start + ((w6 >> 12) & 0xfffffffff)); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*16+12] = (start + ((w6 >> 48) | (w7 << 16) & 0xfffffffff)); out[0*16+13] = (start + ((w7 >> 20) & 0xfffffffff)); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*16+14] = (start + ((w7 >> 56) | (w8 << 8) & 0xfffffffff)); out[0*16+15] = (start + ((w8 >> 28)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(1*9+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xfffffffff)); w1 = *(uint64_t *)(in+(1*9+1)*8/sizeof(in[0])); out[1*16+ 1] = (start + ((w0 >> 36) | (w1 << 28) & 0xfffffffff)); out[1*16+ 2] = (start + ((w1 >> 8) & 0xfffffffff)); w2 = *(uint64_t *)(in+(1*9+2)*8/sizeof(in[0])); out[1*16+ 3] = (start + ((w1 >> 44) | (w2 << 20) & 0xfffffffff)); out[1*16+ 4] = (start + ((w2 >> 16) & 0xfffffffff)); w3 = *(uint64_t *)(in+(1*9+3)*8/sizeof(in[0])); out[1*16+ 5] = (start + ((w2 >> 52) | (w3 << 12) & 0xfffffffff)); out[1*16+ 6] = (start + ((w3 >> 24) & 0xfffffffff)); w4 = *(uint64_t *)(in+(1*9+4)*8/sizeof(in[0])); out[1*16+ 7] = (start + ((w3 >> 60) | (w4 << 4) & 0xfffffffff)); w5 = *(uint64_t *)(in+(1*9+5)*8/sizeof(in[0])); out[1*16+ 8] = (start + ((w4 >> 32) | (w5 << 32) & 0xfffffffff)); out[1*16+ 9] = (start + ((w5 >> 4) & 0xfffffffff)); w6 = *(uint64_t *)(in+(1*9+6)*8/sizeof(in[0])); out[1*16+10] = (start + ((w5 >> 40) | (w6 << 24) & 0xfffffffff)); out[1*16+11] = (start + ((w6 >> 12) & 0xfffffffff)); w7 = *(uint64_t *)(in+(1*9+7)*8/sizeof(in[0])); out[1*16+12] = (start + ((w6 >> 48) | (w7 << 16) & 0xfffffffff)); out[1*16+13] = (start + ((w7 >> 20) & 0xfffffffff)); w8 = *(uint64_t *)(in+(1*9+8)*8/sizeof(in[0])); out[1*16+14] = (start + ((w7 >> 56) | (w8 << 8) & 0xfffffffff)); out[1*16+15] = (start + ((w8 >> 28)));;}; out += 32; in += 36*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_37(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*37)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18; w0 = *(uint64_t *)(in+(0*37+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1fffffffff)); w1 = *(uint64_t *)(in+(0*37+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 37) | (w1 << 27) & 0x1fffffffff)); out[0*64+ 2] = (start + ((w1 >> 10) & 0x1fffffffff)); w2 = *(uint64_t *)(in+(0*37+2)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w1 >> 47) | (w2 << 17) & 0x1fffffffff)); out[0*64+ 4] = (start + ((w2 >> 20) & 0x1fffffffff)); w3 = *(uint64_t *)(in+(0*37+3)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w2 >> 57) | (w3 << 7) & 0x1fffffffff)); w4 = *(uint64_t *)(in+(0*37+4)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w3 >> 30) | (w4 << 34) & 0x1fffffffff)); out[0*64+ 7] = (start + ((w4 >> 3) & 0x1fffffffff)); w5 = *(uint64_t *)(in+(0*37+5)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w4 >> 40) | (w5 << 24) & 0x1fffffffff)); out[0*64+ 9] = (start + ((w5 >> 13) & 0x1fffffffff)); w6 = *(uint64_t *)(in+(0*37+6)*8/sizeof(in[0])); out[0*64+10] = (start + ((w5 >> 50) | (w6 << 14) & 0x1fffffffff)); out[0*64+11] = (start + ((w6 >> 23) & 0x1fffffffff)); w7 = *(uint64_t *)(in+(0*37+7)*8/sizeof(in[0])); out[0*64+12] = (start + ((w6 >> 60) | (w7 << 4) & 0x1fffffffff)); w8 = *(uint64_t *)(in+(0*37+8)*8/sizeof(in[0])); out[0*64+13] = (start + ((w7 >> 33) | (w8 << 31) & 0x1fffffffff)); out[0*64+14] = (start + ((w8 >> 6) & 0x1fffffffff)); w9 = *(uint64_t *)(in+(0*37+9)*8/sizeof(in[0])); out[0*64+15] = (start + ((w8 >> 43) | (w9 << 21) & 0x1fffffffff)); out[0*64+16] = (start + ((w9 >> 16) & 0x1fffffffff)); w10 = *(uint64_t *)(in+(0*37+10)*8/sizeof(in[0])); out[0*64+17] = (start + ((w9 >> 53) | (w10 << 11) & 0x1fffffffff)); out[0*64+18] = (start + ((w10 >> 26) & 0x1fffffffff)); w11 = *(uint64_t *)(in+(0*37+11)*8/sizeof(in[0])); out[0*64+19] = (start + ((w10 >> 63) | (w11 << 1) & 0x1fffffffff)); w12 = *(uint64_t *)(in+(0*37+12)*8/sizeof(in[0])); out[0*64+20] = (start + ((w11 >> 36) | (w12 << 28) & 0x1fffffffff)); out[0*64+21] = (start + ((w12 >> 9) & 0x1fffffffff)); w13 = *(uint64_t *)(in+(0*37+13)*8/sizeof(in[0])); out[0*64+22] = (start + ((w12 >> 46) | (w13 << 18) & 0x1fffffffff)); out[0*64+23] = (start + ((w13 >> 19) & 0x1fffffffff)); w14 = *(uint64_t *)(in+(0*37+14)*8/sizeof(in[0])); out[0*64+24] = (start + ((w13 >> 56) | (w14 << 8) & 0x1fffffffff)); w15 = *(uint64_t *)(in+(0*37+15)*8/sizeof(in[0])); out[0*64+25] = (start + ((w14 >> 29) | (w15 << 35) & 0x1fffffffff)); out[0*64+26] = (start + ((w15 >> 2) & 0x1fffffffff)); w16 = *(uint64_t *)(in+(0*37+16)*8/sizeof(in[0])); out[0*64+27] = (start + ((w15 >> 39) | (w16 << 25) & 0x1fffffffff)); out[0*64+28] = (start + ((w16 >> 12) & 0x1fffffffff)); w17 = *(uint64_t *)(in+(0*37+17)*8/sizeof(in[0])); out[0*64+29] = (start + ((w16 >> 49) | (w17 << 15) & 0x1fffffffff)); out[0*64+30] = (start + ((w17 >> 22) & 0x1fffffffff)); w18 = *(uint32_t *)(in+(0*37+18)*8/sizeof(in[0])); out[0*64+31] = (start + ((w17 >> 59) | (w18 << 5) & 0x1fffffffff));;}; out += 32; in += 37*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_38(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*38)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3fffffffff)); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*32+ 1] = (start + ((w0 >> 38) | (w1 << 26) & 0x3fffffffff)); out[0*32+ 2] = (start + ((w1 >> 12) & 0x3fffffffff)); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*32+ 3] = (start + ((w1 >> 50) | (w2 << 14) & 0x3fffffffff)); out[0*32+ 4] = (start + ((w2 >> 24) & 0x3fffffffff)); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*32+ 5] = (start + ((w2 >> 62) | (w3 << 2) & 0x3fffffffff)); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*32+ 6] = (start + ((w3 >> 36) | (w4 << 28) & 0x3fffffffff)); out[0*32+ 7] = (start + ((w4 >> 10) & 0x3fffffffff)); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*32+ 8] = (start + ((w4 >> 48) | (w5 << 16) & 0x3fffffffff)); out[0*32+ 9] = (start + ((w5 >> 22) & 0x3fffffffff)); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*32+10] = (start + ((w5 >> 60) | (w6 << 4) & 0x3fffffffff)); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*32+11] = (start + ((w6 >> 34) | (w7 << 30) & 0x3fffffffff)); out[0*32+12] = (start + ((w7 >> 8) & 0x3fffffffff)); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*32+13] = (start + ((w7 >> 46) | (w8 << 18) & 0x3fffffffff)); out[0*32+14] = (start + ((w8 >> 20) & 0x3fffffffff)); w9 = *(uint64_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*32+15] = (start + ((w8 >> 58) | (w9 << 6) & 0x3fffffffff)); w10 = *(uint64_t *)(in+(0*19+10)*8/sizeof(in[0])); out[0*32+16] = (start + ((w9 >> 32) | (w10 << 32) & 0x3fffffffff)); out[0*32+17] = (start + ((w10 >> 6) & 0x3fffffffff)); w11 = *(uint64_t *)(in+(0*19+11)*8/sizeof(in[0])); out[0*32+18] = (start + ((w10 >> 44) | (w11 << 20) & 0x3fffffffff)); out[0*32+19] = (start + ((w11 >> 18) & 0x3fffffffff)); w12 = *(uint64_t *)(in+(0*19+12)*8/sizeof(in[0])); out[0*32+20] = (start + ((w11 >> 56) | (w12 << 8) & 0x3fffffffff)); w13 = *(uint64_t *)(in+(0*19+13)*8/sizeof(in[0])); out[0*32+21] = (start + ((w12 >> 30) | (w13 << 34) & 0x3fffffffff)); out[0*32+22] = (start + ((w13 >> 4) & 0x3fffffffff)); w14 = *(uint64_t *)(in+(0*19+14)*8/sizeof(in[0])); out[0*32+23] = (start + ((w13 >> 42) | (w14 << 22) & 0x3fffffffff)); out[0*32+24] = (start + ((w14 >> 16) & 0x3fffffffff)); w15 = *(uint64_t *)(in+(0*19+15)*8/sizeof(in[0])); out[0*32+25] = (start + ((w14 >> 54) | (w15 << 10) & 0x3fffffffff)); w16 = *(uint64_t *)(in+(0*19+16)*8/sizeof(in[0])); out[0*32+26] = (start + ((w15 >> 28) | (w16 << 36) & 0x3fffffffff)); out[0*32+27] = (start + ((w16 >> 2) & 0x3fffffffff)); w17 = *(uint64_t *)(in+(0*19+17)*8/sizeof(in[0])); out[0*32+28] = (start + ((w16 >> 40) | (w17 << 24) & 0x3fffffffff)); out[0*32+29] = (start + ((w17 >> 14) & 0x3fffffffff)); w18 = *(uint64_t *)(in+(0*19+18)*8/sizeof(in[0])); out[0*32+30] = (start + ((w17 >> 52) | (w18 << 12) & 0x3fffffffff)); out[0*32+31] = (start + ((w18 >> 26)));;}; out += 32; in += 38*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_39(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*39)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(0*39+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7fffffffff)); w1 = *(uint64_t *)(in+(0*39+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 39) | (w1 << 25) & 0x7fffffffff)); out[0*64+ 2] = (start + ((w1 >> 14) & 0x7fffffffff)); w2 = *(uint64_t *)(in+(0*39+2)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w1 >> 53) | (w2 << 11) & 0x7fffffffff)); w3 = *(uint64_t *)(in+(0*39+3)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w2 >> 28) | (w3 << 36) & 0x7fffffffff)); out[0*64+ 5] = (start + ((w3 >> 3) & 0x7fffffffff)); w4 = *(uint64_t *)(in+(0*39+4)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w3 >> 42) | (w4 << 22) & 0x7fffffffff)); out[0*64+ 7] = (start + ((w4 >> 17) & 0x7fffffffff)); w5 = *(uint64_t *)(in+(0*39+5)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w4 >> 56) | (w5 << 8) & 0x7fffffffff)); w6 = *(uint64_t *)(in+(0*39+6)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w5 >> 31) | (w6 << 33) & 0x7fffffffff)); out[0*64+10] = (start + ((w6 >> 6) & 0x7fffffffff)); w7 = *(uint64_t *)(in+(0*39+7)*8/sizeof(in[0])); out[0*64+11] = (start + ((w6 >> 45) | (w7 << 19) & 0x7fffffffff)); out[0*64+12] = (start + ((w7 >> 20) & 0x7fffffffff)); w8 = *(uint64_t *)(in+(0*39+8)*8/sizeof(in[0])); out[0*64+13] = (start + ((w7 >> 59) | (w8 << 5) & 0x7fffffffff)); w9 = *(uint64_t *)(in+(0*39+9)*8/sizeof(in[0])); out[0*64+14] = (start + ((w8 >> 34) | (w9 << 30) & 0x7fffffffff)); out[0*64+15] = (start + ((w9 >> 9) & 0x7fffffffff)); w10 = *(uint64_t *)(in+(0*39+10)*8/sizeof(in[0])); out[0*64+16] = (start + ((w9 >> 48) | (w10 << 16) & 0x7fffffffff)); out[0*64+17] = (start + ((w10 >> 23) & 0x7fffffffff)); w11 = *(uint64_t *)(in+(0*39+11)*8/sizeof(in[0])); out[0*64+18] = (start + ((w10 >> 62) | (w11 << 2) & 0x7fffffffff)); w12 = *(uint64_t *)(in+(0*39+12)*8/sizeof(in[0])); out[0*64+19] = (start + ((w11 >> 37) | (w12 << 27) & 0x7fffffffff)); out[0*64+20] = (start + ((w12 >> 12) & 0x7fffffffff)); w13 = *(uint64_t *)(in+(0*39+13)*8/sizeof(in[0])); out[0*64+21] = (start + ((w12 >> 51) | (w13 << 13) & 0x7fffffffff)); w14 = *(uint64_t *)(in+(0*39+14)*8/sizeof(in[0])); out[0*64+22] = (start + ((w13 >> 26) | (w14 << 38) & 0x7fffffffff)); out[0*64+23] = (start + ((w14 >> 1) & 0x7fffffffff)); w15 = *(uint64_t *)(in+(0*39+15)*8/sizeof(in[0])); out[0*64+24] = (start + ((w14 >> 40) | (w15 << 24) & 0x7fffffffff)); out[0*64+25] = (start + ((w15 >> 15) & 0x7fffffffff)); w16 = *(uint64_t *)(in+(0*39+16)*8/sizeof(in[0])); out[0*64+26] = (start + ((w15 >> 54) | (w16 << 10) & 0x7fffffffff)); w17 = *(uint64_t *)(in+(0*39+17)*8/sizeof(in[0])); out[0*64+27] = (start + ((w16 >> 29) | (w17 << 35) & 0x7fffffffff)); out[0*64+28] = (start + ((w17 >> 4) & 0x7fffffffff)); w18 = *(uint64_t *)(in+(0*39+18)*8/sizeof(in[0])); out[0*64+29] = (start + ((w17 >> 43) | (w18 << 21) & 0x7fffffffff)); out[0*64+30] = (start + ((w18 >> 18) & 0x7fffffffff)); w19 = *(uint32_t *)(in+(0*39+19)*8/sizeof(in[0])); out[0*64+31] = (start + ((w18 >> 57) | (w19 << 7) & 0x7fffffffff));;}; out += 32; in += 39*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_40(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*40)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*8+ 0] = (start + ((w0 ) & 0xffffffffff)); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*8+ 1] = (start + ((w0 >> 40) | (w1 << 24) & 0xffffffffff)); out[0*8+ 2] = (start + ((w1 >> 16) & 0xffffffffff)); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*8+ 3] = (start + ((w1 >> 56) | (w2 << 8) & 0xffffffffff)); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*8+ 4] = (start + ((w2 >> 32) | (w3 << 32) & 0xffffffffff)); out[0*8+ 5] = (start + ((w3 >> 8) & 0xffffffffff)); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*8+ 6] = (start + ((w3 >> 48) | (w4 << 16) & 0xffffffffff)); out[0*8+ 7] = (start + ((w4 >> 24)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*8+ 0] = (start + ((w0 ) & 0xffffffffff)); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*8+ 1] = (start + ((w0 >> 40) | (w1 << 24) & 0xffffffffff)); out[1*8+ 2] = (start + ((w1 >> 16) & 0xffffffffff)); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*8+ 3] = (start + ((w1 >> 56) | (w2 << 8) & 0xffffffffff)); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*8+ 4] = (start + ((w2 >> 32) | (w3 << 32) & 0xffffffffff)); out[1*8+ 5] = (start + ((w3 >> 8) & 0xffffffffff)); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*8+ 6] = (start + ((w3 >> 48) | (w4 << 16) & 0xffffffffff)); out[1*8+ 7] = (start + ((w4 >> 24)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(2*5+0)*8/sizeof(in[0])); out[2*8+ 0] = (start + ((w0 ) & 0xffffffffff)); w1 = *(uint64_t *)(in+(2*5+1)*8/sizeof(in[0])); out[2*8+ 1] = (start + ((w0 >> 40) | (w1 << 24) & 0xffffffffff)); out[2*8+ 2] = (start + ((w1 >> 16) & 0xffffffffff)); w2 = *(uint64_t *)(in+(2*5+2)*8/sizeof(in[0])); out[2*8+ 3] = (start + ((w1 >> 56) | (w2 << 8) & 0xffffffffff)); w3 = *(uint64_t *)(in+(2*5+3)*8/sizeof(in[0])); out[2*8+ 4] = (start + ((w2 >> 32) | (w3 << 32) & 0xffffffffff)); out[2*8+ 5] = (start + ((w3 >> 8) & 0xffffffffff)); w4 = *(uint64_t *)(in+(2*5+4)*8/sizeof(in[0])); out[2*8+ 6] = (start + ((w3 >> 48) | (w4 << 16) & 0xffffffffff)); out[2*8+ 7] = (start + ((w4 >> 24)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(3*5+0)*8/sizeof(in[0])); out[3*8+ 0] = (start + ((w0 ) & 0xffffffffff)); w1 = *(uint64_t *)(in+(3*5+1)*8/sizeof(in[0])); out[3*8+ 1] = (start + ((w0 >> 40) | (w1 << 24) & 0xffffffffff)); out[3*8+ 2] = (start + ((w1 >> 16) & 0xffffffffff)); w2 = *(uint64_t *)(in+(3*5+2)*8/sizeof(in[0])); out[3*8+ 3] = (start + ((w1 >> 56) | (w2 << 8) & 0xffffffffff)); w3 = *(uint64_t *)(in+(3*5+3)*8/sizeof(in[0])); out[3*8+ 4] = (start + ((w2 >> 32) | (w3 << 32) & 0xffffffffff)); out[3*8+ 5] = (start + ((w3 >> 8) & 0xffffffffff)); w4 = *(uint64_t *)(in+(3*5+4)*8/sizeof(in[0])); out[3*8+ 6] = (start + ((w3 >> 48) | (w4 << 16) & 0xffffffffff)); out[3*8+ 7] = (start + ((w4 >> 24)));;}; out += 32; in += 40*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_41(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*41)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20; w0 = *(uint64_t *)(in+(0*41+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1ffffffffff)); w1 = *(uint64_t *)(in+(0*41+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 41) | (w1 << 23) & 0x1ffffffffff)); out[0*64+ 2] = (start + ((w1 >> 18) & 0x1ffffffffff)); w2 = *(uint64_t *)(in+(0*41+2)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w1 >> 59) | (w2 << 5) & 0x1ffffffffff)); w3 = *(uint64_t *)(in+(0*41+3)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w2 >> 36) | (w3 << 28) & 0x1ffffffffff)); out[0*64+ 5] = (start + ((w3 >> 13) & 0x1ffffffffff)); w4 = *(uint64_t *)(in+(0*41+4)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w3 >> 54) | (w4 << 10) & 0x1ffffffffff)); w5 = *(uint64_t *)(in+(0*41+5)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w4 >> 31) | (w5 << 33) & 0x1ffffffffff)); out[0*64+ 8] = (start + ((w5 >> 8) & 0x1ffffffffff)); w6 = *(uint64_t *)(in+(0*41+6)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w5 >> 49) | (w6 << 15) & 0x1ffffffffff)); w7 = *(uint64_t *)(in+(0*41+7)*8/sizeof(in[0])); out[0*64+10] = (start + ((w6 >> 26) | (w7 << 38) & 0x1ffffffffff)); out[0*64+11] = (start + ((w7 >> 3) & 0x1ffffffffff)); w8 = *(uint64_t *)(in+(0*41+8)*8/sizeof(in[0])); out[0*64+12] = (start + ((w7 >> 44) | (w8 << 20) & 0x1ffffffffff)); out[0*64+13] = (start + ((w8 >> 21) & 0x1ffffffffff)); w9 = *(uint64_t *)(in+(0*41+9)*8/sizeof(in[0])); out[0*64+14] = (start + ((w8 >> 62) | (w9 << 2) & 0x1ffffffffff)); w10 = *(uint64_t *)(in+(0*41+10)*8/sizeof(in[0])); out[0*64+15] = (start + ((w9 >> 39) | (w10 << 25) & 0x1ffffffffff)); out[0*64+16] = (start + ((w10 >> 16) & 0x1ffffffffff)); w11 = *(uint64_t *)(in+(0*41+11)*8/sizeof(in[0])); out[0*64+17] = (start + ((w10 >> 57) | (w11 << 7) & 0x1ffffffffff)); w12 = *(uint64_t *)(in+(0*41+12)*8/sizeof(in[0])); out[0*64+18] = (start + ((w11 >> 34) | (w12 << 30) & 0x1ffffffffff)); out[0*64+19] = (start + ((w12 >> 11) & 0x1ffffffffff)); w13 = *(uint64_t *)(in+(0*41+13)*8/sizeof(in[0])); out[0*64+20] = (start + ((w12 >> 52) | (w13 << 12) & 0x1ffffffffff)); w14 = *(uint64_t *)(in+(0*41+14)*8/sizeof(in[0])); out[0*64+21] = (start + ((w13 >> 29) | (w14 << 35) & 0x1ffffffffff)); out[0*64+22] = (start + ((w14 >> 6) & 0x1ffffffffff)); w15 = *(uint64_t *)(in+(0*41+15)*8/sizeof(in[0])); out[0*64+23] = (start + ((w14 >> 47) | (w15 << 17) & 0x1ffffffffff)); w16 = *(uint64_t *)(in+(0*41+16)*8/sizeof(in[0])); out[0*64+24] = (start + ((w15 >> 24) | (w16 << 40) & 0x1ffffffffff)); out[0*64+25] = (start + ((w16 >> 1) & 0x1ffffffffff)); w17 = *(uint64_t *)(in+(0*41+17)*8/sizeof(in[0])); out[0*64+26] = (start + ((w16 >> 42) | (w17 << 22) & 0x1ffffffffff)); out[0*64+27] = (start + ((w17 >> 19) & 0x1ffffffffff)); w18 = *(uint64_t *)(in+(0*41+18)*8/sizeof(in[0])); out[0*64+28] = (start + ((w17 >> 60) | (w18 << 4) & 0x1ffffffffff)); w19 = *(uint64_t *)(in+(0*41+19)*8/sizeof(in[0])); out[0*64+29] = (start + ((w18 >> 37) | (w19 << 27) & 0x1ffffffffff)); out[0*64+30] = (start + ((w19 >> 14) & 0x1ffffffffff)); w20 = *(uint32_t *)(in+(0*41+20)*8/sizeof(in[0])); out[0*64+31] = (start + ((w19 >> 55) | (w20 << 9) & 0x1ffffffffff));;}; out += 32; in += 41*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_42(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*42)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3ffffffffff)); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*32+ 1] = (start + ((w0 >> 42) | (w1 << 22) & 0x3ffffffffff)); out[0*32+ 2] = (start + ((w1 >> 20) & 0x3ffffffffff)); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*32+ 3] = (start + ((w1 >> 62) | (w2 << 2) & 0x3ffffffffff)); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*32+ 4] = (start + ((w2 >> 40) | (w3 << 24) & 0x3ffffffffff)); out[0*32+ 5] = (start + ((w3 >> 18) & 0x3ffffffffff)); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*32+ 6] = (start + ((w3 >> 60) | (w4 << 4) & 0x3ffffffffff)); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*32+ 7] = (start + ((w4 >> 38) | (w5 << 26) & 0x3ffffffffff)); out[0*32+ 8] = (start + ((w5 >> 16) & 0x3ffffffffff)); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*32+ 9] = (start + ((w5 >> 58) | (w6 << 6) & 0x3ffffffffff)); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*32+10] = (start + ((w6 >> 36) | (w7 << 28) & 0x3ffffffffff)); out[0*32+11] = (start + ((w7 >> 14) & 0x3ffffffffff)); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*32+12] = (start + ((w7 >> 56) | (w8 << 8) & 0x3ffffffffff)); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*32+13] = (start + ((w8 >> 34) | (w9 << 30) & 0x3ffffffffff)); out[0*32+14] = (start + ((w9 >> 12) & 0x3ffffffffff)); w10 = *(uint64_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*32+15] = (start + ((w9 >> 54) | (w10 << 10) & 0x3ffffffffff)); w11 = *(uint64_t *)(in+(0*21+11)*8/sizeof(in[0])); out[0*32+16] = (start + ((w10 >> 32) | (w11 << 32) & 0x3ffffffffff)); out[0*32+17] = (start + ((w11 >> 10) & 0x3ffffffffff)); w12 = *(uint64_t *)(in+(0*21+12)*8/sizeof(in[0])); out[0*32+18] = (start + ((w11 >> 52) | (w12 << 12) & 0x3ffffffffff)); w13 = *(uint64_t *)(in+(0*21+13)*8/sizeof(in[0])); out[0*32+19] = (start + ((w12 >> 30) | (w13 << 34) & 0x3ffffffffff)); out[0*32+20] = (start + ((w13 >> 8) & 0x3ffffffffff)); w14 = *(uint64_t *)(in+(0*21+14)*8/sizeof(in[0])); out[0*32+21] = (start + ((w13 >> 50) | (w14 << 14) & 0x3ffffffffff)); w15 = *(uint64_t *)(in+(0*21+15)*8/sizeof(in[0])); out[0*32+22] = (start + ((w14 >> 28) | (w15 << 36) & 0x3ffffffffff)); out[0*32+23] = (start + ((w15 >> 6) & 0x3ffffffffff)); w16 = *(uint64_t *)(in+(0*21+16)*8/sizeof(in[0])); out[0*32+24] = (start + ((w15 >> 48) | (w16 << 16) & 0x3ffffffffff)); w17 = *(uint64_t *)(in+(0*21+17)*8/sizeof(in[0])); out[0*32+25] = (start + ((w16 >> 26) | (w17 << 38) & 0x3ffffffffff)); out[0*32+26] = (start + ((w17 >> 4) & 0x3ffffffffff)); w18 = *(uint64_t *)(in+(0*21+18)*8/sizeof(in[0])); out[0*32+27] = (start + ((w17 >> 46) | (w18 << 18) & 0x3ffffffffff)); w19 = *(uint64_t *)(in+(0*21+19)*8/sizeof(in[0])); out[0*32+28] = (start + ((w18 >> 24) | (w19 << 40) & 0x3ffffffffff)); out[0*32+29] = (start + ((w19 >> 2) & 0x3ffffffffff)); w20 = *(uint64_t *)(in+(0*21+20)*8/sizeof(in[0])); out[0*32+30] = (start + ((w19 >> 44) | (w20 << 20) & 0x3ffffffffff)); out[0*32+31] = (start + ((w20 >> 22)));;}; out += 32; in += 42*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_43(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*43)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(0*43+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7ffffffffff)); w1 = *(uint64_t *)(in+(0*43+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 43) | (w1 << 21) & 0x7ffffffffff)); w2 = *(uint64_t *)(in+(0*43+2)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w1 >> 22) | (w2 << 42) & 0x7ffffffffff)); out[0*64+ 3] = (start + ((w2 >> 1) & 0x7ffffffffff)); w3 = *(uint64_t *)(in+(0*43+3)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w2 >> 44) | (w3 << 20) & 0x7ffffffffff)); w4 = *(uint64_t *)(in+(0*43+4)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w3 >> 23) | (w4 << 41) & 0x7ffffffffff)); out[0*64+ 6] = (start + ((w4 >> 2) & 0x7ffffffffff)); w5 = *(uint64_t *)(in+(0*43+5)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w4 >> 45) | (w5 << 19) & 0x7ffffffffff)); w6 = *(uint64_t *)(in+(0*43+6)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w5 >> 24) | (w6 << 40) & 0x7ffffffffff)); out[0*64+ 9] = (start + ((w6 >> 3) & 0x7ffffffffff)); w7 = *(uint64_t *)(in+(0*43+7)*8/sizeof(in[0])); out[0*64+10] = (start + ((w6 >> 46) | (w7 << 18) & 0x7ffffffffff)); w8 = *(uint64_t *)(in+(0*43+8)*8/sizeof(in[0])); out[0*64+11] = (start + ((w7 >> 25) | (w8 << 39) & 0x7ffffffffff)); out[0*64+12] = (start + ((w8 >> 4) & 0x7ffffffffff)); w9 = *(uint64_t *)(in+(0*43+9)*8/sizeof(in[0])); out[0*64+13] = (start + ((w8 >> 47) | (w9 << 17) & 0x7ffffffffff)); w10 = *(uint64_t *)(in+(0*43+10)*8/sizeof(in[0])); out[0*64+14] = (start + ((w9 >> 26) | (w10 << 38) & 0x7ffffffffff)); out[0*64+15] = (start + ((w10 >> 5) & 0x7ffffffffff)); w11 = *(uint64_t *)(in+(0*43+11)*8/sizeof(in[0])); out[0*64+16] = (start + ((w10 >> 48) | (w11 << 16) & 0x7ffffffffff)); w12 = *(uint64_t *)(in+(0*43+12)*8/sizeof(in[0])); out[0*64+17] = (start + ((w11 >> 27) | (w12 << 37) & 0x7ffffffffff)); out[0*64+18] = (start + ((w12 >> 6) & 0x7ffffffffff)); w13 = *(uint64_t *)(in+(0*43+13)*8/sizeof(in[0])); out[0*64+19] = (start + ((w12 >> 49) | (w13 << 15) & 0x7ffffffffff)); w14 = *(uint64_t *)(in+(0*43+14)*8/sizeof(in[0])); out[0*64+20] = (start + ((w13 >> 28) | (w14 << 36) & 0x7ffffffffff)); out[0*64+21] = (start + ((w14 >> 7) & 0x7ffffffffff)); w15 = *(uint64_t *)(in+(0*43+15)*8/sizeof(in[0])); out[0*64+22] = (start + ((w14 >> 50) | (w15 << 14) & 0x7ffffffffff)); w16 = *(uint64_t *)(in+(0*43+16)*8/sizeof(in[0])); out[0*64+23] = (start + ((w15 >> 29) | (w16 << 35) & 0x7ffffffffff)); out[0*64+24] = (start + ((w16 >> 8) & 0x7ffffffffff)); w17 = *(uint64_t *)(in+(0*43+17)*8/sizeof(in[0])); out[0*64+25] = (start + ((w16 >> 51) | (w17 << 13) & 0x7ffffffffff)); w18 = *(uint64_t *)(in+(0*43+18)*8/sizeof(in[0])); out[0*64+26] = (start + ((w17 >> 30) | (w18 << 34) & 0x7ffffffffff)); out[0*64+27] = (start + ((w18 >> 9) & 0x7ffffffffff)); w19 = *(uint64_t *)(in+(0*43+19)*8/sizeof(in[0])); out[0*64+28] = (start + ((w18 >> 52) | (w19 << 12) & 0x7ffffffffff)); w20 = *(uint64_t *)(in+(0*43+20)*8/sizeof(in[0])); out[0*64+29] = (start + ((w19 >> 31) | (w20 << 33) & 0x7ffffffffff)); out[0*64+30] = (start + ((w20 >> 10) & 0x7ffffffffff)); w21 = *(uint32_t *)(in+(0*43+21)*8/sizeof(in[0])); out[0*64+31] = (start + ((w20 >> 53) | (w21 << 11) & 0x7ffffffffff));;}; out += 32; in += 43*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_44(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*44)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xfffffffffff)); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*16+ 1] = (start + ((w0 >> 44) | (w1 << 20) & 0xfffffffffff)); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*16+ 2] = (start + ((w1 >> 24) | (w2 << 40) & 0xfffffffffff)); out[0*16+ 3] = (start + ((w2 >> 4) & 0xfffffffffff)); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*16+ 4] = (start + ((w2 >> 48) | (w3 << 16) & 0xfffffffffff)); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*16+ 5] = (start + ((w3 >> 28) | (w4 << 36) & 0xfffffffffff)); out[0*16+ 6] = (start + ((w4 >> 8) & 0xfffffffffff)); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*16+ 7] = (start + ((w4 >> 52) | (w5 << 12) & 0xfffffffffff)); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*16+ 8] = (start + ((w5 >> 32) | (w6 << 32) & 0xfffffffffff)); out[0*16+ 9] = (start + ((w6 >> 12) & 0xfffffffffff)); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*16+10] = (start + ((w6 >> 56) | (w7 << 8) & 0xfffffffffff)); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*16+11] = (start + ((w7 >> 36) | (w8 << 28) & 0xfffffffffff)); out[0*16+12] = (start + ((w8 >> 16) & 0xfffffffffff)); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*16+13] = (start + ((w8 >> 60) | (w9 << 4) & 0xfffffffffff)); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*16+14] = (start + ((w9 >> 40) | (w10 << 24) & 0xfffffffffff)); out[0*16+15] = (start + ((w10 >> 20)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(1*11+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xfffffffffff)); w1 = *(uint64_t *)(in+(1*11+1)*8/sizeof(in[0])); out[1*16+ 1] = (start + ((w0 >> 44) | (w1 << 20) & 0xfffffffffff)); w2 = *(uint64_t *)(in+(1*11+2)*8/sizeof(in[0])); out[1*16+ 2] = (start + ((w1 >> 24) | (w2 << 40) & 0xfffffffffff)); out[1*16+ 3] = (start + ((w2 >> 4) & 0xfffffffffff)); w3 = *(uint64_t *)(in+(1*11+3)*8/sizeof(in[0])); out[1*16+ 4] = (start + ((w2 >> 48) | (w3 << 16) & 0xfffffffffff)); w4 = *(uint64_t *)(in+(1*11+4)*8/sizeof(in[0])); out[1*16+ 5] = (start + ((w3 >> 28) | (w4 << 36) & 0xfffffffffff)); out[1*16+ 6] = (start + ((w4 >> 8) & 0xfffffffffff)); w5 = *(uint64_t *)(in+(1*11+5)*8/sizeof(in[0])); out[1*16+ 7] = (start + ((w4 >> 52) | (w5 << 12) & 0xfffffffffff)); w6 = *(uint64_t *)(in+(1*11+6)*8/sizeof(in[0])); out[1*16+ 8] = (start + ((w5 >> 32) | (w6 << 32) & 0xfffffffffff)); out[1*16+ 9] = (start + ((w6 >> 12) & 0xfffffffffff)); w7 = *(uint64_t *)(in+(1*11+7)*8/sizeof(in[0])); out[1*16+10] = (start + ((w6 >> 56) | (w7 << 8) & 0xfffffffffff)); w8 = *(uint64_t *)(in+(1*11+8)*8/sizeof(in[0])); out[1*16+11] = (start + ((w7 >> 36) | (w8 << 28) & 0xfffffffffff)); out[1*16+12] = (start + ((w8 >> 16) & 0xfffffffffff)); w9 = *(uint64_t *)(in+(1*11+9)*8/sizeof(in[0])); out[1*16+13] = (start + ((w8 >> 60) | (w9 << 4) & 0xfffffffffff)); w10 = *(uint64_t *)(in+(1*11+10)*8/sizeof(in[0])); out[1*16+14] = (start + ((w9 >> 40) | (w10 << 24) & 0xfffffffffff)); out[1*16+15] = (start + ((w10 >> 20)));;}; out += 32; in += 44*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_45(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*45)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22; w0 = *(uint64_t *)(in+(0*45+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1fffffffffff)); w1 = *(uint64_t *)(in+(0*45+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 45) | (w1 << 19) & 0x1fffffffffff)); w2 = *(uint64_t *)(in+(0*45+2)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w1 >> 26) | (w2 << 38) & 0x1fffffffffff)); out[0*64+ 3] = (start + ((w2 >> 7) & 0x1fffffffffff)); w3 = *(uint64_t *)(in+(0*45+3)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w2 >> 52) | (w3 << 12) & 0x1fffffffffff)); w4 = *(uint64_t *)(in+(0*45+4)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w3 >> 33) | (w4 << 31) & 0x1fffffffffff)); out[0*64+ 6] = (start + ((w4 >> 14) & 0x1fffffffffff)); w5 = *(uint64_t *)(in+(0*45+5)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w4 >> 59) | (w5 << 5) & 0x1fffffffffff)); w6 = *(uint64_t *)(in+(0*45+6)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w5 >> 40) | (w6 << 24) & 0x1fffffffffff)); w7 = *(uint64_t *)(in+(0*45+7)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w6 >> 21) | (w7 << 43) & 0x1fffffffffff)); out[0*64+10] = (start + ((w7 >> 2) & 0x1fffffffffff)); w8 = *(uint64_t *)(in+(0*45+8)*8/sizeof(in[0])); out[0*64+11] = (start + ((w7 >> 47) | (w8 << 17) & 0x1fffffffffff)); w9 = *(uint64_t *)(in+(0*45+9)*8/sizeof(in[0])); out[0*64+12] = (start + ((w8 >> 28) | (w9 << 36) & 0x1fffffffffff)); out[0*64+13] = (start + ((w9 >> 9) & 0x1fffffffffff)); w10 = *(uint64_t *)(in+(0*45+10)*8/sizeof(in[0])); out[0*64+14] = (start + ((w9 >> 54) | (w10 << 10) & 0x1fffffffffff)); w11 = *(uint64_t *)(in+(0*45+11)*8/sizeof(in[0])); out[0*64+15] = (start + ((w10 >> 35) | (w11 << 29) & 0x1fffffffffff)); out[0*64+16] = (start + ((w11 >> 16) & 0x1fffffffffff)); w12 = *(uint64_t *)(in+(0*45+12)*8/sizeof(in[0])); out[0*64+17] = (start + ((w11 >> 61) | (w12 << 3) & 0x1fffffffffff)); w13 = *(uint64_t *)(in+(0*45+13)*8/sizeof(in[0])); out[0*64+18] = (start + ((w12 >> 42) | (w13 << 22) & 0x1fffffffffff)); w14 = *(uint64_t *)(in+(0*45+14)*8/sizeof(in[0])); out[0*64+19] = (start + ((w13 >> 23) | (w14 << 41) & 0x1fffffffffff)); out[0*64+20] = (start + ((w14 >> 4) & 0x1fffffffffff)); w15 = *(uint64_t *)(in+(0*45+15)*8/sizeof(in[0])); out[0*64+21] = (start + ((w14 >> 49) | (w15 << 15) & 0x1fffffffffff)); w16 = *(uint64_t *)(in+(0*45+16)*8/sizeof(in[0])); out[0*64+22] = (start + ((w15 >> 30) | (w16 << 34) & 0x1fffffffffff)); out[0*64+23] = (start + ((w16 >> 11) & 0x1fffffffffff)); w17 = *(uint64_t *)(in+(0*45+17)*8/sizeof(in[0])); out[0*64+24] = (start + ((w16 >> 56) | (w17 << 8) & 0x1fffffffffff)); w18 = *(uint64_t *)(in+(0*45+18)*8/sizeof(in[0])); out[0*64+25] = (start + ((w17 >> 37) | (w18 << 27) & 0x1fffffffffff)); out[0*64+26] = (start + ((w18 >> 18) & 0x1fffffffffff)); w19 = *(uint64_t *)(in+(0*45+19)*8/sizeof(in[0])); out[0*64+27] = (start + ((w18 >> 63) | (w19 << 1) & 0x1fffffffffff)); w20 = *(uint64_t *)(in+(0*45+20)*8/sizeof(in[0])); out[0*64+28] = (start + ((w19 >> 44) | (w20 << 20) & 0x1fffffffffff)); w21 = *(uint64_t *)(in+(0*45+21)*8/sizeof(in[0])); out[0*64+29] = (start + ((w20 >> 25) | (w21 << 39) & 0x1fffffffffff)); out[0*64+30] = (start + ((w21 >> 6) & 0x1fffffffffff)); w22 = *(uint32_t *)(in+(0*45+22)*8/sizeof(in[0])); out[0*64+31] = (start + ((w21 >> 51) | (w22 << 13) & 0x1fffffffffff));;}; out += 32; in += 45*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_46(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*46)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3fffffffffff)); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*32+ 1] = (start + ((w0 >> 46) | (w1 << 18) & 0x3fffffffffff)); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*32+ 2] = (start + ((w1 >> 28) | (w2 << 36) & 0x3fffffffffff)); out[0*32+ 3] = (start + ((w2 >> 10) & 0x3fffffffffff)); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*32+ 4] = (start + ((w2 >> 56) | (w3 << 8) & 0x3fffffffffff)); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*32+ 5] = (start + ((w3 >> 38) | (w4 << 26) & 0x3fffffffffff)); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*32+ 6] = (start + ((w4 >> 20) | (w5 << 44) & 0x3fffffffffff)); out[0*32+ 7] = (start + ((w5 >> 2) & 0x3fffffffffff)); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*32+ 8] = (start + ((w5 >> 48) | (w6 << 16) & 0x3fffffffffff)); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*32+ 9] = (start + ((w6 >> 30) | (w7 << 34) & 0x3fffffffffff)); out[0*32+10] = (start + ((w7 >> 12) & 0x3fffffffffff)); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*32+11] = (start + ((w7 >> 58) | (w8 << 6) & 0x3fffffffffff)); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*32+12] = (start + ((w8 >> 40) | (w9 << 24) & 0x3fffffffffff)); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*32+13] = (start + ((w9 >> 22) | (w10 << 42) & 0x3fffffffffff)); out[0*32+14] = (start + ((w10 >> 4) & 0x3fffffffffff)); w11 = *(uint64_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*32+15] = (start + ((w10 >> 50) | (w11 << 14) & 0x3fffffffffff)); w12 = *(uint64_t *)(in+(0*23+12)*8/sizeof(in[0])); out[0*32+16] = (start + ((w11 >> 32) | (w12 << 32) & 0x3fffffffffff)); out[0*32+17] = (start + ((w12 >> 14) & 0x3fffffffffff)); w13 = *(uint64_t *)(in+(0*23+13)*8/sizeof(in[0])); out[0*32+18] = (start + ((w12 >> 60) | (w13 << 4) & 0x3fffffffffff)); w14 = *(uint64_t *)(in+(0*23+14)*8/sizeof(in[0])); out[0*32+19] = (start + ((w13 >> 42) | (w14 << 22) & 0x3fffffffffff)); w15 = *(uint64_t *)(in+(0*23+15)*8/sizeof(in[0])); out[0*32+20] = (start + ((w14 >> 24) | (w15 << 40) & 0x3fffffffffff)); out[0*32+21] = (start + ((w15 >> 6) & 0x3fffffffffff)); w16 = *(uint64_t *)(in+(0*23+16)*8/sizeof(in[0])); out[0*32+22] = (start + ((w15 >> 52) | (w16 << 12) & 0x3fffffffffff)); w17 = *(uint64_t *)(in+(0*23+17)*8/sizeof(in[0])); out[0*32+23] = (start + ((w16 >> 34) | (w17 << 30) & 0x3fffffffffff)); out[0*32+24] = (start + ((w17 >> 16) & 0x3fffffffffff)); w18 = *(uint64_t *)(in+(0*23+18)*8/sizeof(in[0])); out[0*32+25] = (start + ((w17 >> 62) | (w18 << 2) & 0x3fffffffffff)); w19 = *(uint64_t *)(in+(0*23+19)*8/sizeof(in[0])); out[0*32+26] = (start + ((w18 >> 44) | (w19 << 20) & 0x3fffffffffff)); w20 = *(uint64_t *)(in+(0*23+20)*8/sizeof(in[0])); out[0*32+27] = (start + ((w19 >> 26) | (w20 << 38) & 0x3fffffffffff)); out[0*32+28] = (start + ((w20 >> 8) & 0x3fffffffffff)); w21 = *(uint64_t *)(in+(0*23+21)*8/sizeof(in[0])); out[0*32+29] = (start + ((w20 >> 54) | (w21 << 10) & 0x3fffffffffff)); w22 = *(uint64_t *)(in+(0*23+22)*8/sizeof(in[0])); out[0*32+30] = (start + ((w21 >> 36) | (w22 << 28) & 0x3fffffffffff)); out[0*32+31] = (start + ((w22 >> 18)));;}; out += 32; in += 46*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_47(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*47)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(0*47+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7fffffffffff)); w1 = *(uint64_t *)(in+(0*47+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 47) | (w1 << 17) & 0x7fffffffffff)); w2 = *(uint64_t *)(in+(0*47+2)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w1 >> 30) | (w2 << 34) & 0x7fffffffffff)); out[0*64+ 3] = (start + ((w2 >> 13) & 0x7fffffffffff)); w3 = *(uint64_t *)(in+(0*47+3)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w2 >> 60) | (w3 << 4) & 0x7fffffffffff)); w4 = *(uint64_t *)(in+(0*47+4)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w3 >> 43) | (w4 << 21) & 0x7fffffffffff)); w5 = *(uint64_t *)(in+(0*47+5)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w4 >> 26) | (w5 << 38) & 0x7fffffffffff)); out[0*64+ 7] = (start + ((w5 >> 9) & 0x7fffffffffff)); w6 = *(uint64_t *)(in+(0*47+6)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w5 >> 56) | (w6 << 8) & 0x7fffffffffff)); w7 = *(uint64_t *)(in+(0*47+7)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w6 >> 39) | (w7 << 25) & 0x7fffffffffff)); w8 = *(uint64_t *)(in+(0*47+8)*8/sizeof(in[0])); out[0*64+10] = (start + ((w7 >> 22) | (w8 << 42) & 0x7fffffffffff)); out[0*64+11] = (start + ((w8 >> 5) & 0x7fffffffffff)); w9 = *(uint64_t *)(in+(0*47+9)*8/sizeof(in[0])); out[0*64+12] = (start + ((w8 >> 52) | (w9 << 12) & 0x7fffffffffff)); w10 = *(uint64_t *)(in+(0*47+10)*8/sizeof(in[0])); out[0*64+13] = (start + ((w9 >> 35) | (w10 << 29) & 0x7fffffffffff)); w11 = *(uint64_t *)(in+(0*47+11)*8/sizeof(in[0])); out[0*64+14] = (start + ((w10 >> 18) | (w11 << 46) & 0x7fffffffffff)); out[0*64+15] = (start + ((w11 >> 1) & 0x7fffffffffff)); w12 = *(uint64_t *)(in+(0*47+12)*8/sizeof(in[0])); out[0*64+16] = (start + ((w11 >> 48) | (w12 << 16) & 0x7fffffffffff)); w13 = *(uint64_t *)(in+(0*47+13)*8/sizeof(in[0])); out[0*64+17] = (start + ((w12 >> 31) | (w13 << 33) & 0x7fffffffffff)); out[0*64+18] = (start + ((w13 >> 14) & 0x7fffffffffff)); w14 = *(uint64_t *)(in+(0*47+14)*8/sizeof(in[0])); out[0*64+19] = (start + ((w13 >> 61) | (w14 << 3) & 0x7fffffffffff)); w15 = *(uint64_t *)(in+(0*47+15)*8/sizeof(in[0])); out[0*64+20] = (start + ((w14 >> 44) | (w15 << 20) & 0x7fffffffffff)); w16 = *(uint64_t *)(in+(0*47+16)*8/sizeof(in[0])); out[0*64+21] = (start + ((w15 >> 27) | (w16 << 37) & 0x7fffffffffff)); out[0*64+22] = (start + ((w16 >> 10) & 0x7fffffffffff)); w17 = *(uint64_t *)(in+(0*47+17)*8/sizeof(in[0])); out[0*64+23] = (start + ((w16 >> 57) | (w17 << 7) & 0x7fffffffffff)); w18 = *(uint64_t *)(in+(0*47+18)*8/sizeof(in[0])); out[0*64+24] = (start + ((w17 >> 40) | (w18 << 24) & 0x7fffffffffff)); w19 = *(uint64_t *)(in+(0*47+19)*8/sizeof(in[0])); out[0*64+25] = (start + ((w18 >> 23) | (w19 << 41) & 0x7fffffffffff)); out[0*64+26] = (start + ((w19 >> 6) & 0x7fffffffffff)); w20 = *(uint64_t *)(in+(0*47+20)*8/sizeof(in[0])); out[0*64+27] = (start + ((w19 >> 53) | (w20 << 11) & 0x7fffffffffff)); w21 = *(uint64_t *)(in+(0*47+21)*8/sizeof(in[0])); out[0*64+28] = (start + ((w20 >> 36) | (w21 << 28) & 0x7fffffffffff)); w22 = *(uint64_t *)(in+(0*47+22)*8/sizeof(in[0])); out[0*64+29] = (start + ((w21 >> 19) | (w22 << 45) & 0x7fffffffffff)); out[0*64+30] = (start + ((w22 >> 2) & 0x7fffffffffff)); w23 = *(uint32_t *)(in+(0*47+23)*8/sizeof(in[0])); out[0*64+31] = (start + ((w22 >> 49) | (w23 << 15) & 0x7fffffffffff));;}; out += 32; in += 47*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_48(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*48)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*4+ 0] = (start + ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*4+ 1] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*4+ 2] = (start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[0*4+ 3] = (start + ((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*4+ 0] = (start + ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*4+ 1] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*4+ 2] = (start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[1*4+ 3] = (start + ((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*4+ 0] = (start + ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*4+ 1] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*4+ 2] = (start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[2*4+ 3] = (start + ((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*4+ 0] = (start + ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*4+ 1] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*4+ 2] = (start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[3*4+ 3] = (start + ((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(4*3+0)*8/sizeof(in[0])); out[4*4+ 0] = (start + ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(4*3+1)*8/sizeof(in[0])); out[4*4+ 1] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(4*3+2)*8/sizeof(in[0])); out[4*4+ 2] = (start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[4*4+ 3] = (start + ((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(5*3+0)*8/sizeof(in[0])); out[5*4+ 0] = (start + ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(5*3+1)*8/sizeof(in[0])); out[5*4+ 1] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(5*3+2)*8/sizeof(in[0])); out[5*4+ 2] = (start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[5*4+ 3] = (start + ((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(6*3+0)*8/sizeof(in[0])); out[6*4+ 0] = (start + ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(6*3+1)*8/sizeof(in[0])); out[6*4+ 1] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(6*3+2)*8/sizeof(in[0])); out[6*4+ 2] = (start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[6*4+ 3] = (start + ((w2 >> 16)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(7*3+0)*8/sizeof(in[0])); out[7*4+ 0] = (start + ((w0 ) & 0xffffffffffff)); w1 = *(uint64_t *)(in+(7*3+1)*8/sizeof(in[0])); out[7*4+ 1] = (start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)); w2 = *(uint64_t *)(in+(7*3+2)*8/sizeof(in[0])); out[7*4+ 2] = (start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)); out[7*4+ 3] = (start + ((w2 >> 16)));;}; out += 32; in += 48*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_49(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*49)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24; w0 = *(uint64_t *)(in+(0*49+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1ffffffffffff)); w1 = *(uint64_t *)(in+(0*49+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 49) | (w1 << 15) & 0x1ffffffffffff)); w2 = *(uint64_t *)(in+(0*49+2)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w1 >> 34) | (w2 << 30) & 0x1ffffffffffff)); w3 = *(uint64_t *)(in+(0*49+3)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w2 >> 19) | (w3 << 45) & 0x1ffffffffffff)); out[0*64+ 4] = (start + ((w3 >> 4) & 0x1ffffffffffff)); w4 = *(uint64_t *)(in+(0*49+4)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w3 >> 53) | (w4 << 11) & 0x1ffffffffffff)); w5 = *(uint64_t *)(in+(0*49+5)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w4 >> 38) | (w5 << 26) & 0x1ffffffffffff)); w6 = *(uint64_t *)(in+(0*49+6)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w5 >> 23) | (w6 << 41) & 0x1ffffffffffff)); out[0*64+ 8] = (start + ((w6 >> 8) & 0x1ffffffffffff)); w7 = *(uint64_t *)(in+(0*49+7)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w6 >> 57) | (w7 << 7) & 0x1ffffffffffff)); w8 = *(uint64_t *)(in+(0*49+8)*8/sizeof(in[0])); out[0*64+10] = (start + ((w7 >> 42) | (w8 << 22) & 0x1ffffffffffff)); w9 = *(uint64_t *)(in+(0*49+9)*8/sizeof(in[0])); out[0*64+11] = (start + ((w8 >> 27) | (w9 << 37) & 0x1ffffffffffff)); out[0*64+12] = (start + ((w9 >> 12) & 0x1ffffffffffff)); w10 = *(uint64_t *)(in+(0*49+10)*8/sizeof(in[0])); out[0*64+13] = (start + ((w9 >> 61) | (w10 << 3) & 0x1ffffffffffff)); w11 = *(uint64_t *)(in+(0*49+11)*8/sizeof(in[0])); out[0*64+14] = (start + ((w10 >> 46) | (w11 << 18) & 0x1ffffffffffff)); w12 = *(uint64_t *)(in+(0*49+12)*8/sizeof(in[0])); out[0*64+15] = (start + ((w11 >> 31) | (w12 << 33) & 0x1ffffffffffff)); w13 = *(uint64_t *)(in+(0*49+13)*8/sizeof(in[0])); out[0*64+16] = (start + ((w12 >> 16) | (w13 << 48) & 0x1ffffffffffff)); out[0*64+17] = (start + ((w13 >> 1) & 0x1ffffffffffff)); w14 = *(uint64_t *)(in+(0*49+14)*8/sizeof(in[0])); out[0*64+18] = (start + ((w13 >> 50) | (w14 << 14) & 0x1ffffffffffff)); w15 = *(uint64_t *)(in+(0*49+15)*8/sizeof(in[0])); out[0*64+19] = (start + ((w14 >> 35) | (w15 << 29) & 0x1ffffffffffff)); w16 = *(uint64_t *)(in+(0*49+16)*8/sizeof(in[0])); out[0*64+20] = (start + ((w15 >> 20) | (w16 << 44) & 0x1ffffffffffff)); out[0*64+21] = (start + ((w16 >> 5) & 0x1ffffffffffff)); w17 = *(uint64_t *)(in+(0*49+17)*8/sizeof(in[0])); out[0*64+22] = (start + ((w16 >> 54) | (w17 << 10) & 0x1ffffffffffff)); w18 = *(uint64_t *)(in+(0*49+18)*8/sizeof(in[0])); out[0*64+23] = (start + ((w17 >> 39) | (w18 << 25) & 0x1ffffffffffff)); w19 = *(uint64_t *)(in+(0*49+19)*8/sizeof(in[0])); out[0*64+24] = (start + ((w18 >> 24) | (w19 << 40) & 0x1ffffffffffff)); out[0*64+25] = (start + ((w19 >> 9) & 0x1ffffffffffff)); w20 = *(uint64_t *)(in+(0*49+20)*8/sizeof(in[0])); out[0*64+26] = (start + ((w19 >> 58) | (w20 << 6) & 0x1ffffffffffff)); w21 = *(uint64_t *)(in+(0*49+21)*8/sizeof(in[0])); out[0*64+27] = (start + ((w20 >> 43) | (w21 << 21) & 0x1ffffffffffff)); w22 = *(uint64_t *)(in+(0*49+22)*8/sizeof(in[0])); out[0*64+28] = (start + ((w21 >> 28) | (w22 << 36) & 0x1ffffffffffff)); out[0*64+29] = (start + ((w22 >> 13) & 0x1ffffffffffff)); w23 = *(uint64_t *)(in+(0*49+23)*8/sizeof(in[0])); out[0*64+30] = (start + ((w22 >> 62) | (w23 << 2) & 0x1ffffffffffff)); w24 = *(uint32_t *)(in+(0*49+24)*8/sizeof(in[0])); out[0*64+31] = (start + ((w23 >> 47) | (w24 << 17) & 0x1ffffffffffff));;}; out += 32; in += 49*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_50(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*50)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3ffffffffffff)); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*32+ 1] = (start + ((w0 >> 50) | (w1 << 14) & 0x3ffffffffffff)); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*32+ 2] = (start + ((w1 >> 36) | (w2 << 28) & 0x3ffffffffffff)); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*32+ 3] = (start + ((w2 >> 22) | (w3 << 42) & 0x3ffffffffffff)); out[0*32+ 4] = (start + ((w3 >> 8) & 0x3ffffffffffff)); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*32+ 5] = (start + ((w3 >> 58) | (w4 << 6) & 0x3ffffffffffff)); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*32+ 6] = (start + ((w4 >> 44) | (w5 << 20) & 0x3ffffffffffff)); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*32+ 7] = (start + ((w5 >> 30) | (w6 << 34) & 0x3ffffffffffff)); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*32+ 8] = (start + ((w6 >> 16) | (w7 << 48) & 0x3ffffffffffff)); out[0*32+ 9] = (start + ((w7 >> 2) & 0x3ffffffffffff)); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*32+10] = (start + ((w7 >> 52) | (w8 << 12) & 0x3ffffffffffff)); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*32+11] = (start + ((w8 >> 38) | (w9 << 26) & 0x3ffffffffffff)); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*32+12] = (start + ((w9 >> 24) | (w10 << 40) & 0x3ffffffffffff)); out[0*32+13] = (start + ((w10 >> 10) & 0x3ffffffffffff)); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*32+14] = (start + ((w10 >> 60) | (w11 << 4) & 0x3ffffffffffff)); w12 = *(uint64_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*32+15] = (start + ((w11 >> 46) | (w12 << 18) & 0x3ffffffffffff)); w13 = *(uint64_t *)(in+(0*25+13)*8/sizeof(in[0])); out[0*32+16] = (start + ((w12 >> 32) | (w13 << 32) & 0x3ffffffffffff)); w14 = *(uint64_t *)(in+(0*25+14)*8/sizeof(in[0])); out[0*32+17] = (start + ((w13 >> 18) | (w14 << 46) & 0x3ffffffffffff)); out[0*32+18] = (start + ((w14 >> 4) & 0x3ffffffffffff)); w15 = *(uint64_t *)(in+(0*25+15)*8/sizeof(in[0])); out[0*32+19] = (start + ((w14 >> 54) | (w15 << 10) & 0x3ffffffffffff)); w16 = *(uint64_t *)(in+(0*25+16)*8/sizeof(in[0])); out[0*32+20] = (start + ((w15 >> 40) | (w16 << 24) & 0x3ffffffffffff)); w17 = *(uint64_t *)(in+(0*25+17)*8/sizeof(in[0])); out[0*32+21] = (start + ((w16 >> 26) | (w17 << 38) & 0x3ffffffffffff)); out[0*32+22] = (start + ((w17 >> 12) & 0x3ffffffffffff)); w18 = *(uint64_t *)(in+(0*25+18)*8/sizeof(in[0])); out[0*32+23] = (start + ((w17 >> 62) | (w18 << 2) & 0x3ffffffffffff)); w19 = *(uint64_t *)(in+(0*25+19)*8/sizeof(in[0])); out[0*32+24] = (start + ((w18 >> 48) | (w19 << 16) & 0x3ffffffffffff)); w20 = *(uint64_t *)(in+(0*25+20)*8/sizeof(in[0])); out[0*32+25] = (start + ((w19 >> 34) | (w20 << 30) & 0x3ffffffffffff)); w21 = *(uint64_t *)(in+(0*25+21)*8/sizeof(in[0])); out[0*32+26] = (start + ((w20 >> 20) | (w21 << 44) & 0x3ffffffffffff)); out[0*32+27] = (start + ((w21 >> 6) & 0x3ffffffffffff)); w22 = *(uint64_t *)(in+(0*25+22)*8/sizeof(in[0])); out[0*32+28] = (start + ((w21 >> 56) | (w22 << 8) & 0x3ffffffffffff)); w23 = *(uint64_t *)(in+(0*25+23)*8/sizeof(in[0])); out[0*32+29] = (start + ((w22 >> 42) | (w23 << 22) & 0x3ffffffffffff)); w24 = *(uint64_t *)(in+(0*25+24)*8/sizeof(in[0])); out[0*32+30] = (start + ((w23 >> 28) | (w24 << 36) & 0x3ffffffffffff)); out[0*32+31] = (start + ((w24 >> 14)));;}; out += 32; in += 50*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_51(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*51)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(0*51+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7ffffffffffff)); w1 = *(uint64_t *)(in+(0*51+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 51) | (w1 << 13) & 0x7ffffffffffff)); w2 = *(uint64_t *)(in+(0*51+2)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w1 >> 38) | (w2 << 26) & 0x7ffffffffffff)); w3 = *(uint64_t *)(in+(0*51+3)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w2 >> 25) | (w3 << 39) & 0x7ffffffffffff)); out[0*64+ 4] = (start + ((w3 >> 12) & 0x7ffffffffffff)); w4 = *(uint64_t *)(in+(0*51+4)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w3 >> 63) | (w4 << 1) & 0x7ffffffffffff)); w5 = *(uint64_t *)(in+(0*51+5)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w4 >> 50) | (w5 << 14) & 0x7ffffffffffff)); w6 = *(uint64_t *)(in+(0*51+6)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w5 >> 37) | (w6 << 27) & 0x7ffffffffffff)); w7 = *(uint64_t *)(in+(0*51+7)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w6 >> 24) | (w7 << 40) & 0x7ffffffffffff)); out[0*64+ 9] = (start + ((w7 >> 11) & 0x7ffffffffffff)); w8 = *(uint64_t *)(in+(0*51+8)*8/sizeof(in[0])); out[0*64+10] = (start + ((w7 >> 62) | (w8 << 2) & 0x7ffffffffffff)); w9 = *(uint64_t *)(in+(0*51+9)*8/sizeof(in[0])); out[0*64+11] = (start + ((w8 >> 49) | (w9 << 15) & 0x7ffffffffffff)); w10 = *(uint64_t *)(in+(0*51+10)*8/sizeof(in[0])); out[0*64+12] = (start + ((w9 >> 36) | (w10 << 28) & 0x7ffffffffffff)); w11 = *(uint64_t *)(in+(0*51+11)*8/sizeof(in[0])); out[0*64+13] = (start + ((w10 >> 23) | (w11 << 41) & 0x7ffffffffffff)); out[0*64+14] = (start + ((w11 >> 10) & 0x7ffffffffffff)); w12 = *(uint64_t *)(in+(0*51+12)*8/sizeof(in[0])); out[0*64+15] = (start + ((w11 >> 61) | (w12 << 3) & 0x7ffffffffffff)); w13 = *(uint64_t *)(in+(0*51+13)*8/sizeof(in[0])); out[0*64+16] = (start + ((w12 >> 48) | (w13 << 16) & 0x7ffffffffffff)); w14 = *(uint64_t *)(in+(0*51+14)*8/sizeof(in[0])); out[0*64+17] = (start + ((w13 >> 35) | (w14 << 29) & 0x7ffffffffffff)); w15 = *(uint64_t *)(in+(0*51+15)*8/sizeof(in[0])); out[0*64+18] = (start + ((w14 >> 22) | (w15 << 42) & 0x7ffffffffffff)); out[0*64+19] = (start + ((w15 >> 9) & 0x7ffffffffffff)); w16 = *(uint64_t *)(in+(0*51+16)*8/sizeof(in[0])); out[0*64+20] = (start + ((w15 >> 60) | (w16 << 4) & 0x7ffffffffffff)); w17 = *(uint64_t *)(in+(0*51+17)*8/sizeof(in[0])); out[0*64+21] = (start + ((w16 >> 47) | (w17 << 17) & 0x7ffffffffffff)); w18 = *(uint64_t *)(in+(0*51+18)*8/sizeof(in[0])); out[0*64+22] = (start + ((w17 >> 34) | (w18 << 30) & 0x7ffffffffffff)); w19 = *(uint64_t *)(in+(0*51+19)*8/sizeof(in[0])); out[0*64+23] = (start + ((w18 >> 21) | (w19 << 43) & 0x7ffffffffffff)); out[0*64+24] = (start + ((w19 >> 8) & 0x7ffffffffffff)); w20 = *(uint64_t *)(in+(0*51+20)*8/sizeof(in[0])); out[0*64+25] = (start + ((w19 >> 59) | (w20 << 5) & 0x7ffffffffffff)); w21 = *(uint64_t *)(in+(0*51+21)*8/sizeof(in[0])); out[0*64+26] = (start + ((w20 >> 46) | (w21 << 18) & 0x7ffffffffffff)); w22 = *(uint64_t *)(in+(0*51+22)*8/sizeof(in[0])); out[0*64+27] = (start + ((w21 >> 33) | (w22 << 31) & 0x7ffffffffffff)); w23 = *(uint64_t *)(in+(0*51+23)*8/sizeof(in[0])); out[0*64+28] = (start + ((w22 >> 20) | (w23 << 44) & 0x7ffffffffffff)); out[0*64+29] = (start + ((w23 >> 7) & 0x7ffffffffffff)); w24 = *(uint64_t *)(in+(0*51+24)*8/sizeof(in[0])); out[0*64+30] = (start + ((w23 >> 58) | (w24 << 6) & 0x7ffffffffffff)); w25 = *(uint32_t *)(in+(0*51+25)*8/sizeof(in[0])); out[0*64+31] = (start + ((w24 >> 45) | (w25 << 19) & 0x7ffffffffffff));;}; out += 32; in += 51*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_52(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*52)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xfffffffffffff)); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*16+ 1] = (start + ((w0 >> 52) | (w1 << 12) & 0xfffffffffffff)); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*16+ 2] = (start + ((w1 >> 40) | (w2 << 24) & 0xfffffffffffff)); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*16+ 3] = (start + ((w2 >> 28) | (w3 << 36) & 0xfffffffffffff)); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*16+ 4] = (start + ((w3 >> 16) | (w4 << 48) & 0xfffffffffffff)); out[0*16+ 5] = (start + ((w4 >> 4) & 0xfffffffffffff)); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*16+ 6] = (start + ((w4 >> 56) | (w5 << 8) & 0xfffffffffffff)); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*16+ 7] = (start + ((w5 >> 44) | (w6 << 20) & 0xfffffffffffff)); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*16+ 8] = (start + ((w6 >> 32) | (w7 << 32) & 0xfffffffffffff)); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*16+ 9] = (start + ((w7 >> 20) | (w8 << 44) & 0xfffffffffffff)); out[0*16+10] = (start + ((w8 >> 8) & 0xfffffffffffff)); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*16+11] = (start + ((w8 >> 60) | (w9 << 4) & 0xfffffffffffff)); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*16+12] = (start + ((w9 >> 48) | (w10 << 16) & 0xfffffffffffff)); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*16+13] = (start + ((w10 >> 36) | (w11 << 28) & 0xfffffffffffff)); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*16+14] = (start + ((w11 >> 24) | (w12 << 40) & 0xfffffffffffff)); out[0*16+15] = (start + ((w12 >> 12)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(1*13+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xfffffffffffff)); w1 = *(uint64_t *)(in+(1*13+1)*8/sizeof(in[0])); out[1*16+ 1] = (start + ((w0 >> 52) | (w1 << 12) & 0xfffffffffffff)); w2 = *(uint64_t *)(in+(1*13+2)*8/sizeof(in[0])); out[1*16+ 2] = (start + ((w1 >> 40) | (w2 << 24) & 0xfffffffffffff)); w3 = *(uint64_t *)(in+(1*13+3)*8/sizeof(in[0])); out[1*16+ 3] = (start + ((w2 >> 28) | (w3 << 36) & 0xfffffffffffff)); w4 = *(uint64_t *)(in+(1*13+4)*8/sizeof(in[0])); out[1*16+ 4] = (start + ((w3 >> 16) | (w4 << 48) & 0xfffffffffffff)); out[1*16+ 5] = (start + ((w4 >> 4) & 0xfffffffffffff)); w5 = *(uint64_t *)(in+(1*13+5)*8/sizeof(in[0])); out[1*16+ 6] = (start + ((w4 >> 56) | (w5 << 8) & 0xfffffffffffff)); w6 = *(uint64_t *)(in+(1*13+6)*8/sizeof(in[0])); out[1*16+ 7] = (start + ((w5 >> 44) | (w6 << 20) & 0xfffffffffffff)); w7 = *(uint64_t *)(in+(1*13+7)*8/sizeof(in[0])); out[1*16+ 8] = (start + ((w6 >> 32) | (w7 << 32) & 0xfffffffffffff)); w8 = *(uint64_t *)(in+(1*13+8)*8/sizeof(in[0])); out[1*16+ 9] = (start + ((w7 >> 20) | (w8 << 44) & 0xfffffffffffff)); out[1*16+10] = (start + ((w8 >> 8) & 0xfffffffffffff)); w9 = *(uint64_t *)(in+(1*13+9)*8/sizeof(in[0])); out[1*16+11] = (start + ((w8 >> 60) | (w9 << 4) & 0xfffffffffffff)); w10 = *(uint64_t *)(in+(1*13+10)*8/sizeof(in[0])); out[1*16+12] = (start + ((w9 >> 48) | (w10 << 16) & 0xfffffffffffff)); w11 = *(uint64_t *)(in+(1*13+11)*8/sizeof(in[0])); out[1*16+13] = (start + ((w10 >> 36) | (w11 << 28) & 0xfffffffffffff)); w12 = *(uint64_t *)(in+(1*13+12)*8/sizeof(in[0])); out[1*16+14] = (start + ((w11 >> 24) | (w12 << 40) & 0xfffffffffffff)); out[1*16+15] = (start + ((w12 >> 12)));;}; out += 32; in += 52*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_53(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*53)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26; w0 = *(uint64_t *)(in+(0*53+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1fffffffffffff)); w1 = *(uint64_t *)(in+(0*53+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 53) | (w1 << 11) & 0x1fffffffffffff)); w2 = *(uint64_t *)(in+(0*53+2)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w1 >> 42) | (w2 << 22) & 0x1fffffffffffff)); w3 = *(uint64_t *)(in+(0*53+3)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w2 >> 31) | (w3 << 33) & 0x1fffffffffffff)); w4 = *(uint64_t *)(in+(0*53+4)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w3 >> 20) | (w4 << 44) & 0x1fffffffffffff)); out[0*64+ 5] = (start + ((w4 >> 9) & 0x1fffffffffffff)); w5 = *(uint64_t *)(in+(0*53+5)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w4 >> 62) | (w5 << 2) & 0x1fffffffffffff)); w6 = *(uint64_t *)(in+(0*53+6)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w5 >> 51) | (w6 << 13) & 0x1fffffffffffff)); w7 = *(uint64_t *)(in+(0*53+7)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w6 >> 40) | (w7 << 24) & 0x1fffffffffffff)); w8 = *(uint64_t *)(in+(0*53+8)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w7 >> 29) | (w8 << 35) & 0x1fffffffffffff)); w9 = *(uint64_t *)(in+(0*53+9)*8/sizeof(in[0])); out[0*64+10] = (start + ((w8 >> 18) | (w9 << 46) & 0x1fffffffffffff)); out[0*64+11] = (start + ((w9 >> 7) & 0x1fffffffffffff)); w10 = *(uint64_t *)(in+(0*53+10)*8/sizeof(in[0])); out[0*64+12] = (start + ((w9 >> 60) | (w10 << 4) & 0x1fffffffffffff)); w11 = *(uint64_t *)(in+(0*53+11)*8/sizeof(in[0])); out[0*64+13] = (start + ((w10 >> 49) | (w11 << 15) & 0x1fffffffffffff)); w12 = *(uint64_t *)(in+(0*53+12)*8/sizeof(in[0])); out[0*64+14] = (start + ((w11 >> 38) | (w12 << 26) & 0x1fffffffffffff)); w13 = *(uint64_t *)(in+(0*53+13)*8/sizeof(in[0])); out[0*64+15] = (start + ((w12 >> 27) | (w13 << 37) & 0x1fffffffffffff)); w14 = *(uint64_t *)(in+(0*53+14)*8/sizeof(in[0])); out[0*64+16] = (start + ((w13 >> 16) | (w14 << 48) & 0x1fffffffffffff)); out[0*64+17] = (start + ((w14 >> 5) & 0x1fffffffffffff)); w15 = *(uint64_t *)(in+(0*53+15)*8/sizeof(in[0])); out[0*64+18] = (start + ((w14 >> 58) | (w15 << 6) & 0x1fffffffffffff)); w16 = *(uint64_t *)(in+(0*53+16)*8/sizeof(in[0])); out[0*64+19] = (start + ((w15 >> 47) | (w16 << 17) & 0x1fffffffffffff)); w17 = *(uint64_t *)(in+(0*53+17)*8/sizeof(in[0])); out[0*64+20] = (start + ((w16 >> 36) | (w17 << 28) & 0x1fffffffffffff)); w18 = *(uint64_t *)(in+(0*53+18)*8/sizeof(in[0])); out[0*64+21] = (start + ((w17 >> 25) | (w18 << 39) & 0x1fffffffffffff)); w19 = *(uint64_t *)(in+(0*53+19)*8/sizeof(in[0])); out[0*64+22] = (start + ((w18 >> 14) | (w19 << 50) & 0x1fffffffffffff)); out[0*64+23] = (start + ((w19 >> 3) & 0x1fffffffffffff)); w20 = *(uint64_t *)(in+(0*53+20)*8/sizeof(in[0])); out[0*64+24] = (start + ((w19 >> 56) | (w20 << 8) & 0x1fffffffffffff)); w21 = *(uint64_t *)(in+(0*53+21)*8/sizeof(in[0])); out[0*64+25] = (start + ((w20 >> 45) | (w21 << 19) & 0x1fffffffffffff)); w22 = *(uint64_t *)(in+(0*53+22)*8/sizeof(in[0])); out[0*64+26] = (start + ((w21 >> 34) | (w22 << 30) & 0x1fffffffffffff)); w23 = *(uint64_t *)(in+(0*53+23)*8/sizeof(in[0])); out[0*64+27] = (start + ((w22 >> 23) | (w23 << 41) & 0x1fffffffffffff)); w24 = *(uint64_t *)(in+(0*53+24)*8/sizeof(in[0])); out[0*64+28] = (start + ((w23 >> 12) | (w24 << 52) & 0x1fffffffffffff)); out[0*64+29] = (start + ((w24 >> 1) & 0x1fffffffffffff)); w25 = *(uint64_t *)(in+(0*53+25)*8/sizeof(in[0])); out[0*64+30] = (start + ((w24 >> 54) | (w25 << 10) & 0x1fffffffffffff)); w26 = *(uint32_t *)(in+(0*53+26)*8/sizeof(in[0])); out[0*64+31] = (start + ((w25 >> 43) | (w26 << 21) & 0x1fffffffffffff));;}; out += 32; in += 53*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_54(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*54)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3fffffffffffff)); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*32+ 1] = (start + ((w0 >> 54) | (w1 << 10) & 0x3fffffffffffff)); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*32+ 2] = (start + ((w1 >> 44) | (w2 << 20) & 0x3fffffffffffff)); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*32+ 3] = (start + ((w2 >> 34) | (w3 << 30) & 0x3fffffffffffff)); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*32+ 4] = (start + ((w3 >> 24) | (w4 << 40) & 0x3fffffffffffff)); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*32+ 5] = (start + ((w4 >> 14) | (w5 << 50) & 0x3fffffffffffff)); out[0*32+ 6] = (start + ((w5 >> 4) & 0x3fffffffffffff)); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*32+ 7] = (start + ((w5 >> 58) | (w6 << 6) & 0x3fffffffffffff)); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*32+ 8] = (start + ((w6 >> 48) | (w7 << 16) & 0x3fffffffffffff)); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*32+ 9] = (start + ((w7 >> 38) | (w8 << 26) & 0x3fffffffffffff)); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*32+10] = (start + ((w8 >> 28) | (w9 << 36) & 0x3fffffffffffff)); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*32+11] = (start + ((w9 >> 18) | (w10 << 46) & 0x3fffffffffffff)); out[0*32+12] = (start + ((w10 >> 8) & 0x3fffffffffffff)); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*32+13] = (start + ((w10 >> 62) | (w11 << 2) & 0x3fffffffffffff)); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*32+14] = (start + ((w11 >> 52) | (w12 << 12) & 0x3fffffffffffff)); w13 = *(uint64_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*32+15] = (start + ((w12 >> 42) | (w13 << 22) & 0x3fffffffffffff)); w14 = *(uint64_t *)(in+(0*27+14)*8/sizeof(in[0])); out[0*32+16] = (start + ((w13 >> 32) | (w14 << 32) & 0x3fffffffffffff)); w15 = *(uint64_t *)(in+(0*27+15)*8/sizeof(in[0])); out[0*32+17] = (start + ((w14 >> 22) | (w15 << 42) & 0x3fffffffffffff)); w16 = *(uint64_t *)(in+(0*27+16)*8/sizeof(in[0])); out[0*32+18] = (start + ((w15 >> 12) | (w16 << 52) & 0x3fffffffffffff)); out[0*32+19] = (start + ((w16 >> 2) & 0x3fffffffffffff)); w17 = *(uint64_t *)(in+(0*27+17)*8/sizeof(in[0])); out[0*32+20] = (start + ((w16 >> 56) | (w17 << 8) & 0x3fffffffffffff)); w18 = *(uint64_t *)(in+(0*27+18)*8/sizeof(in[0])); out[0*32+21] = (start + ((w17 >> 46) | (w18 << 18) & 0x3fffffffffffff)); w19 = *(uint64_t *)(in+(0*27+19)*8/sizeof(in[0])); out[0*32+22] = (start + ((w18 >> 36) | (w19 << 28) & 0x3fffffffffffff)); w20 = *(uint64_t *)(in+(0*27+20)*8/sizeof(in[0])); out[0*32+23] = (start + ((w19 >> 26) | (w20 << 38) & 0x3fffffffffffff)); w21 = *(uint64_t *)(in+(0*27+21)*8/sizeof(in[0])); out[0*32+24] = (start + ((w20 >> 16) | (w21 << 48) & 0x3fffffffffffff)); out[0*32+25] = (start + ((w21 >> 6) & 0x3fffffffffffff)); w22 = *(uint64_t *)(in+(0*27+22)*8/sizeof(in[0])); out[0*32+26] = (start + ((w21 >> 60) | (w22 << 4) & 0x3fffffffffffff)); w23 = *(uint64_t *)(in+(0*27+23)*8/sizeof(in[0])); out[0*32+27] = (start + ((w22 >> 50) | (w23 << 14) & 0x3fffffffffffff)); w24 = *(uint64_t *)(in+(0*27+24)*8/sizeof(in[0])); out[0*32+28] = (start + ((w23 >> 40) | (w24 << 24) & 0x3fffffffffffff)); w25 = *(uint64_t *)(in+(0*27+25)*8/sizeof(in[0])); out[0*32+29] = (start + ((w24 >> 30) | (w25 << 34) & 0x3fffffffffffff)); w26 = *(uint64_t *)(in+(0*27+26)*8/sizeof(in[0])); out[0*32+30] = (start + ((w25 >> 20) | (w26 << 44) & 0x3fffffffffffff)); out[0*32+31] = (start + ((w26 >> 10)));;}; out += 32; in += 54*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_55(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*55)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(0*55+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7fffffffffffff)); w1 = *(uint64_t *)(in+(0*55+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 55) | (w1 << 9) & 0x7fffffffffffff)); w2 = *(uint64_t *)(in+(0*55+2)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w1 >> 46) | (w2 << 18) & 0x7fffffffffffff)); w3 = *(uint64_t *)(in+(0*55+3)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w2 >> 37) | (w3 << 27) & 0x7fffffffffffff)); w4 = *(uint64_t *)(in+(0*55+4)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w3 >> 28) | (w4 << 36) & 0x7fffffffffffff)); w5 = *(uint64_t *)(in+(0*55+5)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w4 >> 19) | (w5 << 45) & 0x7fffffffffffff)); w6 = *(uint64_t *)(in+(0*55+6)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w5 >> 10) | (w6 << 54) & 0x7fffffffffffff)); out[0*64+ 7] = (start + ((w6 >> 1) & 0x7fffffffffffff)); w7 = *(uint64_t *)(in+(0*55+7)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w6 >> 56) | (w7 << 8) & 0x7fffffffffffff)); w8 = *(uint64_t *)(in+(0*55+8)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w7 >> 47) | (w8 << 17) & 0x7fffffffffffff)); w9 = *(uint64_t *)(in+(0*55+9)*8/sizeof(in[0])); out[0*64+10] = (start + ((w8 >> 38) | (w9 << 26) & 0x7fffffffffffff)); w10 = *(uint64_t *)(in+(0*55+10)*8/sizeof(in[0])); out[0*64+11] = (start + ((w9 >> 29) | (w10 << 35) & 0x7fffffffffffff)); w11 = *(uint64_t *)(in+(0*55+11)*8/sizeof(in[0])); out[0*64+12] = (start + ((w10 >> 20) | (w11 << 44) & 0x7fffffffffffff)); w12 = *(uint64_t *)(in+(0*55+12)*8/sizeof(in[0])); out[0*64+13] = (start + ((w11 >> 11) | (w12 << 53) & 0x7fffffffffffff)); out[0*64+14] = (start + ((w12 >> 2) & 0x7fffffffffffff)); w13 = *(uint64_t *)(in+(0*55+13)*8/sizeof(in[0])); out[0*64+15] = (start + ((w12 >> 57) | (w13 << 7) & 0x7fffffffffffff)); w14 = *(uint64_t *)(in+(0*55+14)*8/sizeof(in[0])); out[0*64+16] = (start + ((w13 >> 48) | (w14 << 16) & 0x7fffffffffffff)); w15 = *(uint64_t *)(in+(0*55+15)*8/sizeof(in[0])); out[0*64+17] = (start + ((w14 >> 39) | (w15 << 25) & 0x7fffffffffffff)); w16 = *(uint64_t *)(in+(0*55+16)*8/sizeof(in[0])); out[0*64+18] = (start + ((w15 >> 30) | (w16 << 34) & 0x7fffffffffffff)); w17 = *(uint64_t *)(in+(0*55+17)*8/sizeof(in[0])); out[0*64+19] = (start + ((w16 >> 21) | (w17 << 43) & 0x7fffffffffffff)); w18 = *(uint64_t *)(in+(0*55+18)*8/sizeof(in[0])); out[0*64+20] = (start + ((w17 >> 12) | (w18 << 52) & 0x7fffffffffffff)); out[0*64+21] = (start + ((w18 >> 3) & 0x7fffffffffffff)); w19 = *(uint64_t *)(in+(0*55+19)*8/sizeof(in[0])); out[0*64+22] = (start + ((w18 >> 58) | (w19 << 6) & 0x7fffffffffffff)); w20 = *(uint64_t *)(in+(0*55+20)*8/sizeof(in[0])); out[0*64+23] = (start + ((w19 >> 49) | (w20 << 15) & 0x7fffffffffffff)); w21 = *(uint64_t *)(in+(0*55+21)*8/sizeof(in[0])); out[0*64+24] = (start + ((w20 >> 40) | (w21 << 24) & 0x7fffffffffffff)); w22 = *(uint64_t *)(in+(0*55+22)*8/sizeof(in[0])); out[0*64+25] = (start + ((w21 >> 31) | (w22 << 33) & 0x7fffffffffffff)); w23 = *(uint64_t *)(in+(0*55+23)*8/sizeof(in[0])); out[0*64+26] = (start + ((w22 >> 22) | (w23 << 42) & 0x7fffffffffffff)); w24 = *(uint64_t *)(in+(0*55+24)*8/sizeof(in[0])); out[0*64+27] = (start + ((w23 >> 13) | (w24 << 51) & 0x7fffffffffffff)); out[0*64+28] = (start + ((w24 >> 4) & 0x7fffffffffffff)); w25 = *(uint64_t *)(in+(0*55+25)*8/sizeof(in[0])); out[0*64+29] = (start + ((w24 >> 59) | (w25 << 5) & 0x7fffffffffffff)); w26 = *(uint64_t *)(in+(0*55+26)*8/sizeof(in[0])); out[0*64+30] = (start + ((w25 >> 50) | (w26 << 14) & 0x7fffffffffffff)); w27 = *(uint32_t *)(in+(0*55+27)*8/sizeof(in[0])); out[0*64+31] = (start + ((w26 >> 41) | (w27 << 23) & 0x7fffffffffffff));;}; out += 32; in += 55*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_56(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*56)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*8+ 0] = (start + ((w0 ) & 0xffffffffffffff)); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*8+ 1] = (start + ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*8+ 2] = (start + ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*8+ 3] = (start + ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*8+ 4] = (start + ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*8+ 5] = (start + ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*8+ 6] = (start + ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)); out[0*8+ 7] = (start + ((w6 >> 8)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*8+ 0] = (start + ((w0 ) & 0xffffffffffffff)); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*8+ 1] = (start + ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*8+ 2] = (start + ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*8+ 3] = (start + ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*8+ 4] = (start + ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*8+ 5] = (start + ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*8+ 6] = (start + ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)); out[1*8+ 7] = (start + ((w6 >> 8)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(2*7+0)*8/sizeof(in[0])); out[2*8+ 0] = (start + ((w0 ) & 0xffffffffffffff)); w1 = *(uint64_t *)(in+(2*7+1)*8/sizeof(in[0])); out[2*8+ 1] = (start + ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)); w2 = *(uint64_t *)(in+(2*7+2)*8/sizeof(in[0])); out[2*8+ 2] = (start + ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)); w3 = *(uint64_t *)(in+(2*7+3)*8/sizeof(in[0])); out[2*8+ 3] = (start + ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)); w4 = *(uint64_t *)(in+(2*7+4)*8/sizeof(in[0])); out[2*8+ 4] = (start + ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)); w5 = *(uint64_t *)(in+(2*7+5)*8/sizeof(in[0])); out[2*8+ 5] = (start + ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)); w6 = *(uint64_t *)(in+(2*7+6)*8/sizeof(in[0])); out[2*8+ 6] = (start + ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)); out[2*8+ 7] = (start + ((w6 >> 8)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(3*7+0)*8/sizeof(in[0])); out[3*8+ 0] = (start + ((w0 ) & 0xffffffffffffff)); w1 = *(uint64_t *)(in+(3*7+1)*8/sizeof(in[0])); out[3*8+ 1] = (start + ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)); w2 = *(uint64_t *)(in+(3*7+2)*8/sizeof(in[0])); out[3*8+ 2] = (start + ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)); w3 = *(uint64_t *)(in+(3*7+3)*8/sizeof(in[0])); out[3*8+ 3] = (start + ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)); w4 = *(uint64_t *)(in+(3*7+4)*8/sizeof(in[0])); out[3*8+ 4] = (start + ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)); w5 = *(uint64_t *)(in+(3*7+5)*8/sizeof(in[0])); out[3*8+ 5] = (start + ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)); w6 = *(uint64_t *)(in+(3*7+6)*8/sizeof(in[0])); out[3*8+ 6] = (start + ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)); out[3*8+ 7] = (start + ((w6 >> 8)));;}; out += 32; in += 56*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_57(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*57)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28; w0 = *(uint64_t *)(in+(0*57+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1ffffffffffffff)); w1 = *(uint64_t *)(in+(0*57+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 57) | (w1 << 7) & 0x1ffffffffffffff)); w2 = *(uint64_t *)(in+(0*57+2)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w1 >> 50) | (w2 << 14) & 0x1ffffffffffffff)); w3 = *(uint64_t *)(in+(0*57+3)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w2 >> 43) | (w3 << 21) & 0x1ffffffffffffff)); w4 = *(uint64_t *)(in+(0*57+4)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w3 >> 36) | (w4 << 28) & 0x1ffffffffffffff)); w5 = *(uint64_t *)(in+(0*57+5)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w4 >> 29) | (w5 << 35) & 0x1ffffffffffffff)); w6 = *(uint64_t *)(in+(0*57+6)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w5 >> 22) | (w6 << 42) & 0x1ffffffffffffff)); w7 = *(uint64_t *)(in+(0*57+7)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w6 >> 15) | (w7 << 49) & 0x1ffffffffffffff)); w8 = *(uint64_t *)(in+(0*57+8)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w7 >> 8) | (w8 << 56) & 0x1ffffffffffffff)); out[0*64+ 9] = (start + ((w8 >> 1) & 0x1ffffffffffffff)); w9 = *(uint64_t *)(in+(0*57+9)*8/sizeof(in[0])); out[0*64+10] = (start + ((w8 >> 58) | (w9 << 6) & 0x1ffffffffffffff)); w10 = *(uint64_t *)(in+(0*57+10)*8/sizeof(in[0])); out[0*64+11] = (start + ((w9 >> 51) | (w10 << 13) & 0x1ffffffffffffff)); w11 = *(uint64_t *)(in+(0*57+11)*8/sizeof(in[0])); out[0*64+12] = (start + ((w10 >> 44) | (w11 << 20) & 0x1ffffffffffffff)); w12 = *(uint64_t *)(in+(0*57+12)*8/sizeof(in[0])); out[0*64+13] = (start + ((w11 >> 37) | (w12 << 27) & 0x1ffffffffffffff)); w13 = *(uint64_t *)(in+(0*57+13)*8/sizeof(in[0])); out[0*64+14] = (start + ((w12 >> 30) | (w13 << 34) & 0x1ffffffffffffff)); w14 = *(uint64_t *)(in+(0*57+14)*8/sizeof(in[0])); out[0*64+15] = (start + ((w13 >> 23) | (w14 << 41) & 0x1ffffffffffffff)); w15 = *(uint64_t *)(in+(0*57+15)*8/sizeof(in[0])); out[0*64+16] = (start + ((w14 >> 16) | (w15 << 48) & 0x1ffffffffffffff)); w16 = *(uint64_t *)(in+(0*57+16)*8/sizeof(in[0])); out[0*64+17] = (start + ((w15 >> 9) | (w16 << 55) & 0x1ffffffffffffff)); out[0*64+18] = (start + ((w16 >> 2) & 0x1ffffffffffffff)); w17 = *(uint64_t *)(in+(0*57+17)*8/sizeof(in[0])); out[0*64+19] = (start + ((w16 >> 59) | (w17 << 5) & 0x1ffffffffffffff)); w18 = *(uint64_t *)(in+(0*57+18)*8/sizeof(in[0])); out[0*64+20] = (start + ((w17 >> 52) | (w18 << 12) & 0x1ffffffffffffff)); w19 = *(uint64_t *)(in+(0*57+19)*8/sizeof(in[0])); out[0*64+21] = (start + ((w18 >> 45) | (w19 << 19) & 0x1ffffffffffffff)); w20 = *(uint64_t *)(in+(0*57+20)*8/sizeof(in[0])); out[0*64+22] = (start + ((w19 >> 38) | (w20 << 26) & 0x1ffffffffffffff)); w21 = *(uint64_t *)(in+(0*57+21)*8/sizeof(in[0])); out[0*64+23] = (start + ((w20 >> 31) | (w21 << 33) & 0x1ffffffffffffff)); w22 = *(uint64_t *)(in+(0*57+22)*8/sizeof(in[0])); out[0*64+24] = (start + ((w21 >> 24) | (w22 << 40) & 0x1ffffffffffffff)); w23 = *(uint64_t *)(in+(0*57+23)*8/sizeof(in[0])); out[0*64+25] = (start + ((w22 >> 17) | (w23 << 47) & 0x1ffffffffffffff)); w24 = *(uint64_t *)(in+(0*57+24)*8/sizeof(in[0])); out[0*64+26] = (start + ((w23 >> 10) | (w24 << 54) & 0x1ffffffffffffff)); out[0*64+27] = (start + ((w24 >> 3) & 0x1ffffffffffffff)); w25 = *(uint64_t *)(in+(0*57+25)*8/sizeof(in[0])); out[0*64+28] = (start + ((w24 >> 60) | (w25 << 4) & 0x1ffffffffffffff)); w26 = *(uint64_t *)(in+(0*57+26)*8/sizeof(in[0])); out[0*64+29] = (start + ((w25 >> 53) | (w26 << 11) & 0x1ffffffffffffff)); w27 = *(uint64_t *)(in+(0*57+27)*8/sizeof(in[0])); out[0*64+30] = (start + ((w26 >> 46) | (w27 << 18) & 0x1ffffffffffffff)); w28 = *(uint32_t *)(in+(0*57+28)*8/sizeof(in[0])); out[0*64+31] = (start + ((w27 >> 39) | (w28 << 25) & 0x1ffffffffffffff));;}; out += 32; in += 57*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_58(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*58)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3ffffffffffffff)); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*32+ 1] = (start + ((w0 >> 58) | (w1 << 6) & 0x3ffffffffffffff)); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*32+ 2] = (start + ((w1 >> 52) | (w2 << 12) & 0x3ffffffffffffff)); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*32+ 3] = (start + ((w2 >> 46) | (w3 << 18) & 0x3ffffffffffffff)); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*32+ 4] = (start + ((w3 >> 40) | (w4 << 24) & 0x3ffffffffffffff)); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*32+ 5] = (start + ((w4 >> 34) | (w5 << 30) & 0x3ffffffffffffff)); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*32+ 6] = (start + ((w5 >> 28) | (w6 << 36) & 0x3ffffffffffffff)); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*32+ 7] = (start + ((w6 >> 22) | (w7 << 42) & 0x3ffffffffffffff)); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*32+ 8] = (start + ((w7 >> 16) | (w8 << 48) & 0x3ffffffffffffff)); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*32+ 9] = (start + ((w8 >> 10) | (w9 << 54) & 0x3ffffffffffffff)); out[0*32+10] = (start + ((w9 >> 4) & 0x3ffffffffffffff)); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*32+11] = (start + ((w9 >> 62) | (w10 << 2) & 0x3ffffffffffffff)); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*32+12] = (start + ((w10 >> 56) | (w11 << 8) & 0x3ffffffffffffff)); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*32+13] = (start + ((w11 >> 50) | (w12 << 14) & 0x3ffffffffffffff)); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*32+14] = (start + ((w12 >> 44) | (w13 << 20) & 0x3ffffffffffffff)); w14 = *(uint64_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*32+15] = (start + ((w13 >> 38) | (w14 << 26) & 0x3ffffffffffffff)); w15 = *(uint64_t *)(in+(0*29+15)*8/sizeof(in[0])); out[0*32+16] = (start + ((w14 >> 32) | (w15 << 32) & 0x3ffffffffffffff)); w16 = *(uint64_t *)(in+(0*29+16)*8/sizeof(in[0])); out[0*32+17] = (start + ((w15 >> 26) | (w16 << 38) & 0x3ffffffffffffff)); w17 = *(uint64_t *)(in+(0*29+17)*8/sizeof(in[0])); out[0*32+18] = (start + ((w16 >> 20) | (w17 << 44) & 0x3ffffffffffffff)); w18 = *(uint64_t *)(in+(0*29+18)*8/sizeof(in[0])); out[0*32+19] = (start + ((w17 >> 14) | (w18 << 50) & 0x3ffffffffffffff)); w19 = *(uint64_t *)(in+(0*29+19)*8/sizeof(in[0])); out[0*32+20] = (start + ((w18 >> 8) | (w19 << 56) & 0x3ffffffffffffff)); out[0*32+21] = (start + ((w19 >> 2) & 0x3ffffffffffffff)); w20 = *(uint64_t *)(in+(0*29+20)*8/sizeof(in[0])); out[0*32+22] = (start + ((w19 >> 60) | (w20 << 4) & 0x3ffffffffffffff)); w21 = *(uint64_t *)(in+(0*29+21)*8/sizeof(in[0])); out[0*32+23] = (start + ((w20 >> 54) | (w21 << 10) & 0x3ffffffffffffff)); w22 = *(uint64_t *)(in+(0*29+22)*8/sizeof(in[0])); out[0*32+24] = (start + ((w21 >> 48) | (w22 << 16) & 0x3ffffffffffffff)); w23 = *(uint64_t *)(in+(0*29+23)*8/sizeof(in[0])); out[0*32+25] = (start + ((w22 >> 42) | (w23 << 22) & 0x3ffffffffffffff)); w24 = *(uint64_t *)(in+(0*29+24)*8/sizeof(in[0])); out[0*32+26] = (start + ((w23 >> 36) | (w24 << 28) & 0x3ffffffffffffff)); w25 = *(uint64_t *)(in+(0*29+25)*8/sizeof(in[0])); out[0*32+27] = (start + ((w24 >> 30) | (w25 << 34) & 0x3ffffffffffffff)); w26 = *(uint64_t *)(in+(0*29+26)*8/sizeof(in[0])); out[0*32+28] = (start + ((w25 >> 24) | (w26 << 40) & 0x3ffffffffffffff)); w27 = *(uint64_t *)(in+(0*29+27)*8/sizeof(in[0])); out[0*32+29] = (start + ((w26 >> 18) | (w27 << 46) & 0x3ffffffffffffff)); w28 = *(uint64_t *)(in+(0*29+28)*8/sizeof(in[0])); out[0*32+30] = (start + ((w27 >> 12) | (w28 << 52) & 0x3ffffffffffffff)); out[0*32+31] = (start + ((w28 >> 6)));;}; out += 32; in += 58*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_59(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*59)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(0*59+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7ffffffffffffff)); w1 = *(uint64_t *)(in+(0*59+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 59) | (w1 << 5) & 0x7ffffffffffffff)); w2 = *(uint64_t *)(in+(0*59+2)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w1 >> 54) | (w2 << 10) & 0x7ffffffffffffff)); w3 = *(uint64_t *)(in+(0*59+3)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w2 >> 49) | (w3 << 15) & 0x7ffffffffffffff)); w4 = *(uint64_t *)(in+(0*59+4)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w3 >> 44) | (w4 << 20) & 0x7ffffffffffffff)); w5 = *(uint64_t *)(in+(0*59+5)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w4 >> 39) | (w5 << 25) & 0x7ffffffffffffff)); w6 = *(uint64_t *)(in+(0*59+6)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w5 >> 34) | (w6 << 30) & 0x7ffffffffffffff)); w7 = *(uint64_t *)(in+(0*59+7)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w6 >> 29) | (w7 << 35) & 0x7ffffffffffffff)); w8 = *(uint64_t *)(in+(0*59+8)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w7 >> 24) | (w8 << 40) & 0x7ffffffffffffff)); w9 = *(uint64_t *)(in+(0*59+9)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w8 >> 19) | (w9 << 45) & 0x7ffffffffffffff)); w10 = *(uint64_t *)(in+(0*59+10)*8/sizeof(in[0])); out[0*64+10] = (start + ((w9 >> 14) | (w10 << 50) & 0x7ffffffffffffff)); w11 = *(uint64_t *)(in+(0*59+11)*8/sizeof(in[0])); out[0*64+11] = (start + ((w10 >> 9) | (w11 << 55) & 0x7ffffffffffffff)); out[0*64+12] = (start + ((w11 >> 4) & 0x7ffffffffffffff)); w12 = *(uint64_t *)(in+(0*59+12)*8/sizeof(in[0])); out[0*64+13] = (start + ((w11 >> 63) | (w12 << 1) & 0x7ffffffffffffff)); w13 = *(uint64_t *)(in+(0*59+13)*8/sizeof(in[0])); out[0*64+14] = (start + ((w12 >> 58) | (w13 << 6) & 0x7ffffffffffffff)); w14 = *(uint64_t *)(in+(0*59+14)*8/sizeof(in[0])); out[0*64+15] = (start + ((w13 >> 53) | (w14 << 11) & 0x7ffffffffffffff)); w15 = *(uint64_t *)(in+(0*59+15)*8/sizeof(in[0])); out[0*64+16] = (start + ((w14 >> 48) | (w15 << 16) & 0x7ffffffffffffff)); w16 = *(uint64_t *)(in+(0*59+16)*8/sizeof(in[0])); out[0*64+17] = (start + ((w15 >> 43) | (w16 << 21) & 0x7ffffffffffffff)); w17 = *(uint64_t *)(in+(0*59+17)*8/sizeof(in[0])); out[0*64+18] = (start + ((w16 >> 38) | (w17 << 26) & 0x7ffffffffffffff)); w18 = *(uint64_t *)(in+(0*59+18)*8/sizeof(in[0])); out[0*64+19] = (start + ((w17 >> 33) | (w18 << 31) & 0x7ffffffffffffff)); w19 = *(uint64_t *)(in+(0*59+19)*8/sizeof(in[0])); out[0*64+20] = (start + ((w18 >> 28) | (w19 << 36) & 0x7ffffffffffffff)); w20 = *(uint64_t *)(in+(0*59+20)*8/sizeof(in[0])); out[0*64+21] = (start + ((w19 >> 23) | (w20 << 41) & 0x7ffffffffffffff)); w21 = *(uint64_t *)(in+(0*59+21)*8/sizeof(in[0])); out[0*64+22] = (start + ((w20 >> 18) | (w21 << 46) & 0x7ffffffffffffff)); w22 = *(uint64_t *)(in+(0*59+22)*8/sizeof(in[0])); out[0*64+23] = (start + ((w21 >> 13) | (w22 << 51) & 0x7ffffffffffffff)); w23 = *(uint64_t *)(in+(0*59+23)*8/sizeof(in[0])); out[0*64+24] = (start + ((w22 >> 8) | (w23 << 56) & 0x7ffffffffffffff)); out[0*64+25] = (start + ((w23 >> 3) & 0x7ffffffffffffff)); w24 = *(uint64_t *)(in+(0*59+24)*8/sizeof(in[0])); out[0*64+26] = (start + ((w23 >> 62) | (w24 << 2) & 0x7ffffffffffffff)); w25 = *(uint64_t *)(in+(0*59+25)*8/sizeof(in[0])); out[0*64+27] = (start + ((w24 >> 57) | (w25 << 7) & 0x7ffffffffffffff)); w26 = *(uint64_t *)(in+(0*59+26)*8/sizeof(in[0])); out[0*64+28] = (start + ((w25 >> 52) | (w26 << 12) & 0x7ffffffffffffff)); w27 = *(uint64_t *)(in+(0*59+27)*8/sizeof(in[0])); out[0*64+29] = (start + ((w26 >> 47) | (w27 << 17) & 0x7ffffffffffffff)); w28 = *(uint64_t *)(in+(0*59+28)*8/sizeof(in[0])); out[0*64+30] = (start + ((w27 >> 42) | (w28 << 22) & 0x7ffffffffffffff)); w29 = *(uint32_t *)(in+(0*59+29)*8/sizeof(in[0])); out[0*64+31] = (start + ((w28 >> 37) | (w29 << 27) & 0x7ffffffffffffff));;}; out += 32; in += 59*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_60(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*60)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*16+ 0] = (start + ((w0 ) & 0xfffffffffffffff)); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*16+ 1] = (start + ((w0 >> 60) | (w1 << 4) & 0xfffffffffffffff)); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*16+ 2] = (start + ((w1 >> 56) | (w2 << 8) & 0xfffffffffffffff)); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*16+ 3] = (start + ((w2 >> 52) | (w3 << 12) & 0xfffffffffffffff)); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*16+ 4] = (start + ((w3 >> 48) | (w4 << 16) & 0xfffffffffffffff)); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*16+ 5] = (start + ((w4 >> 44) | (w5 << 20) & 0xfffffffffffffff)); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*16+ 6] = (start + ((w5 >> 40) | (w6 << 24) & 0xfffffffffffffff)); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*16+ 7] = (start + ((w6 >> 36) | (w7 << 28) & 0xfffffffffffffff)); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*16+ 8] = (start + ((w7 >> 32) | (w8 << 32) & 0xfffffffffffffff)); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*16+ 9] = (start + ((w8 >> 28) | (w9 << 36) & 0xfffffffffffffff)); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*16+10] = (start + ((w9 >> 24) | (w10 << 40) & 0xfffffffffffffff)); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*16+11] = (start + ((w10 >> 20) | (w11 << 44) & 0xfffffffffffffff)); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*16+12] = (start + ((w11 >> 16) | (w12 << 48) & 0xfffffffffffffff)); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*16+13] = (start + ((w12 >> 12) | (w13 << 52) & 0xfffffffffffffff)); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*16+14] = (start + ((w13 >> 8) | (w14 << 56) & 0xfffffffffffffff)); out[0*16+15] = (start + ((w14 >> 4)));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(1*15+0)*8/sizeof(in[0])); out[1*16+ 0] = (start + ((w0 ) & 0xfffffffffffffff)); w1 = *(uint64_t *)(in+(1*15+1)*8/sizeof(in[0])); out[1*16+ 1] = (start + ((w0 >> 60) | (w1 << 4) & 0xfffffffffffffff)); w2 = *(uint64_t *)(in+(1*15+2)*8/sizeof(in[0])); out[1*16+ 2] = (start + ((w1 >> 56) | (w2 << 8) & 0xfffffffffffffff)); w3 = *(uint64_t *)(in+(1*15+3)*8/sizeof(in[0])); out[1*16+ 3] = (start + ((w2 >> 52) | (w3 << 12) & 0xfffffffffffffff)); w4 = *(uint64_t *)(in+(1*15+4)*8/sizeof(in[0])); out[1*16+ 4] = (start + ((w3 >> 48) | (w4 << 16) & 0xfffffffffffffff)); w5 = *(uint64_t *)(in+(1*15+5)*8/sizeof(in[0])); out[1*16+ 5] = (start + ((w4 >> 44) | (w5 << 20) & 0xfffffffffffffff)); w6 = *(uint64_t *)(in+(1*15+6)*8/sizeof(in[0])); out[1*16+ 6] = (start + ((w5 >> 40) | (w6 << 24) & 0xfffffffffffffff)); w7 = *(uint64_t *)(in+(1*15+7)*8/sizeof(in[0])); out[1*16+ 7] = (start + ((w6 >> 36) | (w7 << 28) & 0xfffffffffffffff)); w8 = *(uint64_t *)(in+(1*15+8)*8/sizeof(in[0])); out[1*16+ 8] = (start + ((w7 >> 32) | (w8 << 32) & 0xfffffffffffffff)); w9 = *(uint64_t *)(in+(1*15+9)*8/sizeof(in[0])); out[1*16+ 9] = (start + ((w8 >> 28) | (w9 << 36) & 0xfffffffffffffff)); w10 = *(uint64_t *)(in+(1*15+10)*8/sizeof(in[0])); out[1*16+10] = (start + ((w9 >> 24) | (w10 << 40) & 0xfffffffffffffff)); w11 = *(uint64_t *)(in+(1*15+11)*8/sizeof(in[0])); out[1*16+11] = (start + ((w10 >> 20) | (w11 << 44) & 0xfffffffffffffff)); w12 = *(uint64_t *)(in+(1*15+12)*8/sizeof(in[0])); out[1*16+12] = (start + ((w11 >> 16) | (w12 << 48) & 0xfffffffffffffff)); w13 = *(uint64_t *)(in+(1*15+13)*8/sizeof(in[0])); out[1*16+13] = (start + ((w12 >> 12) | (w13 << 52) & 0xfffffffffffffff)); w14 = *(uint64_t *)(in+(1*15+14)*8/sizeof(in[0])); out[1*16+14] = (start + ((w13 >> 8) | (w14 << 56) & 0xfffffffffffffff)); out[1*16+15] = (start + ((w14 >> 4)));;}; out += 32; in += 60*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_61(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*61)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30; w0 = *(uint64_t *)(in+(0*61+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x1fffffffffffffff)); w1 = *(uint64_t *)(in+(0*61+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 61) | (w1 << 3) & 0x1fffffffffffffff)); w2 = *(uint64_t *)(in+(0*61+2)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w1 >> 58) | (w2 << 6) & 0x1fffffffffffffff)); w3 = *(uint64_t *)(in+(0*61+3)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w2 >> 55) | (w3 << 9) & 0x1fffffffffffffff)); w4 = *(uint64_t *)(in+(0*61+4)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w3 >> 52) | (w4 << 12) & 0x1fffffffffffffff)); w5 = *(uint64_t *)(in+(0*61+5)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w4 >> 49) | (w5 << 15) & 0x1fffffffffffffff)); w6 = *(uint64_t *)(in+(0*61+6)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w5 >> 46) | (w6 << 18) & 0x1fffffffffffffff)); w7 = *(uint64_t *)(in+(0*61+7)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w6 >> 43) | (w7 << 21) & 0x1fffffffffffffff)); w8 = *(uint64_t *)(in+(0*61+8)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w7 >> 40) | (w8 << 24) & 0x1fffffffffffffff)); w9 = *(uint64_t *)(in+(0*61+9)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w8 >> 37) | (w9 << 27) & 0x1fffffffffffffff)); w10 = *(uint64_t *)(in+(0*61+10)*8/sizeof(in[0])); out[0*64+10] = (start + ((w9 >> 34) | (w10 << 30) & 0x1fffffffffffffff)); w11 = *(uint64_t *)(in+(0*61+11)*8/sizeof(in[0])); out[0*64+11] = (start + ((w10 >> 31) | (w11 << 33) & 0x1fffffffffffffff)); w12 = *(uint64_t *)(in+(0*61+12)*8/sizeof(in[0])); out[0*64+12] = (start + ((w11 >> 28) | (w12 << 36) & 0x1fffffffffffffff)); w13 = *(uint64_t *)(in+(0*61+13)*8/sizeof(in[0])); out[0*64+13] = (start + ((w12 >> 25) | (w13 << 39) & 0x1fffffffffffffff)); w14 = *(uint64_t *)(in+(0*61+14)*8/sizeof(in[0])); out[0*64+14] = (start + ((w13 >> 22) | (w14 << 42) & 0x1fffffffffffffff)); w15 = *(uint64_t *)(in+(0*61+15)*8/sizeof(in[0])); out[0*64+15] = (start + ((w14 >> 19) | (w15 << 45) & 0x1fffffffffffffff)); w16 = *(uint64_t *)(in+(0*61+16)*8/sizeof(in[0])); out[0*64+16] = (start + ((w15 >> 16) | (w16 << 48) & 0x1fffffffffffffff)); w17 = *(uint64_t *)(in+(0*61+17)*8/sizeof(in[0])); out[0*64+17] = (start + ((w16 >> 13) | (w17 << 51) & 0x1fffffffffffffff)); w18 = *(uint64_t *)(in+(0*61+18)*8/sizeof(in[0])); out[0*64+18] = (start + ((w17 >> 10) | (w18 << 54) & 0x1fffffffffffffff)); w19 = *(uint64_t *)(in+(0*61+19)*8/sizeof(in[0])); out[0*64+19] = (start + ((w18 >> 7) | (w19 << 57) & 0x1fffffffffffffff)); w20 = *(uint64_t *)(in+(0*61+20)*8/sizeof(in[0])); out[0*64+20] = (start + ((w19 >> 4) | (w20 << 60) & 0x1fffffffffffffff)); out[0*64+21] = (start + ((w20 >> 1) & 0x1fffffffffffffff)); w21 = *(uint64_t *)(in+(0*61+21)*8/sizeof(in[0])); out[0*64+22] = (start + ((w20 >> 62) | (w21 << 2) & 0x1fffffffffffffff)); w22 = *(uint64_t *)(in+(0*61+22)*8/sizeof(in[0])); out[0*64+23] = (start + ((w21 >> 59) | (w22 << 5) & 0x1fffffffffffffff)); w23 = *(uint64_t *)(in+(0*61+23)*8/sizeof(in[0])); out[0*64+24] = (start + ((w22 >> 56) | (w23 << 8) & 0x1fffffffffffffff)); w24 = *(uint64_t *)(in+(0*61+24)*8/sizeof(in[0])); out[0*64+25] = (start + ((w23 >> 53) | (w24 << 11) & 0x1fffffffffffffff)); w25 = *(uint64_t *)(in+(0*61+25)*8/sizeof(in[0])); out[0*64+26] = (start + ((w24 >> 50) | (w25 << 14) & 0x1fffffffffffffff)); w26 = *(uint64_t *)(in+(0*61+26)*8/sizeof(in[0])); out[0*64+27] = (start + ((w25 >> 47) | (w26 << 17) & 0x1fffffffffffffff)); w27 = *(uint64_t *)(in+(0*61+27)*8/sizeof(in[0])); out[0*64+28] = (start + ((w26 >> 44) | (w27 << 20) & 0x1fffffffffffffff)); w28 = *(uint64_t *)(in+(0*61+28)*8/sizeof(in[0])); out[0*64+29] = (start + ((w27 >> 41) | (w28 << 23) & 0x1fffffffffffffff)); w29 = *(uint64_t *)(in+(0*61+29)*8/sizeof(in[0])); out[0*64+30] = (start + ((w28 >> 38) | (w29 << 26) & 0x1fffffffffffffff)); w30 = *(uint32_t *)(in+(0*61+30)*8/sizeof(in[0])); out[0*64+31] = (start + ((w29 >> 35) | (w30 << 29) & 0x1fffffffffffffff));;}; out += 32; in += 61*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_62(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*62)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*32+ 0] = (start + ((w0 ) & 0x3fffffffffffffff)); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*32+ 1] = (start + ((w0 >> 62) | (w1 << 2) & 0x3fffffffffffffff)); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*32+ 2] = (start + ((w1 >> 60) | (w2 << 4) & 0x3fffffffffffffff)); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*32+ 3] = (start + ((w2 >> 58) | (w3 << 6) & 0x3fffffffffffffff)); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*32+ 4] = (start + ((w3 >> 56) | (w4 << 8) & 0x3fffffffffffffff)); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*32+ 5] = (start + ((w4 >> 54) | (w5 << 10) & 0x3fffffffffffffff)); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*32+ 6] = (start + ((w5 >> 52) | (w6 << 12) & 0x3fffffffffffffff)); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*32+ 7] = (start + ((w6 >> 50) | (w7 << 14) & 0x3fffffffffffffff)); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*32+ 8] = (start + ((w7 >> 48) | (w8 << 16) & 0x3fffffffffffffff)); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*32+ 9] = (start + ((w8 >> 46) | (w9 << 18) & 0x3fffffffffffffff)); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*32+10] = (start + ((w9 >> 44) | (w10 << 20) & 0x3fffffffffffffff)); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*32+11] = (start + ((w10 >> 42) | (w11 << 22) & 0x3fffffffffffffff)); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*32+12] = (start + ((w11 >> 40) | (w12 << 24) & 0x3fffffffffffffff)); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*32+13] = (start + ((w12 >> 38) | (w13 << 26) & 0x3fffffffffffffff)); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*32+14] = (start + ((w13 >> 36) | (w14 << 28) & 0x3fffffffffffffff)); w15 = *(uint64_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*32+15] = (start + ((w14 >> 34) | (w15 << 30) & 0x3fffffffffffffff)); w16 = *(uint64_t *)(in+(0*31+16)*8/sizeof(in[0])); out[0*32+16] = (start + ((w15 >> 32) | (w16 << 32) & 0x3fffffffffffffff)); w17 = *(uint64_t *)(in+(0*31+17)*8/sizeof(in[0])); out[0*32+17] = (start + ((w16 >> 30) | (w17 << 34) & 0x3fffffffffffffff)); w18 = *(uint64_t *)(in+(0*31+18)*8/sizeof(in[0])); out[0*32+18] = (start + ((w17 >> 28) | (w18 << 36) & 0x3fffffffffffffff)); w19 = *(uint64_t *)(in+(0*31+19)*8/sizeof(in[0])); out[0*32+19] = (start + ((w18 >> 26) | (w19 << 38) & 0x3fffffffffffffff)); w20 = *(uint64_t *)(in+(0*31+20)*8/sizeof(in[0])); out[0*32+20] = (start + ((w19 >> 24) | (w20 << 40) & 0x3fffffffffffffff)); w21 = *(uint64_t *)(in+(0*31+21)*8/sizeof(in[0])); out[0*32+21] = (start + ((w20 >> 22) | (w21 << 42) & 0x3fffffffffffffff)); w22 = *(uint64_t *)(in+(0*31+22)*8/sizeof(in[0])); out[0*32+22] = (start + ((w21 >> 20) | (w22 << 44) & 0x3fffffffffffffff)); w23 = *(uint64_t *)(in+(0*31+23)*8/sizeof(in[0])); out[0*32+23] = (start + ((w22 >> 18) | (w23 << 46) & 0x3fffffffffffffff)); w24 = *(uint64_t *)(in+(0*31+24)*8/sizeof(in[0])); out[0*32+24] = (start + ((w23 >> 16) | (w24 << 48) & 0x3fffffffffffffff)); w25 = *(uint64_t *)(in+(0*31+25)*8/sizeof(in[0])); out[0*32+25] = (start + ((w24 >> 14) | (w25 << 50) & 0x3fffffffffffffff)); w26 = *(uint64_t *)(in+(0*31+26)*8/sizeof(in[0])); out[0*32+26] = (start + ((w25 >> 12) | (w26 << 52) & 0x3fffffffffffffff)); w27 = *(uint64_t *)(in+(0*31+27)*8/sizeof(in[0])); out[0*32+27] = (start + ((w26 >> 10) | (w27 << 54) & 0x3fffffffffffffff)); w28 = *(uint64_t *)(in+(0*31+28)*8/sizeof(in[0])); out[0*32+28] = (start + ((w27 >> 8) | (w28 << 56) & 0x3fffffffffffffff)); w29 = *(uint64_t *)(in+(0*31+29)*8/sizeof(in[0])); out[0*32+29] = (start + ((w28 >> 6) | (w29 << 58) & 0x3fffffffffffffff)); w30 = *(uint64_t *)(in+(0*31+30)*8/sizeof(in[0])); out[0*32+30] = (start + ((w29 >> 4) | (w30 << 60) & 0x3fffffffffffffff)); out[0*32+31] = (start + ((w30 >> 2)));;}; out += 32; in += 62*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_63(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*63)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(0*63+0)*8/sizeof(in[0])); out[0*64+ 0] = (start + ((w0 ) & 0x7fffffffffffffff)); w1 = *(uint64_t *)(in+(0*63+1)*8/sizeof(in[0])); out[0*64+ 1] = (start + ((w0 >> 63) | (w1 << 1) & 0x7fffffffffffffff)); w2 = *(uint64_t *)(in+(0*63+2)*8/sizeof(in[0])); out[0*64+ 2] = (start + ((w1 >> 62) | (w2 << 2) & 0x7fffffffffffffff)); w3 = *(uint64_t *)(in+(0*63+3)*8/sizeof(in[0])); out[0*64+ 3] = (start + ((w2 >> 61) | (w3 << 3) & 0x7fffffffffffffff)); w4 = *(uint64_t *)(in+(0*63+4)*8/sizeof(in[0])); out[0*64+ 4] = (start + ((w3 >> 60) | (w4 << 4) & 0x7fffffffffffffff)); w5 = *(uint64_t *)(in+(0*63+5)*8/sizeof(in[0])); out[0*64+ 5] = (start + ((w4 >> 59) | (w5 << 5) & 0x7fffffffffffffff)); w6 = *(uint64_t *)(in+(0*63+6)*8/sizeof(in[0])); out[0*64+ 6] = (start + ((w5 >> 58) | (w6 << 6) & 0x7fffffffffffffff)); w7 = *(uint64_t *)(in+(0*63+7)*8/sizeof(in[0])); out[0*64+ 7] = (start + ((w6 >> 57) | (w7 << 7) & 0x7fffffffffffffff)); w8 = *(uint64_t *)(in+(0*63+8)*8/sizeof(in[0])); out[0*64+ 8] = (start + ((w7 >> 56) | (w8 << 8) & 0x7fffffffffffffff)); w9 = *(uint64_t *)(in+(0*63+9)*8/sizeof(in[0])); out[0*64+ 9] = (start + ((w8 >> 55) | (w9 << 9) & 0x7fffffffffffffff)); w10 = *(uint64_t *)(in+(0*63+10)*8/sizeof(in[0])); out[0*64+10] = (start + ((w9 >> 54) | (w10 << 10) & 0x7fffffffffffffff)); w11 = *(uint64_t *)(in+(0*63+11)*8/sizeof(in[0])); out[0*64+11] = (start + ((w10 >> 53) | (w11 << 11) & 0x7fffffffffffffff)); w12 = *(uint64_t *)(in+(0*63+12)*8/sizeof(in[0])); out[0*64+12] = (start + ((w11 >> 52) | (w12 << 12) & 0x7fffffffffffffff)); w13 = *(uint64_t *)(in+(0*63+13)*8/sizeof(in[0])); out[0*64+13] = (start + ((w12 >> 51) | (w13 << 13) & 0x7fffffffffffffff)); w14 = *(uint64_t *)(in+(0*63+14)*8/sizeof(in[0])); out[0*64+14] = (start + ((w13 >> 50) | (w14 << 14) & 0x7fffffffffffffff)); w15 = *(uint64_t *)(in+(0*63+15)*8/sizeof(in[0])); out[0*64+15] = (start + ((w14 >> 49) | (w15 << 15) & 0x7fffffffffffffff)); w16 = *(uint64_t *)(in+(0*63+16)*8/sizeof(in[0])); out[0*64+16] = (start + ((w15 >> 48) | (w16 << 16) & 0x7fffffffffffffff)); w17 = *(uint64_t *)(in+(0*63+17)*8/sizeof(in[0])); out[0*64+17] = (start + ((w16 >> 47) | (w17 << 17) & 0x7fffffffffffffff)); w18 = *(uint64_t *)(in+(0*63+18)*8/sizeof(in[0])); out[0*64+18] = (start + ((w17 >> 46) | (w18 << 18) & 0x7fffffffffffffff)); w19 = *(uint64_t *)(in+(0*63+19)*8/sizeof(in[0])); out[0*64+19] = (start + ((w18 >> 45) | (w19 << 19) & 0x7fffffffffffffff)); w20 = *(uint64_t *)(in+(0*63+20)*8/sizeof(in[0])); out[0*64+20] = (start + ((w19 >> 44) | (w20 << 20) & 0x7fffffffffffffff)); w21 = *(uint64_t *)(in+(0*63+21)*8/sizeof(in[0])); out[0*64+21] = (start + ((w20 >> 43) | (w21 << 21) & 0x7fffffffffffffff)); w22 = *(uint64_t *)(in+(0*63+22)*8/sizeof(in[0])); out[0*64+22] = (start + ((w21 >> 42) | (w22 << 22) & 0x7fffffffffffffff)); w23 = *(uint64_t *)(in+(0*63+23)*8/sizeof(in[0])); out[0*64+23] = (start + ((w22 >> 41) | (w23 << 23) & 0x7fffffffffffffff)); w24 = *(uint64_t *)(in+(0*63+24)*8/sizeof(in[0])); out[0*64+24] = (start + ((w23 >> 40) | (w24 << 24) & 0x7fffffffffffffff)); w25 = *(uint64_t *)(in+(0*63+25)*8/sizeof(in[0])); out[0*64+25] = (start + ((w24 >> 39) | (w25 << 25) & 0x7fffffffffffffff)); w26 = *(uint64_t *)(in+(0*63+26)*8/sizeof(in[0])); out[0*64+26] = (start + ((w25 >> 38) | (w26 << 26) & 0x7fffffffffffffff)); w27 = *(uint64_t *)(in+(0*63+27)*8/sizeof(in[0])); out[0*64+27] = (start + ((w26 >> 37) | (w27 << 27) & 0x7fffffffffffffff)); w28 = *(uint64_t *)(in+(0*63+28)*8/sizeof(in[0])); out[0*64+28] = (start + ((w27 >> 36) | (w28 << 28) & 0x7fffffffffffffff)); w29 = *(uint64_t *)(in+(0*63+29)*8/sizeof(in[0])); out[0*64+29] = (start + ((w28 >> 35) | (w29 << 29) & 0x7fffffffffffffff)); w30 = *(uint64_t *)(in+(0*63+30)*8/sizeof(in[0])); out[0*64+30] = (start + ((w29 >> 34) | (w30 << 30) & 0x7fffffffffffffff)); w31 = *(uint32_t *)(in+(0*63+31)*8/sizeof(in[0])); out[0*64+31] = (start + ((w30 >> 33) | (w31 << 31) & 0x7fffffffffffffff));;}; out += 32; in += 63*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitfunpack64_64(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*64)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(4*1+0)*8/sizeof(in[0])); out[4*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(5*1+0)*8/sizeof(in[0])); out[5*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(6*1+0)*8/sizeof(in[0])); out[6*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(7*1+0)*8/sizeof(in[0])); out[7*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(8*1+0)*8/sizeof(in[0])); out[8*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(9*1+0)*8/sizeof(in[0])); out[9*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(10*1+0)*8/sizeof(in[0])); out[10*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(11*1+0)*8/sizeof(in[0])); out[11*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(12*1+0)*8/sizeof(in[0])); out[12*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(13*1+0)*8/sizeof(in[0])); out[13*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(14*1+0)*8/sizeof(in[0])); out[14*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(15*1+0)*8/sizeof(in[0])); out[15*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(16*1+0)*8/sizeof(in[0])); out[16*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(17*1+0)*8/sizeof(in[0])); out[17*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(18*1+0)*8/sizeof(in[0])); out[18*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(19*1+0)*8/sizeof(in[0])); out[19*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(20*1+0)*8/sizeof(in[0])); out[20*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(21*1+0)*8/sizeof(in[0])); out[21*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(22*1+0)*8/sizeof(in[0])); out[22*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(23*1+0)*8/sizeof(in[0])); out[23*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(24*1+0)*8/sizeof(in[0])); out[24*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(25*1+0)*8/sizeof(in[0])); out[25*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(26*1+0)*8/sizeof(in[0])); out[26*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(27*1+0)*8/sizeof(in[0])); out[27*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(28*1+0)*8/sizeof(in[0])); out[28*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(29*1+0)*8/sizeof(in[0])); out[29*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(30*1+0)*8/sizeof(in[0])); out[30*1+ 0] = (start + ((w0 )));;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(31*1+0)*8/sizeof(in[0])); out[31*1+ 0] = (start + ((w0 )));;}; out += 32; in += 64*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D64 bitfunpacka64[] = {
  &bitfunpack64_0,
  &bitfunpack64_1,
  &bitfunpack64_2,
  &bitfunpack64_3,
  &bitfunpack64_4,
  &bitfunpack64_5,
  &bitfunpack64_6,
  &bitfunpack64_7,
  &bitfunpack64_8,
  &bitfunpack64_9,
  &bitfunpack64_10,
  &bitfunpack64_11,
  &bitfunpack64_12,
  &bitfunpack64_13,
  &bitfunpack64_14,
  &bitfunpack64_15,
  &bitfunpack64_16,
  &bitfunpack64_17,
  &bitfunpack64_18,
  &bitfunpack64_19,
  &bitfunpack64_20,
  &bitfunpack64_21,
  &bitfunpack64_22,
  &bitfunpack64_23,
  &bitfunpack64_24,
  &bitfunpack64_25,
  &bitfunpack64_26,
  &bitfunpack64_27,
  &bitfunpack64_28,
  &bitfunpack64_29,
  &bitfunpack64_30,
  &bitfunpack64_31,
  &bitfunpack64_32,
  &bitfunpack64_33,
  &bitfunpack64_34,
  &bitfunpack64_35,
  &bitfunpack64_36,
  &bitfunpack64_37,
  &bitfunpack64_38,
  &bitfunpack64_39,
  &bitfunpack64_40,
  &bitfunpack64_41,
  &bitfunpack64_42,
  &bitfunpack64_43,
  &bitfunpack64_44,
  &bitfunpack64_45,
  &bitfunpack64_46,
  &bitfunpack64_47,
  &bitfunpack64_48,
  &bitfunpack64_49,
  &bitfunpack64_50,
  &bitfunpack64_51,
  &bitfunpack64_52,
  &bitfunpack64_53,
  &bitfunpack64_54,
  &bitfunpack64_55,
  &bitfunpack64_56,
  &bitfunpack64_57,
  &bitfunpack64_58,
  &bitfunpack64_59,
  &bitfunpack64_60,
  &bitfunpack64_61,
  &bitfunpack64_62,
  &bitfunpack64_63,
  &bitfunpack64_64
};
unsigned char *bitfunpack64( const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start, unsigned b) { return bitfunpacka64[ b](in, n, out, start); }
unsigned char *bitd1unpack8_0(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint8_t *out_ = out+n; do { { { out[0*0+ 0] = (start += (0)) + (0*0+ 0 +1); out[0*0+ 1] = (start += (0)) + (0*0+ 1 +1); out[0*0+ 2] = (start += (0)) + (0*0+ 2 +1); out[0*0+ 3] = (start += (0)) + (0*0+ 3 +1); out[0*0+ 4] = (start += (0)) + (0*0+ 4 +1); out[0*0+ 5] = (start += (0)) + (0*0+ 5 +1); out[0*0+ 6] = (start += (0)) + (0*0+ 6 +1); out[0*0+ 7] = (start += (0)) + (0*0+ 7 +1); out[0*0+ 8] = (start += (0)) + (0*0+ 8 +1); out[0*0+ 9] = (start += (0)) + (0*0+ 9 +1); out[0*0+10] = (start += (0)) + (0*0+10 +1); out[0*0+11] = (start += (0)) + (0*0+11 +1); out[0*0+12] = (start += (0)) + (0*0+12 +1); out[0*0+13] = (start += (0)) + (0*0+13 +1); out[0*0+14] = (start += (0)) + (0*0+14 +1); out[0*0+15] = (start += (0)) + (0*0+15 +1); out[0*0+16] = (start += (0)) + (0*0+16 +1); out[0*0+17] = (start += (0)) + (0*0+17 +1); out[0*0+18] = (start += (0)) + (0*0+18 +1); out[0*0+19] = (start += (0)) + (0*0+19 +1); out[0*0+20] = (start += (0)) + (0*0+20 +1); out[0*0+21] = (start += (0)) + (0*0+21 +1); out[0*0+22] = (start += (0)) + (0*0+22 +1); out[0*0+23] = (start += (0)) + (0*0+23 +1); out[0*0+24] = (start += (0)) + (0*0+24 +1); out[0*0+25] = (start += (0)) + (0*0+25 +1); out[0*0+26] = (start += (0)) + (0*0+26 +1); out[0*0+27] = (start += (0)) + (0*0+27 +1); out[0*0+28] = (start += (0)) + (0*0+28 +1); out[0*0+29] = (start += (0)) + (0*0+29 +1); out[0*0+30] = (start += (0)) + (0*0+30 +1); out[0*0+31] = (start += (0)) + (0*0+31 +1);;}; out += 32; start += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitd1unpack8_1(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x1)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 1) & 0x1)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 2) & 0x1)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 3) & 0x1)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 4) & 0x1)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 5) & 0x1)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w0 >> 6) & 0x1)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w0 >> 7) & 0x1)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w0 >> 8) & 0x1)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w0 >> 9) & 0x1)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w0 >> 10) & 0x1)) + (0*32+10 +1); out[0*32+11] = (start += ((w0 >> 11) & 0x1)) + (0*32+11 +1); out[0*32+12] = (start += ((w0 >> 12) & 0x1)) + (0*32+12 +1); out[0*32+13] = (start += ((w0 >> 13) & 0x1)) + (0*32+13 +1); out[0*32+14] = (start += ((w0 >> 14) & 0x1)) + (0*32+14 +1); out[0*32+15] = (start += ((w0 >> 15) & 0x1)) + (0*32+15 +1); out[0*32+16] = (start += ((w0 >> 16) & 0x1)) + (0*32+16 +1); out[0*32+17] = (start += ((w0 >> 17) & 0x1)) + (0*32+17 +1); out[0*32+18] = (start += ((w0 >> 18) & 0x1)) + (0*32+18 +1); out[0*32+19] = (start += ((w0 >> 19) & 0x1)) + (0*32+19 +1); out[0*32+20] = (start += ((w0 >> 20) & 0x1)) + (0*32+20 +1); out[0*32+21] = (start += ((w0 >> 21) & 0x1)) + (0*32+21 +1); out[0*32+22] = (start += ((w0 >> 22) & 0x1)) + (0*32+22 +1); out[0*32+23] = (start += ((w0 >> 23) & 0x1)) + (0*32+23 +1); out[0*32+24] = (start += ((w0 >> 24) & 0x1)) + (0*32+24 +1); out[0*32+25] = (start += ((w0 >> 25) & 0x1)) + (0*32+25 +1); out[0*32+26] = (start += ((w0 >> 26) & 0x1)) + (0*32+26 +1); out[0*32+27] = (start += ((w0 >> 27) & 0x1)) + (0*32+27 +1); out[0*32+28] = (start += ((w0 >> 28) & 0x1)) + (0*32+28 +1); out[0*32+29] = (start += ((w0 >> 29) & 0x1)) + (0*32+29 +1); out[0*32+30] = (start += ((w0 >> 30) & 0x1)) + (0*32+30 +1); out[0*32+31] = (start += ((w0 >> 31))) + (0*32+31 +1);;}; out += 32; start += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack8_2(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 2) & 0x3)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 4) & 0x3)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 6) & 0x3)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 8) & 0x3)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 10) & 0x3)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w0 >> 12) & 0x3)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w0 >> 14) & 0x3)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w0 >> 16) & 0x3)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w0 >> 18) & 0x3)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w0 >> 20) & 0x3)) + (0*32+10 +1); out[0*32+11] = (start += ((w0 >> 22) & 0x3)) + (0*32+11 +1); out[0*32+12] = (start += ((w0 >> 24) & 0x3)) + (0*32+12 +1); out[0*32+13] = (start += ((w0 >> 26) & 0x3)) + (0*32+13 +1); out[0*32+14] = (start += ((w0 >> 28) & 0x3)) + (0*32+14 +1); out[0*32+15] = (start += ((w0 >> 30) & 0x3)) + (0*32+15 +1); out[0*32+16] = (start += ((w0 >> 32) & 0x3)) + (0*32+16 +1); out[0*32+17] = (start += ((w0 >> 34) & 0x3)) + (0*32+17 +1); out[0*32+18] = (start += ((w0 >> 36) & 0x3)) + (0*32+18 +1); out[0*32+19] = (start += ((w0 >> 38) & 0x3)) + (0*32+19 +1); out[0*32+20] = (start += ((w0 >> 40) & 0x3)) + (0*32+20 +1); out[0*32+21] = (start += ((w0 >> 42) & 0x3)) + (0*32+21 +1); out[0*32+22] = (start += ((w0 >> 44) & 0x3)) + (0*32+22 +1); out[0*32+23] = (start += ((w0 >> 46) & 0x3)) + (0*32+23 +1); out[0*32+24] = (start += ((w0 >> 48) & 0x3)) + (0*32+24 +1); out[0*32+25] = (start += ((w0 >> 50) & 0x3)) + (0*32+25 +1); out[0*32+26] = (start += ((w0 >> 52) & 0x3)) + (0*32+26 +1); out[0*32+27] = (start += ((w0 >> 54) & 0x3)) + (0*32+27 +1); out[0*32+28] = (start += ((w0 >> 56) & 0x3)) + (0*32+28 +1); out[0*32+29] = (start += ((w0 >> 58) & 0x3)) + (0*32+29 +1); out[0*32+30] = (start += ((w0 >> 60) & 0x3)) + (0*32+30 +1); out[0*32+31] = (start += ((w0 >> 62))) + (0*32+31 +1);;}; out += 32; start += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack8_3(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 3) & 0x7)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 6) & 0x7)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 9) & 0x7)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 12) & 0x7)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 15) & 0x7)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 18) & 0x7)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w0 >> 21) & 0x7)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w0 >> 24) & 0x7)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w0 >> 27) & 0x7)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w0 >> 30) & 0x7)) + (0*64+10 +1); out[0*64+11] = (start += ((w0 >> 33) & 0x7)) + (0*64+11 +1); out[0*64+12] = (start += ((w0 >> 36) & 0x7)) + (0*64+12 +1); out[0*64+13] = (start += ((w0 >> 39) & 0x7)) + (0*64+13 +1); out[0*64+14] = (start += ((w0 >> 42) & 0x7)) + (0*64+14 +1); out[0*64+15] = (start += ((w0 >> 45) & 0x7)) + (0*64+15 +1); out[0*64+16] = (start += ((w0 >> 48) & 0x7)) + (0*64+16 +1); out[0*64+17] = (start += ((w0 >> 51) & 0x7)) + (0*64+17 +1); out[0*64+18] = (start += ((w0 >> 54) & 0x7)) + (0*64+18 +1); out[0*64+19] = (start += ((w0 >> 57) & 0x7)) + (0*64+19 +1); out[0*64+20] = (start += ((w0 >> 60) & 0x7)) + (0*64+20 +1); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start += ((w0 >> 63) | (w1 << 1) & 0x7)) + (0*64+21 +1); out[0*64+22] = (start += ((w1 >> 2) & 0x7)) + (0*64+22 +1); out[0*64+23] = (start += ((w1 >> 5) & 0x7)) + (0*64+23 +1); out[0*64+24] = (start += ((w1 >> 8) & 0x7)) + (0*64+24 +1); out[0*64+25] = (start += ((w1 >> 11) & 0x7)) + (0*64+25 +1); out[0*64+26] = (start += ((w1 >> 14) & 0x7)) + (0*64+26 +1); out[0*64+27] = (start += ((w1 >> 17) & 0x7)) + (0*64+27 +1); out[0*64+28] = (start += ((w1 >> 20) & 0x7)) + (0*64+28 +1); out[0*64+29] = (start += ((w1 >> 23) & 0x7)) + (0*64+29 +1); out[0*64+30] = (start += ((w1 >> 26) & 0x7)) + (0*64+30 +1); out[0*64+31] = (start += ((w1 >> 29) & 0x7)) + (0*64+31 +1);;}; out += 32; start += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack8_4(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xf)) + (0*16+ 0 +1); out[0*16+ 1] = (start += ((w0 >> 4) & 0xf)) + (0*16+ 1 +1); out[0*16+ 2] = (start += ((w0 >> 8) & 0xf)) + (0*16+ 2 +1); out[0*16+ 3] = (start += ((w0 >> 12) & 0xf)) + (0*16+ 3 +1); out[0*16+ 4] = (start += ((w0 >> 16) & 0xf)) + (0*16+ 4 +1); out[0*16+ 5] = (start += ((w0 >> 20) & 0xf)) + (0*16+ 5 +1); out[0*16+ 6] = (start += ((w0 >> 24) & 0xf)) + (0*16+ 6 +1); out[0*16+ 7] = (start += ((w0 >> 28) & 0xf)) + (0*16+ 7 +1); out[0*16+ 8] = (start += ((w0 >> 32) & 0xf)) + (0*16+ 8 +1); out[0*16+ 9] = (start += ((w0 >> 36) & 0xf)) + (0*16+ 9 +1); out[0*16+10] = (start += ((w0 >> 40) & 0xf)) + (0*16+10 +1); out[0*16+11] = (start += ((w0 >> 44) & 0xf)) + (0*16+11 +1); out[0*16+12] = (start += ((w0 >> 48) & 0xf)) + (0*16+12 +1); out[0*16+13] = (start += ((w0 >> 52) & 0xf)) + (0*16+13 +1); out[0*16+14] = (start += ((w0 >> 56) & 0xf)) + (0*16+14 +1); out[0*16+15] = (start += ((w0 >> 60))) + (0*16+15 +1);;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xf)) + (1*16+ 0 +1); out[1*16+ 1] = (start += ((w0 >> 4) & 0xf)) + (1*16+ 1 +1); out[1*16+ 2] = (start += ((w0 >> 8) & 0xf)) + (1*16+ 2 +1); out[1*16+ 3] = (start += ((w0 >> 12) & 0xf)) + (1*16+ 3 +1); out[1*16+ 4] = (start += ((w0 >> 16) & 0xf)) + (1*16+ 4 +1); out[1*16+ 5] = (start += ((w0 >> 20) & 0xf)) + (1*16+ 5 +1); out[1*16+ 6] = (start += ((w0 >> 24) & 0xf)) + (1*16+ 6 +1); out[1*16+ 7] = (start += ((w0 >> 28) & 0xf)) + (1*16+ 7 +1); out[1*16+ 8] = (start += ((w0 >> 32) & 0xf)) + (1*16+ 8 +1); out[1*16+ 9] = (start += ((w0 >> 36) & 0xf)) + (1*16+ 9 +1); out[1*16+10] = (start += ((w0 >> 40) & 0xf)) + (1*16+10 +1); out[1*16+11] = (start += ((w0 >> 44) & 0xf)) + (1*16+11 +1); out[1*16+12] = (start += ((w0 >> 48) & 0xf)) + (1*16+12 +1); out[1*16+13] = (start += ((w0 >> 52) & 0xf)) + (1*16+13 +1); out[1*16+14] = (start += ((w0 >> 56) & 0xf)) + (1*16+14 +1); out[1*16+15] = (start += ((w0 >> 60))) + (1*16+15 +1);;}; out += 32; start += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack8_5(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1f)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 5) & 0x1f)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 10) & 0x1f)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 15) & 0x1f)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 20) & 0x1f)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 25) & 0x1f)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 30) & 0x1f)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w0 >> 35) & 0x1f)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w0 >> 40) & 0x1f)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w0 >> 45) & 0x1f)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w0 >> 50) & 0x1f)) + (0*64+10 +1); out[0*64+11] = (start += ((w0 >> 55) & 0x1f)) + (0*64+11 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start += ((w0 >> 60) | (w1 << 4) & 0x1f)) + (0*64+12 +1); out[0*64+13] = (start += ((w1 >> 1) & 0x1f)) + (0*64+13 +1); out[0*64+14] = (start += ((w1 >> 6) & 0x1f)) + (0*64+14 +1); out[0*64+15] = (start += ((w1 >> 11) & 0x1f)) + (0*64+15 +1); out[0*64+16] = (start += ((w1 >> 16) & 0x1f)) + (0*64+16 +1); out[0*64+17] = (start += ((w1 >> 21) & 0x1f)) + (0*64+17 +1); out[0*64+18] = (start += ((w1 >> 26) & 0x1f)) + (0*64+18 +1); out[0*64+19] = (start += ((w1 >> 31) & 0x1f)) + (0*64+19 +1); out[0*64+20] = (start += ((w1 >> 36) & 0x1f)) + (0*64+20 +1); out[0*64+21] = (start += ((w1 >> 41) & 0x1f)) + (0*64+21 +1); out[0*64+22] = (start += ((w1 >> 46) & 0x1f)) + (0*64+22 +1); out[0*64+23] = (start += ((w1 >> 51) & 0x1f)) + (0*64+23 +1); out[0*64+24] = (start += ((w1 >> 56) & 0x1f)) + (0*64+24 +1); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start += ((w1 >> 61) | (w2 << 3) & 0x1f)) + (0*64+25 +1); out[0*64+26] = (start += ((w2 >> 2) & 0x1f)) + (0*64+26 +1); out[0*64+27] = (start += ((w2 >> 7) & 0x1f)) + (0*64+27 +1); out[0*64+28] = (start += ((w2 >> 12) & 0x1f)) + (0*64+28 +1); out[0*64+29] = (start += ((w2 >> 17) & 0x1f)) + (0*64+29 +1); out[0*64+30] = (start += ((w2 >> 22) & 0x1f)) + (0*64+30 +1); out[0*64+31] = (start += ((w2 >> 27) & 0x1f)) + (0*64+31 +1);;}; out += 32; start += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack8_6(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3f)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 6) & 0x3f)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 12) & 0x3f)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 18) & 0x3f)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 24) & 0x3f)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 30) & 0x3f)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w0 >> 36) & 0x3f)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w0 >> 42) & 0x3f)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w0 >> 48) & 0x3f)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w0 >> 54) & 0x3f)) + (0*32+ 9 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start += ((w0 >> 60) | (w1 << 4) & 0x3f)) + (0*32+10 +1); out[0*32+11] = (start += ((w1 >> 2) & 0x3f)) + (0*32+11 +1); out[0*32+12] = (start += ((w1 >> 8) & 0x3f)) + (0*32+12 +1); out[0*32+13] = (start += ((w1 >> 14) & 0x3f)) + (0*32+13 +1); out[0*32+14] = (start += ((w1 >> 20) & 0x3f)) + (0*32+14 +1); out[0*32+15] = (start += ((w1 >> 26) & 0x3f)) + (0*32+15 +1); out[0*32+16] = (start += ((w1 >> 32) & 0x3f)) + (0*32+16 +1); out[0*32+17] = (start += ((w1 >> 38) & 0x3f)) + (0*32+17 +1); out[0*32+18] = (start += ((w1 >> 44) & 0x3f)) + (0*32+18 +1); out[0*32+19] = (start += ((w1 >> 50) & 0x3f)) + (0*32+19 +1); out[0*32+20] = (start += ((w1 >> 56) & 0x3f)) + (0*32+20 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start += ((w1 >> 62) | (w2 << 2) & 0x3f)) + (0*32+21 +1); out[0*32+22] = (start += ((w2 >> 4) & 0x3f)) + (0*32+22 +1); out[0*32+23] = (start += ((w2 >> 10) & 0x3f)) + (0*32+23 +1); out[0*32+24] = (start += ((w2 >> 16) & 0x3f)) + (0*32+24 +1); out[0*32+25] = (start += ((w2 >> 22) & 0x3f)) + (0*32+25 +1); out[0*32+26] = (start += ((w2 >> 28) & 0x3f)) + (0*32+26 +1); out[0*32+27] = (start += ((w2 >> 34) & 0x3f)) + (0*32+27 +1); out[0*32+28] = (start += ((w2 >> 40) & 0x3f)) + (0*32+28 +1); out[0*32+29] = (start += ((w2 >> 46) & 0x3f)) + (0*32+29 +1); out[0*32+30] = (start += ((w2 >> 52) & 0x3f)) + (0*32+30 +1); out[0*32+31] = (start += ((w2 >> 58))) + (0*32+31 +1);;}; out += 32; start += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack8_7(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7f)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 7) & 0x7f)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 14) & 0x7f)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 21) & 0x7f)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 28) & 0x7f)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 35) & 0x7f)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 42) & 0x7f)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w0 >> 49) & 0x7f)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w0 >> 56) & 0x7f)) + (0*64+ 8 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w0 >> 63) | (w1 << 1) & 0x7f)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w1 >> 6) & 0x7f)) + (0*64+10 +1); out[0*64+11] = (start += ((w1 >> 13) & 0x7f)) + (0*64+11 +1); out[0*64+12] = (start += ((w1 >> 20) & 0x7f)) + (0*64+12 +1); out[0*64+13] = (start += ((w1 >> 27) & 0x7f)) + (0*64+13 +1); out[0*64+14] = (start += ((w1 >> 34) & 0x7f)) + (0*64+14 +1); out[0*64+15] = (start += ((w1 >> 41) & 0x7f)) + (0*64+15 +1); out[0*64+16] = (start += ((w1 >> 48) & 0x7f)) + (0*64+16 +1); out[0*64+17] = (start += ((w1 >> 55) & 0x7f)) + (0*64+17 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start += ((w1 >> 62) | (w2 << 2) & 0x7f)) + (0*64+18 +1); out[0*64+19] = (start += ((w2 >> 5) & 0x7f)) + (0*64+19 +1); out[0*64+20] = (start += ((w2 >> 12) & 0x7f)) + (0*64+20 +1); out[0*64+21] = (start += ((w2 >> 19) & 0x7f)) + (0*64+21 +1); out[0*64+22] = (start += ((w2 >> 26) & 0x7f)) + (0*64+22 +1); out[0*64+23] = (start += ((w2 >> 33) & 0x7f)) + (0*64+23 +1); out[0*64+24] = (start += ((w2 >> 40) & 0x7f)) + (0*64+24 +1); out[0*64+25] = (start += ((w2 >> 47) & 0x7f)) + (0*64+25 +1); out[0*64+26] = (start += ((w2 >> 54) & 0x7f)) + (0*64+26 +1); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start += ((w2 >> 61) | (w3 << 3) & 0x7f)) + (0*64+27 +1); out[0*64+28] = (start += ((w3 >> 4) & 0x7f)) + (0*64+28 +1); out[0*64+29] = (start += ((w3 >> 11) & 0x7f)) + (0*64+29 +1); out[0*64+30] = (start += ((w3 >> 18) & 0x7f)) + (0*64+30 +1); out[0*64+31] = (start += ((w3 >> 25) & 0x7f)) + (0*64+31 +1);;}; out += 32; start += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack8_8(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xff)) + (0*8+ 0 +1); out[0*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (0*8+ 1 +1); out[0*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (0*8+ 2 +1); out[0*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (0*8+ 3 +1); out[0*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (0*8+ 4 +1); out[0*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (0*8+ 5 +1); out[0*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (0*8+ 6 +1); out[0*8+ 7] = (start += ((w0 >> 56))) + (0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xff)) + (1*8+ 0 +1); out[1*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (1*8+ 1 +1); out[1*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (1*8+ 2 +1); out[1*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (1*8+ 3 +1); out[1*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (1*8+ 4 +1); out[1*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (1*8+ 5 +1); out[1*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (1*8+ 6 +1); out[1*8+ 7] = (start += ((w0 >> 56))) + (1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xff)) + (2*8+ 0 +1); out[2*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (2*8+ 1 +1); out[2*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (2*8+ 2 +1); out[2*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (2*8+ 3 +1); out[2*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (2*8+ 4 +1); out[2*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (2*8+ 5 +1); out[2*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (2*8+ 6 +1); out[2*8+ 7] = (start += ((w0 >> 56))) + (2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xff)) + (3*8+ 0 +1); out[3*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (3*8+ 1 +1); out[3*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (3*8+ 2 +1); out[3*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (3*8+ 3 +1); out[3*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (3*8+ 4 +1); out[3*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (3*8+ 5 +1); out[3*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (3*8+ 6 +1); out[3*8+ 7] = (start += ((w0 >> 56))) + (3*8+ 7 +1);;}; out += 32; start += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D8 bitd1unpacka8[] = {
  &bitd1unpack8_0,
  &bitd1unpack8_1,
  &bitd1unpack8_2,
  &bitd1unpack8_3,
  &bitd1unpack8_4,
  &bitd1unpack8_5,
  &bitd1unpack8_6,
  &bitd1unpack8_7,
  &bitd1unpack8_8
};
unsigned char *bitd1unpack8( const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start, unsigned b) { return bitd1unpacka8[ b](in, n, out, start); }
unsigned char *bitd1unpack16_0(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint16_t *out_ = out+n; do { { { out[0*0+ 0] = (start += (0)) + (0*0+ 0 +1); out[0*0+ 1] = (start += (0)) + (0*0+ 1 +1); out[0*0+ 2] = (start += (0)) + (0*0+ 2 +1); out[0*0+ 3] = (start += (0)) + (0*0+ 3 +1); out[0*0+ 4] = (start += (0)) + (0*0+ 4 +1); out[0*0+ 5] = (start += (0)) + (0*0+ 5 +1); out[0*0+ 6] = (start += (0)) + (0*0+ 6 +1); out[0*0+ 7] = (start += (0)) + (0*0+ 7 +1); out[0*0+ 8] = (start += (0)) + (0*0+ 8 +1); out[0*0+ 9] = (start += (0)) + (0*0+ 9 +1); out[0*0+10] = (start += (0)) + (0*0+10 +1); out[0*0+11] = (start += (0)) + (0*0+11 +1); out[0*0+12] = (start += (0)) + (0*0+12 +1); out[0*0+13] = (start += (0)) + (0*0+13 +1); out[0*0+14] = (start += (0)) + (0*0+14 +1); out[0*0+15] = (start += (0)) + (0*0+15 +1); out[0*0+16] = (start += (0)) + (0*0+16 +1); out[0*0+17] = (start += (0)) + (0*0+17 +1); out[0*0+18] = (start += (0)) + (0*0+18 +1); out[0*0+19] = (start += (0)) + (0*0+19 +1); out[0*0+20] = (start += (0)) + (0*0+20 +1); out[0*0+21] = (start += (0)) + (0*0+21 +1); out[0*0+22] = (start += (0)) + (0*0+22 +1); out[0*0+23] = (start += (0)) + (0*0+23 +1); out[0*0+24] = (start += (0)) + (0*0+24 +1); out[0*0+25] = (start += (0)) + (0*0+25 +1); out[0*0+26] = (start += (0)) + (0*0+26 +1); out[0*0+27] = (start += (0)) + (0*0+27 +1); out[0*0+28] = (start += (0)) + (0*0+28 +1); out[0*0+29] = (start += (0)) + (0*0+29 +1); out[0*0+30] = (start += (0)) + (0*0+30 +1); out[0*0+31] = (start += (0)) + (0*0+31 +1);;}; out += 32; start += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitd1unpack16_1(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x1)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 1) & 0x1)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 2) & 0x1)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 3) & 0x1)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 4) & 0x1)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 5) & 0x1)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w0 >> 6) & 0x1)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w0 >> 7) & 0x1)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w0 >> 8) & 0x1)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w0 >> 9) & 0x1)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w0 >> 10) & 0x1)) + (0*32+10 +1); out[0*32+11] = (start += ((w0 >> 11) & 0x1)) + (0*32+11 +1); out[0*32+12] = (start += ((w0 >> 12) & 0x1)) + (0*32+12 +1); out[0*32+13] = (start += ((w0 >> 13) & 0x1)) + (0*32+13 +1); out[0*32+14] = (start += ((w0 >> 14) & 0x1)) + (0*32+14 +1); out[0*32+15] = (start += ((w0 >> 15) & 0x1)) + (0*32+15 +1); out[0*32+16] = (start += ((w0 >> 16) & 0x1)) + (0*32+16 +1); out[0*32+17] = (start += ((w0 >> 17) & 0x1)) + (0*32+17 +1); out[0*32+18] = (start += ((w0 >> 18) & 0x1)) + (0*32+18 +1); out[0*32+19] = (start += ((w0 >> 19) & 0x1)) + (0*32+19 +1); out[0*32+20] = (start += ((w0 >> 20) & 0x1)) + (0*32+20 +1); out[0*32+21] = (start += ((w0 >> 21) & 0x1)) + (0*32+21 +1); out[0*32+22] = (start += ((w0 >> 22) & 0x1)) + (0*32+22 +1); out[0*32+23] = (start += ((w0 >> 23) & 0x1)) + (0*32+23 +1); out[0*32+24] = (start += ((w0 >> 24) & 0x1)) + (0*32+24 +1); out[0*32+25] = (start += ((w0 >> 25) & 0x1)) + (0*32+25 +1); out[0*32+26] = (start += ((w0 >> 26) & 0x1)) + (0*32+26 +1); out[0*32+27] = (start += ((w0 >> 27) & 0x1)) + (0*32+27 +1); out[0*32+28] = (start += ((w0 >> 28) & 0x1)) + (0*32+28 +1); out[0*32+29] = (start += ((w0 >> 29) & 0x1)) + (0*32+29 +1); out[0*32+30] = (start += ((w0 >> 30) & 0x1)) + (0*32+30 +1); out[0*32+31] = (start += ((w0 >> 31))) + (0*32+31 +1);;}; out += 32; start += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_2(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 2) & 0x3)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 4) & 0x3)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 6) & 0x3)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 8) & 0x3)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 10) & 0x3)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w0 >> 12) & 0x3)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w0 >> 14) & 0x3)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w0 >> 16) & 0x3)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w0 >> 18) & 0x3)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w0 >> 20) & 0x3)) + (0*32+10 +1); out[0*32+11] = (start += ((w0 >> 22) & 0x3)) + (0*32+11 +1); out[0*32+12] = (start += ((w0 >> 24) & 0x3)) + (0*32+12 +1); out[0*32+13] = (start += ((w0 >> 26) & 0x3)) + (0*32+13 +1); out[0*32+14] = (start += ((w0 >> 28) & 0x3)) + (0*32+14 +1); out[0*32+15] = (start += ((w0 >> 30) & 0x3)) + (0*32+15 +1); out[0*32+16] = (start += ((w0 >> 32) & 0x3)) + (0*32+16 +1); out[0*32+17] = (start += ((w0 >> 34) & 0x3)) + (0*32+17 +1); out[0*32+18] = (start += ((w0 >> 36) & 0x3)) + (0*32+18 +1); out[0*32+19] = (start += ((w0 >> 38) & 0x3)) + (0*32+19 +1); out[0*32+20] = (start += ((w0 >> 40) & 0x3)) + (0*32+20 +1); out[0*32+21] = (start += ((w0 >> 42) & 0x3)) + (0*32+21 +1); out[0*32+22] = (start += ((w0 >> 44) & 0x3)) + (0*32+22 +1); out[0*32+23] = (start += ((w0 >> 46) & 0x3)) + (0*32+23 +1); out[0*32+24] = (start += ((w0 >> 48) & 0x3)) + (0*32+24 +1); out[0*32+25] = (start += ((w0 >> 50) & 0x3)) + (0*32+25 +1); out[0*32+26] = (start += ((w0 >> 52) & 0x3)) + (0*32+26 +1); out[0*32+27] = (start += ((w0 >> 54) & 0x3)) + (0*32+27 +1); out[0*32+28] = (start += ((w0 >> 56) & 0x3)) + (0*32+28 +1); out[0*32+29] = (start += ((w0 >> 58) & 0x3)) + (0*32+29 +1); out[0*32+30] = (start += ((w0 >> 60) & 0x3)) + (0*32+30 +1); out[0*32+31] = (start += ((w0 >> 62))) + (0*32+31 +1);;}; out += 32; start += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_3(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 3) & 0x7)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 6) & 0x7)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 9) & 0x7)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 12) & 0x7)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 15) & 0x7)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 18) & 0x7)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w0 >> 21) & 0x7)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w0 >> 24) & 0x7)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w0 >> 27) & 0x7)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w0 >> 30) & 0x7)) + (0*64+10 +1); out[0*64+11] = (start += ((w0 >> 33) & 0x7)) + (0*64+11 +1); out[0*64+12] = (start += ((w0 >> 36) & 0x7)) + (0*64+12 +1); out[0*64+13] = (start += ((w0 >> 39) & 0x7)) + (0*64+13 +1); out[0*64+14] = (start += ((w0 >> 42) & 0x7)) + (0*64+14 +1); out[0*64+15] = (start += ((w0 >> 45) & 0x7)) + (0*64+15 +1); out[0*64+16] = (start += ((w0 >> 48) & 0x7)) + (0*64+16 +1); out[0*64+17] = (start += ((w0 >> 51) & 0x7)) + (0*64+17 +1); out[0*64+18] = (start += ((w0 >> 54) & 0x7)) + (0*64+18 +1); out[0*64+19] = (start += ((w0 >> 57) & 0x7)) + (0*64+19 +1); out[0*64+20] = (start += ((w0 >> 60) & 0x7)) + (0*64+20 +1); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start += ((w0 >> 63) | (w1 << 1) & 0x7)) + (0*64+21 +1); out[0*64+22] = (start += ((w1 >> 2) & 0x7)) + (0*64+22 +1); out[0*64+23] = (start += ((w1 >> 5) & 0x7)) + (0*64+23 +1); out[0*64+24] = (start += ((w1 >> 8) & 0x7)) + (0*64+24 +1); out[0*64+25] = (start += ((w1 >> 11) & 0x7)) + (0*64+25 +1); out[0*64+26] = (start += ((w1 >> 14) & 0x7)) + (0*64+26 +1); out[0*64+27] = (start += ((w1 >> 17) & 0x7)) + (0*64+27 +1); out[0*64+28] = (start += ((w1 >> 20) & 0x7)) + (0*64+28 +1); out[0*64+29] = (start += ((w1 >> 23) & 0x7)) + (0*64+29 +1); out[0*64+30] = (start += ((w1 >> 26) & 0x7)) + (0*64+30 +1); out[0*64+31] = (start += ((w1 >> 29) & 0x7)) + (0*64+31 +1);;}; out += 32; start += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_4(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xf)) + (0*16+ 0 +1); out[0*16+ 1] = (start += ((w0 >> 4) & 0xf)) + (0*16+ 1 +1); out[0*16+ 2] = (start += ((w0 >> 8) & 0xf)) + (0*16+ 2 +1); out[0*16+ 3] = (start += ((w0 >> 12) & 0xf)) + (0*16+ 3 +1); out[0*16+ 4] = (start += ((w0 >> 16) & 0xf)) + (0*16+ 4 +1); out[0*16+ 5] = (start += ((w0 >> 20) & 0xf)) + (0*16+ 5 +1); out[0*16+ 6] = (start += ((w0 >> 24) & 0xf)) + (0*16+ 6 +1); out[0*16+ 7] = (start += ((w0 >> 28) & 0xf)) + (0*16+ 7 +1); out[0*16+ 8] = (start += ((w0 >> 32) & 0xf)) + (0*16+ 8 +1); out[0*16+ 9] = (start += ((w0 >> 36) & 0xf)) + (0*16+ 9 +1); out[0*16+10] = (start += ((w0 >> 40) & 0xf)) + (0*16+10 +1); out[0*16+11] = (start += ((w0 >> 44) & 0xf)) + (0*16+11 +1); out[0*16+12] = (start += ((w0 >> 48) & 0xf)) + (0*16+12 +1); out[0*16+13] = (start += ((w0 >> 52) & 0xf)) + (0*16+13 +1); out[0*16+14] = (start += ((w0 >> 56) & 0xf)) + (0*16+14 +1); out[0*16+15] = (start += ((w0 >> 60))) + (0*16+15 +1);;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xf)) + (1*16+ 0 +1); out[1*16+ 1] = (start += ((w0 >> 4) & 0xf)) + (1*16+ 1 +1); out[1*16+ 2] = (start += ((w0 >> 8) & 0xf)) + (1*16+ 2 +1); out[1*16+ 3] = (start += ((w0 >> 12) & 0xf)) + (1*16+ 3 +1); out[1*16+ 4] = (start += ((w0 >> 16) & 0xf)) + (1*16+ 4 +1); out[1*16+ 5] = (start += ((w0 >> 20) & 0xf)) + (1*16+ 5 +1); out[1*16+ 6] = (start += ((w0 >> 24) & 0xf)) + (1*16+ 6 +1); out[1*16+ 7] = (start += ((w0 >> 28) & 0xf)) + (1*16+ 7 +1); out[1*16+ 8] = (start += ((w0 >> 32) & 0xf)) + (1*16+ 8 +1); out[1*16+ 9] = (start += ((w0 >> 36) & 0xf)) + (1*16+ 9 +1); out[1*16+10] = (start += ((w0 >> 40) & 0xf)) + (1*16+10 +1); out[1*16+11] = (start += ((w0 >> 44) & 0xf)) + (1*16+11 +1); out[1*16+12] = (start += ((w0 >> 48) & 0xf)) + (1*16+12 +1); out[1*16+13] = (start += ((w0 >> 52) & 0xf)) + (1*16+13 +1); out[1*16+14] = (start += ((w0 >> 56) & 0xf)) + (1*16+14 +1); out[1*16+15] = (start += ((w0 >> 60))) + (1*16+15 +1);;}; out += 32; start += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_5(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1f)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 5) & 0x1f)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 10) & 0x1f)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 15) & 0x1f)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 20) & 0x1f)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 25) & 0x1f)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 30) & 0x1f)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w0 >> 35) & 0x1f)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w0 >> 40) & 0x1f)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w0 >> 45) & 0x1f)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w0 >> 50) & 0x1f)) + (0*64+10 +1); out[0*64+11] = (start += ((w0 >> 55) & 0x1f)) + (0*64+11 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start += ((w0 >> 60) | (w1 << 4) & 0x1f)) + (0*64+12 +1); out[0*64+13] = (start += ((w1 >> 1) & 0x1f)) + (0*64+13 +1); out[0*64+14] = (start += ((w1 >> 6) & 0x1f)) + (0*64+14 +1); out[0*64+15] = (start += ((w1 >> 11) & 0x1f)) + (0*64+15 +1); out[0*64+16] = (start += ((w1 >> 16) & 0x1f)) + (0*64+16 +1); out[0*64+17] = (start += ((w1 >> 21) & 0x1f)) + (0*64+17 +1); out[0*64+18] = (start += ((w1 >> 26) & 0x1f)) + (0*64+18 +1); out[0*64+19] = (start += ((w1 >> 31) & 0x1f)) + (0*64+19 +1); out[0*64+20] = (start += ((w1 >> 36) & 0x1f)) + (0*64+20 +1); out[0*64+21] = (start += ((w1 >> 41) & 0x1f)) + (0*64+21 +1); out[0*64+22] = (start += ((w1 >> 46) & 0x1f)) + (0*64+22 +1); out[0*64+23] = (start += ((w1 >> 51) & 0x1f)) + (0*64+23 +1); out[0*64+24] = (start += ((w1 >> 56) & 0x1f)) + (0*64+24 +1); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start += ((w1 >> 61) | (w2 << 3) & 0x1f)) + (0*64+25 +1); out[0*64+26] = (start += ((w2 >> 2) & 0x1f)) + (0*64+26 +1); out[0*64+27] = (start += ((w2 >> 7) & 0x1f)) + (0*64+27 +1); out[0*64+28] = (start += ((w2 >> 12) & 0x1f)) + (0*64+28 +1); out[0*64+29] = (start += ((w2 >> 17) & 0x1f)) + (0*64+29 +1); out[0*64+30] = (start += ((w2 >> 22) & 0x1f)) + (0*64+30 +1); out[0*64+31] = (start += ((w2 >> 27) & 0x1f)) + (0*64+31 +1);;}; out += 32; start += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_6(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3f)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 6) & 0x3f)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 12) & 0x3f)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 18) & 0x3f)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 24) & 0x3f)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 30) & 0x3f)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w0 >> 36) & 0x3f)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w0 >> 42) & 0x3f)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w0 >> 48) & 0x3f)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w0 >> 54) & 0x3f)) + (0*32+ 9 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start += ((w0 >> 60) | (w1 << 4) & 0x3f)) + (0*32+10 +1); out[0*32+11] = (start += ((w1 >> 2) & 0x3f)) + (0*32+11 +1); out[0*32+12] = (start += ((w1 >> 8) & 0x3f)) + (0*32+12 +1); out[0*32+13] = (start += ((w1 >> 14) & 0x3f)) + (0*32+13 +1); out[0*32+14] = (start += ((w1 >> 20) & 0x3f)) + (0*32+14 +1); out[0*32+15] = (start += ((w1 >> 26) & 0x3f)) + (0*32+15 +1); out[0*32+16] = (start += ((w1 >> 32) & 0x3f)) + (0*32+16 +1); out[0*32+17] = (start += ((w1 >> 38) & 0x3f)) + (0*32+17 +1); out[0*32+18] = (start += ((w1 >> 44) & 0x3f)) + (0*32+18 +1); out[0*32+19] = (start += ((w1 >> 50) & 0x3f)) + (0*32+19 +1); out[0*32+20] = (start += ((w1 >> 56) & 0x3f)) + (0*32+20 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start += ((w1 >> 62) | (w2 << 2) & 0x3f)) + (0*32+21 +1); out[0*32+22] = (start += ((w2 >> 4) & 0x3f)) + (0*32+22 +1); out[0*32+23] = (start += ((w2 >> 10) & 0x3f)) + (0*32+23 +1); out[0*32+24] = (start += ((w2 >> 16) & 0x3f)) + (0*32+24 +1); out[0*32+25] = (start += ((w2 >> 22) & 0x3f)) + (0*32+25 +1); out[0*32+26] = (start += ((w2 >> 28) & 0x3f)) + (0*32+26 +1); out[0*32+27] = (start += ((w2 >> 34) & 0x3f)) + (0*32+27 +1); out[0*32+28] = (start += ((w2 >> 40) & 0x3f)) + (0*32+28 +1); out[0*32+29] = (start += ((w2 >> 46) & 0x3f)) + (0*32+29 +1); out[0*32+30] = (start += ((w2 >> 52) & 0x3f)) + (0*32+30 +1); out[0*32+31] = (start += ((w2 >> 58))) + (0*32+31 +1);;}; out += 32; start += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_7(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7f)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 7) & 0x7f)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 14) & 0x7f)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 21) & 0x7f)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 28) & 0x7f)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 35) & 0x7f)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 42) & 0x7f)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w0 >> 49) & 0x7f)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w0 >> 56) & 0x7f)) + (0*64+ 8 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w0 >> 63) | (w1 << 1) & 0x7f)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w1 >> 6) & 0x7f)) + (0*64+10 +1); out[0*64+11] = (start += ((w1 >> 13) & 0x7f)) + (0*64+11 +1); out[0*64+12] = (start += ((w1 >> 20) & 0x7f)) + (0*64+12 +1); out[0*64+13] = (start += ((w1 >> 27) & 0x7f)) + (0*64+13 +1); out[0*64+14] = (start += ((w1 >> 34) & 0x7f)) + (0*64+14 +1); out[0*64+15] = (start += ((w1 >> 41) & 0x7f)) + (0*64+15 +1); out[0*64+16] = (start += ((w1 >> 48) & 0x7f)) + (0*64+16 +1); out[0*64+17] = (start += ((w1 >> 55) & 0x7f)) + (0*64+17 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start += ((w1 >> 62) | (w2 << 2) & 0x7f)) + (0*64+18 +1); out[0*64+19] = (start += ((w2 >> 5) & 0x7f)) + (0*64+19 +1); out[0*64+20] = (start += ((w2 >> 12) & 0x7f)) + (0*64+20 +1); out[0*64+21] = (start += ((w2 >> 19) & 0x7f)) + (0*64+21 +1); out[0*64+22] = (start += ((w2 >> 26) & 0x7f)) + (0*64+22 +1); out[0*64+23] = (start += ((w2 >> 33) & 0x7f)) + (0*64+23 +1); out[0*64+24] = (start += ((w2 >> 40) & 0x7f)) + (0*64+24 +1); out[0*64+25] = (start += ((w2 >> 47) & 0x7f)) + (0*64+25 +1); out[0*64+26] = (start += ((w2 >> 54) & 0x7f)) + (0*64+26 +1); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start += ((w2 >> 61) | (w3 << 3) & 0x7f)) + (0*64+27 +1); out[0*64+28] = (start += ((w3 >> 4) & 0x7f)) + (0*64+28 +1); out[0*64+29] = (start += ((w3 >> 11) & 0x7f)) + (0*64+29 +1); out[0*64+30] = (start += ((w3 >> 18) & 0x7f)) + (0*64+30 +1); out[0*64+31] = (start += ((w3 >> 25) & 0x7f)) + (0*64+31 +1);;}; out += 32; start += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_8(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xff)) + (0*8+ 0 +1); out[0*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (0*8+ 1 +1); out[0*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (0*8+ 2 +1); out[0*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (0*8+ 3 +1); out[0*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (0*8+ 4 +1); out[0*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (0*8+ 5 +1); out[0*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (0*8+ 6 +1); out[0*8+ 7] = (start += ((w0 >> 56))) + (0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xff)) + (1*8+ 0 +1); out[1*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (1*8+ 1 +1); out[1*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (1*8+ 2 +1); out[1*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (1*8+ 3 +1); out[1*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (1*8+ 4 +1); out[1*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (1*8+ 5 +1); out[1*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (1*8+ 6 +1); out[1*8+ 7] = (start += ((w0 >> 56))) + (1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xff)) + (2*8+ 0 +1); out[2*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (2*8+ 1 +1); out[2*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (2*8+ 2 +1); out[2*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (2*8+ 3 +1); out[2*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (2*8+ 4 +1); out[2*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (2*8+ 5 +1); out[2*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (2*8+ 6 +1); out[2*8+ 7] = (start += ((w0 >> 56))) + (2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xff)) + (3*8+ 0 +1); out[3*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (3*8+ 1 +1); out[3*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (3*8+ 2 +1); out[3*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (3*8+ 3 +1); out[3*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (3*8+ 4 +1); out[3*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (3*8+ 5 +1); out[3*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (3*8+ 6 +1); out[3*8+ 7] = (start += ((w0 >> 56))) + (3*8+ 7 +1);;}; out += 32; start += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_9(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 9) & 0x1ff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 18) & 0x1ff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 27) & 0x1ff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 36) & 0x1ff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 45) & 0x1ff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 54) & 0x1ff)) + (0*64+ 6 +1); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w0 >> 63) | (w1 << 1) & 0x1ff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w1 >> 8) & 0x1ff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w1 >> 17) & 0x1ff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w1 >> 26) & 0x1ff)) + (0*64+10 +1); out[0*64+11] = (start += ((w1 >> 35) & 0x1ff)) + (0*64+11 +1); out[0*64+12] = (start += ((w1 >> 44) & 0x1ff)) + (0*64+12 +1); out[0*64+13] = (start += ((w1 >> 53) & 0x1ff)) + (0*64+13 +1); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (start += ((w1 >> 62) | (w2 << 2) & 0x1ff)) + (0*64+14 +1); out[0*64+15] = (start += ((w2 >> 7) & 0x1ff)) + (0*64+15 +1); out[0*64+16] = (start += ((w2 >> 16) & 0x1ff)) + (0*64+16 +1); out[0*64+17] = (start += ((w2 >> 25) & 0x1ff)) + (0*64+17 +1); out[0*64+18] = (start += ((w2 >> 34) & 0x1ff)) + (0*64+18 +1); out[0*64+19] = (start += ((w2 >> 43) & 0x1ff)) + (0*64+19 +1); out[0*64+20] = (start += ((w2 >> 52) & 0x1ff)) + (0*64+20 +1); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (start += ((w2 >> 61) | (w3 << 3) & 0x1ff)) + (0*64+21 +1); out[0*64+22] = (start += ((w3 >> 6) & 0x1ff)) + (0*64+22 +1); out[0*64+23] = (start += ((w3 >> 15) & 0x1ff)) + (0*64+23 +1); out[0*64+24] = (start += ((w3 >> 24) & 0x1ff)) + (0*64+24 +1); out[0*64+25] = (start += ((w3 >> 33) & 0x1ff)) + (0*64+25 +1); out[0*64+26] = (start += ((w3 >> 42) & 0x1ff)) + (0*64+26 +1); out[0*64+27] = (start += ((w3 >> 51) & 0x1ff)) + (0*64+27 +1); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (start += ((w3 >> 60) | (w4 << 4) & 0x1ff)) + (0*64+28 +1); out[0*64+29] = (start += ((w4 >> 5) & 0x1ff)) + (0*64+29 +1); out[0*64+30] = (start += ((w4 >> 14) & 0x1ff)) + (0*64+30 +1); out[0*64+31] = (start += ((w4 >> 23) & 0x1ff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_10(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ff)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 10) & 0x3ff)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 20) & 0x3ff)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 30) & 0x3ff)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 40) & 0x3ff)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 50) & 0x3ff)) + (0*32+ 5 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w0 >> 60) | (w1 << 4) & 0x3ff)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w1 >> 6) & 0x3ff)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w1 >> 16) & 0x3ff)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w1 >> 26) & 0x3ff)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w1 >> 36) & 0x3ff)) + (0*32+10 +1); out[0*32+11] = (start += ((w1 >> 46) & 0x3ff)) + (0*32+11 +1); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (start += ((w1 >> 56) | (w2 << 8) & 0x3ff)) + (0*32+12 +1); out[0*32+13] = (start += ((w2 >> 2) & 0x3ff)) + (0*32+13 +1); out[0*32+14] = (start += ((w2 >> 12) & 0x3ff)) + (0*32+14 +1); out[0*32+15] = (start += ((w2 >> 22) & 0x3ff)) + (0*32+15 +1); out[0*32+16] = (start += ((w2 >> 32) & 0x3ff)) + (0*32+16 +1); out[0*32+17] = (start += ((w2 >> 42) & 0x3ff)) + (0*32+17 +1); out[0*32+18] = (start += ((w2 >> 52) & 0x3ff)) + (0*32+18 +1); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (start += ((w2 >> 62) | (w3 << 2) & 0x3ff)) + (0*32+19 +1); out[0*32+20] = (start += ((w3 >> 8) & 0x3ff)) + (0*32+20 +1); out[0*32+21] = (start += ((w3 >> 18) & 0x3ff)) + (0*32+21 +1); out[0*32+22] = (start += ((w3 >> 28) & 0x3ff)) + (0*32+22 +1); out[0*32+23] = (start += ((w3 >> 38) & 0x3ff)) + (0*32+23 +1); out[0*32+24] = (start += ((w3 >> 48) & 0x3ff)) + (0*32+24 +1); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (start += ((w3 >> 58) | (w4 << 6) & 0x3ff)) + (0*32+25 +1); out[0*32+26] = (start += ((w4 >> 4) & 0x3ff)) + (0*32+26 +1); out[0*32+27] = (start += ((w4 >> 14) & 0x3ff)) + (0*32+27 +1); out[0*32+28] = (start += ((w4 >> 24) & 0x3ff)) + (0*32+28 +1); out[0*32+29] = (start += ((w4 >> 34) & 0x3ff)) + (0*32+29 +1); out[0*32+30] = (start += ((w4 >> 44) & 0x3ff)) + (0*32+30 +1); out[0*32+31] = (start += ((w4 >> 54))) + (0*32+31 +1);;}; out += 32; start += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_11(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 11) & 0x7ff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 22) & 0x7ff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 33) & 0x7ff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 44) & 0x7ff)) + (0*64+ 4 +1); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w0 >> 55) | (w1 << 9) & 0x7ff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w1 >> 2) & 0x7ff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w1 >> 13) & 0x7ff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w1 >> 24) & 0x7ff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w1 >> 35) & 0x7ff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w1 >> 46) & 0x7ff)) + (0*64+10 +1); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (start += ((w1 >> 57) | (w2 << 7) & 0x7ff)) + (0*64+11 +1); out[0*64+12] = (start += ((w2 >> 4) & 0x7ff)) + (0*64+12 +1); out[0*64+13] = (start += ((w2 >> 15) & 0x7ff)) + (0*64+13 +1); out[0*64+14] = (start += ((w2 >> 26) & 0x7ff)) + (0*64+14 +1); out[0*64+15] = (start += ((w2 >> 37) & 0x7ff)) + (0*64+15 +1); out[0*64+16] = (start += ((w2 >> 48) & 0x7ff)) + (0*64+16 +1); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (start += ((w2 >> 59) | (w3 << 5) & 0x7ff)) + (0*64+17 +1); out[0*64+18] = (start += ((w3 >> 6) & 0x7ff)) + (0*64+18 +1); out[0*64+19] = (start += ((w3 >> 17) & 0x7ff)) + (0*64+19 +1); out[0*64+20] = (start += ((w3 >> 28) & 0x7ff)) + (0*64+20 +1); out[0*64+21] = (start += ((w3 >> 39) & 0x7ff)) + (0*64+21 +1); out[0*64+22] = (start += ((w3 >> 50) & 0x7ff)) + (0*64+22 +1); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (start += ((w3 >> 61) | (w4 << 3) & 0x7ff)) + (0*64+23 +1); out[0*64+24] = (start += ((w4 >> 8) & 0x7ff)) + (0*64+24 +1); out[0*64+25] = (start += ((w4 >> 19) & 0x7ff)) + (0*64+25 +1); out[0*64+26] = (start += ((w4 >> 30) & 0x7ff)) + (0*64+26 +1); out[0*64+27] = (start += ((w4 >> 41) & 0x7ff)) + (0*64+27 +1); out[0*64+28] = (start += ((w4 >> 52) & 0x7ff)) + (0*64+28 +1); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (start += ((w4 >> 63) | (w5 << 1) & 0x7ff)) + (0*64+29 +1); out[0*64+30] = (start += ((w5 >> 10) & 0x7ff)) + (0*64+30 +1); out[0*64+31] = (start += ((w5 >> 21) & 0x7ff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_12(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfff)) + (0*16+ 0 +1); out[0*16+ 1] = (start += ((w0 >> 12) & 0xfff)) + (0*16+ 1 +1); out[0*16+ 2] = (start += ((w0 >> 24) & 0xfff)) + (0*16+ 2 +1); out[0*16+ 3] = (start += ((w0 >> 36) & 0xfff)) + (0*16+ 3 +1); out[0*16+ 4] = (start += ((w0 >> 48) & 0xfff)) + (0*16+ 4 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (start += ((w0 >> 60) | (w1 << 4) & 0xfff)) + (0*16+ 5 +1); out[0*16+ 6] = (start += ((w1 >> 8) & 0xfff)) + (0*16+ 6 +1); out[0*16+ 7] = (start += ((w1 >> 20) & 0xfff)) + (0*16+ 7 +1); out[0*16+ 8] = (start += ((w1 >> 32) & 0xfff)) + (0*16+ 8 +1); out[0*16+ 9] = (start += ((w1 >> 44) & 0xfff)) + (0*16+ 9 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (start += ((w1 >> 56) | (w2 << 8) & 0xfff)) + (0*16+10 +1); out[0*16+11] = (start += ((w2 >> 4) & 0xfff)) + (0*16+11 +1); out[0*16+12] = (start += ((w2 >> 16) & 0xfff)) + (0*16+12 +1); out[0*16+13] = (start += ((w2 >> 28) & 0xfff)) + (0*16+13 +1); out[0*16+14] = (start += ((w2 >> 40) & 0xfff)) + (0*16+14 +1); out[0*16+15] = (start += ((w2 >> 52))) + (0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfff)) + (1*16+ 0 +1); out[1*16+ 1] = (start += ((w0 >> 12) & 0xfff)) + (1*16+ 1 +1); out[1*16+ 2] = (start += ((w0 >> 24) & 0xfff)) + (1*16+ 2 +1); out[1*16+ 3] = (start += ((w0 >> 36) & 0xfff)) + (1*16+ 3 +1); out[1*16+ 4] = (start += ((w0 >> 48) & 0xfff)) + (1*16+ 4 +1); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (start += ((w0 >> 60) | (w1 << 4) & 0xfff)) + (1*16+ 5 +1); out[1*16+ 6] = (start += ((w1 >> 8) & 0xfff)) + (1*16+ 6 +1); out[1*16+ 7] = (start += ((w1 >> 20) & 0xfff)) + (1*16+ 7 +1); out[1*16+ 8] = (start += ((w1 >> 32) & 0xfff)) + (1*16+ 8 +1); out[1*16+ 9] = (start += ((w1 >> 44) & 0xfff)) + (1*16+ 9 +1); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (start += ((w1 >> 56) | (w2 << 8) & 0xfff)) + (1*16+10 +1); out[1*16+11] = (start += ((w2 >> 4) & 0xfff)) + (1*16+11 +1); out[1*16+12] = (start += ((w2 >> 16) & 0xfff)) + (1*16+12 +1); out[1*16+13] = (start += ((w2 >> 28) & 0xfff)) + (1*16+13 +1); out[1*16+14] = (start += ((w2 >> 40) & 0xfff)) + (1*16+14 +1); out[1*16+15] = (start += ((w2 >> 52))) + (1*16+15 +1);;}; out += 32; start += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_13(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 13) & 0x1fff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 26) & 0x1fff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 39) & 0x1fff)) + (0*64+ 3 +1); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w0 >> 52) | (w1 << 12) & 0x1fff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w1 >> 1) & 0x1fff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w1 >> 14) & 0x1fff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w1 >> 27) & 0x1fff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w1 >> 40) & 0x1fff)) + (0*64+ 8 +1); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w1 >> 53) | (w2 << 11) & 0x1fff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w2 >> 2) & 0x1fff)) + (0*64+10 +1); out[0*64+11] = (start += ((w2 >> 15) & 0x1fff)) + (0*64+11 +1); out[0*64+12] = (start += ((w2 >> 28) & 0x1fff)) + (0*64+12 +1); out[0*64+13] = (start += ((w2 >> 41) & 0x1fff)) + (0*64+13 +1); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (start += ((w2 >> 54) | (w3 << 10) & 0x1fff)) + (0*64+14 +1); out[0*64+15] = (start += ((w3 >> 3) & 0x1fff)) + (0*64+15 +1); out[0*64+16] = (start += ((w3 >> 16) & 0x1fff)) + (0*64+16 +1); out[0*64+17] = (start += ((w3 >> 29) & 0x1fff)) + (0*64+17 +1); out[0*64+18] = (start += ((w3 >> 42) & 0x1fff)) + (0*64+18 +1); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (start += ((w3 >> 55) | (w4 << 9) & 0x1fff)) + (0*64+19 +1); out[0*64+20] = (start += ((w4 >> 4) & 0x1fff)) + (0*64+20 +1); out[0*64+21] = (start += ((w4 >> 17) & 0x1fff)) + (0*64+21 +1); out[0*64+22] = (start += ((w4 >> 30) & 0x1fff)) + (0*64+22 +1); out[0*64+23] = (start += ((w4 >> 43) & 0x1fff)) + (0*64+23 +1); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (start += ((w4 >> 56) | (w5 << 8) & 0x1fff)) + (0*64+24 +1); out[0*64+25] = (start += ((w5 >> 5) & 0x1fff)) + (0*64+25 +1); out[0*64+26] = (start += ((w5 >> 18) & 0x1fff)) + (0*64+26 +1); out[0*64+27] = (start += ((w5 >> 31) & 0x1fff)) + (0*64+27 +1); out[0*64+28] = (start += ((w5 >> 44) & 0x1fff)) + (0*64+28 +1); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (start += ((w5 >> 57) | (w6 << 7) & 0x1fff)) + (0*64+29 +1); out[0*64+30] = (start += ((w6 >> 6) & 0x1fff)) + (0*64+30 +1); out[0*64+31] = (start += ((w6 >> 19) & 0x1fff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_14(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fff)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 14) & 0x3fff)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 28) & 0x3fff)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 42) & 0x3fff)) + (0*32+ 3 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w0 >> 56) | (w1 << 8) & 0x3fff)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w1 >> 6) & 0x3fff)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w1 >> 20) & 0x3fff)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w1 >> 34) & 0x3fff)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w1 >> 48) & 0x3fff)) + (0*32+ 8 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w1 >> 62) | (w2 << 2) & 0x3fff)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w2 >> 12) & 0x3fff)) + (0*32+10 +1); out[0*32+11] = (start += ((w2 >> 26) & 0x3fff)) + (0*32+11 +1); out[0*32+12] = (start += ((w2 >> 40) & 0x3fff)) + (0*32+12 +1); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (start += ((w2 >> 54) | (w3 << 10) & 0x3fff)) + (0*32+13 +1); out[0*32+14] = (start += ((w3 >> 4) & 0x3fff)) + (0*32+14 +1); out[0*32+15] = (start += ((w3 >> 18) & 0x3fff)) + (0*32+15 +1); out[0*32+16] = (start += ((w3 >> 32) & 0x3fff)) + (0*32+16 +1); out[0*32+17] = (start += ((w3 >> 46) & 0x3fff)) + (0*32+17 +1); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (start += ((w3 >> 60) | (w4 << 4) & 0x3fff)) + (0*32+18 +1); out[0*32+19] = (start += ((w4 >> 10) & 0x3fff)) + (0*32+19 +1); out[0*32+20] = (start += ((w4 >> 24) & 0x3fff)) + (0*32+20 +1); out[0*32+21] = (start += ((w4 >> 38) & 0x3fff)) + (0*32+21 +1); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (start += ((w4 >> 52) | (w5 << 12) & 0x3fff)) + (0*32+22 +1); out[0*32+23] = (start += ((w5 >> 2) & 0x3fff)) + (0*32+23 +1); out[0*32+24] = (start += ((w5 >> 16) & 0x3fff)) + (0*32+24 +1); out[0*32+25] = (start += ((w5 >> 30) & 0x3fff)) + (0*32+25 +1); out[0*32+26] = (start += ((w5 >> 44) & 0x3fff)) + (0*32+26 +1); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (start += ((w5 >> 58) | (w6 << 6) & 0x3fff)) + (0*32+27 +1); out[0*32+28] = (start += ((w6 >> 8) & 0x3fff)) + (0*32+28 +1); out[0*32+29] = (start += ((w6 >> 22) & 0x3fff)) + (0*32+29 +1); out[0*32+30] = (start += ((w6 >> 36) & 0x3fff)) + (0*32+30 +1); out[0*32+31] = (start += ((w6 >> 50))) + (0*32+31 +1);;}; out += 32; start += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_15(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 15) & 0x7fff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 30) & 0x7fff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 45) & 0x7fff)) + (0*64+ 3 +1); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w0 >> 60) | (w1 << 4) & 0x7fff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w1 >> 11) & 0x7fff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w1 >> 26) & 0x7fff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w1 >> 41) & 0x7fff)) + (0*64+ 7 +1); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w1 >> 56) | (w2 << 8) & 0x7fff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w2 >> 7) & 0x7fff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w2 >> 22) & 0x7fff)) + (0*64+10 +1); out[0*64+11] = (start += ((w2 >> 37) & 0x7fff)) + (0*64+11 +1); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (start += ((w2 >> 52) | (w3 << 12) & 0x7fff)) + (0*64+12 +1); out[0*64+13] = (start += ((w3 >> 3) & 0x7fff)) + (0*64+13 +1); out[0*64+14] = (start += ((w3 >> 18) & 0x7fff)) + (0*64+14 +1); out[0*64+15] = (start += ((w3 >> 33) & 0x7fff)) + (0*64+15 +1); out[0*64+16] = (start += ((w3 >> 48) & 0x7fff)) + (0*64+16 +1); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (start += ((w3 >> 63) | (w4 << 1) & 0x7fff)) + (0*64+17 +1); out[0*64+18] = (start += ((w4 >> 14) & 0x7fff)) + (0*64+18 +1); out[0*64+19] = (start += ((w4 >> 29) & 0x7fff)) + (0*64+19 +1); out[0*64+20] = (start += ((w4 >> 44) & 0x7fff)) + (0*64+20 +1); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (start += ((w4 >> 59) | (w5 << 5) & 0x7fff)) + (0*64+21 +1); out[0*64+22] = (start += ((w5 >> 10) & 0x7fff)) + (0*64+22 +1); out[0*64+23] = (start += ((w5 >> 25) & 0x7fff)) + (0*64+23 +1); out[0*64+24] = (start += ((w5 >> 40) & 0x7fff)) + (0*64+24 +1); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (start += ((w5 >> 55) | (w6 << 9) & 0x7fff)) + (0*64+25 +1); out[0*64+26] = (start += ((w6 >> 6) & 0x7fff)) + (0*64+26 +1); out[0*64+27] = (start += ((w6 >> 21) & 0x7fff)) + (0*64+27 +1); out[0*64+28] = (start += ((w6 >> 36) & 0x7fff)) + (0*64+28 +1); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (start += ((w6 >> 51) | (w7 << 13) & 0x7fff)) + (0*64+29 +1); out[0*64+30] = (start += ((w7 >> 2) & 0x7fff)) + (0*64+30 +1); out[0*64+31] = (start += ((w7 >> 17) & 0x7fff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack16_16(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = (start += (*(uint16_t *)(in+0*8+ 0))) + (0*4+ 0 +1); out[0*4+ 1] = (start += (*(uint16_t *)(in+0*8+ 2))) + (0*4+ 1 +1); out[0*4+ 2] = (start += (*(uint16_t *)(in+0*8+ 4))) + (0*4+ 2 +1); out[0*4+ 3] = (start += (*(uint16_t *)(in+0*8+ 6))) + (0*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = (start += (*(uint16_t *)(in+1*8+ 0))) + (1*4+ 0 +1); out[1*4+ 1] = (start += (*(uint16_t *)(in+1*8+ 2))) + (1*4+ 1 +1); out[1*4+ 2] = (start += (*(uint16_t *)(in+1*8+ 4))) + (1*4+ 2 +1); out[1*4+ 3] = (start += (*(uint16_t *)(in+1*8+ 6))) + (1*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = (start += (*(uint16_t *)(in+2*8+ 0))) + (2*4+ 0 +1); out[2*4+ 1] = (start += (*(uint16_t *)(in+2*8+ 2))) + (2*4+ 1 +1); out[2*4+ 2] = (start += (*(uint16_t *)(in+2*8+ 4))) + (2*4+ 2 +1); out[2*4+ 3] = (start += (*(uint16_t *)(in+2*8+ 6))) + (2*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = (start += (*(uint16_t *)(in+3*8+ 0))) + (3*4+ 0 +1); out[3*4+ 1] = (start += (*(uint16_t *)(in+3*8+ 2))) + (3*4+ 1 +1); out[3*4+ 2] = (start += (*(uint16_t *)(in+3*8+ 4))) + (3*4+ 2 +1); out[3*4+ 3] = (start += (*(uint16_t *)(in+3*8+ 6))) + (3*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = (start += (*(uint16_t *)(in+4*8+ 0))) + (4*4+ 0 +1); out[4*4+ 1] = (start += (*(uint16_t *)(in+4*8+ 2))) + (4*4+ 1 +1); out[4*4+ 2] = (start += (*(uint16_t *)(in+4*8+ 4))) + (4*4+ 2 +1); out[4*4+ 3] = (start += (*(uint16_t *)(in+4*8+ 6))) + (4*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = (start += (*(uint16_t *)(in+5*8+ 0))) + (5*4+ 0 +1); out[5*4+ 1] = (start += (*(uint16_t *)(in+5*8+ 2))) + (5*4+ 1 +1); out[5*4+ 2] = (start += (*(uint16_t *)(in+5*8+ 4))) + (5*4+ 2 +1); out[5*4+ 3] = (start += (*(uint16_t *)(in+5*8+ 6))) + (5*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = (start += (*(uint16_t *)(in+6*8+ 0))) + (6*4+ 0 +1); out[6*4+ 1] = (start += (*(uint16_t *)(in+6*8+ 2))) + (6*4+ 1 +1); out[6*4+ 2] = (start += (*(uint16_t *)(in+6*8+ 4))) + (6*4+ 2 +1); out[6*4+ 3] = (start += (*(uint16_t *)(in+6*8+ 6))) + (6*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = (start += (*(uint16_t *)(in+7*8+ 0))) + (7*4+ 0 +1); out[7*4+ 1] = (start += (*(uint16_t *)(in+7*8+ 2))) + (7*4+ 1 +1); out[7*4+ 2] = (start += (*(uint16_t *)(in+7*8+ 4))) + (7*4+ 2 +1); out[7*4+ 3] = (start += (*(uint16_t *)(in+7*8+ 6))) + (7*4+ 3 +1);;}; out += 32; start += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D16 bitd1unpacka16[] = {
  &bitd1unpack16_0,
  &bitd1unpack16_1,
  &bitd1unpack16_2,
  &bitd1unpack16_3,
  &bitd1unpack16_4,
  &bitd1unpack16_5,
  &bitd1unpack16_6,
  &bitd1unpack16_7,
  &bitd1unpack16_8,
  &bitd1unpack16_9,
  &bitd1unpack16_10,
  &bitd1unpack16_11,
  &bitd1unpack16_12,
  &bitd1unpack16_13,
  &bitd1unpack16_14,
  &bitd1unpack16_15,
  &bitd1unpack16_16
};
unsigned char *bitd1unpack16( const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start, unsigned b) { return bitd1unpacka16[ b](in, n, out, start); }
unsigned char *bitd1unpack32_0(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint32_t *out_ = out+n; do { { { out[0*0+ 0] = (start += (0)) + (0*0+ 0 +1); out[0*0+ 1] = (start += (0)) + (0*0+ 1 +1); out[0*0+ 2] = (start += (0)) + (0*0+ 2 +1); out[0*0+ 3] = (start += (0)) + (0*0+ 3 +1); out[0*0+ 4] = (start += (0)) + (0*0+ 4 +1); out[0*0+ 5] = (start += (0)) + (0*0+ 5 +1); out[0*0+ 6] = (start += (0)) + (0*0+ 6 +1); out[0*0+ 7] = (start += (0)) + (0*0+ 7 +1); out[0*0+ 8] = (start += (0)) + (0*0+ 8 +1); out[0*0+ 9] = (start += (0)) + (0*0+ 9 +1); out[0*0+10] = (start += (0)) + (0*0+10 +1); out[0*0+11] = (start += (0)) + (0*0+11 +1); out[0*0+12] = (start += (0)) + (0*0+12 +1); out[0*0+13] = (start += (0)) + (0*0+13 +1); out[0*0+14] = (start += (0)) + (0*0+14 +1); out[0*0+15] = (start += (0)) + (0*0+15 +1); out[0*0+16] = (start += (0)) + (0*0+16 +1); out[0*0+17] = (start += (0)) + (0*0+17 +1); out[0*0+18] = (start += (0)) + (0*0+18 +1); out[0*0+19] = (start += (0)) + (0*0+19 +1); out[0*0+20] = (start += (0)) + (0*0+20 +1); out[0*0+21] = (start += (0)) + (0*0+21 +1); out[0*0+22] = (start += (0)) + (0*0+22 +1); out[0*0+23] = (start += (0)) + (0*0+23 +1); out[0*0+24] = (start += (0)) + (0*0+24 +1); out[0*0+25] = (start += (0)) + (0*0+25 +1); out[0*0+26] = (start += (0)) + (0*0+26 +1); out[0*0+27] = (start += (0)) + (0*0+27 +1); out[0*0+28] = (start += (0)) + (0*0+28 +1); out[0*0+29] = (start += (0)) + (0*0+29 +1); out[0*0+30] = (start += (0)) + (0*0+30 +1); out[0*0+31] = (start += (0)) + (0*0+31 +1);;}; out += 32; start += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitd1unpack32_1(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x1)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 1) & 0x1)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 2) & 0x1)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 3) & 0x1)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 4) & 0x1)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 5) & 0x1)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w0 >> 6) & 0x1)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w0 >> 7) & 0x1)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w0 >> 8) & 0x1)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w0 >> 9) & 0x1)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w0 >> 10) & 0x1)) + (0*32+10 +1); out[0*32+11] = (start += ((w0 >> 11) & 0x1)) + (0*32+11 +1); out[0*32+12] = (start += ((w0 >> 12) & 0x1)) + (0*32+12 +1); out[0*32+13] = (start += ((w0 >> 13) & 0x1)) + (0*32+13 +1); out[0*32+14] = (start += ((w0 >> 14) & 0x1)) + (0*32+14 +1); out[0*32+15] = (start += ((w0 >> 15) & 0x1)) + (0*32+15 +1); out[0*32+16] = (start += ((w0 >> 16) & 0x1)) + (0*32+16 +1); out[0*32+17] = (start += ((w0 >> 17) & 0x1)) + (0*32+17 +1); out[0*32+18] = (start += ((w0 >> 18) & 0x1)) + (0*32+18 +1); out[0*32+19] = (start += ((w0 >> 19) & 0x1)) + (0*32+19 +1); out[0*32+20] = (start += ((w0 >> 20) & 0x1)) + (0*32+20 +1); out[0*32+21] = (start += ((w0 >> 21) & 0x1)) + (0*32+21 +1); out[0*32+22] = (start += ((w0 >> 22) & 0x1)) + (0*32+22 +1); out[0*32+23] = (start += ((w0 >> 23) & 0x1)) + (0*32+23 +1); out[0*32+24] = (start += ((w0 >> 24) & 0x1)) + (0*32+24 +1); out[0*32+25] = (start += ((w0 >> 25) & 0x1)) + (0*32+25 +1); out[0*32+26] = (start += ((w0 >> 26) & 0x1)) + (0*32+26 +1); out[0*32+27] = (start += ((w0 >> 27) & 0x1)) + (0*32+27 +1); out[0*32+28] = (start += ((w0 >> 28) & 0x1)) + (0*32+28 +1); out[0*32+29] = (start += ((w0 >> 29) & 0x1)) + (0*32+29 +1); out[0*32+30] = (start += ((w0 >> 30) & 0x1)) + (0*32+30 +1); out[0*32+31] = (start += ((w0 >> 31))) + (0*32+31 +1);;}; out += 32; start += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_2(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 2) & 0x3)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 4) & 0x3)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 6) & 0x3)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 8) & 0x3)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 10) & 0x3)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w0 >> 12) & 0x3)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w0 >> 14) & 0x3)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w0 >> 16) & 0x3)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w0 >> 18) & 0x3)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w0 >> 20) & 0x3)) + (0*32+10 +1); out[0*32+11] = (start += ((w0 >> 22) & 0x3)) + (0*32+11 +1); out[0*32+12] = (start += ((w0 >> 24) & 0x3)) + (0*32+12 +1); out[0*32+13] = (start += ((w0 >> 26) & 0x3)) + (0*32+13 +1); out[0*32+14] = (start += ((w0 >> 28) & 0x3)) + (0*32+14 +1); out[0*32+15] = (start += ((w0 >> 30) & 0x3)) + (0*32+15 +1); out[0*32+16] = (start += ((w0 >> 32) & 0x3)) + (0*32+16 +1); out[0*32+17] = (start += ((w0 >> 34) & 0x3)) + (0*32+17 +1); out[0*32+18] = (start += ((w0 >> 36) & 0x3)) + (0*32+18 +1); out[0*32+19] = (start += ((w0 >> 38) & 0x3)) + (0*32+19 +1); out[0*32+20] = (start += ((w0 >> 40) & 0x3)) + (0*32+20 +1); out[0*32+21] = (start += ((w0 >> 42) & 0x3)) + (0*32+21 +1); out[0*32+22] = (start += ((w0 >> 44) & 0x3)) + (0*32+22 +1); out[0*32+23] = (start += ((w0 >> 46) & 0x3)) + (0*32+23 +1); out[0*32+24] = (start += ((w0 >> 48) & 0x3)) + (0*32+24 +1); out[0*32+25] = (start += ((w0 >> 50) & 0x3)) + (0*32+25 +1); out[0*32+26] = (start += ((w0 >> 52) & 0x3)) + (0*32+26 +1); out[0*32+27] = (start += ((w0 >> 54) & 0x3)) + (0*32+27 +1); out[0*32+28] = (start += ((w0 >> 56) & 0x3)) + (0*32+28 +1); out[0*32+29] = (start += ((w0 >> 58) & 0x3)) + (0*32+29 +1); out[0*32+30] = (start += ((w0 >> 60) & 0x3)) + (0*32+30 +1); out[0*32+31] = (start += ((w0 >> 62))) + (0*32+31 +1);;}; out += 32; start += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_3(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 3) & 0x7)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 6) & 0x7)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 9) & 0x7)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 12) & 0x7)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 15) & 0x7)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 18) & 0x7)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w0 >> 21) & 0x7)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w0 >> 24) & 0x7)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w0 >> 27) & 0x7)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w0 >> 30) & 0x7)) + (0*64+10 +1); out[0*64+11] = (start += ((w0 >> 33) & 0x7)) + (0*64+11 +1); out[0*64+12] = (start += ((w0 >> 36) & 0x7)) + (0*64+12 +1); out[0*64+13] = (start += ((w0 >> 39) & 0x7)) + (0*64+13 +1); out[0*64+14] = (start += ((w0 >> 42) & 0x7)) + (0*64+14 +1); out[0*64+15] = (start += ((w0 >> 45) & 0x7)) + (0*64+15 +1); out[0*64+16] = (start += ((w0 >> 48) & 0x7)) + (0*64+16 +1); out[0*64+17] = (start += ((w0 >> 51) & 0x7)) + (0*64+17 +1); out[0*64+18] = (start += ((w0 >> 54) & 0x7)) + (0*64+18 +1); out[0*64+19] = (start += ((w0 >> 57) & 0x7)) + (0*64+19 +1); out[0*64+20] = (start += ((w0 >> 60) & 0x7)) + (0*64+20 +1); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start += ((w0 >> 63) | (w1 << 1) & 0x7)) + (0*64+21 +1); out[0*64+22] = (start += ((w1 >> 2) & 0x7)) + (0*64+22 +1); out[0*64+23] = (start += ((w1 >> 5) & 0x7)) + (0*64+23 +1); out[0*64+24] = (start += ((w1 >> 8) & 0x7)) + (0*64+24 +1); out[0*64+25] = (start += ((w1 >> 11) & 0x7)) + (0*64+25 +1); out[0*64+26] = (start += ((w1 >> 14) & 0x7)) + (0*64+26 +1); out[0*64+27] = (start += ((w1 >> 17) & 0x7)) + (0*64+27 +1); out[0*64+28] = (start += ((w1 >> 20) & 0x7)) + (0*64+28 +1); out[0*64+29] = (start += ((w1 >> 23) & 0x7)) + (0*64+29 +1); out[0*64+30] = (start += ((w1 >> 26) & 0x7)) + (0*64+30 +1); out[0*64+31] = (start += ((w1 >> 29) & 0x7)) + (0*64+31 +1);;}; out += 32; start += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_4(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xf)) + (0*16+ 0 +1); out[0*16+ 1] = (start += ((w0 >> 4) & 0xf)) + (0*16+ 1 +1); out[0*16+ 2] = (start += ((w0 >> 8) & 0xf)) + (0*16+ 2 +1); out[0*16+ 3] = (start += ((w0 >> 12) & 0xf)) + (0*16+ 3 +1); out[0*16+ 4] = (start += ((w0 >> 16) & 0xf)) + (0*16+ 4 +1); out[0*16+ 5] = (start += ((w0 >> 20) & 0xf)) + (0*16+ 5 +1); out[0*16+ 6] = (start += ((w0 >> 24) & 0xf)) + (0*16+ 6 +1); out[0*16+ 7] = (start += ((w0 >> 28) & 0xf)) + (0*16+ 7 +1); out[0*16+ 8] = (start += ((w0 >> 32) & 0xf)) + (0*16+ 8 +1); out[0*16+ 9] = (start += ((w0 >> 36) & 0xf)) + (0*16+ 9 +1); out[0*16+10] = (start += ((w0 >> 40) & 0xf)) + (0*16+10 +1); out[0*16+11] = (start += ((w0 >> 44) & 0xf)) + (0*16+11 +1); out[0*16+12] = (start += ((w0 >> 48) & 0xf)) + (0*16+12 +1); out[0*16+13] = (start += ((w0 >> 52) & 0xf)) + (0*16+13 +1); out[0*16+14] = (start += ((w0 >> 56) & 0xf)) + (0*16+14 +1); out[0*16+15] = (start += ((w0 >> 60))) + (0*16+15 +1);;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xf)) + (1*16+ 0 +1); out[1*16+ 1] = (start += ((w0 >> 4) & 0xf)) + (1*16+ 1 +1); out[1*16+ 2] = (start += ((w0 >> 8) & 0xf)) + (1*16+ 2 +1); out[1*16+ 3] = (start += ((w0 >> 12) & 0xf)) + (1*16+ 3 +1); out[1*16+ 4] = (start += ((w0 >> 16) & 0xf)) + (1*16+ 4 +1); out[1*16+ 5] = (start += ((w0 >> 20) & 0xf)) + (1*16+ 5 +1); out[1*16+ 6] = (start += ((w0 >> 24) & 0xf)) + (1*16+ 6 +1); out[1*16+ 7] = (start += ((w0 >> 28) & 0xf)) + (1*16+ 7 +1); out[1*16+ 8] = (start += ((w0 >> 32) & 0xf)) + (1*16+ 8 +1); out[1*16+ 9] = (start += ((w0 >> 36) & 0xf)) + (1*16+ 9 +1); out[1*16+10] = (start += ((w0 >> 40) & 0xf)) + (1*16+10 +1); out[1*16+11] = (start += ((w0 >> 44) & 0xf)) + (1*16+11 +1); out[1*16+12] = (start += ((w0 >> 48) & 0xf)) + (1*16+12 +1); out[1*16+13] = (start += ((w0 >> 52) & 0xf)) + (1*16+13 +1); out[1*16+14] = (start += ((w0 >> 56) & 0xf)) + (1*16+14 +1); out[1*16+15] = (start += ((w0 >> 60))) + (1*16+15 +1);;}; out += 32; start += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_5(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1f)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 5) & 0x1f)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 10) & 0x1f)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 15) & 0x1f)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 20) & 0x1f)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 25) & 0x1f)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 30) & 0x1f)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w0 >> 35) & 0x1f)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w0 >> 40) & 0x1f)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w0 >> 45) & 0x1f)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w0 >> 50) & 0x1f)) + (0*64+10 +1); out[0*64+11] = (start += ((w0 >> 55) & 0x1f)) + (0*64+11 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start += ((w0 >> 60) | (w1 << 4) & 0x1f)) + (0*64+12 +1); out[0*64+13] = (start += ((w1 >> 1) & 0x1f)) + (0*64+13 +1); out[0*64+14] = (start += ((w1 >> 6) & 0x1f)) + (0*64+14 +1); out[0*64+15] = (start += ((w1 >> 11) & 0x1f)) + (0*64+15 +1); out[0*64+16] = (start += ((w1 >> 16) & 0x1f)) + (0*64+16 +1); out[0*64+17] = (start += ((w1 >> 21) & 0x1f)) + (0*64+17 +1); out[0*64+18] = (start += ((w1 >> 26) & 0x1f)) + (0*64+18 +1); out[0*64+19] = (start += ((w1 >> 31) & 0x1f)) + (0*64+19 +1); out[0*64+20] = (start += ((w1 >> 36) & 0x1f)) + (0*64+20 +1); out[0*64+21] = (start += ((w1 >> 41) & 0x1f)) + (0*64+21 +1); out[0*64+22] = (start += ((w1 >> 46) & 0x1f)) + (0*64+22 +1); out[0*64+23] = (start += ((w1 >> 51) & 0x1f)) + (0*64+23 +1); out[0*64+24] = (start += ((w1 >> 56) & 0x1f)) + (0*64+24 +1); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start += ((w1 >> 61) | (w2 << 3) & 0x1f)) + (0*64+25 +1); out[0*64+26] = (start += ((w2 >> 2) & 0x1f)) + (0*64+26 +1); out[0*64+27] = (start += ((w2 >> 7) & 0x1f)) + (0*64+27 +1); out[0*64+28] = (start += ((w2 >> 12) & 0x1f)) + (0*64+28 +1); out[0*64+29] = (start += ((w2 >> 17) & 0x1f)) + (0*64+29 +1); out[0*64+30] = (start += ((w2 >> 22) & 0x1f)) + (0*64+30 +1); out[0*64+31] = (start += ((w2 >> 27) & 0x1f)) + (0*64+31 +1);;}; out += 32; start += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_6(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3f)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 6) & 0x3f)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 12) & 0x3f)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 18) & 0x3f)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 24) & 0x3f)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 30) & 0x3f)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w0 >> 36) & 0x3f)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w0 >> 42) & 0x3f)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w0 >> 48) & 0x3f)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w0 >> 54) & 0x3f)) + (0*32+ 9 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start += ((w0 >> 60) | (w1 << 4) & 0x3f)) + (0*32+10 +1); out[0*32+11] = (start += ((w1 >> 2) & 0x3f)) + (0*32+11 +1); out[0*32+12] = (start += ((w1 >> 8) & 0x3f)) + (0*32+12 +1); out[0*32+13] = (start += ((w1 >> 14) & 0x3f)) + (0*32+13 +1); out[0*32+14] = (start += ((w1 >> 20) & 0x3f)) + (0*32+14 +1); out[0*32+15] = (start += ((w1 >> 26) & 0x3f)) + (0*32+15 +1); out[0*32+16] = (start += ((w1 >> 32) & 0x3f)) + (0*32+16 +1); out[0*32+17] = (start += ((w1 >> 38) & 0x3f)) + (0*32+17 +1); out[0*32+18] = (start += ((w1 >> 44) & 0x3f)) + (0*32+18 +1); out[0*32+19] = (start += ((w1 >> 50) & 0x3f)) + (0*32+19 +1); out[0*32+20] = (start += ((w1 >> 56) & 0x3f)) + (0*32+20 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start += ((w1 >> 62) | (w2 << 2) & 0x3f)) + (0*32+21 +1); out[0*32+22] = (start += ((w2 >> 4) & 0x3f)) + (0*32+22 +1); out[0*32+23] = (start += ((w2 >> 10) & 0x3f)) + (0*32+23 +1); out[0*32+24] = (start += ((w2 >> 16) & 0x3f)) + (0*32+24 +1); out[0*32+25] = (start += ((w2 >> 22) & 0x3f)) + (0*32+25 +1); out[0*32+26] = (start += ((w2 >> 28) & 0x3f)) + (0*32+26 +1); out[0*32+27] = (start += ((w2 >> 34) & 0x3f)) + (0*32+27 +1); out[0*32+28] = (start += ((w2 >> 40) & 0x3f)) + (0*32+28 +1); out[0*32+29] = (start += ((w2 >> 46) & 0x3f)) + (0*32+29 +1); out[0*32+30] = (start += ((w2 >> 52) & 0x3f)) + (0*32+30 +1); out[0*32+31] = (start += ((w2 >> 58))) + (0*32+31 +1);;}; out += 32; start += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_7(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7f)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 7) & 0x7f)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 14) & 0x7f)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 21) & 0x7f)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 28) & 0x7f)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 35) & 0x7f)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 42) & 0x7f)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w0 >> 49) & 0x7f)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w0 >> 56) & 0x7f)) + (0*64+ 8 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w0 >> 63) | (w1 << 1) & 0x7f)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w1 >> 6) & 0x7f)) + (0*64+10 +1); out[0*64+11] = (start += ((w1 >> 13) & 0x7f)) + (0*64+11 +1); out[0*64+12] = (start += ((w1 >> 20) & 0x7f)) + (0*64+12 +1); out[0*64+13] = (start += ((w1 >> 27) & 0x7f)) + (0*64+13 +1); out[0*64+14] = (start += ((w1 >> 34) & 0x7f)) + (0*64+14 +1); out[0*64+15] = (start += ((w1 >> 41) & 0x7f)) + (0*64+15 +1); out[0*64+16] = (start += ((w1 >> 48) & 0x7f)) + (0*64+16 +1); out[0*64+17] = (start += ((w1 >> 55) & 0x7f)) + (0*64+17 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start += ((w1 >> 62) | (w2 << 2) & 0x7f)) + (0*64+18 +1); out[0*64+19] = (start += ((w2 >> 5) & 0x7f)) + (0*64+19 +1); out[0*64+20] = (start += ((w2 >> 12) & 0x7f)) + (0*64+20 +1); out[0*64+21] = (start += ((w2 >> 19) & 0x7f)) + (0*64+21 +1); out[0*64+22] = (start += ((w2 >> 26) & 0x7f)) + (0*64+22 +1); out[0*64+23] = (start += ((w2 >> 33) & 0x7f)) + (0*64+23 +1); out[0*64+24] = (start += ((w2 >> 40) & 0x7f)) + (0*64+24 +1); out[0*64+25] = (start += ((w2 >> 47) & 0x7f)) + (0*64+25 +1); out[0*64+26] = (start += ((w2 >> 54) & 0x7f)) + (0*64+26 +1); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start += ((w2 >> 61) | (w3 << 3) & 0x7f)) + (0*64+27 +1); out[0*64+28] = (start += ((w3 >> 4) & 0x7f)) + (0*64+28 +1); out[0*64+29] = (start += ((w3 >> 11) & 0x7f)) + (0*64+29 +1); out[0*64+30] = (start += ((w3 >> 18) & 0x7f)) + (0*64+30 +1); out[0*64+31] = (start += ((w3 >> 25) & 0x7f)) + (0*64+31 +1);;}; out += 32; start += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_8(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xff)) + (0*8+ 0 +1); out[0*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (0*8+ 1 +1); out[0*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (0*8+ 2 +1); out[0*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (0*8+ 3 +1); out[0*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (0*8+ 4 +1); out[0*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (0*8+ 5 +1); out[0*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (0*8+ 6 +1); out[0*8+ 7] = (start += ((w0 >> 56))) + (0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xff)) + (1*8+ 0 +1); out[1*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (1*8+ 1 +1); out[1*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (1*8+ 2 +1); out[1*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (1*8+ 3 +1); out[1*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (1*8+ 4 +1); out[1*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (1*8+ 5 +1); out[1*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (1*8+ 6 +1); out[1*8+ 7] = (start += ((w0 >> 56))) + (1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xff)) + (2*8+ 0 +1); out[2*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (2*8+ 1 +1); out[2*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (2*8+ 2 +1); out[2*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (2*8+ 3 +1); out[2*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (2*8+ 4 +1); out[2*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (2*8+ 5 +1); out[2*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (2*8+ 6 +1); out[2*8+ 7] = (start += ((w0 >> 56))) + (2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xff)) + (3*8+ 0 +1); out[3*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (3*8+ 1 +1); out[3*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (3*8+ 2 +1); out[3*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (3*8+ 3 +1); out[3*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (3*8+ 4 +1); out[3*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (3*8+ 5 +1); out[3*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (3*8+ 6 +1); out[3*8+ 7] = (start += ((w0 >> 56))) + (3*8+ 7 +1);;}; out += 32; start += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_9(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 9) & 0x1ff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 18) & 0x1ff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 27) & 0x1ff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 36) & 0x1ff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 45) & 0x1ff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 54) & 0x1ff)) + (0*64+ 6 +1); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w0 >> 63) | (w1 << 1) & 0x1ff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w1 >> 8) & 0x1ff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w1 >> 17) & 0x1ff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w1 >> 26) & 0x1ff)) + (0*64+10 +1); out[0*64+11] = (start += ((w1 >> 35) & 0x1ff)) + (0*64+11 +1); out[0*64+12] = (start += ((w1 >> 44) & 0x1ff)) + (0*64+12 +1); out[0*64+13] = (start += ((w1 >> 53) & 0x1ff)) + (0*64+13 +1); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (start += ((w1 >> 62) | (w2 << 2) & 0x1ff)) + (0*64+14 +1); out[0*64+15] = (start += ((w2 >> 7) & 0x1ff)) + (0*64+15 +1); out[0*64+16] = (start += ((w2 >> 16) & 0x1ff)) + (0*64+16 +1); out[0*64+17] = (start += ((w2 >> 25) & 0x1ff)) + (0*64+17 +1); out[0*64+18] = (start += ((w2 >> 34) & 0x1ff)) + (0*64+18 +1); out[0*64+19] = (start += ((w2 >> 43) & 0x1ff)) + (0*64+19 +1); out[0*64+20] = (start += ((w2 >> 52) & 0x1ff)) + (0*64+20 +1); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (start += ((w2 >> 61) | (w3 << 3) & 0x1ff)) + (0*64+21 +1); out[0*64+22] = (start += ((w3 >> 6) & 0x1ff)) + (0*64+22 +1); out[0*64+23] = (start += ((w3 >> 15) & 0x1ff)) + (0*64+23 +1); out[0*64+24] = (start += ((w3 >> 24) & 0x1ff)) + (0*64+24 +1); out[0*64+25] = (start += ((w3 >> 33) & 0x1ff)) + (0*64+25 +1); out[0*64+26] = (start += ((w3 >> 42) & 0x1ff)) + (0*64+26 +1); out[0*64+27] = (start += ((w3 >> 51) & 0x1ff)) + (0*64+27 +1); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (start += ((w3 >> 60) | (w4 << 4) & 0x1ff)) + (0*64+28 +1); out[0*64+29] = (start += ((w4 >> 5) & 0x1ff)) + (0*64+29 +1); out[0*64+30] = (start += ((w4 >> 14) & 0x1ff)) + (0*64+30 +1); out[0*64+31] = (start += ((w4 >> 23) & 0x1ff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_10(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ff)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 10) & 0x3ff)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 20) & 0x3ff)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 30) & 0x3ff)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 40) & 0x3ff)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 50) & 0x3ff)) + (0*32+ 5 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w0 >> 60) | (w1 << 4) & 0x3ff)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w1 >> 6) & 0x3ff)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w1 >> 16) & 0x3ff)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w1 >> 26) & 0x3ff)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w1 >> 36) & 0x3ff)) + (0*32+10 +1); out[0*32+11] = (start += ((w1 >> 46) & 0x3ff)) + (0*32+11 +1); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (start += ((w1 >> 56) | (w2 << 8) & 0x3ff)) + (0*32+12 +1); out[0*32+13] = (start += ((w2 >> 2) & 0x3ff)) + (0*32+13 +1); out[0*32+14] = (start += ((w2 >> 12) & 0x3ff)) + (0*32+14 +1); out[0*32+15] = (start += ((w2 >> 22) & 0x3ff)) + (0*32+15 +1); out[0*32+16] = (start += ((w2 >> 32) & 0x3ff)) + (0*32+16 +1); out[0*32+17] = (start += ((w2 >> 42) & 0x3ff)) + (0*32+17 +1); out[0*32+18] = (start += ((w2 >> 52) & 0x3ff)) + (0*32+18 +1); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (start += ((w2 >> 62) | (w3 << 2) & 0x3ff)) + (0*32+19 +1); out[0*32+20] = (start += ((w3 >> 8) & 0x3ff)) + (0*32+20 +1); out[0*32+21] = (start += ((w3 >> 18) & 0x3ff)) + (0*32+21 +1); out[0*32+22] = (start += ((w3 >> 28) & 0x3ff)) + (0*32+22 +1); out[0*32+23] = (start += ((w3 >> 38) & 0x3ff)) + (0*32+23 +1); out[0*32+24] = (start += ((w3 >> 48) & 0x3ff)) + (0*32+24 +1); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (start += ((w3 >> 58) | (w4 << 6) & 0x3ff)) + (0*32+25 +1); out[0*32+26] = (start += ((w4 >> 4) & 0x3ff)) + (0*32+26 +1); out[0*32+27] = (start += ((w4 >> 14) & 0x3ff)) + (0*32+27 +1); out[0*32+28] = (start += ((w4 >> 24) & 0x3ff)) + (0*32+28 +1); out[0*32+29] = (start += ((w4 >> 34) & 0x3ff)) + (0*32+29 +1); out[0*32+30] = (start += ((w4 >> 44) & 0x3ff)) + (0*32+30 +1); out[0*32+31] = (start += ((w4 >> 54))) + (0*32+31 +1);;}; out += 32; start += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_11(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 11) & 0x7ff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 22) & 0x7ff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 33) & 0x7ff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 44) & 0x7ff)) + (0*64+ 4 +1); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w0 >> 55) | (w1 << 9) & 0x7ff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w1 >> 2) & 0x7ff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w1 >> 13) & 0x7ff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w1 >> 24) & 0x7ff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w1 >> 35) & 0x7ff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w1 >> 46) & 0x7ff)) + (0*64+10 +1); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (start += ((w1 >> 57) | (w2 << 7) & 0x7ff)) + (0*64+11 +1); out[0*64+12] = (start += ((w2 >> 4) & 0x7ff)) + (0*64+12 +1); out[0*64+13] = (start += ((w2 >> 15) & 0x7ff)) + (0*64+13 +1); out[0*64+14] = (start += ((w2 >> 26) & 0x7ff)) + (0*64+14 +1); out[0*64+15] = (start += ((w2 >> 37) & 0x7ff)) + (0*64+15 +1); out[0*64+16] = (start += ((w2 >> 48) & 0x7ff)) + (0*64+16 +1); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (start += ((w2 >> 59) | (w3 << 5) & 0x7ff)) + (0*64+17 +1); out[0*64+18] = (start += ((w3 >> 6) & 0x7ff)) + (0*64+18 +1); out[0*64+19] = (start += ((w3 >> 17) & 0x7ff)) + (0*64+19 +1); out[0*64+20] = (start += ((w3 >> 28) & 0x7ff)) + (0*64+20 +1); out[0*64+21] = (start += ((w3 >> 39) & 0x7ff)) + (0*64+21 +1); out[0*64+22] = (start += ((w3 >> 50) & 0x7ff)) + (0*64+22 +1); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (start += ((w3 >> 61) | (w4 << 3) & 0x7ff)) + (0*64+23 +1); out[0*64+24] = (start += ((w4 >> 8) & 0x7ff)) + (0*64+24 +1); out[0*64+25] = (start += ((w4 >> 19) & 0x7ff)) + (0*64+25 +1); out[0*64+26] = (start += ((w4 >> 30) & 0x7ff)) + (0*64+26 +1); out[0*64+27] = (start += ((w4 >> 41) & 0x7ff)) + (0*64+27 +1); out[0*64+28] = (start += ((w4 >> 52) & 0x7ff)) + (0*64+28 +1); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (start += ((w4 >> 63) | (w5 << 1) & 0x7ff)) + (0*64+29 +1); out[0*64+30] = (start += ((w5 >> 10) & 0x7ff)) + (0*64+30 +1); out[0*64+31] = (start += ((w5 >> 21) & 0x7ff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_12(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfff)) + (0*16+ 0 +1); out[0*16+ 1] = (start += ((w0 >> 12) & 0xfff)) + (0*16+ 1 +1); out[0*16+ 2] = (start += ((w0 >> 24) & 0xfff)) + (0*16+ 2 +1); out[0*16+ 3] = (start += ((w0 >> 36) & 0xfff)) + (0*16+ 3 +1); out[0*16+ 4] = (start += ((w0 >> 48) & 0xfff)) + (0*16+ 4 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (start += ((w0 >> 60) | (w1 << 4) & 0xfff)) + (0*16+ 5 +1); out[0*16+ 6] = (start += ((w1 >> 8) & 0xfff)) + (0*16+ 6 +1); out[0*16+ 7] = (start += ((w1 >> 20) & 0xfff)) + (0*16+ 7 +1); out[0*16+ 8] = (start += ((w1 >> 32) & 0xfff)) + (0*16+ 8 +1); out[0*16+ 9] = (start += ((w1 >> 44) & 0xfff)) + (0*16+ 9 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (start += ((w1 >> 56) | (w2 << 8) & 0xfff)) + (0*16+10 +1); out[0*16+11] = (start += ((w2 >> 4) & 0xfff)) + (0*16+11 +1); out[0*16+12] = (start += ((w2 >> 16) & 0xfff)) + (0*16+12 +1); out[0*16+13] = (start += ((w2 >> 28) & 0xfff)) + (0*16+13 +1); out[0*16+14] = (start += ((w2 >> 40) & 0xfff)) + (0*16+14 +1); out[0*16+15] = (start += ((w2 >> 52))) + (0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfff)) + (1*16+ 0 +1); out[1*16+ 1] = (start += ((w0 >> 12) & 0xfff)) + (1*16+ 1 +1); out[1*16+ 2] = (start += ((w0 >> 24) & 0xfff)) + (1*16+ 2 +1); out[1*16+ 3] = (start += ((w0 >> 36) & 0xfff)) + (1*16+ 3 +1); out[1*16+ 4] = (start += ((w0 >> 48) & 0xfff)) + (1*16+ 4 +1); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (start += ((w0 >> 60) | (w1 << 4) & 0xfff)) + (1*16+ 5 +1); out[1*16+ 6] = (start += ((w1 >> 8) & 0xfff)) + (1*16+ 6 +1); out[1*16+ 7] = (start += ((w1 >> 20) & 0xfff)) + (1*16+ 7 +1); out[1*16+ 8] = (start += ((w1 >> 32) & 0xfff)) + (1*16+ 8 +1); out[1*16+ 9] = (start += ((w1 >> 44) & 0xfff)) + (1*16+ 9 +1); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (start += ((w1 >> 56) | (w2 << 8) & 0xfff)) + (1*16+10 +1); out[1*16+11] = (start += ((w2 >> 4) & 0xfff)) + (1*16+11 +1); out[1*16+12] = (start += ((w2 >> 16) & 0xfff)) + (1*16+12 +1); out[1*16+13] = (start += ((w2 >> 28) & 0xfff)) + (1*16+13 +1); out[1*16+14] = (start += ((w2 >> 40) & 0xfff)) + (1*16+14 +1); out[1*16+15] = (start += ((w2 >> 52))) + (1*16+15 +1);;}; out += 32; start += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_13(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 13) & 0x1fff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 26) & 0x1fff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 39) & 0x1fff)) + (0*64+ 3 +1); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w0 >> 52) | (w1 << 12) & 0x1fff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w1 >> 1) & 0x1fff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w1 >> 14) & 0x1fff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w1 >> 27) & 0x1fff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w1 >> 40) & 0x1fff)) + (0*64+ 8 +1); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w1 >> 53) | (w2 << 11) & 0x1fff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w2 >> 2) & 0x1fff)) + (0*64+10 +1); out[0*64+11] = (start += ((w2 >> 15) & 0x1fff)) + (0*64+11 +1); out[0*64+12] = (start += ((w2 >> 28) & 0x1fff)) + (0*64+12 +1); out[0*64+13] = (start += ((w2 >> 41) & 0x1fff)) + (0*64+13 +1); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (start += ((w2 >> 54) | (w3 << 10) & 0x1fff)) + (0*64+14 +1); out[0*64+15] = (start += ((w3 >> 3) & 0x1fff)) + (0*64+15 +1); out[0*64+16] = (start += ((w3 >> 16) & 0x1fff)) + (0*64+16 +1); out[0*64+17] = (start += ((w3 >> 29) & 0x1fff)) + (0*64+17 +1); out[0*64+18] = (start += ((w3 >> 42) & 0x1fff)) + (0*64+18 +1); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (start += ((w3 >> 55) | (w4 << 9) & 0x1fff)) + (0*64+19 +1); out[0*64+20] = (start += ((w4 >> 4) & 0x1fff)) + (0*64+20 +1); out[0*64+21] = (start += ((w4 >> 17) & 0x1fff)) + (0*64+21 +1); out[0*64+22] = (start += ((w4 >> 30) & 0x1fff)) + (0*64+22 +1); out[0*64+23] = (start += ((w4 >> 43) & 0x1fff)) + (0*64+23 +1); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (start += ((w4 >> 56) | (w5 << 8) & 0x1fff)) + (0*64+24 +1); out[0*64+25] = (start += ((w5 >> 5) & 0x1fff)) + (0*64+25 +1); out[0*64+26] = (start += ((w5 >> 18) & 0x1fff)) + (0*64+26 +1); out[0*64+27] = (start += ((w5 >> 31) & 0x1fff)) + (0*64+27 +1); out[0*64+28] = (start += ((w5 >> 44) & 0x1fff)) + (0*64+28 +1); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (start += ((w5 >> 57) | (w6 << 7) & 0x1fff)) + (0*64+29 +1); out[0*64+30] = (start += ((w6 >> 6) & 0x1fff)) + (0*64+30 +1); out[0*64+31] = (start += ((w6 >> 19) & 0x1fff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_14(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fff)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 14) & 0x3fff)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 28) & 0x3fff)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 42) & 0x3fff)) + (0*32+ 3 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w0 >> 56) | (w1 << 8) & 0x3fff)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w1 >> 6) & 0x3fff)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w1 >> 20) & 0x3fff)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w1 >> 34) & 0x3fff)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w1 >> 48) & 0x3fff)) + (0*32+ 8 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w1 >> 62) | (w2 << 2) & 0x3fff)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w2 >> 12) & 0x3fff)) + (0*32+10 +1); out[0*32+11] = (start += ((w2 >> 26) & 0x3fff)) + (0*32+11 +1); out[0*32+12] = (start += ((w2 >> 40) & 0x3fff)) + (0*32+12 +1); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (start += ((w2 >> 54) | (w3 << 10) & 0x3fff)) + (0*32+13 +1); out[0*32+14] = (start += ((w3 >> 4) & 0x3fff)) + (0*32+14 +1); out[0*32+15] = (start += ((w3 >> 18) & 0x3fff)) + (0*32+15 +1); out[0*32+16] = (start += ((w3 >> 32) & 0x3fff)) + (0*32+16 +1); out[0*32+17] = (start += ((w3 >> 46) & 0x3fff)) + (0*32+17 +1); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (start += ((w3 >> 60) | (w4 << 4) & 0x3fff)) + (0*32+18 +1); out[0*32+19] = (start += ((w4 >> 10) & 0x3fff)) + (0*32+19 +1); out[0*32+20] = (start += ((w4 >> 24) & 0x3fff)) + (0*32+20 +1); out[0*32+21] = (start += ((w4 >> 38) & 0x3fff)) + (0*32+21 +1); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (start += ((w4 >> 52) | (w5 << 12) & 0x3fff)) + (0*32+22 +1); out[0*32+23] = (start += ((w5 >> 2) & 0x3fff)) + (0*32+23 +1); out[0*32+24] = (start += ((w5 >> 16) & 0x3fff)) + (0*32+24 +1); out[0*32+25] = (start += ((w5 >> 30) & 0x3fff)) + (0*32+25 +1); out[0*32+26] = (start += ((w5 >> 44) & 0x3fff)) + (0*32+26 +1); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (start += ((w5 >> 58) | (w6 << 6) & 0x3fff)) + (0*32+27 +1); out[0*32+28] = (start += ((w6 >> 8) & 0x3fff)) + (0*32+28 +1); out[0*32+29] = (start += ((w6 >> 22) & 0x3fff)) + (0*32+29 +1); out[0*32+30] = (start += ((w6 >> 36) & 0x3fff)) + (0*32+30 +1); out[0*32+31] = (start += ((w6 >> 50))) + (0*32+31 +1);;}; out += 32; start += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_15(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 15) & 0x7fff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 30) & 0x7fff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 45) & 0x7fff)) + (0*64+ 3 +1); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w0 >> 60) | (w1 << 4) & 0x7fff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w1 >> 11) & 0x7fff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w1 >> 26) & 0x7fff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w1 >> 41) & 0x7fff)) + (0*64+ 7 +1); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w1 >> 56) | (w2 << 8) & 0x7fff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w2 >> 7) & 0x7fff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w2 >> 22) & 0x7fff)) + (0*64+10 +1); out[0*64+11] = (start += ((w2 >> 37) & 0x7fff)) + (0*64+11 +1); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (start += ((w2 >> 52) | (w3 << 12) & 0x7fff)) + (0*64+12 +1); out[0*64+13] = (start += ((w3 >> 3) & 0x7fff)) + (0*64+13 +1); out[0*64+14] = (start += ((w3 >> 18) & 0x7fff)) + (0*64+14 +1); out[0*64+15] = (start += ((w3 >> 33) & 0x7fff)) + (0*64+15 +1); out[0*64+16] = (start += ((w3 >> 48) & 0x7fff)) + (0*64+16 +1); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (start += ((w3 >> 63) | (w4 << 1) & 0x7fff)) + (0*64+17 +1); out[0*64+18] = (start += ((w4 >> 14) & 0x7fff)) + (0*64+18 +1); out[0*64+19] = (start += ((w4 >> 29) & 0x7fff)) + (0*64+19 +1); out[0*64+20] = (start += ((w4 >> 44) & 0x7fff)) + (0*64+20 +1); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (start += ((w4 >> 59) | (w5 << 5) & 0x7fff)) + (0*64+21 +1); out[0*64+22] = (start += ((w5 >> 10) & 0x7fff)) + (0*64+22 +1); out[0*64+23] = (start += ((w5 >> 25) & 0x7fff)) + (0*64+23 +1); out[0*64+24] = (start += ((w5 >> 40) & 0x7fff)) + (0*64+24 +1); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (start += ((w5 >> 55) | (w6 << 9) & 0x7fff)) + (0*64+25 +1); out[0*64+26] = (start += ((w6 >> 6) & 0x7fff)) + (0*64+26 +1); out[0*64+27] = (start += ((w6 >> 21) & 0x7fff)) + (0*64+27 +1); out[0*64+28] = (start += ((w6 >> 36) & 0x7fff)) + (0*64+28 +1); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (start += ((w6 >> 51) | (w7 << 13) & 0x7fff)) + (0*64+29 +1); out[0*64+30] = (start += ((w7 >> 2) & 0x7fff)) + (0*64+30 +1); out[0*64+31] = (start += ((w7 >> 17) & 0x7fff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_16(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = (start += (*(uint16_t *)(in+0*8+ 0))) + (0*4+ 0 +1); out[0*4+ 1] = (start += (*(uint16_t *)(in+0*8+ 2))) + (0*4+ 1 +1); out[0*4+ 2] = (start += (*(uint16_t *)(in+0*8+ 4))) + (0*4+ 2 +1); out[0*4+ 3] = (start += (*(uint16_t *)(in+0*8+ 6))) + (0*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = (start += (*(uint16_t *)(in+1*8+ 0))) + (1*4+ 0 +1); out[1*4+ 1] = (start += (*(uint16_t *)(in+1*8+ 2))) + (1*4+ 1 +1); out[1*4+ 2] = (start += (*(uint16_t *)(in+1*8+ 4))) + (1*4+ 2 +1); out[1*4+ 3] = (start += (*(uint16_t *)(in+1*8+ 6))) + (1*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = (start += (*(uint16_t *)(in+2*8+ 0))) + (2*4+ 0 +1); out[2*4+ 1] = (start += (*(uint16_t *)(in+2*8+ 2))) + (2*4+ 1 +1); out[2*4+ 2] = (start += (*(uint16_t *)(in+2*8+ 4))) + (2*4+ 2 +1); out[2*4+ 3] = (start += (*(uint16_t *)(in+2*8+ 6))) + (2*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = (start += (*(uint16_t *)(in+3*8+ 0))) + (3*4+ 0 +1); out[3*4+ 1] = (start += (*(uint16_t *)(in+3*8+ 2))) + (3*4+ 1 +1); out[3*4+ 2] = (start += (*(uint16_t *)(in+3*8+ 4))) + (3*4+ 2 +1); out[3*4+ 3] = (start += (*(uint16_t *)(in+3*8+ 6))) + (3*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = (start += (*(uint16_t *)(in+4*8+ 0))) + (4*4+ 0 +1); out[4*4+ 1] = (start += (*(uint16_t *)(in+4*8+ 2))) + (4*4+ 1 +1); out[4*4+ 2] = (start += (*(uint16_t *)(in+4*8+ 4))) + (4*4+ 2 +1); out[4*4+ 3] = (start += (*(uint16_t *)(in+4*8+ 6))) + (4*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = (start += (*(uint16_t *)(in+5*8+ 0))) + (5*4+ 0 +1); out[5*4+ 1] = (start += (*(uint16_t *)(in+5*8+ 2))) + (5*4+ 1 +1); out[5*4+ 2] = (start += (*(uint16_t *)(in+5*8+ 4))) + (5*4+ 2 +1); out[5*4+ 3] = (start += (*(uint16_t *)(in+5*8+ 6))) + (5*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = (start += (*(uint16_t *)(in+6*8+ 0))) + (6*4+ 0 +1); out[6*4+ 1] = (start += (*(uint16_t *)(in+6*8+ 2))) + (6*4+ 1 +1); out[6*4+ 2] = (start += (*(uint16_t *)(in+6*8+ 4))) + (6*4+ 2 +1); out[6*4+ 3] = (start += (*(uint16_t *)(in+6*8+ 6))) + (6*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = (start += (*(uint16_t *)(in+7*8+ 0))) + (7*4+ 0 +1); out[7*4+ 1] = (start += (*(uint16_t *)(in+7*8+ 2))) + (7*4+ 1 +1); out[7*4+ 2] = (start += (*(uint16_t *)(in+7*8+ 4))) + (7*4+ 2 +1); out[7*4+ 3] = (start += (*(uint16_t *)(in+7*8+ 6))) + (7*4+ 3 +1);;}; out += 32; start += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_17(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*17)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 17) & 0x1ffff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 34) & 0x1ffff)) + (0*64+ 2 +1); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w0 >> 51) | (w1 << 13) & 0x1ffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w1 >> 4) & 0x1ffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w1 >> 21) & 0x1ffff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w1 >> 38) & 0x1ffff)) + (0*64+ 6 +1); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w1 >> 55) | (w2 << 9) & 0x1ffff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w2 >> 8) & 0x1ffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w2 >> 25) & 0x1ffff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w2 >> 42) & 0x1ffff)) + (0*64+10 +1); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*64+11] = (start += ((w2 >> 59) | (w3 << 5) & 0x1ffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w3 >> 12) & 0x1ffff)) + (0*64+12 +1); out[0*64+13] = (start += ((w3 >> 29) & 0x1ffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w3 >> 46) & 0x1ffff)) + (0*64+14 +1); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*64+15] = (start += ((w3 >> 63) | (w4 << 1) & 0x1ffff)) + (0*64+15 +1); out[0*64+16] = (start += ((w4 >> 16) & 0x1ffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w4 >> 33) & 0x1ffff)) + (0*64+17 +1); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*64+18] = (start += ((w4 >> 50) | (w5 << 14) & 0x1ffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w5 >> 3) & 0x1ffff)) + (0*64+19 +1); out[0*64+20] = (start += ((w5 >> 20) & 0x1ffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w5 >> 37) & 0x1ffff)) + (0*64+21 +1); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*64+22] = (start += ((w5 >> 54) | (w6 << 10) & 0x1ffff)) + (0*64+22 +1); out[0*64+23] = (start += ((w6 >> 7) & 0x1ffff)) + (0*64+23 +1); out[0*64+24] = (start += ((w6 >> 24) & 0x1ffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w6 >> 41) & 0x1ffff)) + (0*64+25 +1); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*64+26] = (start += ((w6 >> 58) | (w7 << 6) & 0x1ffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w7 >> 11) & 0x1ffff)) + (0*64+27 +1); out[0*64+28] = (start += ((w7 >> 28) & 0x1ffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w7 >> 45) & 0x1ffff)) + (0*64+29 +1); w8 = *(uint32_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*64+30] = (start += ((w7 >> 62) | (w8 << 2) & 0x1ffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w8 >> 15) & 0x1ffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 17*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_18(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*18)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffff)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 18) & 0x3ffff)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 36) & 0x3ffff)) + (0*32+ 2 +1); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w0 >> 54) | (w1 << 10) & 0x3ffff)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w1 >> 8) & 0x3ffff)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w1 >> 26) & 0x3ffff)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w1 >> 44) & 0x3ffff)) + (0*32+ 6 +1); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w1 >> 62) | (w2 << 2) & 0x3ffff)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w2 >> 16) & 0x3ffff)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w2 >> 34) & 0x3ffff)) + (0*32+ 9 +1); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*32+10] = (start += ((w2 >> 52) | (w3 << 12) & 0x3ffff)) + (0*32+10 +1); out[0*32+11] = (start += ((w3 >> 6) & 0x3ffff)) + (0*32+11 +1); out[0*32+12] = (start += ((w3 >> 24) & 0x3ffff)) + (0*32+12 +1); out[0*32+13] = (start += ((w3 >> 42) & 0x3ffff)) + (0*32+13 +1); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*32+14] = (start += ((w3 >> 60) | (w4 << 4) & 0x3ffff)) + (0*32+14 +1); out[0*32+15] = (start += ((w4 >> 14) & 0x3ffff)) + (0*32+15 +1); out[0*32+16] = (start += ((w4 >> 32) & 0x3ffff)) + (0*32+16 +1); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*32+17] = (start += ((w4 >> 50) | (w5 << 14) & 0x3ffff)) + (0*32+17 +1); out[0*32+18] = (start += ((w5 >> 4) & 0x3ffff)) + (0*32+18 +1); out[0*32+19] = (start += ((w5 >> 22) & 0x3ffff)) + (0*32+19 +1); out[0*32+20] = (start += ((w5 >> 40) & 0x3ffff)) + (0*32+20 +1); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*32+21] = (start += ((w5 >> 58) | (w6 << 6) & 0x3ffff)) + (0*32+21 +1); out[0*32+22] = (start += ((w6 >> 12) & 0x3ffff)) + (0*32+22 +1); out[0*32+23] = (start += ((w6 >> 30) & 0x3ffff)) + (0*32+23 +1); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*32+24] = (start += ((w6 >> 48) | (w7 << 16) & 0x3ffff)) + (0*32+24 +1); out[0*32+25] = (start += ((w7 >> 2) & 0x3ffff)) + (0*32+25 +1); out[0*32+26] = (start += ((w7 >> 20) & 0x3ffff)) + (0*32+26 +1); out[0*32+27] = (start += ((w7 >> 38) & 0x3ffff)) + (0*32+27 +1); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*32+28] = (start += ((w7 >> 56) | (w8 << 8) & 0x3ffff)) + (0*32+28 +1); out[0*32+29] = (start += ((w8 >> 10) & 0x3ffff)) + (0*32+29 +1); out[0*32+30] = (start += ((w8 >> 28) & 0x3ffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w8 >> 46))) + (0*32+31 +1);;}; out += 32; start += 32; in += 18*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_19(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*19)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 19) & 0x7ffff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 38) & 0x7ffff)) + (0*64+ 2 +1); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w0 >> 57) | (w1 << 7) & 0x7ffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w1 >> 12) & 0x7ffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w1 >> 31) & 0x7ffff)) + (0*64+ 5 +1); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w1 >> 50) | (w2 << 14) & 0x7ffff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w2 >> 5) & 0x7ffff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w2 >> 24) & 0x7ffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w2 >> 43) & 0x7ffff)) + (0*64+ 9 +1); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*64+10] = (start += ((w2 >> 62) | (w3 << 2) & 0x7ffff)) + (0*64+10 +1); out[0*64+11] = (start += ((w3 >> 17) & 0x7ffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w3 >> 36) & 0x7ffff)) + (0*64+12 +1); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*64+13] = (start += ((w3 >> 55) | (w4 << 9) & 0x7ffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w4 >> 10) & 0x7ffff)) + (0*64+14 +1); out[0*64+15] = (start += ((w4 >> 29) & 0x7ffff)) + (0*64+15 +1); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*64+16] = (start += ((w4 >> 48) | (w5 << 16) & 0x7ffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w5 >> 3) & 0x7ffff)) + (0*64+17 +1); out[0*64+18] = (start += ((w5 >> 22) & 0x7ffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w5 >> 41) & 0x7ffff)) + (0*64+19 +1); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*64+20] = (start += ((w5 >> 60) | (w6 << 4) & 0x7ffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w6 >> 15) & 0x7ffff)) + (0*64+21 +1); out[0*64+22] = (start += ((w6 >> 34) & 0x7ffff)) + (0*64+22 +1); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*64+23] = (start += ((w6 >> 53) | (w7 << 11) & 0x7ffff)) + (0*64+23 +1); out[0*64+24] = (start += ((w7 >> 8) & 0x7ffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w7 >> 27) & 0x7ffff)) + (0*64+25 +1); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*64+26] = (start += ((w7 >> 46) | (w8 << 18) & 0x7ffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w8 >> 1) & 0x7ffff)) + (0*64+27 +1); out[0*64+28] = (start += ((w8 >> 20) & 0x7ffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w8 >> 39) & 0x7ffff)) + (0*64+29 +1); w9 = *(uint32_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*64+30] = (start += ((w8 >> 58) | (w9 << 6) & 0x7ffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w9 >> 13) & 0x7ffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 19*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_20(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*20)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffff)) + (0*16+ 0 +1); out[0*16+ 1] = (start += ((w0 >> 20) & 0xfffff)) + (0*16+ 1 +1); out[0*16+ 2] = (start += ((w0 >> 40) & 0xfffff)) + (0*16+ 2 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*16+ 3] = (start += ((w0 >> 60) | (w1 << 4) & 0xfffff)) + (0*16+ 3 +1); out[0*16+ 4] = (start += ((w1 >> 16) & 0xfffff)) + (0*16+ 4 +1); out[0*16+ 5] = (start += ((w1 >> 36) & 0xfffff)) + (0*16+ 5 +1); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*16+ 6] = (start += ((w1 >> 56) | (w2 << 8) & 0xfffff)) + (0*16+ 6 +1); out[0*16+ 7] = (start += ((w2 >> 12) & 0xfffff)) + (0*16+ 7 +1); out[0*16+ 8] = (start += ((w2 >> 32) & 0xfffff)) + (0*16+ 8 +1); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*16+ 9] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffff)) + (0*16+ 9 +1); out[0*16+10] = (start += ((w3 >> 8) & 0xfffff)) + (0*16+10 +1); out[0*16+11] = (start += ((w3 >> 28) & 0xfffff)) + (0*16+11 +1); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*16+12] = (start += ((w3 >> 48) | (w4 << 16) & 0xfffff)) + (0*16+12 +1); out[0*16+13] = (start += ((w4 >> 4) & 0xfffff)) + (0*16+13 +1); out[0*16+14] = (start += ((w4 >> 24) & 0xfffff)) + (0*16+14 +1); out[0*16+15] = (start += ((w4 >> 44))) + (0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffff)) + (1*16+ 0 +1); out[1*16+ 1] = (start += ((w0 >> 20) & 0xfffff)) + (1*16+ 1 +1); out[1*16+ 2] = (start += ((w0 >> 40) & 0xfffff)) + (1*16+ 2 +1); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*16+ 3] = (start += ((w0 >> 60) | (w1 << 4) & 0xfffff)) + (1*16+ 3 +1); out[1*16+ 4] = (start += ((w1 >> 16) & 0xfffff)) + (1*16+ 4 +1); out[1*16+ 5] = (start += ((w1 >> 36) & 0xfffff)) + (1*16+ 5 +1); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*16+ 6] = (start += ((w1 >> 56) | (w2 << 8) & 0xfffff)) + (1*16+ 6 +1); out[1*16+ 7] = (start += ((w2 >> 12) & 0xfffff)) + (1*16+ 7 +1); out[1*16+ 8] = (start += ((w2 >> 32) & 0xfffff)) + (1*16+ 8 +1); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*16+ 9] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffff)) + (1*16+ 9 +1); out[1*16+10] = (start += ((w3 >> 8) & 0xfffff)) + (1*16+10 +1); out[1*16+11] = (start += ((w3 >> 28) & 0xfffff)) + (1*16+11 +1); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*16+12] = (start += ((w3 >> 48) | (w4 << 16) & 0xfffff)) + (1*16+12 +1); out[1*16+13] = (start += ((w4 >> 4) & 0xfffff)) + (1*16+13 +1); out[1*16+14] = (start += ((w4 >> 24) & 0xfffff)) + (1*16+14 +1); out[1*16+15] = (start += ((w4 >> 44))) + (1*16+15 +1);;}; out += 32; start += 32; in += 20*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_21(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*21)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 21) & 0x1fffff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 42) & 0x1fffff)) + (0*64+ 2 +1); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w0 >> 63) | (w1 << 1) & 0x1fffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w1 >> 20) & 0x1fffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w1 >> 41) & 0x1fffff)) + (0*64+ 5 +1); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w1 >> 62) | (w2 << 2) & 0x1fffff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w2 >> 19) & 0x1fffff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w2 >> 40) & 0x1fffff)) + (0*64+ 8 +1); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w2 >> 61) | (w3 << 3) & 0x1fffff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w3 >> 18) & 0x1fffff)) + (0*64+10 +1); out[0*64+11] = (start += ((w3 >> 39) & 0x1fffff)) + (0*64+11 +1); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*64+12] = (start += ((w3 >> 60) | (w4 << 4) & 0x1fffff)) + (0*64+12 +1); out[0*64+13] = (start += ((w4 >> 17) & 0x1fffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w4 >> 38) & 0x1fffff)) + (0*64+14 +1); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*64+15] = (start += ((w4 >> 59) | (w5 << 5) & 0x1fffff)) + (0*64+15 +1); out[0*64+16] = (start += ((w5 >> 16) & 0x1fffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w5 >> 37) & 0x1fffff)) + (0*64+17 +1); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*64+18] = (start += ((w5 >> 58) | (w6 << 6) & 0x1fffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w6 >> 15) & 0x1fffff)) + (0*64+19 +1); out[0*64+20] = (start += ((w6 >> 36) & 0x1fffff)) + (0*64+20 +1); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*64+21] = (start += ((w6 >> 57) | (w7 << 7) & 0x1fffff)) + (0*64+21 +1); out[0*64+22] = (start += ((w7 >> 14) & 0x1fffff)) + (0*64+22 +1); out[0*64+23] = (start += ((w7 >> 35) & 0x1fffff)) + (0*64+23 +1); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*64+24] = (start += ((w7 >> 56) | (w8 << 8) & 0x1fffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w8 >> 13) & 0x1fffff)) + (0*64+25 +1); out[0*64+26] = (start += ((w8 >> 34) & 0x1fffff)) + (0*64+26 +1); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*64+27] = (start += ((w8 >> 55) | (w9 << 9) & 0x1fffff)) + (0*64+27 +1); out[0*64+28] = (start += ((w9 >> 12) & 0x1fffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w9 >> 33) & 0x1fffff)) + (0*64+29 +1); w10 = *(uint32_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*64+30] = (start += ((w9 >> 54) | (w10 << 10) & 0x1fffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w10 >> 11) & 0x1fffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 21*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_22(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*22)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffff)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 22) & 0x3fffff)) + (0*32+ 1 +1); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w0 >> 44) | (w1 << 20) & 0x3fffff)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w1 >> 2) & 0x3fffff)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w1 >> 24) & 0x3fffff)) + (0*32+ 4 +1); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w1 >> 46) | (w2 << 18) & 0x3fffff)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w2 >> 4) & 0x3fffff)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w2 >> 26) & 0x3fffff)) + (0*32+ 7 +1); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w2 >> 48) | (w3 << 16) & 0x3fffff)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w3 >> 6) & 0x3fffff)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w3 >> 28) & 0x3fffff)) + (0*32+10 +1); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*32+11] = (start += ((w3 >> 50) | (w4 << 14) & 0x3fffff)) + (0*32+11 +1); out[0*32+12] = (start += ((w4 >> 8) & 0x3fffff)) + (0*32+12 +1); out[0*32+13] = (start += ((w4 >> 30) & 0x3fffff)) + (0*32+13 +1); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*32+14] = (start += ((w4 >> 52) | (w5 << 12) & 0x3fffff)) + (0*32+14 +1); out[0*32+15] = (start += ((w5 >> 10) & 0x3fffff)) + (0*32+15 +1); out[0*32+16] = (start += ((w5 >> 32) & 0x3fffff)) + (0*32+16 +1); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*32+17] = (start += ((w5 >> 54) | (w6 << 10) & 0x3fffff)) + (0*32+17 +1); out[0*32+18] = (start += ((w6 >> 12) & 0x3fffff)) + (0*32+18 +1); out[0*32+19] = (start += ((w6 >> 34) & 0x3fffff)) + (0*32+19 +1); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*32+20] = (start += ((w6 >> 56) | (w7 << 8) & 0x3fffff)) + (0*32+20 +1); out[0*32+21] = (start += ((w7 >> 14) & 0x3fffff)) + (0*32+21 +1); out[0*32+22] = (start += ((w7 >> 36) & 0x3fffff)) + (0*32+22 +1); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*32+23] = (start += ((w7 >> 58) | (w8 << 6) & 0x3fffff)) + (0*32+23 +1); out[0*32+24] = (start += ((w8 >> 16) & 0x3fffff)) + (0*32+24 +1); out[0*32+25] = (start += ((w8 >> 38) & 0x3fffff)) + (0*32+25 +1); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*32+26] = (start += ((w8 >> 60) | (w9 << 4) & 0x3fffff)) + (0*32+26 +1); out[0*32+27] = (start += ((w9 >> 18) & 0x3fffff)) + (0*32+27 +1); out[0*32+28] = (start += ((w9 >> 40) & 0x3fffff)) + (0*32+28 +1); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*32+29] = (start += ((w9 >> 62) | (w10 << 2) & 0x3fffff)) + (0*32+29 +1); out[0*32+30] = (start += ((w10 >> 20) & 0x3fffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w10 >> 42))) + (0*32+31 +1);;}; out += 32; start += 32; in += 22*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_23(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*23)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 23) & 0x7fffff)) + (0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 46) | (w1 << 18) & 0x7fffff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w1 >> 5) & 0x7fffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w1 >> 28) & 0x7fffff)) + (0*64+ 4 +1); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w1 >> 51) | (w2 << 13) & 0x7fffff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w2 >> 10) & 0x7fffff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w2 >> 33) & 0x7fffff)) + (0*64+ 7 +1); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w2 >> 56) | (w3 << 8) & 0x7fffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w3 >> 15) & 0x7fffff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w3 >> 38) & 0x7fffff)) + (0*64+10 +1); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*64+11] = (start += ((w3 >> 61) | (w4 << 3) & 0x7fffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w4 >> 20) & 0x7fffff)) + (0*64+12 +1); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*64+13] = (start += ((w4 >> 43) | (w5 << 21) & 0x7fffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w5 >> 2) & 0x7fffff)) + (0*64+14 +1); out[0*64+15] = (start += ((w5 >> 25) & 0x7fffff)) + (0*64+15 +1); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*64+16] = (start += ((w5 >> 48) | (w6 << 16) & 0x7fffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w6 >> 7) & 0x7fffff)) + (0*64+17 +1); out[0*64+18] = (start += ((w6 >> 30) & 0x7fffff)) + (0*64+18 +1); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*64+19] = (start += ((w6 >> 53) | (w7 << 11) & 0x7fffff)) + (0*64+19 +1); out[0*64+20] = (start += ((w7 >> 12) & 0x7fffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w7 >> 35) & 0x7fffff)) + (0*64+21 +1); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*64+22] = (start += ((w7 >> 58) | (w8 << 6) & 0x7fffff)) + (0*64+22 +1); out[0*64+23] = (start += ((w8 >> 17) & 0x7fffff)) + (0*64+23 +1); out[0*64+24] = (start += ((w8 >> 40) & 0x7fffff)) + (0*64+24 +1); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*64+25] = (start += ((w8 >> 63) | (w9 << 1) & 0x7fffff)) + (0*64+25 +1); out[0*64+26] = (start += ((w9 >> 22) & 0x7fffff)) + (0*64+26 +1); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*64+27] = (start += ((w9 >> 45) | (w10 << 19) & 0x7fffff)) + (0*64+27 +1); out[0*64+28] = (start += ((w10 >> 4) & 0x7fffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w10 >> 27) & 0x7fffff)) + (0*64+29 +1); w11 = *(uint32_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*64+30] = (start += ((w10 >> 50) | (w11 << 14) & 0x7fffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w11 >> 9) & 0x7fffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 23*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_24(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*24)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xffffff)) + (0*8+ 0 +1); out[0*8+ 1] = (start += ((w0 >> 24) & 0xffffff)) + (0*8+ 1 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)) + (0*8+ 2 +1); out[0*8+ 3] = (start += ((w1 >> 8) & 0xffffff)) + (0*8+ 3 +1); out[0*8+ 4] = (start += ((w1 >> 32) & 0xffffff)) + (0*8+ 4 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)) + (0*8+ 5 +1); out[0*8+ 6] = (start += ((w2 >> 16) & 0xffffff)) + (0*8+ 6 +1); out[0*8+ 7] = (start += ((w2 >> 40))) + (0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xffffff)) + (1*8+ 0 +1); out[1*8+ 1] = (start += ((w0 >> 24) & 0xffffff)) + (1*8+ 1 +1); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)) + (1*8+ 2 +1); out[1*8+ 3] = (start += ((w1 >> 8) & 0xffffff)) + (1*8+ 3 +1); out[1*8+ 4] = (start += ((w1 >> 32) & 0xffffff)) + (1*8+ 4 +1); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)) + (1*8+ 5 +1); out[1*8+ 6] = (start += ((w2 >> 16) & 0xffffff)) + (1*8+ 6 +1); out[1*8+ 7] = (start += ((w2 >> 40))) + (1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xffffff)) + (2*8+ 0 +1); out[2*8+ 1] = (start += ((w0 >> 24) & 0xffffff)) + (2*8+ 1 +1); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)) + (2*8+ 2 +1); out[2*8+ 3] = (start += ((w1 >> 8) & 0xffffff)) + (2*8+ 3 +1); out[2*8+ 4] = (start += ((w1 >> 32) & 0xffffff)) + (2*8+ 4 +1); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)) + (2*8+ 5 +1); out[2*8+ 6] = (start += ((w2 >> 16) & 0xffffff)) + (2*8+ 6 +1); out[2*8+ 7] = (start += ((w2 >> 40))) + (2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xffffff)) + (3*8+ 0 +1); out[3*8+ 1] = (start += ((w0 >> 24) & 0xffffff)) + (3*8+ 1 +1); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)) + (3*8+ 2 +1); out[3*8+ 3] = (start += ((w1 >> 8) & 0xffffff)) + (3*8+ 3 +1); out[3*8+ 4] = (start += ((w1 >> 32) & 0xffffff)) + (3*8+ 4 +1); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)) + (3*8+ 5 +1); out[3*8+ 6] = (start += ((w2 >> 16) & 0xffffff)) + (3*8+ 6 +1); out[3*8+ 7] = (start += ((w2 >> 40))) + (3*8+ 7 +1);;}; out += 32; start += 32; in += 24*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_25(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*25)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 25) & 0x1ffffff)) + (0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 50) | (w1 << 14) & 0x1ffffff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w1 >> 11) & 0x1ffffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w1 >> 36) & 0x1ffffff)) + (0*64+ 4 +1); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w1 >> 61) | (w2 << 3) & 0x1ffffff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w2 >> 22) & 0x1ffffff)) + (0*64+ 6 +1); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w2 >> 47) | (w3 << 17) & 0x1ffffff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w3 >> 8) & 0x1ffffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w3 >> 33) & 0x1ffffff)) + (0*64+ 9 +1); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*64+10] = (start += ((w3 >> 58) | (w4 << 6) & 0x1ffffff)) + (0*64+10 +1); out[0*64+11] = (start += ((w4 >> 19) & 0x1ffffff)) + (0*64+11 +1); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*64+12] = (start += ((w4 >> 44) | (w5 << 20) & 0x1ffffff)) + (0*64+12 +1); out[0*64+13] = (start += ((w5 >> 5) & 0x1ffffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w5 >> 30) & 0x1ffffff)) + (0*64+14 +1); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*64+15] = (start += ((w5 >> 55) | (w6 << 9) & 0x1ffffff)) + (0*64+15 +1); out[0*64+16] = (start += ((w6 >> 16) & 0x1ffffff)) + (0*64+16 +1); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*64+17] = (start += ((w6 >> 41) | (w7 << 23) & 0x1ffffff)) + (0*64+17 +1); out[0*64+18] = (start += ((w7 >> 2) & 0x1ffffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w7 >> 27) & 0x1ffffff)) + (0*64+19 +1); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*64+20] = (start += ((w7 >> 52) | (w8 << 12) & 0x1ffffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w8 >> 13) & 0x1ffffff)) + (0*64+21 +1); out[0*64+22] = (start += ((w8 >> 38) & 0x1ffffff)) + (0*64+22 +1); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*64+23] = (start += ((w8 >> 63) | (w9 << 1) & 0x1ffffff)) + (0*64+23 +1); out[0*64+24] = (start += ((w9 >> 24) & 0x1ffffff)) + (0*64+24 +1); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*64+25] = (start += ((w9 >> 49) | (w10 << 15) & 0x1ffffff)) + (0*64+25 +1); out[0*64+26] = (start += ((w10 >> 10) & 0x1ffffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w10 >> 35) & 0x1ffffff)) + (0*64+27 +1); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*64+28] = (start += ((w10 >> 60) | (w11 << 4) & 0x1ffffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w11 >> 21) & 0x1ffffff)) + (0*64+29 +1); w12 = *(uint32_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*64+30] = (start += ((w11 >> 46) | (w12 << 18) & 0x1ffffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w12 >> 7) & 0x1ffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 25*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_26(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*26)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffffff)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 26) & 0x3ffffff)) + (0*32+ 1 +1); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w0 >> 52) | (w1 << 12) & 0x3ffffff)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w1 >> 14) & 0x3ffffff)) + (0*32+ 3 +1); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w1 >> 40) | (w2 << 24) & 0x3ffffff)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w2 >> 2) & 0x3ffffff)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w2 >> 28) & 0x3ffffff)) + (0*32+ 6 +1); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w2 >> 54) | (w3 << 10) & 0x3ffffff)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w3 >> 16) & 0x3ffffff)) + (0*32+ 8 +1); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w3 >> 42) | (w4 << 22) & 0x3ffffff)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w4 >> 4) & 0x3ffffff)) + (0*32+10 +1); out[0*32+11] = (start += ((w4 >> 30) & 0x3ffffff)) + (0*32+11 +1); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*32+12] = (start += ((w4 >> 56) | (w5 << 8) & 0x3ffffff)) + (0*32+12 +1); out[0*32+13] = (start += ((w5 >> 18) & 0x3ffffff)) + (0*32+13 +1); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*32+14] = (start += ((w5 >> 44) | (w6 << 20) & 0x3ffffff)) + (0*32+14 +1); out[0*32+15] = (start += ((w6 >> 6) & 0x3ffffff)) + (0*32+15 +1); out[0*32+16] = (start += ((w6 >> 32) & 0x3ffffff)) + (0*32+16 +1); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*32+17] = (start += ((w6 >> 58) | (w7 << 6) & 0x3ffffff)) + (0*32+17 +1); out[0*32+18] = (start += ((w7 >> 20) & 0x3ffffff)) + (0*32+18 +1); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*32+19] = (start += ((w7 >> 46) | (w8 << 18) & 0x3ffffff)) + (0*32+19 +1); out[0*32+20] = (start += ((w8 >> 8) & 0x3ffffff)) + (0*32+20 +1); out[0*32+21] = (start += ((w8 >> 34) & 0x3ffffff)) + (0*32+21 +1); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*32+22] = (start += ((w8 >> 60) | (w9 << 4) & 0x3ffffff)) + (0*32+22 +1); out[0*32+23] = (start += ((w9 >> 22) & 0x3ffffff)) + (0*32+23 +1); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*32+24] = (start += ((w9 >> 48) | (w10 << 16) & 0x3ffffff)) + (0*32+24 +1); out[0*32+25] = (start += ((w10 >> 10) & 0x3ffffff)) + (0*32+25 +1); out[0*32+26] = (start += ((w10 >> 36) & 0x3ffffff)) + (0*32+26 +1); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*32+27] = (start += ((w10 >> 62) | (w11 << 2) & 0x3ffffff)) + (0*32+27 +1); out[0*32+28] = (start += ((w11 >> 24) & 0x3ffffff)) + (0*32+28 +1); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*32+29] = (start += ((w11 >> 50) | (w12 << 14) & 0x3ffffff)) + (0*32+29 +1); out[0*32+30] = (start += ((w12 >> 12) & 0x3ffffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w12 >> 38))) + (0*32+31 +1);;}; out += 32; start += 32; in += 26*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_27(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*27)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 27) & 0x7ffffff)) + (0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 54) | (w1 << 10) & 0x7ffffff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w1 >> 17) & 0x7ffffff)) + (0*64+ 3 +1); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w1 >> 44) | (w2 << 20) & 0x7ffffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w2 >> 7) & 0x7ffffff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w2 >> 34) & 0x7ffffff)) + (0*64+ 6 +1); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w2 >> 61) | (w3 << 3) & 0x7ffffff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w3 >> 24) & 0x7ffffff)) + (0*64+ 8 +1); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w3 >> 51) | (w4 << 13) & 0x7ffffff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w4 >> 14) & 0x7ffffff)) + (0*64+10 +1); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*64+11] = (start += ((w4 >> 41) | (w5 << 23) & 0x7ffffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w5 >> 4) & 0x7ffffff)) + (0*64+12 +1); out[0*64+13] = (start += ((w5 >> 31) & 0x7ffffff)) + (0*64+13 +1); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*64+14] = (start += ((w5 >> 58) | (w6 << 6) & 0x7ffffff)) + (0*64+14 +1); out[0*64+15] = (start += ((w6 >> 21) & 0x7ffffff)) + (0*64+15 +1); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*64+16] = (start += ((w6 >> 48) | (w7 << 16) & 0x7ffffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w7 >> 11) & 0x7ffffff)) + (0*64+17 +1); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*64+18] = (start += ((w7 >> 38) | (w8 << 26) & 0x7ffffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w8 >> 1) & 0x7ffffff)) + (0*64+19 +1); out[0*64+20] = (start += ((w8 >> 28) & 0x7ffffff)) + (0*64+20 +1); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*64+21] = (start += ((w8 >> 55) | (w9 << 9) & 0x7ffffff)) + (0*64+21 +1); out[0*64+22] = (start += ((w9 >> 18) & 0x7ffffff)) + (0*64+22 +1); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*64+23] = (start += ((w9 >> 45) | (w10 << 19) & 0x7ffffff)) + (0*64+23 +1); out[0*64+24] = (start += ((w10 >> 8) & 0x7ffffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w10 >> 35) & 0x7ffffff)) + (0*64+25 +1); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*64+26] = (start += ((w10 >> 62) | (w11 << 2) & 0x7ffffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w11 >> 25) & 0x7ffffff)) + (0*64+27 +1); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*64+28] = (start += ((w11 >> 52) | (w12 << 12) & 0x7ffffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w12 >> 15) & 0x7ffffff)) + (0*64+29 +1); w13 = *(uint32_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*64+30] = (start += ((w12 >> 42) | (w13 << 22) & 0x7ffffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w13 >> 5) & 0x7ffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 27*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_28(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*28)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffffff)) + (0*16+ 0 +1); out[0*16+ 1] = (start += ((w0 >> 28) & 0xfffffff)) + (0*16+ 1 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*16+ 2] = (start += ((w0 >> 56) | (w1 << 8) & 0xfffffff)) + (0*16+ 2 +1); out[0*16+ 3] = (start += ((w1 >> 20) & 0xfffffff)) + (0*16+ 3 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*16+ 4] = (start += ((w1 >> 48) | (w2 << 16) & 0xfffffff)) + (0*16+ 4 +1); out[0*16+ 5] = (start += ((w2 >> 12) & 0xfffffff)) + (0*16+ 5 +1); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*16+ 6] = (start += ((w2 >> 40) | (w3 << 24) & 0xfffffff)) + (0*16+ 6 +1); out[0*16+ 7] = (start += ((w3 >> 4) & 0xfffffff)) + (0*16+ 7 +1); out[0*16+ 8] = (start += ((w3 >> 32) & 0xfffffff)) + (0*16+ 8 +1); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*16+ 9] = (start += ((w3 >> 60) | (w4 << 4) & 0xfffffff)) + (0*16+ 9 +1); out[0*16+10] = (start += ((w4 >> 24) & 0xfffffff)) + (0*16+10 +1); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*16+11] = (start += ((w4 >> 52) | (w5 << 12) & 0xfffffff)) + (0*16+11 +1); out[0*16+12] = (start += ((w5 >> 16) & 0xfffffff)) + (0*16+12 +1); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*16+13] = (start += ((w5 >> 44) | (w6 << 20) & 0xfffffff)) + (0*16+13 +1); out[0*16+14] = (start += ((w6 >> 8) & 0xfffffff)) + (0*16+14 +1); out[0*16+15] = (start += ((w6 >> 36))) + (0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffffff)) + (1*16+ 0 +1); out[1*16+ 1] = (start += ((w0 >> 28) & 0xfffffff)) + (1*16+ 1 +1); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*16+ 2] = (start += ((w0 >> 56) | (w1 << 8) & 0xfffffff)) + (1*16+ 2 +1); out[1*16+ 3] = (start += ((w1 >> 20) & 0xfffffff)) + (1*16+ 3 +1); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*16+ 4] = (start += ((w1 >> 48) | (w2 << 16) & 0xfffffff)) + (1*16+ 4 +1); out[1*16+ 5] = (start += ((w2 >> 12) & 0xfffffff)) + (1*16+ 5 +1); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*16+ 6] = (start += ((w2 >> 40) | (w3 << 24) & 0xfffffff)) + (1*16+ 6 +1); out[1*16+ 7] = (start += ((w3 >> 4) & 0xfffffff)) + (1*16+ 7 +1); out[1*16+ 8] = (start += ((w3 >> 32) & 0xfffffff)) + (1*16+ 8 +1); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*16+ 9] = (start += ((w3 >> 60) | (w4 << 4) & 0xfffffff)) + (1*16+ 9 +1); out[1*16+10] = (start += ((w4 >> 24) & 0xfffffff)) + (1*16+10 +1); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*16+11] = (start += ((w4 >> 52) | (w5 << 12) & 0xfffffff)) + (1*16+11 +1); out[1*16+12] = (start += ((w5 >> 16) & 0xfffffff)) + (1*16+12 +1); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*16+13] = (start += ((w5 >> 44) | (w6 << 20) & 0xfffffff)) + (1*16+13 +1); out[1*16+14] = (start += ((w6 >> 8) & 0xfffffff)) + (1*16+14 +1); out[1*16+15] = (start += ((w6 >> 36))) + (1*16+15 +1);;}; out += 32; start += 32; in += 28*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_29(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*29)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 29) & 0x1fffffff)) + (0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 58) | (w1 << 6) & 0x1fffffff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w1 >> 23) & 0x1fffffff)) + (0*64+ 3 +1); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w1 >> 52) | (w2 << 12) & 0x1fffffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w2 >> 17) & 0x1fffffff)) + (0*64+ 5 +1); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w2 >> 46) | (w3 << 18) & 0x1fffffff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w3 >> 11) & 0x1fffffff)) + (0*64+ 7 +1); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w3 >> 40) | (w4 << 24) & 0x1fffffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w4 >> 5) & 0x1fffffff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w4 >> 34) & 0x1fffffff)) + (0*64+10 +1); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*64+11] = (start += ((w4 >> 63) | (w5 << 1) & 0x1fffffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w5 >> 28) & 0x1fffffff)) + (0*64+12 +1); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*64+13] = (start += ((w5 >> 57) | (w6 << 7) & 0x1fffffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w6 >> 22) & 0x1fffffff)) + (0*64+14 +1); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*64+15] = (start += ((w6 >> 51) | (w7 << 13) & 0x1fffffff)) + (0*64+15 +1); out[0*64+16] = (start += ((w7 >> 16) & 0x1fffffff)) + (0*64+16 +1); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*64+17] = (start += ((w7 >> 45) | (w8 << 19) & 0x1fffffff)) + (0*64+17 +1); out[0*64+18] = (start += ((w8 >> 10) & 0x1fffffff)) + (0*64+18 +1); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*64+19] = (start += ((w8 >> 39) | (w9 << 25) & 0x1fffffff)) + (0*64+19 +1); out[0*64+20] = (start += ((w9 >> 4) & 0x1fffffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w9 >> 33) & 0x1fffffff)) + (0*64+21 +1); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*64+22] = (start += ((w9 >> 62) | (w10 << 2) & 0x1fffffff)) + (0*64+22 +1); out[0*64+23] = (start += ((w10 >> 27) & 0x1fffffff)) + (0*64+23 +1); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*64+24] = (start += ((w10 >> 56) | (w11 << 8) & 0x1fffffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w11 >> 21) & 0x1fffffff)) + (0*64+25 +1); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*64+26] = (start += ((w11 >> 50) | (w12 << 14) & 0x1fffffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w12 >> 15) & 0x1fffffff)) + (0*64+27 +1); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*64+28] = (start += ((w12 >> 44) | (w13 << 20) & 0x1fffffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w13 >> 9) & 0x1fffffff)) + (0*64+29 +1); w14 = *(uint32_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*64+30] = (start += ((w13 >> 38) | (w14 << 26) & 0x1fffffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w14 >> 3) & 0x1fffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 29*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_30(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*30)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffffff)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 30) & 0x3fffffff)) + (0*32+ 1 +1); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w0 >> 60) | (w1 << 4) & 0x3fffffff)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w1 >> 26) & 0x3fffffff)) + (0*32+ 3 +1); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w1 >> 56) | (w2 << 8) & 0x3fffffff)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w2 >> 22) & 0x3fffffff)) + (0*32+ 5 +1); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w2 >> 52) | (w3 << 12) & 0x3fffffff)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w3 >> 18) & 0x3fffffff)) + (0*32+ 7 +1); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w3 >> 48) | (w4 << 16) & 0x3fffffff)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w4 >> 14) & 0x3fffffff)) + (0*32+ 9 +1); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*32+10] = (start += ((w4 >> 44) | (w5 << 20) & 0x3fffffff)) + (0*32+10 +1); out[0*32+11] = (start += ((w5 >> 10) & 0x3fffffff)) + (0*32+11 +1); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*32+12] = (start += ((w5 >> 40) | (w6 << 24) & 0x3fffffff)) + (0*32+12 +1); out[0*32+13] = (start += ((w6 >> 6) & 0x3fffffff)) + (0*32+13 +1); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*32+14] = (start += ((w6 >> 36) | (w7 << 28) & 0x3fffffff)) + (0*32+14 +1); out[0*32+15] = (start += ((w7 >> 2) & 0x3fffffff)) + (0*32+15 +1); out[0*32+16] = (start += ((w7 >> 32) & 0x3fffffff)) + (0*32+16 +1); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*32+17] = (start += ((w7 >> 62) | (w8 << 2) & 0x3fffffff)) + (0*32+17 +1); out[0*32+18] = (start += ((w8 >> 28) & 0x3fffffff)) + (0*32+18 +1); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*32+19] = (start += ((w8 >> 58) | (w9 << 6) & 0x3fffffff)) + (0*32+19 +1); out[0*32+20] = (start += ((w9 >> 24) & 0x3fffffff)) + (0*32+20 +1); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*32+21] = (start += ((w9 >> 54) | (w10 << 10) & 0x3fffffff)) + (0*32+21 +1); out[0*32+22] = (start += ((w10 >> 20) & 0x3fffffff)) + (0*32+22 +1); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*32+23] = (start += ((w10 >> 50) | (w11 << 14) & 0x3fffffff)) + (0*32+23 +1); out[0*32+24] = (start += ((w11 >> 16) & 0x3fffffff)) + (0*32+24 +1); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*32+25] = (start += ((w11 >> 46) | (w12 << 18) & 0x3fffffff)) + (0*32+25 +1); out[0*32+26] = (start += ((w12 >> 12) & 0x3fffffff)) + (0*32+26 +1); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*32+27] = (start += ((w12 >> 42) | (w13 << 22) & 0x3fffffff)) + (0*32+27 +1); out[0*32+28] = (start += ((w13 >> 8) & 0x3fffffff)) + (0*32+28 +1); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*32+29] = (start += ((w13 >> 38) | (w14 << 26) & 0x3fffffff)) + (0*32+29 +1); out[0*32+30] = (start += ((w14 >> 4) & 0x3fffffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w14 >> 34))) + (0*32+31 +1);;}; out += 32; start += 32; in += 30*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_31(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*31)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 31) & 0x7fffffff)) + (0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 62) | (w1 << 2) & 0x7fffffff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w1 >> 29) & 0x7fffffff)) + (0*64+ 3 +1); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w1 >> 60) | (w2 << 4) & 0x7fffffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w2 >> 27) & 0x7fffffff)) + (0*64+ 5 +1); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w2 >> 58) | (w3 << 6) & 0x7fffffff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w3 >> 25) & 0x7fffffff)) + (0*64+ 7 +1); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w3 >> 56) | (w4 << 8) & 0x7fffffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w4 >> 23) & 0x7fffffff)) + (0*64+ 9 +1); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*64+10] = (start += ((w4 >> 54) | (w5 << 10) & 0x7fffffff)) + (0*64+10 +1); out[0*64+11] = (start += ((w5 >> 21) & 0x7fffffff)) + (0*64+11 +1); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*64+12] = (start += ((w5 >> 52) | (w6 << 12) & 0x7fffffff)) + (0*64+12 +1); out[0*64+13] = (start += ((w6 >> 19) & 0x7fffffff)) + (0*64+13 +1); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*64+14] = (start += ((w6 >> 50) | (w7 << 14) & 0x7fffffff)) + (0*64+14 +1); out[0*64+15] = (start += ((w7 >> 17) & 0x7fffffff)) + (0*64+15 +1); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*64+16] = (start += ((w7 >> 48) | (w8 << 16) & 0x7fffffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w8 >> 15) & 0x7fffffff)) + (0*64+17 +1); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*64+18] = (start += ((w8 >> 46) | (w9 << 18) & 0x7fffffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w9 >> 13) & 0x7fffffff)) + (0*64+19 +1); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*64+20] = (start += ((w9 >> 44) | (w10 << 20) & 0x7fffffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w10 >> 11) & 0x7fffffff)) + (0*64+21 +1); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*64+22] = (start += ((w10 >> 42) | (w11 << 22) & 0x7fffffff)) + (0*64+22 +1); out[0*64+23] = (start += ((w11 >> 9) & 0x7fffffff)) + (0*64+23 +1); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*64+24] = (start += ((w11 >> 40) | (w12 << 24) & 0x7fffffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w12 >> 7) & 0x7fffffff)) + (0*64+25 +1); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*64+26] = (start += ((w12 >> 38) | (w13 << 26) & 0x7fffffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w13 >> 5) & 0x7fffffff)) + (0*64+27 +1); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*64+28] = (start += ((w13 >> 36) | (w14 << 28) & 0x7fffffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w14 >> 3) & 0x7fffffff)) + (0*64+29 +1); w15 = *(uint32_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*64+30] = (start += ((w14 >> 34) | (w15 << 30) & 0x7fffffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w15 >> 1) & 0x7fffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 31*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack32_32(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*32)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[0*2+ 0] = (start += (*(uint32_t *)(in+0*8+ 0))) + (0*2+ 0 +1); out[0*2+ 1] = (start += (*(uint32_t *)(in+0*8+ 4))) + (0*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[1*2+ 0] = (start += (*(uint32_t *)(in+1*8+ 0))) + (1*2+ 0 +1); out[1*2+ 1] = (start += (*(uint32_t *)(in+1*8+ 4))) + (1*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[2*2+ 0] = (start += (*(uint32_t *)(in+2*8+ 0))) + (2*2+ 0 +1); out[2*2+ 1] = (start += (*(uint32_t *)(in+2*8+ 4))) + (2*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[3*2+ 0] = (start += (*(uint32_t *)(in+3*8+ 0))) + (3*2+ 0 +1); out[3*2+ 1] = (start += (*(uint32_t *)(in+3*8+ 4))) + (3*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[4*2+ 0] = (start += (*(uint32_t *)(in+4*8+ 0))) + (4*2+ 0 +1); out[4*2+ 1] = (start += (*(uint32_t *)(in+4*8+ 4))) + (4*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[5*2+ 0] = (start += (*(uint32_t *)(in+5*8+ 0))) + (5*2+ 0 +1); out[5*2+ 1] = (start += (*(uint32_t *)(in+5*8+ 4))) + (5*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[6*2+ 0] = (start += (*(uint32_t *)(in+6*8+ 0))) + (6*2+ 0 +1); out[6*2+ 1] = (start += (*(uint32_t *)(in+6*8+ 4))) + (6*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[7*2+ 0] = (start += (*(uint32_t *)(in+7*8+ 0))) + (7*2+ 0 +1); out[7*2+ 1] = (start += (*(uint32_t *)(in+7*8+ 4))) + (7*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[8*2+ 0] = (start += (*(uint32_t *)(in+8*8+ 0))) + (8*2+ 0 +1); out[8*2+ 1] = (start += (*(uint32_t *)(in+8*8+ 4))) + (8*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[9*2+ 0] = (start += (*(uint32_t *)(in+9*8+ 0))) + (9*2+ 0 +1); out[9*2+ 1] = (start += (*(uint32_t *)(in+9*8+ 4))) + (9*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[10*2+ 0] = (start += (*(uint32_t *)(in+10*8+ 0))) + (10*2+ 0 +1); out[10*2+ 1] = (start += (*(uint32_t *)(in+10*8+ 4))) + (10*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[11*2+ 0] = (start += (*(uint32_t *)(in+11*8+ 0))) + (11*2+ 0 +1); out[11*2+ 1] = (start += (*(uint32_t *)(in+11*8+ 4))) + (11*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[12*2+ 0] = (start += (*(uint32_t *)(in+12*8+ 0))) + (12*2+ 0 +1); out[12*2+ 1] = (start += (*(uint32_t *)(in+12*8+ 4))) + (12*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[13*2+ 0] = (start += (*(uint32_t *)(in+13*8+ 0))) + (13*2+ 0 +1); out[13*2+ 1] = (start += (*(uint32_t *)(in+13*8+ 4))) + (13*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[14*2+ 0] = (start += (*(uint32_t *)(in+14*8+ 0))) + (14*2+ 0 +1); out[14*2+ 1] = (start += (*(uint32_t *)(in+14*8+ 4))) + (14*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[15*2+ 0] = (start += (*(uint32_t *)(in+15*8+ 0))) + (15*2+ 0 +1); out[15*2+ 1] = (start += (*(uint32_t *)(in+15*8+ 4))) + (15*2+ 1 +1);;}; out += 32; start += 32; in += 32*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D32 bitd1unpacka32[] = {
  &bitd1unpack32_0,
  &bitd1unpack32_1,
  &bitd1unpack32_2,
  &bitd1unpack32_3,
  &bitd1unpack32_4,
  &bitd1unpack32_5,
  &bitd1unpack32_6,
  &bitd1unpack32_7,
  &bitd1unpack32_8,
  &bitd1unpack32_9,
  &bitd1unpack32_10,
  &bitd1unpack32_11,
  &bitd1unpack32_12,
  &bitd1unpack32_13,
  &bitd1unpack32_14,
  &bitd1unpack32_15,
  &bitd1unpack32_16,
  &bitd1unpack32_17,
  &bitd1unpack32_18,
  &bitd1unpack32_19,
  &bitd1unpack32_20,
  &bitd1unpack32_21,
  &bitd1unpack32_22,
  &bitd1unpack32_23,
  &bitd1unpack32_24,
  &bitd1unpack32_25,
  &bitd1unpack32_26,
  &bitd1unpack32_27,
  &bitd1unpack32_28,
  &bitd1unpack32_29,
  &bitd1unpack32_30,
  &bitd1unpack32_31,
  &bitd1unpack32_32
};
unsigned char *bitd1unpack32( const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start, unsigned b) { return bitd1unpacka32[ b](in, n, out, start); }
unsigned char *bitd1unpack64_0(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint64_t *out_ = out+n; do { { { out[0*0+ 0] = (start += (0)) + (0*0+ 0 +1); out[0*0+ 1] = (start += (0)) + (0*0+ 1 +1); out[0*0+ 2] = (start += (0)) + (0*0+ 2 +1); out[0*0+ 3] = (start += (0)) + (0*0+ 3 +1); out[0*0+ 4] = (start += (0)) + (0*0+ 4 +1); out[0*0+ 5] = (start += (0)) + (0*0+ 5 +1); out[0*0+ 6] = (start += (0)) + (0*0+ 6 +1); out[0*0+ 7] = (start += (0)) + (0*0+ 7 +1); out[0*0+ 8] = (start += (0)) + (0*0+ 8 +1); out[0*0+ 9] = (start += (0)) + (0*0+ 9 +1); out[0*0+10] = (start += (0)) + (0*0+10 +1); out[0*0+11] = (start += (0)) + (0*0+11 +1); out[0*0+12] = (start += (0)) + (0*0+12 +1); out[0*0+13] = (start += (0)) + (0*0+13 +1); out[0*0+14] = (start += (0)) + (0*0+14 +1); out[0*0+15] = (start += (0)) + (0*0+15 +1); out[0*0+16] = (start += (0)) + (0*0+16 +1); out[0*0+17] = (start += (0)) + (0*0+17 +1); out[0*0+18] = (start += (0)) + (0*0+18 +1); out[0*0+19] = (start += (0)) + (0*0+19 +1); out[0*0+20] = (start += (0)) + (0*0+20 +1); out[0*0+21] = (start += (0)) + (0*0+21 +1); out[0*0+22] = (start += (0)) + (0*0+22 +1); out[0*0+23] = (start += (0)) + (0*0+23 +1); out[0*0+24] = (start += (0)) + (0*0+24 +1); out[0*0+25] = (start += (0)) + (0*0+25 +1); out[0*0+26] = (start += (0)) + (0*0+26 +1); out[0*0+27] = (start += (0)) + (0*0+27 +1); out[0*0+28] = (start += (0)) + (0*0+28 +1); out[0*0+29] = (start += (0)) + (0*0+29 +1); out[0*0+30] = (start += (0)) + (0*0+30 +1); out[0*0+31] = (start += (0)) + (0*0+31 +1);;}; out += 32; start += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitd1unpack64_1(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x1)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 1) & 0x1)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 2) & 0x1)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 3) & 0x1)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 4) & 0x1)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 5) & 0x1)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w0 >> 6) & 0x1)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w0 >> 7) & 0x1)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w0 >> 8) & 0x1)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w0 >> 9) & 0x1)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w0 >> 10) & 0x1)) + (0*32+10 +1); out[0*32+11] = (start += ((w0 >> 11) & 0x1)) + (0*32+11 +1); out[0*32+12] = (start += ((w0 >> 12) & 0x1)) + (0*32+12 +1); out[0*32+13] = (start += ((w0 >> 13) & 0x1)) + (0*32+13 +1); out[0*32+14] = (start += ((w0 >> 14) & 0x1)) + (0*32+14 +1); out[0*32+15] = (start += ((w0 >> 15) & 0x1)) + (0*32+15 +1); out[0*32+16] = (start += ((w0 >> 16) & 0x1)) + (0*32+16 +1); out[0*32+17] = (start += ((w0 >> 17) & 0x1)) + (0*32+17 +1); out[0*32+18] = (start += ((w0 >> 18) & 0x1)) + (0*32+18 +1); out[0*32+19] = (start += ((w0 >> 19) & 0x1)) + (0*32+19 +1); out[0*32+20] = (start += ((w0 >> 20) & 0x1)) + (0*32+20 +1); out[0*32+21] = (start += ((w0 >> 21) & 0x1)) + (0*32+21 +1); out[0*32+22] = (start += ((w0 >> 22) & 0x1)) + (0*32+22 +1); out[0*32+23] = (start += ((w0 >> 23) & 0x1)) + (0*32+23 +1); out[0*32+24] = (start += ((w0 >> 24) & 0x1)) + (0*32+24 +1); out[0*32+25] = (start += ((w0 >> 25) & 0x1)) + (0*32+25 +1); out[0*32+26] = (start += ((w0 >> 26) & 0x1)) + (0*32+26 +1); out[0*32+27] = (start += ((w0 >> 27) & 0x1)) + (0*32+27 +1); out[0*32+28] = (start += ((w0 >> 28) & 0x1)) + (0*32+28 +1); out[0*32+29] = (start += ((w0 >> 29) & 0x1)) + (0*32+29 +1); out[0*32+30] = (start += ((w0 >> 30) & 0x1)) + (0*32+30 +1); out[0*32+31] = (start += ((w0 >> 31))) + (0*32+31 +1);;}; out += 32; start += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_2(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 2) & 0x3)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 4) & 0x3)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 6) & 0x3)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 8) & 0x3)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 10) & 0x3)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w0 >> 12) & 0x3)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w0 >> 14) & 0x3)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w0 >> 16) & 0x3)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w0 >> 18) & 0x3)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w0 >> 20) & 0x3)) + (0*32+10 +1); out[0*32+11] = (start += ((w0 >> 22) & 0x3)) + (0*32+11 +1); out[0*32+12] = (start += ((w0 >> 24) & 0x3)) + (0*32+12 +1); out[0*32+13] = (start += ((w0 >> 26) & 0x3)) + (0*32+13 +1); out[0*32+14] = (start += ((w0 >> 28) & 0x3)) + (0*32+14 +1); out[0*32+15] = (start += ((w0 >> 30) & 0x3)) + (0*32+15 +1); out[0*32+16] = (start += ((w0 >> 32) & 0x3)) + (0*32+16 +1); out[0*32+17] = (start += ((w0 >> 34) & 0x3)) + (0*32+17 +1); out[0*32+18] = (start += ((w0 >> 36) & 0x3)) + (0*32+18 +1); out[0*32+19] = (start += ((w0 >> 38) & 0x3)) + (0*32+19 +1); out[0*32+20] = (start += ((w0 >> 40) & 0x3)) + (0*32+20 +1); out[0*32+21] = (start += ((w0 >> 42) & 0x3)) + (0*32+21 +1); out[0*32+22] = (start += ((w0 >> 44) & 0x3)) + (0*32+22 +1); out[0*32+23] = (start += ((w0 >> 46) & 0x3)) + (0*32+23 +1); out[0*32+24] = (start += ((w0 >> 48) & 0x3)) + (0*32+24 +1); out[0*32+25] = (start += ((w0 >> 50) & 0x3)) + (0*32+25 +1); out[0*32+26] = (start += ((w0 >> 52) & 0x3)) + (0*32+26 +1); out[0*32+27] = (start += ((w0 >> 54) & 0x3)) + (0*32+27 +1); out[0*32+28] = (start += ((w0 >> 56) & 0x3)) + (0*32+28 +1); out[0*32+29] = (start += ((w0 >> 58) & 0x3)) + (0*32+29 +1); out[0*32+30] = (start += ((w0 >> 60) & 0x3)) + (0*32+30 +1); out[0*32+31] = (start += ((w0 >> 62))) + (0*32+31 +1);;}; out += 32; start += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_3(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 3) & 0x7)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 6) & 0x7)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 9) & 0x7)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 12) & 0x7)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 15) & 0x7)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 18) & 0x7)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w0 >> 21) & 0x7)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w0 >> 24) & 0x7)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w0 >> 27) & 0x7)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w0 >> 30) & 0x7)) + (0*64+10 +1); out[0*64+11] = (start += ((w0 >> 33) & 0x7)) + (0*64+11 +1); out[0*64+12] = (start += ((w0 >> 36) & 0x7)) + (0*64+12 +1); out[0*64+13] = (start += ((w0 >> 39) & 0x7)) + (0*64+13 +1); out[0*64+14] = (start += ((w0 >> 42) & 0x7)) + (0*64+14 +1); out[0*64+15] = (start += ((w0 >> 45) & 0x7)) + (0*64+15 +1); out[0*64+16] = (start += ((w0 >> 48) & 0x7)) + (0*64+16 +1); out[0*64+17] = (start += ((w0 >> 51) & 0x7)) + (0*64+17 +1); out[0*64+18] = (start += ((w0 >> 54) & 0x7)) + (0*64+18 +1); out[0*64+19] = (start += ((w0 >> 57) & 0x7)) + (0*64+19 +1); out[0*64+20] = (start += ((w0 >> 60) & 0x7)) + (0*64+20 +1); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = (start += ((w0 >> 63) | (w1 << 1) & 0x7)) + (0*64+21 +1); out[0*64+22] = (start += ((w1 >> 2) & 0x7)) + (0*64+22 +1); out[0*64+23] = (start += ((w1 >> 5) & 0x7)) + (0*64+23 +1); out[0*64+24] = (start += ((w1 >> 8) & 0x7)) + (0*64+24 +1); out[0*64+25] = (start += ((w1 >> 11) & 0x7)) + (0*64+25 +1); out[0*64+26] = (start += ((w1 >> 14) & 0x7)) + (0*64+26 +1); out[0*64+27] = (start += ((w1 >> 17) & 0x7)) + (0*64+27 +1); out[0*64+28] = (start += ((w1 >> 20) & 0x7)) + (0*64+28 +1); out[0*64+29] = (start += ((w1 >> 23) & 0x7)) + (0*64+29 +1); out[0*64+30] = (start += ((w1 >> 26) & 0x7)) + (0*64+30 +1); out[0*64+31] = (start += ((w1 >> 29) & 0x7)) + (0*64+31 +1);;}; out += 32; start += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_4(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xf)) + (0*16+ 0 +1); out[0*16+ 1] = (start += ((w0 >> 4) & 0xf)) + (0*16+ 1 +1); out[0*16+ 2] = (start += ((w0 >> 8) & 0xf)) + (0*16+ 2 +1); out[0*16+ 3] = (start += ((w0 >> 12) & 0xf)) + (0*16+ 3 +1); out[0*16+ 4] = (start += ((w0 >> 16) & 0xf)) + (0*16+ 4 +1); out[0*16+ 5] = (start += ((w0 >> 20) & 0xf)) + (0*16+ 5 +1); out[0*16+ 6] = (start += ((w0 >> 24) & 0xf)) + (0*16+ 6 +1); out[0*16+ 7] = (start += ((w0 >> 28) & 0xf)) + (0*16+ 7 +1); out[0*16+ 8] = (start += ((w0 >> 32) & 0xf)) + (0*16+ 8 +1); out[0*16+ 9] = (start += ((w0 >> 36) & 0xf)) + (0*16+ 9 +1); out[0*16+10] = (start += ((w0 >> 40) & 0xf)) + (0*16+10 +1); out[0*16+11] = (start += ((w0 >> 44) & 0xf)) + (0*16+11 +1); out[0*16+12] = (start += ((w0 >> 48) & 0xf)) + (0*16+12 +1); out[0*16+13] = (start += ((w0 >> 52) & 0xf)) + (0*16+13 +1); out[0*16+14] = (start += ((w0 >> 56) & 0xf)) + (0*16+14 +1); out[0*16+15] = (start += ((w0 >> 60))) + (0*16+15 +1);;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xf)) + (1*16+ 0 +1); out[1*16+ 1] = (start += ((w0 >> 4) & 0xf)) + (1*16+ 1 +1); out[1*16+ 2] = (start += ((w0 >> 8) & 0xf)) + (1*16+ 2 +1); out[1*16+ 3] = (start += ((w0 >> 12) & 0xf)) + (1*16+ 3 +1); out[1*16+ 4] = (start += ((w0 >> 16) & 0xf)) + (1*16+ 4 +1); out[1*16+ 5] = (start += ((w0 >> 20) & 0xf)) + (1*16+ 5 +1); out[1*16+ 6] = (start += ((w0 >> 24) & 0xf)) + (1*16+ 6 +1); out[1*16+ 7] = (start += ((w0 >> 28) & 0xf)) + (1*16+ 7 +1); out[1*16+ 8] = (start += ((w0 >> 32) & 0xf)) + (1*16+ 8 +1); out[1*16+ 9] = (start += ((w0 >> 36) & 0xf)) + (1*16+ 9 +1); out[1*16+10] = (start += ((w0 >> 40) & 0xf)) + (1*16+10 +1); out[1*16+11] = (start += ((w0 >> 44) & 0xf)) + (1*16+11 +1); out[1*16+12] = (start += ((w0 >> 48) & 0xf)) + (1*16+12 +1); out[1*16+13] = (start += ((w0 >> 52) & 0xf)) + (1*16+13 +1); out[1*16+14] = (start += ((w0 >> 56) & 0xf)) + (1*16+14 +1); out[1*16+15] = (start += ((w0 >> 60))) + (1*16+15 +1);;}; out += 32; start += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_5(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1f)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 5) & 0x1f)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 10) & 0x1f)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 15) & 0x1f)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 20) & 0x1f)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 25) & 0x1f)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 30) & 0x1f)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w0 >> 35) & 0x1f)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w0 >> 40) & 0x1f)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w0 >> 45) & 0x1f)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w0 >> 50) & 0x1f)) + (0*64+10 +1); out[0*64+11] = (start += ((w0 >> 55) & 0x1f)) + (0*64+11 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = (start += ((w0 >> 60) | (w1 << 4) & 0x1f)) + (0*64+12 +1); out[0*64+13] = (start += ((w1 >> 1) & 0x1f)) + (0*64+13 +1); out[0*64+14] = (start += ((w1 >> 6) & 0x1f)) + (0*64+14 +1); out[0*64+15] = (start += ((w1 >> 11) & 0x1f)) + (0*64+15 +1); out[0*64+16] = (start += ((w1 >> 16) & 0x1f)) + (0*64+16 +1); out[0*64+17] = (start += ((w1 >> 21) & 0x1f)) + (0*64+17 +1); out[0*64+18] = (start += ((w1 >> 26) & 0x1f)) + (0*64+18 +1); out[0*64+19] = (start += ((w1 >> 31) & 0x1f)) + (0*64+19 +1); out[0*64+20] = (start += ((w1 >> 36) & 0x1f)) + (0*64+20 +1); out[0*64+21] = (start += ((w1 >> 41) & 0x1f)) + (0*64+21 +1); out[0*64+22] = (start += ((w1 >> 46) & 0x1f)) + (0*64+22 +1); out[0*64+23] = (start += ((w1 >> 51) & 0x1f)) + (0*64+23 +1); out[0*64+24] = (start += ((w1 >> 56) & 0x1f)) + (0*64+24 +1); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = (start += ((w1 >> 61) | (w2 << 3) & 0x1f)) + (0*64+25 +1); out[0*64+26] = (start += ((w2 >> 2) & 0x1f)) + (0*64+26 +1); out[0*64+27] = (start += ((w2 >> 7) & 0x1f)) + (0*64+27 +1); out[0*64+28] = (start += ((w2 >> 12) & 0x1f)) + (0*64+28 +1); out[0*64+29] = (start += ((w2 >> 17) & 0x1f)) + (0*64+29 +1); out[0*64+30] = (start += ((w2 >> 22) & 0x1f)) + (0*64+30 +1); out[0*64+31] = (start += ((w2 >> 27) & 0x1f)) + (0*64+31 +1);;}; out += 32; start += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_6(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3f)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 6) & 0x3f)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 12) & 0x3f)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 18) & 0x3f)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 24) & 0x3f)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 30) & 0x3f)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w0 >> 36) & 0x3f)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w0 >> 42) & 0x3f)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w0 >> 48) & 0x3f)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w0 >> 54) & 0x3f)) + (0*32+ 9 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = (start += ((w0 >> 60) | (w1 << 4) & 0x3f)) + (0*32+10 +1); out[0*32+11] = (start += ((w1 >> 2) & 0x3f)) + (0*32+11 +1); out[0*32+12] = (start += ((w1 >> 8) & 0x3f)) + (0*32+12 +1); out[0*32+13] = (start += ((w1 >> 14) & 0x3f)) + (0*32+13 +1); out[0*32+14] = (start += ((w1 >> 20) & 0x3f)) + (0*32+14 +1); out[0*32+15] = (start += ((w1 >> 26) & 0x3f)) + (0*32+15 +1); out[0*32+16] = (start += ((w1 >> 32) & 0x3f)) + (0*32+16 +1); out[0*32+17] = (start += ((w1 >> 38) & 0x3f)) + (0*32+17 +1); out[0*32+18] = (start += ((w1 >> 44) & 0x3f)) + (0*32+18 +1); out[0*32+19] = (start += ((w1 >> 50) & 0x3f)) + (0*32+19 +1); out[0*32+20] = (start += ((w1 >> 56) & 0x3f)) + (0*32+20 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = (start += ((w1 >> 62) | (w2 << 2) & 0x3f)) + (0*32+21 +1); out[0*32+22] = (start += ((w2 >> 4) & 0x3f)) + (0*32+22 +1); out[0*32+23] = (start += ((w2 >> 10) & 0x3f)) + (0*32+23 +1); out[0*32+24] = (start += ((w2 >> 16) & 0x3f)) + (0*32+24 +1); out[0*32+25] = (start += ((w2 >> 22) & 0x3f)) + (0*32+25 +1); out[0*32+26] = (start += ((w2 >> 28) & 0x3f)) + (0*32+26 +1); out[0*32+27] = (start += ((w2 >> 34) & 0x3f)) + (0*32+27 +1); out[0*32+28] = (start += ((w2 >> 40) & 0x3f)) + (0*32+28 +1); out[0*32+29] = (start += ((w2 >> 46) & 0x3f)) + (0*32+29 +1); out[0*32+30] = (start += ((w2 >> 52) & 0x3f)) + (0*32+30 +1); out[0*32+31] = (start += ((w2 >> 58))) + (0*32+31 +1);;}; out += 32; start += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_7(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7f)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 7) & 0x7f)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 14) & 0x7f)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 21) & 0x7f)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 28) & 0x7f)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 35) & 0x7f)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 42) & 0x7f)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w0 >> 49) & 0x7f)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w0 >> 56) & 0x7f)) + (0*64+ 8 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w0 >> 63) | (w1 << 1) & 0x7f)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w1 >> 6) & 0x7f)) + (0*64+10 +1); out[0*64+11] = (start += ((w1 >> 13) & 0x7f)) + (0*64+11 +1); out[0*64+12] = (start += ((w1 >> 20) & 0x7f)) + (0*64+12 +1); out[0*64+13] = (start += ((w1 >> 27) & 0x7f)) + (0*64+13 +1); out[0*64+14] = (start += ((w1 >> 34) & 0x7f)) + (0*64+14 +1); out[0*64+15] = (start += ((w1 >> 41) & 0x7f)) + (0*64+15 +1); out[0*64+16] = (start += ((w1 >> 48) & 0x7f)) + (0*64+16 +1); out[0*64+17] = (start += ((w1 >> 55) & 0x7f)) + (0*64+17 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = (start += ((w1 >> 62) | (w2 << 2) & 0x7f)) + (0*64+18 +1); out[0*64+19] = (start += ((w2 >> 5) & 0x7f)) + (0*64+19 +1); out[0*64+20] = (start += ((w2 >> 12) & 0x7f)) + (0*64+20 +1); out[0*64+21] = (start += ((w2 >> 19) & 0x7f)) + (0*64+21 +1); out[0*64+22] = (start += ((w2 >> 26) & 0x7f)) + (0*64+22 +1); out[0*64+23] = (start += ((w2 >> 33) & 0x7f)) + (0*64+23 +1); out[0*64+24] = (start += ((w2 >> 40) & 0x7f)) + (0*64+24 +1); out[0*64+25] = (start += ((w2 >> 47) & 0x7f)) + (0*64+25 +1); out[0*64+26] = (start += ((w2 >> 54) & 0x7f)) + (0*64+26 +1); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = (start += ((w2 >> 61) | (w3 << 3) & 0x7f)) + (0*64+27 +1); out[0*64+28] = (start += ((w3 >> 4) & 0x7f)) + (0*64+28 +1); out[0*64+29] = (start += ((w3 >> 11) & 0x7f)) + (0*64+29 +1); out[0*64+30] = (start += ((w3 >> 18) & 0x7f)) + (0*64+30 +1); out[0*64+31] = (start += ((w3 >> 25) & 0x7f)) + (0*64+31 +1);;}; out += 32; start += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_8(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xff)) + (0*8+ 0 +1); out[0*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (0*8+ 1 +1); out[0*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (0*8+ 2 +1); out[0*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (0*8+ 3 +1); out[0*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (0*8+ 4 +1); out[0*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (0*8+ 5 +1); out[0*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (0*8+ 6 +1); out[0*8+ 7] = (start += ((w0 >> 56))) + (0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xff)) + (1*8+ 0 +1); out[1*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (1*8+ 1 +1); out[1*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (1*8+ 2 +1); out[1*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (1*8+ 3 +1); out[1*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (1*8+ 4 +1); out[1*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (1*8+ 5 +1); out[1*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (1*8+ 6 +1); out[1*8+ 7] = (start += ((w0 >> 56))) + (1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xff)) + (2*8+ 0 +1); out[2*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (2*8+ 1 +1); out[2*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (2*8+ 2 +1); out[2*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (2*8+ 3 +1); out[2*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (2*8+ 4 +1); out[2*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (2*8+ 5 +1); out[2*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (2*8+ 6 +1); out[2*8+ 7] = (start += ((w0 >> 56))) + (2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xff)) + (3*8+ 0 +1); out[3*8+ 1] = (start += ((w0 >> 8) & 0xff)) + (3*8+ 1 +1); out[3*8+ 2] = (start += ((w0 >> 16) & 0xff)) + (3*8+ 2 +1); out[3*8+ 3] = (start += ((w0 >> 24) & 0xff)) + (3*8+ 3 +1); out[3*8+ 4] = (start += ((w0 >> 32) & 0xff)) + (3*8+ 4 +1); out[3*8+ 5] = (start += ((w0 >> 40) & 0xff)) + (3*8+ 5 +1); out[3*8+ 6] = (start += ((w0 >> 48) & 0xff)) + (3*8+ 6 +1); out[3*8+ 7] = (start += ((w0 >> 56))) + (3*8+ 7 +1);;}; out += 32; start += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_9(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 9) & 0x1ff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 18) & 0x1ff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 27) & 0x1ff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 36) & 0x1ff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w0 >> 45) & 0x1ff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w0 >> 54) & 0x1ff)) + (0*64+ 6 +1); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w0 >> 63) | (w1 << 1) & 0x1ff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w1 >> 8) & 0x1ff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w1 >> 17) & 0x1ff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w1 >> 26) & 0x1ff)) + (0*64+10 +1); out[0*64+11] = (start += ((w1 >> 35) & 0x1ff)) + (0*64+11 +1); out[0*64+12] = (start += ((w1 >> 44) & 0x1ff)) + (0*64+12 +1); out[0*64+13] = (start += ((w1 >> 53) & 0x1ff)) + (0*64+13 +1); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = (start += ((w1 >> 62) | (w2 << 2) & 0x1ff)) + (0*64+14 +1); out[0*64+15] = (start += ((w2 >> 7) & 0x1ff)) + (0*64+15 +1); out[0*64+16] = (start += ((w2 >> 16) & 0x1ff)) + (0*64+16 +1); out[0*64+17] = (start += ((w2 >> 25) & 0x1ff)) + (0*64+17 +1); out[0*64+18] = (start += ((w2 >> 34) & 0x1ff)) + (0*64+18 +1); out[0*64+19] = (start += ((w2 >> 43) & 0x1ff)) + (0*64+19 +1); out[0*64+20] = (start += ((w2 >> 52) & 0x1ff)) + (0*64+20 +1); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = (start += ((w2 >> 61) | (w3 << 3) & 0x1ff)) + (0*64+21 +1); out[0*64+22] = (start += ((w3 >> 6) & 0x1ff)) + (0*64+22 +1); out[0*64+23] = (start += ((w3 >> 15) & 0x1ff)) + (0*64+23 +1); out[0*64+24] = (start += ((w3 >> 24) & 0x1ff)) + (0*64+24 +1); out[0*64+25] = (start += ((w3 >> 33) & 0x1ff)) + (0*64+25 +1); out[0*64+26] = (start += ((w3 >> 42) & 0x1ff)) + (0*64+26 +1); out[0*64+27] = (start += ((w3 >> 51) & 0x1ff)) + (0*64+27 +1); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = (start += ((w3 >> 60) | (w4 << 4) & 0x1ff)) + (0*64+28 +1); out[0*64+29] = (start += ((w4 >> 5) & 0x1ff)) + (0*64+29 +1); out[0*64+30] = (start += ((w4 >> 14) & 0x1ff)) + (0*64+30 +1); out[0*64+31] = (start += ((w4 >> 23) & 0x1ff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_10(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ff)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 10) & 0x3ff)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 20) & 0x3ff)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 30) & 0x3ff)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w0 >> 40) & 0x3ff)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w0 >> 50) & 0x3ff)) + (0*32+ 5 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w0 >> 60) | (w1 << 4) & 0x3ff)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w1 >> 6) & 0x3ff)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w1 >> 16) & 0x3ff)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w1 >> 26) & 0x3ff)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w1 >> 36) & 0x3ff)) + (0*32+10 +1); out[0*32+11] = (start += ((w1 >> 46) & 0x3ff)) + (0*32+11 +1); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = (start += ((w1 >> 56) | (w2 << 8) & 0x3ff)) + (0*32+12 +1); out[0*32+13] = (start += ((w2 >> 2) & 0x3ff)) + (0*32+13 +1); out[0*32+14] = (start += ((w2 >> 12) & 0x3ff)) + (0*32+14 +1); out[0*32+15] = (start += ((w2 >> 22) & 0x3ff)) + (0*32+15 +1); out[0*32+16] = (start += ((w2 >> 32) & 0x3ff)) + (0*32+16 +1); out[0*32+17] = (start += ((w2 >> 42) & 0x3ff)) + (0*32+17 +1); out[0*32+18] = (start += ((w2 >> 52) & 0x3ff)) + (0*32+18 +1); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = (start += ((w2 >> 62) | (w3 << 2) & 0x3ff)) + (0*32+19 +1); out[0*32+20] = (start += ((w3 >> 8) & 0x3ff)) + (0*32+20 +1); out[0*32+21] = (start += ((w3 >> 18) & 0x3ff)) + (0*32+21 +1); out[0*32+22] = (start += ((w3 >> 28) & 0x3ff)) + (0*32+22 +1); out[0*32+23] = (start += ((w3 >> 38) & 0x3ff)) + (0*32+23 +1); out[0*32+24] = (start += ((w3 >> 48) & 0x3ff)) + (0*32+24 +1); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = (start += ((w3 >> 58) | (w4 << 6) & 0x3ff)) + (0*32+25 +1); out[0*32+26] = (start += ((w4 >> 4) & 0x3ff)) + (0*32+26 +1); out[0*32+27] = (start += ((w4 >> 14) & 0x3ff)) + (0*32+27 +1); out[0*32+28] = (start += ((w4 >> 24) & 0x3ff)) + (0*32+28 +1); out[0*32+29] = (start += ((w4 >> 34) & 0x3ff)) + (0*32+29 +1); out[0*32+30] = (start += ((w4 >> 44) & 0x3ff)) + (0*32+30 +1); out[0*32+31] = (start += ((w4 >> 54))) + (0*32+31 +1);;}; out += 32; start += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_11(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 11) & 0x7ff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 22) & 0x7ff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 33) & 0x7ff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w0 >> 44) & 0x7ff)) + (0*64+ 4 +1); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w0 >> 55) | (w1 << 9) & 0x7ff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w1 >> 2) & 0x7ff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w1 >> 13) & 0x7ff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w1 >> 24) & 0x7ff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w1 >> 35) & 0x7ff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w1 >> 46) & 0x7ff)) + (0*64+10 +1); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = (start += ((w1 >> 57) | (w2 << 7) & 0x7ff)) + (0*64+11 +1); out[0*64+12] = (start += ((w2 >> 4) & 0x7ff)) + (0*64+12 +1); out[0*64+13] = (start += ((w2 >> 15) & 0x7ff)) + (0*64+13 +1); out[0*64+14] = (start += ((w2 >> 26) & 0x7ff)) + (0*64+14 +1); out[0*64+15] = (start += ((w2 >> 37) & 0x7ff)) + (0*64+15 +1); out[0*64+16] = (start += ((w2 >> 48) & 0x7ff)) + (0*64+16 +1); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = (start += ((w2 >> 59) | (w3 << 5) & 0x7ff)) + (0*64+17 +1); out[0*64+18] = (start += ((w3 >> 6) & 0x7ff)) + (0*64+18 +1); out[0*64+19] = (start += ((w3 >> 17) & 0x7ff)) + (0*64+19 +1); out[0*64+20] = (start += ((w3 >> 28) & 0x7ff)) + (0*64+20 +1); out[0*64+21] = (start += ((w3 >> 39) & 0x7ff)) + (0*64+21 +1); out[0*64+22] = (start += ((w3 >> 50) & 0x7ff)) + (0*64+22 +1); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = (start += ((w3 >> 61) | (w4 << 3) & 0x7ff)) + (0*64+23 +1); out[0*64+24] = (start += ((w4 >> 8) & 0x7ff)) + (0*64+24 +1); out[0*64+25] = (start += ((w4 >> 19) & 0x7ff)) + (0*64+25 +1); out[0*64+26] = (start += ((w4 >> 30) & 0x7ff)) + (0*64+26 +1); out[0*64+27] = (start += ((w4 >> 41) & 0x7ff)) + (0*64+27 +1); out[0*64+28] = (start += ((w4 >> 52) & 0x7ff)) + (0*64+28 +1); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = (start += ((w4 >> 63) | (w5 << 1) & 0x7ff)) + (0*64+29 +1); out[0*64+30] = (start += ((w5 >> 10) & 0x7ff)) + (0*64+30 +1); out[0*64+31] = (start += ((w5 >> 21) & 0x7ff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_12(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfff)) + (0*16+ 0 +1); out[0*16+ 1] = (start += ((w0 >> 12) & 0xfff)) + (0*16+ 1 +1); out[0*16+ 2] = (start += ((w0 >> 24) & 0xfff)) + (0*16+ 2 +1); out[0*16+ 3] = (start += ((w0 >> 36) & 0xfff)) + (0*16+ 3 +1); out[0*16+ 4] = (start += ((w0 >> 48) & 0xfff)) + (0*16+ 4 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = (start += ((w0 >> 60) | (w1 << 4) & 0xfff)) + (0*16+ 5 +1); out[0*16+ 6] = (start += ((w1 >> 8) & 0xfff)) + (0*16+ 6 +1); out[0*16+ 7] = (start += ((w1 >> 20) & 0xfff)) + (0*16+ 7 +1); out[0*16+ 8] = (start += ((w1 >> 32) & 0xfff)) + (0*16+ 8 +1); out[0*16+ 9] = (start += ((w1 >> 44) & 0xfff)) + (0*16+ 9 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = (start += ((w1 >> 56) | (w2 << 8) & 0xfff)) + (0*16+10 +1); out[0*16+11] = (start += ((w2 >> 4) & 0xfff)) + (0*16+11 +1); out[0*16+12] = (start += ((w2 >> 16) & 0xfff)) + (0*16+12 +1); out[0*16+13] = (start += ((w2 >> 28) & 0xfff)) + (0*16+13 +1); out[0*16+14] = (start += ((w2 >> 40) & 0xfff)) + (0*16+14 +1); out[0*16+15] = (start += ((w2 >> 52))) + (0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfff)) + (1*16+ 0 +1); out[1*16+ 1] = (start += ((w0 >> 12) & 0xfff)) + (1*16+ 1 +1); out[1*16+ 2] = (start += ((w0 >> 24) & 0xfff)) + (1*16+ 2 +1); out[1*16+ 3] = (start += ((w0 >> 36) & 0xfff)) + (1*16+ 3 +1); out[1*16+ 4] = (start += ((w0 >> 48) & 0xfff)) + (1*16+ 4 +1); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = (start += ((w0 >> 60) | (w1 << 4) & 0xfff)) + (1*16+ 5 +1); out[1*16+ 6] = (start += ((w1 >> 8) & 0xfff)) + (1*16+ 6 +1); out[1*16+ 7] = (start += ((w1 >> 20) & 0xfff)) + (1*16+ 7 +1); out[1*16+ 8] = (start += ((w1 >> 32) & 0xfff)) + (1*16+ 8 +1); out[1*16+ 9] = (start += ((w1 >> 44) & 0xfff)) + (1*16+ 9 +1); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = (start += ((w1 >> 56) | (w2 << 8) & 0xfff)) + (1*16+10 +1); out[1*16+11] = (start += ((w2 >> 4) & 0xfff)) + (1*16+11 +1); out[1*16+12] = (start += ((w2 >> 16) & 0xfff)) + (1*16+12 +1); out[1*16+13] = (start += ((w2 >> 28) & 0xfff)) + (1*16+13 +1); out[1*16+14] = (start += ((w2 >> 40) & 0xfff)) + (1*16+14 +1); out[1*16+15] = (start += ((w2 >> 52))) + (1*16+15 +1);;}; out += 32; start += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_13(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 13) & 0x1fff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 26) & 0x1fff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 39) & 0x1fff)) + (0*64+ 3 +1); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w0 >> 52) | (w1 << 12) & 0x1fff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w1 >> 1) & 0x1fff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w1 >> 14) & 0x1fff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w1 >> 27) & 0x1fff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w1 >> 40) & 0x1fff)) + (0*64+ 8 +1); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w1 >> 53) | (w2 << 11) & 0x1fff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w2 >> 2) & 0x1fff)) + (0*64+10 +1); out[0*64+11] = (start += ((w2 >> 15) & 0x1fff)) + (0*64+11 +1); out[0*64+12] = (start += ((w2 >> 28) & 0x1fff)) + (0*64+12 +1); out[0*64+13] = (start += ((w2 >> 41) & 0x1fff)) + (0*64+13 +1); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = (start += ((w2 >> 54) | (w3 << 10) & 0x1fff)) + (0*64+14 +1); out[0*64+15] = (start += ((w3 >> 3) & 0x1fff)) + (0*64+15 +1); out[0*64+16] = (start += ((w3 >> 16) & 0x1fff)) + (0*64+16 +1); out[0*64+17] = (start += ((w3 >> 29) & 0x1fff)) + (0*64+17 +1); out[0*64+18] = (start += ((w3 >> 42) & 0x1fff)) + (0*64+18 +1); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = (start += ((w3 >> 55) | (w4 << 9) & 0x1fff)) + (0*64+19 +1); out[0*64+20] = (start += ((w4 >> 4) & 0x1fff)) + (0*64+20 +1); out[0*64+21] = (start += ((w4 >> 17) & 0x1fff)) + (0*64+21 +1); out[0*64+22] = (start += ((w4 >> 30) & 0x1fff)) + (0*64+22 +1); out[0*64+23] = (start += ((w4 >> 43) & 0x1fff)) + (0*64+23 +1); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = (start += ((w4 >> 56) | (w5 << 8) & 0x1fff)) + (0*64+24 +1); out[0*64+25] = (start += ((w5 >> 5) & 0x1fff)) + (0*64+25 +1); out[0*64+26] = (start += ((w5 >> 18) & 0x1fff)) + (0*64+26 +1); out[0*64+27] = (start += ((w5 >> 31) & 0x1fff)) + (0*64+27 +1); out[0*64+28] = (start += ((w5 >> 44) & 0x1fff)) + (0*64+28 +1); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = (start += ((w5 >> 57) | (w6 << 7) & 0x1fff)) + (0*64+29 +1); out[0*64+30] = (start += ((w6 >> 6) & 0x1fff)) + (0*64+30 +1); out[0*64+31] = (start += ((w6 >> 19) & 0x1fff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_14(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fff)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 14) & 0x3fff)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 28) & 0x3fff)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w0 >> 42) & 0x3fff)) + (0*32+ 3 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w0 >> 56) | (w1 << 8) & 0x3fff)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w1 >> 6) & 0x3fff)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w1 >> 20) & 0x3fff)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w1 >> 34) & 0x3fff)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w1 >> 48) & 0x3fff)) + (0*32+ 8 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w1 >> 62) | (w2 << 2) & 0x3fff)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w2 >> 12) & 0x3fff)) + (0*32+10 +1); out[0*32+11] = (start += ((w2 >> 26) & 0x3fff)) + (0*32+11 +1); out[0*32+12] = (start += ((w2 >> 40) & 0x3fff)) + (0*32+12 +1); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = (start += ((w2 >> 54) | (w3 << 10) & 0x3fff)) + (0*32+13 +1); out[0*32+14] = (start += ((w3 >> 4) & 0x3fff)) + (0*32+14 +1); out[0*32+15] = (start += ((w3 >> 18) & 0x3fff)) + (0*32+15 +1); out[0*32+16] = (start += ((w3 >> 32) & 0x3fff)) + (0*32+16 +1); out[0*32+17] = (start += ((w3 >> 46) & 0x3fff)) + (0*32+17 +1); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = (start += ((w3 >> 60) | (w4 << 4) & 0x3fff)) + (0*32+18 +1); out[0*32+19] = (start += ((w4 >> 10) & 0x3fff)) + (0*32+19 +1); out[0*32+20] = (start += ((w4 >> 24) & 0x3fff)) + (0*32+20 +1); out[0*32+21] = (start += ((w4 >> 38) & 0x3fff)) + (0*32+21 +1); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = (start += ((w4 >> 52) | (w5 << 12) & 0x3fff)) + (0*32+22 +1); out[0*32+23] = (start += ((w5 >> 2) & 0x3fff)) + (0*32+23 +1); out[0*32+24] = (start += ((w5 >> 16) & 0x3fff)) + (0*32+24 +1); out[0*32+25] = (start += ((w5 >> 30) & 0x3fff)) + (0*32+25 +1); out[0*32+26] = (start += ((w5 >> 44) & 0x3fff)) + (0*32+26 +1); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = (start += ((w5 >> 58) | (w6 << 6) & 0x3fff)) + (0*32+27 +1); out[0*32+28] = (start += ((w6 >> 8) & 0x3fff)) + (0*32+28 +1); out[0*32+29] = (start += ((w6 >> 22) & 0x3fff)) + (0*32+29 +1); out[0*32+30] = (start += ((w6 >> 36) & 0x3fff)) + (0*32+30 +1); out[0*32+31] = (start += ((w6 >> 50))) + (0*32+31 +1);;}; out += 32; start += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_15(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 15) & 0x7fff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 30) & 0x7fff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w0 >> 45) & 0x7fff)) + (0*64+ 3 +1); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w0 >> 60) | (w1 << 4) & 0x7fff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w1 >> 11) & 0x7fff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w1 >> 26) & 0x7fff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w1 >> 41) & 0x7fff)) + (0*64+ 7 +1); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w1 >> 56) | (w2 << 8) & 0x7fff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w2 >> 7) & 0x7fff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w2 >> 22) & 0x7fff)) + (0*64+10 +1); out[0*64+11] = (start += ((w2 >> 37) & 0x7fff)) + (0*64+11 +1); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = (start += ((w2 >> 52) | (w3 << 12) & 0x7fff)) + (0*64+12 +1); out[0*64+13] = (start += ((w3 >> 3) & 0x7fff)) + (0*64+13 +1); out[0*64+14] = (start += ((w3 >> 18) & 0x7fff)) + (0*64+14 +1); out[0*64+15] = (start += ((w3 >> 33) & 0x7fff)) + (0*64+15 +1); out[0*64+16] = (start += ((w3 >> 48) & 0x7fff)) + (0*64+16 +1); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = (start += ((w3 >> 63) | (w4 << 1) & 0x7fff)) + (0*64+17 +1); out[0*64+18] = (start += ((w4 >> 14) & 0x7fff)) + (0*64+18 +1); out[0*64+19] = (start += ((w4 >> 29) & 0x7fff)) + (0*64+19 +1); out[0*64+20] = (start += ((w4 >> 44) & 0x7fff)) + (0*64+20 +1); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = (start += ((w4 >> 59) | (w5 << 5) & 0x7fff)) + (0*64+21 +1); out[0*64+22] = (start += ((w5 >> 10) & 0x7fff)) + (0*64+22 +1); out[0*64+23] = (start += ((w5 >> 25) & 0x7fff)) + (0*64+23 +1); out[0*64+24] = (start += ((w5 >> 40) & 0x7fff)) + (0*64+24 +1); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = (start += ((w5 >> 55) | (w6 << 9) & 0x7fff)) + (0*64+25 +1); out[0*64+26] = (start += ((w6 >> 6) & 0x7fff)) + (0*64+26 +1); out[0*64+27] = (start += ((w6 >> 21) & 0x7fff)) + (0*64+27 +1); out[0*64+28] = (start += ((w6 >> 36) & 0x7fff)) + (0*64+28 +1); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = (start += ((w6 >> 51) | (w7 << 13) & 0x7fff)) + (0*64+29 +1); out[0*64+30] = (start += ((w7 >> 2) & 0x7fff)) + (0*64+30 +1); out[0*64+31] = (start += ((w7 >> 17) & 0x7fff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_16(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = (start += (*(uint16_t *)(in+0*8+ 0))) + (0*4+ 0 +1); out[0*4+ 1] = (start += (*(uint16_t *)(in+0*8+ 2))) + (0*4+ 1 +1); out[0*4+ 2] = (start += (*(uint16_t *)(in+0*8+ 4))) + (0*4+ 2 +1); out[0*4+ 3] = (start += (*(uint16_t *)(in+0*8+ 6))) + (0*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = (start += (*(uint16_t *)(in+1*8+ 0))) + (1*4+ 0 +1); out[1*4+ 1] = (start += (*(uint16_t *)(in+1*8+ 2))) + (1*4+ 1 +1); out[1*4+ 2] = (start += (*(uint16_t *)(in+1*8+ 4))) + (1*4+ 2 +1); out[1*4+ 3] = (start += (*(uint16_t *)(in+1*8+ 6))) + (1*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = (start += (*(uint16_t *)(in+2*8+ 0))) + (2*4+ 0 +1); out[2*4+ 1] = (start += (*(uint16_t *)(in+2*8+ 2))) + (2*4+ 1 +1); out[2*4+ 2] = (start += (*(uint16_t *)(in+2*8+ 4))) + (2*4+ 2 +1); out[2*4+ 3] = (start += (*(uint16_t *)(in+2*8+ 6))) + (2*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = (start += (*(uint16_t *)(in+3*8+ 0))) + (3*4+ 0 +1); out[3*4+ 1] = (start += (*(uint16_t *)(in+3*8+ 2))) + (3*4+ 1 +1); out[3*4+ 2] = (start += (*(uint16_t *)(in+3*8+ 4))) + (3*4+ 2 +1); out[3*4+ 3] = (start += (*(uint16_t *)(in+3*8+ 6))) + (3*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = (start += (*(uint16_t *)(in+4*8+ 0))) + (4*4+ 0 +1); out[4*4+ 1] = (start += (*(uint16_t *)(in+4*8+ 2))) + (4*4+ 1 +1); out[4*4+ 2] = (start += (*(uint16_t *)(in+4*8+ 4))) + (4*4+ 2 +1); out[4*4+ 3] = (start += (*(uint16_t *)(in+4*8+ 6))) + (4*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = (start += (*(uint16_t *)(in+5*8+ 0))) + (5*4+ 0 +1); out[5*4+ 1] = (start += (*(uint16_t *)(in+5*8+ 2))) + (5*4+ 1 +1); out[5*4+ 2] = (start += (*(uint16_t *)(in+5*8+ 4))) + (5*4+ 2 +1); out[5*4+ 3] = (start += (*(uint16_t *)(in+5*8+ 6))) + (5*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = (start += (*(uint16_t *)(in+6*8+ 0))) + (6*4+ 0 +1); out[6*4+ 1] = (start += (*(uint16_t *)(in+6*8+ 2))) + (6*4+ 1 +1); out[6*4+ 2] = (start += (*(uint16_t *)(in+6*8+ 4))) + (6*4+ 2 +1); out[6*4+ 3] = (start += (*(uint16_t *)(in+6*8+ 6))) + (6*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = (start += (*(uint16_t *)(in+7*8+ 0))) + (7*4+ 0 +1); out[7*4+ 1] = (start += (*(uint16_t *)(in+7*8+ 2))) + (7*4+ 1 +1); out[7*4+ 2] = (start += (*(uint16_t *)(in+7*8+ 4))) + (7*4+ 2 +1); out[7*4+ 3] = (start += (*(uint16_t *)(in+7*8+ 6))) + (7*4+ 3 +1);;}; out += 32; start += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_17(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*17)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 17) & 0x1ffff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 34) & 0x1ffff)) + (0*64+ 2 +1); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w0 >> 51) | (w1 << 13) & 0x1ffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w1 >> 4) & 0x1ffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w1 >> 21) & 0x1ffff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w1 >> 38) & 0x1ffff)) + (0*64+ 6 +1); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w1 >> 55) | (w2 << 9) & 0x1ffff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w2 >> 8) & 0x1ffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w2 >> 25) & 0x1ffff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w2 >> 42) & 0x1ffff)) + (0*64+10 +1); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*64+11] = (start += ((w2 >> 59) | (w3 << 5) & 0x1ffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w3 >> 12) & 0x1ffff)) + (0*64+12 +1); out[0*64+13] = (start += ((w3 >> 29) & 0x1ffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w3 >> 46) & 0x1ffff)) + (0*64+14 +1); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*64+15] = (start += ((w3 >> 63) | (w4 << 1) & 0x1ffff)) + (0*64+15 +1); out[0*64+16] = (start += ((w4 >> 16) & 0x1ffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w4 >> 33) & 0x1ffff)) + (0*64+17 +1); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*64+18] = (start += ((w4 >> 50) | (w5 << 14) & 0x1ffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w5 >> 3) & 0x1ffff)) + (0*64+19 +1); out[0*64+20] = (start += ((w5 >> 20) & 0x1ffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w5 >> 37) & 0x1ffff)) + (0*64+21 +1); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*64+22] = (start += ((w5 >> 54) | (w6 << 10) & 0x1ffff)) + (0*64+22 +1); out[0*64+23] = (start += ((w6 >> 7) & 0x1ffff)) + (0*64+23 +1); out[0*64+24] = (start += ((w6 >> 24) & 0x1ffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w6 >> 41) & 0x1ffff)) + (0*64+25 +1); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*64+26] = (start += ((w6 >> 58) | (w7 << 6) & 0x1ffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w7 >> 11) & 0x1ffff)) + (0*64+27 +1); out[0*64+28] = (start += ((w7 >> 28) & 0x1ffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w7 >> 45) & 0x1ffff)) + (0*64+29 +1); w8 = *(uint32_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*64+30] = (start += ((w7 >> 62) | (w8 << 2) & 0x1ffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w8 >> 15) & 0x1ffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 17*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_18(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*18)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffff)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 18) & 0x3ffff)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w0 >> 36) & 0x3ffff)) + (0*32+ 2 +1); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w0 >> 54) | (w1 << 10) & 0x3ffff)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w1 >> 8) & 0x3ffff)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w1 >> 26) & 0x3ffff)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w1 >> 44) & 0x3ffff)) + (0*32+ 6 +1); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w1 >> 62) | (w2 << 2) & 0x3ffff)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w2 >> 16) & 0x3ffff)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w2 >> 34) & 0x3ffff)) + (0*32+ 9 +1); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*32+10] = (start += ((w2 >> 52) | (w3 << 12) & 0x3ffff)) + (0*32+10 +1); out[0*32+11] = (start += ((w3 >> 6) & 0x3ffff)) + (0*32+11 +1); out[0*32+12] = (start += ((w3 >> 24) & 0x3ffff)) + (0*32+12 +1); out[0*32+13] = (start += ((w3 >> 42) & 0x3ffff)) + (0*32+13 +1); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*32+14] = (start += ((w3 >> 60) | (w4 << 4) & 0x3ffff)) + (0*32+14 +1); out[0*32+15] = (start += ((w4 >> 14) & 0x3ffff)) + (0*32+15 +1); out[0*32+16] = (start += ((w4 >> 32) & 0x3ffff)) + (0*32+16 +1); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*32+17] = (start += ((w4 >> 50) | (w5 << 14) & 0x3ffff)) + (0*32+17 +1); out[0*32+18] = (start += ((w5 >> 4) & 0x3ffff)) + (0*32+18 +1); out[0*32+19] = (start += ((w5 >> 22) & 0x3ffff)) + (0*32+19 +1); out[0*32+20] = (start += ((w5 >> 40) & 0x3ffff)) + (0*32+20 +1); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*32+21] = (start += ((w5 >> 58) | (w6 << 6) & 0x3ffff)) + (0*32+21 +1); out[0*32+22] = (start += ((w6 >> 12) & 0x3ffff)) + (0*32+22 +1); out[0*32+23] = (start += ((w6 >> 30) & 0x3ffff)) + (0*32+23 +1); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*32+24] = (start += ((w6 >> 48) | (w7 << 16) & 0x3ffff)) + (0*32+24 +1); out[0*32+25] = (start += ((w7 >> 2) & 0x3ffff)) + (0*32+25 +1); out[0*32+26] = (start += ((w7 >> 20) & 0x3ffff)) + (0*32+26 +1); out[0*32+27] = (start += ((w7 >> 38) & 0x3ffff)) + (0*32+27 +1); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*32+28] = (start += ((w7 >> 56) | (w8 << 8) & 0x3ffff)) + (0*32+28 +1); out[0*32+29] = (start += ((w8 >> 10) & 0x3ffff)) + (0*32+29 +1); out[0*32+30] = (start += ((w8 >> 28) & 0x3ffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w8 >> 46))) + (0*32+31 +1);;}; out += 32; start += 32; in += 18*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_19(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*19)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 19) & 0x7ffff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 38) & 0x7ffff)) + (0*64+ 2 +1); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w0 >> 57) | (w1 << 7) & 0x7ffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w1 >> 12) & 0x7ffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w1 >> 31) & 0x7ffff)) + (0*64+ 5 +1); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w1 >> 50) | (w2 << 14) & 0x7ffff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w2 >> 5) & 0x7ffff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w2 >> 24) & 0x7ffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w2 >> 43) & 0x7ffff)) + (0*64+ 9 +1); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*64+10] = (start += ((w2 >> 62) | (w3 << 2) & 0x7ffff)) + (0*64+10 +1); out[0*64+11] = (start += ((w3 >> 17) & 0x7ffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w3 >> 36) & 0x7ffff)) + (0*64+12 +1); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*64+13] = (start += ((w3 >> 55) | (w4 << 9) & 0x7ffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w4 >> 10) & 0x7ffff)) + (0*64+14 +1); out[0*64+15] = (start += ((w4 >> 29) & 0x7ffff)) + (0*64+15 +1); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*64+16] = (start += ((w4 >> 48) | (w5 << 16) & 0x7ffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w5 >> 3) & 0x7ffff)) + (0*64+17 +1); out[0*64+18] = (start += ((w5 >> 22) & 0x7ffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w5 >> 41) & 0x7ffff)) + (0*64+19 +1); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*64+20] = (start += ((w5 >> 60) | (w6 << 4) & 0x7ffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w6 >> 15) & 0x7ffff)) + (0*64+21 +1); out[0*64+22] = (start += ((w6 >> 34) & 0x7ffff)) + (0*64+22 +1); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*64+23] = (start += ((w6 >> 53) | (w7 << 11) & 0x7ffff)) + (0*64+23 +1); out[0*64+24] = (start += ((w7 >> 8) & 0x7ffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w7 >> 27) & 0x7ffff)) + (0*64+25 +1); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*64+26] = (start += ((w7 >> 46) | (w8 << 18) & 0x7ffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w8 >> 1) & 0x7ffff)) + (0*64+27 +1); out[0*64+28] = (start += ((w8 >> 20) & 0x7ffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w8 >> 39) & 0x7ffff)) + (0*64+29 +1); w9 = *(uint32_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*64+30] = (start += ((w8 >> 58) | (w9 << 6) & 0x7ffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w9 >> 13) & 0x7ffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 19*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_20(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*20)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffff)) + (0*16+ 0 +1); out[0*16+ 1] = (start += ((w0 >> 20) & 0xfffff)) + (0*16+ 1 +1); out[0*16+ 2] = (start += ((w0 >> 40) & 0xfffff)) + (0*16+ 2 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*16+ 3] = (start += ((w0 >> 60) | (w1 << 4) & 0xfffff)) + (0*16+ 3 +1); out[0*16+ 4] = (start += ((w1 >> 16) & 0xfffff)) + (0*16+ 4 +1); out[0*16+ 5] = (start += ((w1 >> 36) & 0xfffff)) + (0*16+ 5 +1); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*16+ 6] = (start += ((w1 >> 56) | (w2 << 8) & 0xfffff)) + (0*16+ 6 +1); out[0*16+ 7] = (start += ((w2 >> 12) & 0xfffff)) + (0*16+ 7 +1); out[0*16+ 8] = (start += ((w2 >> 32) & 0xfffff)) + (0*16+ 8 +1); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*16+ 9] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffff)) + (0*16+ 9 +1); out[0*16+10] = (start += ((w3 >> 8) & 0xfffff)) + (0*16+10 +1); out[0*16+11] = (start += ((w3 >> 28) & 0xfffff)) + (0*16+11 +1); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*16+12] = (start += ((w3 >> 48) | (w4 << 16) & 0xfffff)) + (0*16+12 +1); out[0*16+13] = (start += ((w4 >> 4) & 0xfffff)) + (0*16+13 +1); out[0*16+14] = (start += ((w4 >> 24) & 0xfffff)) + (0*16+14 +1); out[0*16+15] = (start += ((w4 >> 44))) + (0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffff)) + (1*16+ 0 +1); out[1*16+ 1] = (start += ((w0 >> 20) & 0xfffff)) + (1*16+ 1 +1); out[1*16+ 2] = (start += ((w0 >> 40) & 0xfffff)) + (1*16+ 2 +1); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*16+ 3] = (start += ((w0 >> 60) | (w1 << 4) & 0xfffff)) + (1*16+ 3 +1); out[1*16+ 4] = (start += ((w1 >> 16) & 0xfffff)) + (1*16+ 4 +1); out[1*16+ 5] = (start += ((w1 >> 36) & 0xfffff)) + (1*16+ 5 +1); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*16+ 6] = (start += ((w1 >> 56) | (w2 << 8) & 0xfffff)) + (1*16+ 6 +1); out[1*16+ 7] = (start += ((w2 >> 12) & 0xfffff)) + (1*16+ 7 +1); out[1*16+ 8] = (start += ((w2 >> 32) & 0xfffff)) + (1*16+ 8 +1); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*16+ 9] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffff)) + (1*16+ 9 +1); out[1*16+10] = (start += ((w3 >> 8) & 0xfffff)) + (1*16+10 +1); out[1*16+11] = (start += ((w3 >> 28) & 0xfffff)) + (1*16+11 +1); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*16+12] = (start += ((w3 >> 48) | (w4 << 16) & 0xfffff)) + (1*16+12 +1); out[1*16+13] = (start += ((w4 >> 4) & 0xfffff)) + (1*16+13 +1); out[1*16+14] = (start += ((w4 >> 24) & 0xfffff)) + (1*16+14 +1); out[1*16+15] = (start += ((w4 >> 44))) + (1*16+15 +1);;}; out += 32; start += 32; in += 20*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_21(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*21)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 21) & 0x1fffff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w0 >> 42) & 0x1fffff)) + (0*64+ 2 +1); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w0 >> 63) | (w1 << 1) & 0x1fffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w1 >> 20) & 0x1fffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w1 >> 41) & 0x1fffff)) + (0*64+ 5 +1); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w1 >> 62) | (w2 << 2) & 0x1fffff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w2 >> 19) & 0x1fffff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w2 >> 40) & 0x1fffff)) + (0*64+ 8 +1); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w2 >> 61) | (w3 << 3) & 0x1fffff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w3 >> 18) & 0x1fffff)) + (0*64+10 +1); out[0*64+11] = (start += ((w3 >> 39) & 0x1fffff)) + (0*64+11 +1); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*64+12] = (start += ((w3 >> 60) | (w4 << 4) & 0x1fffff)) + (0*64+12 +1); out[0*64+13] = (start += ((w4 >> 17) & 0x1fffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w4 >> 38) & 0x1fffff)) + (0*64+14 +1); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*64+15] = (start += ((w4 >> 59) | (w5 << 5) & 0x1fffff)) + (0*64+15 +1); out[0*64+16] = (start += ((w5 >> 16) & 0x1fffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w5 >> 37) & 0x1fffff)) + (0*64+17 +1); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*64+18] = (start += ((w5 >> 58) | (w6 << 6) & 0x1fffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w6 >> 15) & 0x1fffff)) + (0*64+19 +1); out[0*64+20] = (start += ((w6 >> 36) & 0x1fffff)) + (0*64+20 +1); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*64+21] = (start += ((w6 >> 57) | (w7 << 7) & 0x1fffff)) + (0*64+21 +1); out[0*64+22] = (start += ((w7 >> 14) & 0x1fffff)) + (0*64+22 +1); out[0*64+23] = (start += ((w7 >> 35) & 0x1fffff)) + (0*64+23 +1); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*64+24] = (start += ((w7 >> 56) | (w8 << 8) & 0x1fffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w8 >> 13) & 0x1fffff)) + (0*64+25 +1); out[0*64+26] = (start += ((w8 >> 34) & 0x1fffff)) + (0*64+26 +1); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*64+27] = (start += ((w8 >> 55) | (w9 << 9) & 0x1fffff)) + (0*64+27 +1); out[0*64+28] = (start += ((w9 >> 12) & 0x1fffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w9 >> 33) & 0x1fffff)) + (0*64+29 +1); w10 = *(uint32_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*64+30] = (start += ((w9 >> 54) | (w10 << 10) & 0x1fffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w10 >> 11) & 0x1fffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 21*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_22(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*22)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffff)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 22) & 0x3fffff)) + (0*32+ 1 +1); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w0 >> 44) | (w1 << 20) & 0x3fffff)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w1 >> 2) & 0x3fffff)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w1 >> 24) & 0x3fffff)) + (0*32+ 4 +1); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w1 >> 46) | (w2 << 18) & 0x3fffff)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w2 >> 4) & 0x3fffff)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w2 >> 26) & 0x3fffff)) + (0*32+ 7 +1); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w2 >> 48) | (w3 << 16) & 0x3fffff)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w3 >> 6) & 0x3fffff)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w3 >> 28) & 0x3fffff)) + (0*32+10 +1); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*32+11] = (start += ((w3 >> 50) | (w4 << 14) & 0x3fffff)) + (0*32+11 +1); out[0*32+12] = (start += ((w4 >> 8) & 0x3fffff)) + (0*32+12 +1); out[0*32+13] = (start += ((w4 >> 30) & 0x3fffff)) + (0*32+13 +1); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*32+14] = (start += ((w4 >> 52) | (w5 << 12) & 0x3fffff)) + (0*32+14 +1); out[0*32+15] = (start += ((w5 >> 10) & 0x3fffff)) + (0*32+15 +1); out[0*32+16] = (start += ((w5 >> 32) & 0x3fffff)) + (0*32+16 +1); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*32+17] = (start += ((w5 >> 54) | (w6 << 10) & 0x3fffff)) + (0*32+17 +1); out[0*32+18] = (start += ((w6 >> 12) & 0x3fffff)) + (0*32+18 +1); out[0*32+19] = (start += ((w6 >> 34) & 0x3fffff)) + (0*32+19 +1); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*32+20] = (start += ((w6 >> 56) | (w7 << 8) & 0x3fffff)) + (0*32+20 +1); out[0*32+21] = (start += ((w7 >> 14) & 0x3fffff)) + (0*32+21 +1); out[0*32+22] = (start += ((w7 >> 36) & 0x3fffff)) + (0*32+22 +1); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*32+23] = (start += ((w7 >> 58) | (w8 << 6) & 0x3fffff)) + (0*32+23 +1); out[0*32+24] = (start += ((w8 >> 16) & 0x3fffff)) + (0*32+24 +1); out[0*32+25] = (start += ((w8 >> 38) & 0x3fffff)) + (0*32+25 +1); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*32+26] = (start += ((w8 >> 60) | (w9 << 4) & 0x3fffff)) + (0*32+26 +1); out[0*32+27] = (start += ((w9 >> 18) & 0x3fffff)) + (0*32+27 +1); out[0*32+28] = (start += ((w9 >> 40) & 0x3fffff)) + (0*32+28 +1); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*32+29] = (start += ((w9 >> 62) | (w10 << 2) & 0x3fffff)) + (0*32+29 +1); out[0*32+30] = (start += ((w10 >> 20) & 0x3fffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w10 >> 42))) + (0*32+31 +1);;}; out += 32; start += 32; in += 22*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_23(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*23)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 23) & 0x7fffff)) + (0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 46) | (w1 << 18) & 0x7fffff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w1 >> 5) & 0x7fffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w1 >> 28) & 0x7fffff)) + (0*64+ 4 +1); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w1 >> 51) | (w2 << 13) & 0x7fffff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w2 >> 10) & 0x7fffff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w2 >> 33) & 0x7fffff)) + (0*64+ 7 +1); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w2 >> 56) | (w3 << 8) & 0x7fffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w3 >> 15) & 0x7fffff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w3 >> 38) & 0x7fffff)) + (0*64+10 +1); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*64+11] = (start += ((w3 >> 61) | (w4 << 3) & 0x7fffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w4 >> 20) & 0x7fffff)) + (0*64+12 +1); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*64+13] = (start += ((w4 >> 43) | (w5 << 21) & 0x7fffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w5 >> 2) & 0x7fffff)) + (0*64+14 +1); out[0*64+15] = (start += ((w5 >> 25) & 0x7fffff)) + (0*64+15 +1); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*64+16] = (start += ((w5 >> 48) | (w6 << 16) & 0x7fffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w6 >> 7) & 0x7fffff)) + (0*64+17 +1); out[0*64+18] = (start += ((w6 >> 30) & 0x7fffff)) + (0*64+18 +1); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*64+19] = (start += ((w6 >> 53) | (w7 << 11) & 0x7fffff)) + (0*64+19 +1); out[0*64+20] = (start += ((w7 >> 12) & 0x7fffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w7 >> 35) & 0x7fffff)) + (0*64+21 +1); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*64+22] = (start += ((w7 >> 58) | (w8 << 6) & 0x7fffff)) + (0*64+22 +1); out[0*64+23] = (start += ((w8 >> 17) & 0x7fffff)) + (0*64+23 +1); out[0*64+24] = (start += ((w8 >> 40) & 0x7fffff)) + (0*64+24 +1); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*64+25] = (start += ((w8 >> 63) | (w9 << 1) & 0x7fffff)) + (0*64+25 +1); out[0*64+26] = (start += ((w9 >> 22) & 0x7fffff)) + (0*64+26 +1); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*64+27] = (start += ((w9 >> 45) | (w10 << 19) & 0x7fffff)) + (0*64+27 +1); out[0*64+28] = (start += ((w10 >> 4) & 0x7fffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w10 >> 27) & 0x7fffff)) + (0*64+29 +1); w11 = *(uint32_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*64+30] = (start += ((w10 >> 50) | (w11 << 14) & 0x7fffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w11 >> 9) & 0x7fffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 23*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_24(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*24)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xffffff)) + (0*8+ 0 +1); out[0*8+ 1] = (start += ((w0 >> 24) & 0xffffff)) + (0*8+ 1 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)) + (0*8+ 2 +1); out[0*8+ 3] = (start += ((w1 >> 8) & 0xffffff)) + (0*8+ 3 +1); out[0*8+ 4] = (start += ((w1 >> 32) & 0xffffff)) + (0*8+ 4 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)) + (0*8+ 5 +1); out[0*8+ 6] = (start += ((w2 >> 16) & 0xffffff)) + (0*8+ 6 +1); out[0*8+ 7] = (start += ((w2 >> 40))) + (0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xffffff)) + (1*8+ 0 +1); out[1*8+ 1] = (start += ((w0 >> 24) & 0xffffff)) + (1*8+ 1 +1); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)) + (1*8+ 2 +1); out[1*8+ 3] = (start += ((w1 >> 8) & 0xffffff)) + (1*8+ 3 +1); out[1*8+ 4] = (start += ((w1 >> 32) & 0xffffff)) + (1*8+ 4 +1); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)) + (1*8+ 5 +1); out[1*8+ 6] = (start += ((w2 >> 16) & 0xffffff)) + (1*8+ 6 +1); out[1*8+ 7] = (start += ((w2 >> 40))) + (1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xffffff)) + (2*8+ 0 +1); out[2*8+ 1] = (start += ((w0 >> 24) & 0xffffff)) + (2*8+ 1 +1); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)) + (2*8+ 2 +1); out[2*8+ 3] = (start += ((w1 >> 8) & 0xffffff)) + (2*8+ 3 +1); out[2*8+ 4] = (start += ((w1 >> 32) & 0xffffff)) + (2*8+ 4 +1); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)) + (2*8+ 5 +1); out[2*8+ 6] = (start += ((w2 >> 16) & 0xffffff)) + (2*8+ 6 +1); out[2*8+ 7] = (start += ((w2 >> 40))) + (2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xffffff)) + (3*8+ 0 +1); out[3*8+ 1] = (start += ((w0 >> 24) & 0xffffff)) + (3*8+ 1 +1); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*8+ 2] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffff)) + (3*8+ 2 +1); out[3*8+ 3] = (start += ((w1 >> 8) & 0xffffff)) + (3*8+ 3 +1); out[3*8+ 4] = (start += ((w1 >> 32) & 0xffffff)) + (3*8+ 4 +1); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*8+ 5] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffff)) + (3*8+ 5 +1); out[3*8+ 6] = (start += ((w2 >> 16) & 0xffffff)) + (3*8+ 6 +1); out[3*8+ 7] = (start += ((w2 >> 40))) + (3*8+ 7 +1);;}; out += 32; start += 32; in += 24*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_25(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*25)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 25) & 0x1ffffff)) + (0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 50) | (w1 << 14) & 0x1ffffff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w1 >> 11) & 0x1ffffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w1 >> 36) & 0x1ffffff)) + (0*64+ 4 +1); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w1 >> 61) | (w2 << 3) & 0x1ffffff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w2 >> 22) & 0x1ffffff)) + (0*64+ 6 +1); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w2 >> 47) | (w3 << 17) & 0x1ffffff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w3 >> 8) & 0x1ffffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w3 >> 33) & 0x1ffffff)) + (0*64+ 9 +1); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*64+10] = (start += ((w3 >> 58) | (w4 << 6) & 0x1ffffff)) + (0*64+10 +1); out[0*64+11] = (start += ((w4 >> 19) & 0x1ffffff)) + (0*64+11 +1); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*64+12] = (start += ((w4 >> 44) | (w5 << 20) & 0x1ffffff)) + (0*64+12 +1); out[0*64+13] = (start += ((w5 >> 5) & 0x1ffffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w5 >> 30) & 0x1ffffff)) + (0*64+14 +1); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*64+15] = (start += ((w5 >> 55) | (w6 << 9) & 0x1ffffff)) + (0*64+15 +1); out[0*64+16] = (start += ((w6 >> 16) & 0x1ffffff)) + (0*64+16 +1); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*64+17] = (start += ((w6 >> 41) | (w7 << 23) & 0x1ffffff)) + (0*64+17 +1); out[0*64+18] = (start += ((w7 >> 2) & 0x1ffffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w7 >> 27) & 0x1ffffff)) + (0*64+19 +1); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*64+20] = (start += ((w7 >> 52) | (w8 << 12) & 0x1ffffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w8 >> 13) & 0x1ffffff)) + (0*64+21 +1); out[0*64+22] = (start += ((w8 >> 38) & 0x1ffffff)) + (0*64+22 +1); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*64+23] = (start += ((w8 >> 63) | (w9 << 1) & 0x1ffffff)) + (0*64+23 +1); out[0*64+24] = (start += ((w9 >> 24) & 0x1ffffff)) + (0*64+24 +1); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*64+25] = (start += ((w9 >> 49) | (w10 << 15) & 0x1ffffff)) + (0*64+25 +1); out[0*64+26] = (start += ((w10 >> 10) & 0x1ffffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w10 >> 35) & 0x1ffffff)) + (0*64+27 +1); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*64+28] = (start += ((w10 >> 60) | (w11 << 4) & 0x1ffffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w11 >> 21) & 0x1ffffff)) + (0*64+29 +1); w12 = *(uint32_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*64+30] = (start += ((w11 >> 46) | (w12 << 18) & 0x1ffffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w12 >> 7) & 0x1ffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 25*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_26(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*26)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffffff)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 26) & 0x3ffffff)) + (0*32+ 1 +1); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w0 >> 52) | (w1 << 12) & 0x3ffffff)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w1 >> 14) & 0x3ffffff)) + (0*32+ 3 +1); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w1 >> 40) | (w2 << 24) & 0x3ffffff)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w2 >> 2) & 0x3ffffff)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w2 >> 28) & 0x3ffffff)) + (0*32+ 6 +1); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w2 >> 54) | (w3 << 10) & 0x3ffffff)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w3 >> 16) & 0x3ffffff)) + (0*32+ 8 +1); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w3 >> 42) | (w4 << 22) & 0x3ffffff)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w4 >> 4) & 0x3ffffff)) + (0*32+10 +1); out[0*32+11] = (start += ((w4 >> 30) & 0x3ffffff)) + (0*32+11 +1); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*32+12] = (start += ((w4 >> 56) | (w5 << 8) & 0x3ffffff)) + (0*32+12 +1); out[0*32+13] = (start += ((w5 >> 18) & 0x3ffffff)) + (0*32+13 +1); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*32+14] = (start += ((w5 >> 44) | (w6 << 20) & 0x3ffffff)) + (0*32+14 +1); out[0*32+15] = (start += ((w6 >> 6) & 0x3ffffff)) + (0*32+15 +1); out[0*32+16] = (start += ((w6 >> 32) & 0x3ffffff)) + (0*32+16 +1); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*32+17] = (start += ((w6 >> 58) | (w7 << 6) & 0x3ffffff)) + (0*32+17 +1); out[0*32+18] = (start += ((w7 >> 20) & 0x3ffffff)) + (0*32+18 +1); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*32+19] = (start += ((w7 >> 46) | (w8 << 18) & 0x3ffffff)) + (0*32+19 +1); out[0*32+20] = (start += ((w8 >> 8) & 0x3ffffff)) + (0*32+20 +1); out[0*32+21] = (start += ((w8 >> 34) & 0x3ffffff)) + (0*32+21 +1); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*32+22] = (start += ((w8 >> 60) | (w9 << 4) & 0x3ffffff)) + (0*32+22 +1); out[0*32+23] = (start += ((w9 >> 22) & 0x3ffffff)) + (0*32+23 +1); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*32+24] = (start += ((w9 >> 48) | (w10 << 16) & 0x3ffffff)) + (0*32+24 +1); out[0*32+25] = (start += ((w10 >> 10) & 0x3ffffff)) + (0*32+25 +1); out[0*32+26] = (start += ((w10 >> 36) & 0x3ffffff)) + (0*32+26 +1); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*32+27] = (start += ((w10 >> 62) | (w11 << 2) & 0x3ffffff)) + (0*32+27 +1); out[0*32+28] = (start += ((w11 >> 24) & 0x3ffffff)) + (0*32+28 +1); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*32+29] = (start += ((w11 >> 50) | (w12 << 14) & 0x3ffffff)) + (0*32+29 +1); out[0*32+30] = (start += ((w12 >> 12) & 0x3ffffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w12 >> 38))) + (0*32+31 +1);;}; out += 32; start += 32; in += 26*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_27(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*27)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 27) & 0x7ffffff)) + (0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 54) | (w1 << 10) & 0x7ffffff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w1 >> 17) & 0x7ffffff)) + (0*64+ 3 +1); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w1 >> 44) | (w2 << 20) & 0x7ffffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w2 >> 7) & 0x7ffffff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w2 >> 34) & 0x7ffffff)) + (0*64+ 6 +1); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w2 >> 61) | (w3 << 3) & 0x7ffffff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w3 >> 24) & 0x7ffffff)) + (0*64+ 8 +1); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w3 >> 51) | (w4 << 13) & 0x7ffffff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w4 >> 14) & 0x7ffffff)) + (0*64+10 +1); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*64+11] = (start += ((w4 >> 41) | (w5 << 23) & 0x7ffffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w5 >> 4) & 0x7ffffff)) + (0*64+12 +1); out[0*64+13] = (start += ((w5 >> 31) & 0x7ffffff)) + (0*64+13 +1); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*64+14] = (start += ((w5 >> 58) | (w6 << 6) & 0x7ffffff)) + (0*64+14 +1); out[0*64+15] = (start += ((w6 >> 21) & 0x7ffffff)) + (0*64+15 +1); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*64+16] = (start += ((w6 >> 48) | (w7 << 16) & 0x7ffffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w7 >> 11) & 0x7ffffff)) + (0*64+17 +1); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*64+18] = (start += ((w7 >> 38) | (w8 << 26) & 0x7ffffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w8 >> 1) & 0x7ffffff)) + (0*64+19 +1); out[0*64+20] = (start += ((w8 >> 28) & 0x7ffffff)) + (0*64+20 +1); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*64+21] = (start += ((w8 >> 55) | (w9 << 9) & 0x7ffffff)) + (0*64+21 +1); out[0*64+22] = (start += ((w9 >> 18) & 0x7ffffff)) + (0*64+22 +1); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*64+23] = (start += ((w9 >> 45) | (w10 << 19) & 0x7ffffff)) + (0*64+23 +1); out[0*64+24] = (start += ((w10 >> 8) & 0x7ffffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w10 >> 35) & 0x7ffffff)) + (0*64+25 +1); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*64+26] = (start += ((w10 >> 62) | (w11 << 2) & 0x7ffffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w11 >> 25) & 0x7ffffff)) + (0*64+27 +1); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*64+28] = (start += ((w11 >> 52) | (w12 << 12) & 0x7ffffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w12 >> 15) & 0x7ffffff)) + (0*64+29 +1); w13 = *(uint32_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*64+30] = (start += ((w12 >> 42) | (w13 << 22) & 0x7ffffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w13 >> 5) & 0x7ffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 27*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_28(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*28)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffffff)) + (0*16+ 0 +1); out[0*16+ 1] = (start += ((w0 >> 28) & 0xfffffff)) + (0*16+ 1 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*16+ 2] = (start += ((w0 >> 56) | (w1 << 8) & 0xfffffff)) + (0*16+ 2 +1); out[0*16+ 3] = (start += ((w1 >> 20) & 0xfffffff)) + (0*16+ 3 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*16+ 4] = (start += ((w1 >> 48) | (w2 << 16) & 0xfffffff)) + (0*16+ 4 +1); out[0*16+ 5] = (start += ((w2 >> 12) & 0xfffffff)) + (0*16+ 5 +1); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*16+ 6] = (start += ((w2 >> 40) | (w3 << 24) & 0xfffffff)) + (0*16+ 6 +1); out[0*16+ 7] = (start += ((w3 >> 4) & 0xfffffff)) + (0*16+ 7 +1); out[0*16+ 8] = (start += ((w3 >> 32) & 0xfffffff)) + (0*16+ 8 +1); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*16+ 9] = (start += ((w3 >> 60) | (w4 << 4) & 0xfffffff)) + (0*16+ 9 +1); out[0*16+10] = (start += ((w4 >> 24) & 0xfffffff)) + (0*16+10 +1); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*16+11] = (start += ((w4 >> 52) | (w5 << 12) & 0xfffffff)) + (0*16+11 +1); out[0*16+12] = (start += ((w5 >> 16) & 0xfffffff)) + (0*16+12 +1); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*16+13] = (start += ((w5 >> 44) | (w6 << 20) & 0xfffffff)) + (0*16+13 +1); out[0*16+14] = (start += ((w6 >> 8) & 0xfffffff)) + (0*16+14 +1); out[0*16+15] = (start += ((w6 >> 36))) + (0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffffff)) + (1*16+ 0 +1); out[1*16+ 1] = (start += ((w0 >> 28) & 0xfffffff)) + (1*16+ 1 +1); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*16+ 2] = (start += ((w0 >> 56) | (w1 << 8) & 0xfffffff)) + (1*16+ 2 +1); out[1*16+ 3] = (start += ((w1 >> 20) & 0xfffffff)) + (1*16+ 3 +1); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*16+ 4] = (start += ((w1 >> 48) | (w2 << 16) & 0xfffffff)) + (1*16+ 4 +1); out[1*16+ 5] = (start += ((w2 >> 12) & 0xfffffff)) + (1*16+ 5 +1); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*16+ 6] = (start += ((w2 >> 40) | (w3 << 24) & 0xfffffff)) + (1*16+ 6 +1); out[1*16+ 7] = (start += ((w3 >> 4) & 0xfffffff)) + (1*16+ 7 +1); out[1*16+ 8] = (start += ((w3 >> 32) & 0xfffffff)) + (1*16+ 8 +1); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*16+ 9] = (start += ((w3 >> 60) | (w4 << 4) & 0xfffffff)) + (1*16+ 9 +1); out[1*16+10] = (start += ((w4 >> 24) & 0xfffffff)) + (1*16+10 +1); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*16+11] = (start += ((w4 >> 52) | (w5 << 12) & 0xfffffff)) + (1*16+11 +1); out[1*16+12] = (start += ((w5 >> 16) & 0xfffffff)) + (1*16+12 +1); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*16+13] = (start += ((w5 >> 44) | (w6 << 20) & 0xfffffff)) + (1*16+13 +1); out[1*16+14] = (start += ((w6 >> 8) & 0xfffffff)) + (1*16+14 +1); out[1*16+15] = (start += ((w6 >> 36))) + (1*16+15 +1);;}; out += 32; start += 32; in += 28*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_29(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*29)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 29) & 0x1fffffff)) + (0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 58) | (w1 << 6) & 0x1fffffff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w1 >> 23) & 0x1fffffff)) + (0*64+ 3 +1); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w1 >> 52) | (w2 << 12) & 0x1fffffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w2 >> 17) & 0x1fffffff)) + (0*64+ 5 +1); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w2 >> 46) | (w3 << 18) & 0x1fffffff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w3 >> 11) & 0x1fffffff)) + (0*64+ 7 +1); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w3 >> 40) | (w4 << 24) & 0x1fffffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w4 >> 5) & 0x1fffffff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w4 >> 34) & 0x1fffffff)) + (0*64+10 +1); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*64+11] = (start += ((w4 >> 63) | (w5 << 1) & 0x1fffffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w5 >> 28) & 0x1fffffff)) + (0*64+12 +1); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*64+13] = (start += ((w5 >> 57) | (w6 << 7) & 0x1fffffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w6 >> 22) & 0x1fffffff)) + (0*64+14 +1); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*64+15] = (start += ((w6 >> 51) | (w7 << 13) & 0x1fffffff)) + (0*64+15 +1); out[0*64+16] = (start += ((w7 >> 16) & 0x1fffffff)) + (0*64+16 +1); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*64+17] = (start += ((w7 >> 45) | (w8 << 19) & 0x1fffffff)) + (0*64+17 +1); out[0*64+18] = (start += ((w8 >> 10) & 0x1fffffff)) + (0*64+18 +1); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*64+19] = (start += ((w8 >> 39) | (w9 << 25) & 0x1fffffff)) + (0*64+19 +1); out[0*64+20] = (start += ((w9 >> 4) & 0x1fffffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w9 >> 33) & 0x1fffffff)) + (0*64+21 +1); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*64+22] = (start += ((w9 >> 62) | (w10 << 2) & 0x1fffffff)) + (0*64+22 +1); out[0*64+23] = (start += ((w10 >> 27) & 0x1fffffff)) + (0*64+23 +1); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*64+24] = (start += ((w10 >> 56) | (w11 << 8) & 0x1fffffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w11 >> 21) & 0x1fffffff)) + (0*64+25 +1); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*64+26] = (start += ((w11 >> 50) | (w12 << 14) & 0x1fffffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w12 >> 15) & 0x1fffffff)) + (0*64+27 +1); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*64+28] = (start += ((w12 >> 44) | (w13 << 20) & 0x1fffffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w13 >> 9) & 0x1fffffff)) + (0*64+29 +1); w14 = *(uint32_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*64+30] = (start += ((w13 >> 38) | (w14 << 26) & 0x1fffffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w14 >> 3) & 0x1fffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 29*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_30(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*30)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffffff)) + (0*32+ 0 +1); out[0*32+ 1] = (start += ((w0 >> 30) & 0x3fffffff)) + (0*32+ 1 +1); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w0 >> 60) | (w1 << 4) & 0x3fffffff)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w1 >> 26) & 0x3fffffff)) + (0*32+ 3 +1); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w1 >> 56) | (w2 << 8) & 0x3fffffff)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w2 >> 22) & 0x3fffffff)) + (0*32+ 5 +1); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w2 >> 52) | (w3 << 12) & 0x3fffffff)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w3 >> 18) & 0x3fffffff)) + (0*32+ 7 +1); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w3 >> 48) | (w4 << 16) & 0x3fffffff)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w4 >> 14) & 0x3fffffff)) + (0*32+ 9 +1); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*32+10] = (start += ((w4 >> 44) | (w5 << 20) & 0x3fffffff)) + (0*32+10 +1); out[0*32+11] = (start += ((w5 >> 10) & 0x3fffffff)) + (0*32+11 +1); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*32+12] = (start += ((w5 >> 40) | (w6 << 24) & 0x3fffffff)) + (0*32+12 +1); out[0*32+13] = (start += ((w6 >> 6) & 0x3fffffff)) + (0*32+13 +1); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*32+14] = (start += ((w6 >> 36) | (w7 << 28) & 0x3fffffff)) + (0*32+14 +1); out[0*32+15] = (start += ((w7 >> 2) & 0x3fffffff)) + (0*32+15 +1); out[0*32+16] = (start += ((w7 >> 32) & 0x3fffffff)) + (0*32+16 +1); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*32+17] = (start += ((w7 >> 62) | (w8 << 2) & 0x3fffffff)) + (0*32+17 +1); out[0*32+18] = (start += ((w8 >> 28) & 0x3fffffff)) + (0*32+18 +1); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*32+19] = (start += ((w8 >> 58) | (w9 << 6) & 0x3fffffff)) + (0*32+19 +1); out[0*32+20] = (start += ((w9 >> 24) & 0x3fffffff)) + (0*32+20 +1); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*32+21] = (start += ((w9 >> 54) | (w10 << 10) & 0x3fffffff)) + (0*32+21 +1); out[0*32+22] = (start += ((w10 >> 20) & 0x3fffffff)) + (0*32+22 +1); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*32+23] = (start += ((w10 >> 50) | (w11 << 14) & 0x3fffffff)) + (0*32+23 +1); out[0*32+24] = (start += ((w11 >> 16) & 0x3fffffff)) + (0*32+24 +1); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*32+25] = (start += ((w11 >> 46) | (w12 << 18) & 0x3fffffff)) + (0*32+25 +1); out[0*32+26] = (start += ((w12 >> 12) & 0x3fffffff)) + (0*32+26 +1); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*32+27] = (start += ((w12 >> 42) | (w13 << 22) & 0x3fffffff)) + (0*32+27 +1); out[0*32+28] = (start += ((w13 >> 8) & 0x3fffffff)) + (0*32+28 +1); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*32+29] = (start += ((w13 >> 38) | (w14 << 26) & 0x3fffffff)) + (0*32+29 +1); out[0*32+30] = (start += ((w14 >> 4) & 0x3fffffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w14 >> 34))) + (0*32+31 +1);;}; out += 32; start += 32; in += 30*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_31(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*31)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffffff)) + (0*64+ 0 +1); out[0*64+ 1] = (start += ((w0 >> 31) & 0x7fffffff)) + (0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w0 >> 62) | (w1 << 2) & 0x7fffffff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w1 >> 29) & 0x7fffffff)) + (0*64+ 3 +1); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w1 >> 60) | (w2 << 4) & 0x7fffffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w2 >> 27) & 0x7fffffff)) + (0*64+ 5 +1); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w2 >> 58) | (w3 << 6) & 0x7fffffff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w3 >> 25) & 0x7fffffff)) + (0*64+ 7 +1); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w3 >> 56) | (w4 << 8) & 0x7fffffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w4 >> 23) & 0x7fffffff)) + (0*64+ 9 +1); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*64+10] = (start += ((w4 >> 54) | (w5 << 10) & 0x7fffffff)) + (0*64+10 +1); out[0*64+11] = (start += ((w5 >> 21) & 0x7fffffff)) + (0*64+11 +1); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*64+12] = (start += ((w5 >> 52) | (w6 << 12) & 0x7fffffff)) + (0*64+12 +1); out[0*64+13] = (start += ((w6 >> 19) & 0x7fffffff)) + (0*64+13 +1); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*64+14] = (start += ((w6 >> 50) | (w7 << 14) & 0x7fffffff)) + (0*64+14 +1); out[0*64+15] = (start += ((w7 >> 17) & 0x7fffffff)) + (0*64+15 +1); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*64+16] = (start += ((w7 >> 48) | (w8 << 16) & 0x7fffffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w8 >> 15) & 0x7fffffff)) + (0*64+17 +1); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*64+18] = (start += ((w8 >> 46) | (w9 << 18) & 0x7fffffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w9 >> 13) & 0x7fffffff)) + (0*64+19 +1); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*64+20] = (start += ((w9 >> 44) | (w10 << 20) & 0x7fffffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w10 >> 11) & 0x7fffffff)) + (0*64+21 +1); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*64+22] = (start += ((w10 >> 42) | (w11 << 22) & 0x7fffffff)) + (0*64+22 +1); out[0*64+23] = (start += ((w11 >> 9) & 0x7fffffff)) + (0*64+23 +1); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*64+24] = (start += ((w11 >> 40) | (w12 << 24) & 0x7fffffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w12 >> 7) & 0x7fffffff)) + (0*64+25 +1); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*64+26] = (start += ((w12 >> 38) | (w13 << 26) & 0x7fffffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w13 >> 5) & 0x7fffffff)) + (0*64+27 +1); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*64+28] = (start += ((w13 >> 36) | (w14 << 28) & 0x7fffffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w14 >> 3) & 0x7fffffff)) + (0*64+29 +1); w15 = *(uint32_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*64+30] = (start += ((w14 >> 34) | (w15 << 30) & 0x7fffffff)) + (0*64+30 +1); out[0*64+31] = (start += ((w15 >> 1) & 0x7fffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 31*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_32(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*32)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[0*2+ 0] = (start += (*(uint32_t *)(in+0*8+ 0))) + (0*2+ 0 +1); out[0*2+ 1] = (start += (*(uint32_t *)(in+0*8+ 4))) + (0*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[1*2+ 0] = (start += (*(uint32_t *)(in+1*8+ 0))) + (1*2+ 0 +1); out[1*2+ 1] = (start += (*(uint32_t *)(in+1*8+ 4))) + (1*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[2*2+ 0] = (start += (*(uint32_t *)(in+2*8+ 0))) + (2*2+ 0 +1); out[2*2+ 1] = (start += (*(uint32_t *)(in+2*8+ 4))) + (2*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[3*2+ 0] = (start += (*(uint32_t *)(in+3*8+ 0))) + (3*2+ 0 +1); out[3*2+ 1] = (start += (*(uint32_t *)(in+3*8+ 4))) + (3*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[4*2+ 0] = (start += (*(uint32_t *)(in+4*8+ 0))) + (4*2+ 0 +1); out[4*2+ 1] = (start += (*(uint32_t *)(in+4*8+ 4))) + (4*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[5*2+ 0] = (start += (*(uint32_t *)(in+5*8+ 0))) + (5*2+ 0 +1); out[5*2+ 1] = (start += (*(uint32_t *)(in+5*8+ 4))) + (5*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[6*2+ 0] = (start += (*(uint32_t *)(in+6*8+ 0))) + (6*2+ 0 +1); out[6*2+ 1] = (start += (*(uint32_t *)(in+6*8+ 4))) + (6*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[7*2+ 0] = (start += (*(uint32_t *)(in+7*8+ 0))) + (7*2+ 0 +1); out[7*2+ 1] = (start += (*(uint32_t *)(in+7*8+ 4))) + (7*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[8*2+ 0] = (start += (*(uint32_t *)(in+8*8+ 0))) + (8*2+ 0 +1); out[8*2+ 1] = (start += (*(uint32_t *)(in+8*8+ 4))) + (8*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[9*2+ 0] = (start += (*(uint32_t *)(in+9*8+ 0))) + (9*2+ 0 +1); out[9*2+ 1] = (start += (*(uint32_t *)(in+9*8+ 4))) + (9*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[10*2+ 0] = (start += (*(uint32_t *)(in+10*8+ 0))) + (10*2+ 0 +1); out[10*2+ 1] = (start += (*(uint32_t *)(in+10*8+ 4))) + (10*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[11*2+ 0] = (start += (*(uint32_t *)(in+11*8+ 0))) + (11*2+ 0 +1); out[11*2+ 1] = (start += (*(uint32_t *)(in+11*8+ 4))) + (11*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[12*2+ 0] = (start += (*(uint32_t *)(in+12*8+ 0))) + (12*2+ 0 +1); out[12*2+ 1] = (start += (*(uint32_t *)(in+12*8+ 4))) + (12*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[13*2+ 0] = (start += (*(uint32_t *)(in+13*8+ 0))) + (13*2+ 0 +1); out[13*2+ 1] = (start += (*(uint32_t *)(in+13*8+ 4))) + (13*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[14*2+ 0] = (start += (*(uint32_t *)(in+14*8+ 0))) + (14*2+ 0 +1); out[14*2+ 1] = (start += (*(uint32_t *)(in+14*8+ 4))) + (14*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[15*2+ 0] = (start += (*(uint32_t *)(in+15*8+ 0))) + (15*2+ 0 +1); out[15*2+ 1] = (start += (*(uint32_t *)(in+15*8+ 4))) + (15*2+ 1 +1);;}; out += 32; start += 32; in += 32*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_33(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*33)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16; w0 = *(uint64_t *)(in+(0*33+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*33+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 33) | (w1 << 31) & 0x1ffffffff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w1 >> 2) & 0x1ffffffff)) + (0*64+ 2 +1); w2 = *(uint64_t *)(in+(0*33+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w1 >> 35) | (w2 << 29) & 0x1ffffffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w2 >> 4) & 0x1ffffffff)) + (0*64+ 4 +1); w3 = *(uint64_t *)(in+(0*33+3)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w2 >> 37) | (w3 << 27) & 0x1ffffffff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w3 >> 6) & 0x1ffffffff)) + (0*64+ 6 +1); w4 = *(uint64_t *)(in+(0*33+4)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w3 >> 39) | (w4 << 25) & 0x1ffffffff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w4 >> 8) & 0x1ffffffff)) + (0*64+ 8 +1); w5 = *(uint64_t *)(in+(0*33+5)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w4 >> 41) | (w5 << 23) & 0x1ffffffff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w5 >> 10) & 0x1ffffffff)) + (0*64+10 +1); w6 = *(uint64_t *)(in+(0*33+6)*8/sizeof(in[0])); out[0*64+11] = (start += ((w5 >> 43) | (w6 << 21) & 0x1ffffffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w6 >> 12) & 0x1ffffffff)) + (0*64+12 +1); w7 = *(uint64_t *)(in+(0*33+7)*8/sizeof(in[0])); out[0*64+13] = (start += ((w6 >> 45) | (w7 << 19) & 0x1ffffffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w7 >> 14) & 0x1ffffffff)) + (0*64+14 +1); w8 = *(uint64_t *)(in+(0*33+8)*8/sizeof(in[0])); out[0*64+15] = (start += ((w7 >> 47) | (w8 << 17) & 0x1ffffffff)) + (0*64+15 +1); out[0*64+16] = (start += ((w8 >> 16) & 0x1ffffffff)) + (0*64+16 +1); w9 = *(uint64_t *)(in+(0*33+9)*8/sizeof(in[0])); out[0*64+17] = (start += ((w8 >> 49) | (w9 << 15) & 0x1ffffffff)) + (0*64+17 +1); out[0*64+18] = (start += ((w9 >> 18) & 0x1ffffffff)) + (0*64+18 +1); w10 = *(uint64_t *)(in+(0*33+10)*8/sizeof(in[0])); out[0*64+19] = (start += ((w9 >> 51) | (w10 << 13) & 0x1ffffffff)) + (0*64+19 +1); out[0*64+20] = (start += ((w10 >> 20) & 0x1ffffffff)) + (0*64+20 +1); w11 = *(uint64_t *)(in+(0*33+11)*8/sizeof(in[0])); out[0*64+21] = (start += ((w10 >> 53) | (w11 << 11) & 0x1ffffffff)) + (0*64+21 +1); out[0*64+22] = (start += ((w11 >> 22) & 0x1ffffffff)) + (0*64+22 +1); w12 = *(uint64_t *)(in+(0*33+12)*8/sizeof(in[0])); out[0*64+23] = (start += ((w11 >> 55) | (w12 << 9) & 0x1ffffffff)) + (0*64+23 +1); out[0*64+24] = (start += ((w12 >> 24) & 0x1ffffffff)) + (0*64+24 +1); w13 = *(uint64_t *)(in+(0*33+13)*8/sizeof(in[0])); out[0*64+25] = (start += ((w12 >> 57) | (w13 << 7) & 0x1ffffffff)) + (0*64+25 +1); out[0*64+26] = (start += ((w13 >> 26) & 0x1ffffffff)) + (0*64+26 +1); w14 = *(uint64_t *)(in+(0*33+14)*8/sizeof(in[0])); out[0*64+27] = (start += ((w13 >> 59) | (w14 << 5) & 0x1ffffffff)) + (0*64+27 +1); out[0*64+28] = (start += ((w14 >> 28) & 0x1ffffffff)) + (0*64+28 +1); w15 = *(uint64_t *)(in+(0*33+15)*8/sizeof(in[0])); out[0*64+29] = (start += ((w14 >> 61) | (w15 << 3) & 0x1ffffffff)) + (0*64+29 +1); out[0*64+30] = (start += ((w15 >> 30) & 0x1ffffffff)) + (0*64+30 +1); w16 = *(uint32_t *)(in+(0*33+16)*8/sizeof(in[0])); out[0*64+31] = (start += ((w15 >> 63) | (w16 << 1) & 0x1ffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 33*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_34(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*34)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffffffff)) + (0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 34) | (w1 << 30) & 0x3ffffffff)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w1 >> 4) & 0x3ffffffff)) + (0*32+ 2 +1); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w1 >> 38) | (w2 << 26) & 0x3ffffffff)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w2 >> 8) & 0x3ffffffff)) + (0*32+ 4 +1); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w2 >> 42) | (w3 << 22) & 0x3ffffffff)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w3 >> 12) & 0x3ffffffff)) + (0*32+ 6 +1); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w3 >> 46) | (w4 << 18) & 0x3ffffffff)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w4 >> 16) & 0x3ffffffff)) + (0*32+ 8 +1); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w4 >> 50) | (w5 << 14) & 0x3ffffffff)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w5 >> 20) & 0x3ffffffff)) + (0*32+10 +1); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*32+11] = (start += ((w5 >> 54) | (w6 << 10) & 0x3ffffffff)) + (0*32+11 +1); out[0*32+12] = (start += ((w6 >> 24) & 0x3ffffffff)) + (0*32+12 +1); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*32+13] = (start += ((w6 >> 58) | (w7 << 6) & 0x3ffffffff)) + (0*32+13 +1); out[0*32+14] = (start += ((w7 >> 28) & 0x3ffffffff)) + (0*32+14 +1); w8 = *(uint64_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*32+15] = (start += ((w7 >> 62) | (w8 << 2) & 0x3ffffffff)) + (0*32+15 +1); w9 = *(uint64_t *)(in+(0*17+9)*8/sizeof(in[0])); out[0*32+16] = (start += ((w8 >> 32) | (w9 << 32) & 0x3ffffffff)) + (0*32+16 +1); out[0*32+17] = (start += ((w9 >> 2) & 0x3ffffffff)) + (0*32+17 +1); w10 = *(uint64_t *)(in+(0*17+10)*8/sizeof(in[0])); out[0*32+18] = (start += ((w9 >> 36) | (w10 << 28) & 0x3ffffffff)) + (0*32+18 +1); out[0*32+19] = (start += ((w10 >> 6) & 0x3ffffffff)) + (0*32+19 +1); w11 = *(uint64_t *)(in+(0*17+11)*8/sizeof(in[0])); out[0*32+20] = (start += ((w10 >> 40) | (w11 << 24) & 0x3ffffffff)) + (0*32+20 +1); out[0*32+21] = (start += ((w11 >> 10) & 0x3ffffffff)) + (0*32+21 +1); w12 = *(uint64_t *)(in+(0*17+12)*8/sizeof(in[0])); out[0*32+22] = (start += ((w11 >> 44) | (w12 << 20) & 0x3ffffffff)) + (0*32+22 +1); out[0*32+23] = (start += ((w12 >> 14) & 0x3ffffffff)) + (0*32+23 +1); w13 = *(uint64_t *)(in+(0*17+13)*8/sizeof(in[0])); out[0*32+24] = (start += ((w12 >> 48) | (w13 << 16) & 0x3ffffffff)) + (0*32+24 +1); out[0*32+25] = (start += ((w13 >> 18) & 0x3ffffffff)) + (0*32+25 +1); w14 = *(uint64_t *)(in+(0*17+14)*8/sizeof(in[0])); out[0*32+26] = (start += ((w13 >> 52) | (w14 << 12) & 0x3ffffffff)) + (0*32+26 +1); out[0*32+27] = (start += ((w14 >> 22) & 0x3ffffffff)) + (0*32+27 +1); w15 = *(uint64_t *)(in+(0*17+15)*8/sizeof(in[0])); out[0*32+28] = (start += ((w14 >> 56) | (w15 << 8) & 0x3ffffffff)) + (0*32+28 +1); out[0*32+29] = (start += ((w15 >> 26) & 0x3ffffffff)) + (0*32+29 +1); w16 = *(uint64_t *)(in+(0*17+16)*8/sizeof(in[0])); out[0*32+30] = (start += ((w15 >> 60) | (w16 << 4) & 0x3ffffffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w16 >> 30))) + (0*32+31 +1);;}; out += 32; start += 32; in += 34*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_35(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*35)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(0*35+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*35+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 35) | (w1 << 29) & 0x7ffffffff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w1 >> 6) & 0x7ffffffff)) + (0*64+ 2 +1); w2 = *(uint64_t *)(in+(0*35+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w1 >> 41) | (w2 << 23) & 0x7ffffffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w2 >> 12) & 0x7ffffffff)) + (0*64+ 4 +1); w3 = *(uint64_t *)(in+(0*35+3)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w2 >> 47) | (w3 << 17) & 0x7ffffffff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w3 >> 18) & 0x7ffffffff)) + (0*64+ 6 +1); w4 = *(uint64_t *)(in+(0*35+4)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w3 >> 53) | (w4 << 11) & 0x7ffffffff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w4 >> 24) & 0x7ffffffff)) + (0*64+ 8 +1); w5 = *(uint64_t *)(in+(0*35+5)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w4 >> 59) | (w5 << 5) & 0x7ffffffff)) + (0*64+ 9 +1); w6 = *(uint64_t *)(in+(0*35+6)*8/sizeof(in[0])); out[0*64+10] = (start += ((w5 >> 30) | (w6 << 34) & 0x7ffffffff)) + (0*64+10 +1); out[0*64+11] = (start += ((w6 >> 1) & 0x7ffffffff)) + (0*64+11 +1); w7 = *(uint64_t *)(in+(0*35+7)*8/sizeof(in[0])); out[0*64+12] = (start += ((w6 >> 36) | (w7 << 28) & 0x7ffffffff)) + (0*64+12 +1); out[0*64+13] = (start += ((w7 >> 7) & 0x7ffffffff)) + (0*64+13 +1); w8 = *(uint64_t *)(in+(0*35+8)*8/sizeof(in[0])); out[0*64+14] = (start += ((w7 >> 42) | (w8 << 22) & 0x7ffffffff)) + (0*64+14 +1); out[0*64+15] = (start += ((w8 >> 13) & 0x7ffffffff)) + (0*64+15 +1); w9 = *(uint64_t *)(in+(0*35+9)*8/sizeof(in[0])); out[0*64+16] = (start += ((w8 >> 48) | (w9 << 16) & 0x7ffffffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w9 >> 19) & 0x7ffffffff)) + (0*64+17 +1); w10 = *(uint64_t *)(in+(0*35+10)*8/sizeof(in[0])); out[0*64+18] = (start += ((w9 >> 54) | (w10 << 10) & 0x7ffffffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w10 >> 25) & 0x7ffffffff)) + (0*64+19 +1); w11 = *(uint64_t *)(in+(0*35+11)*8/sizeof(in[0])); out[0*64+20] = (start += ((w10 >> 60) | (w11 << 4) & 0x7ffffffff)) + (0*64+20 +1); w12 = *(uint64_t *)(in+(0*35+12)*8/sizeof(in[0])); out[0*64+21] = (start += ((w11 >> 31) | (w12 << 33) & 0x7ffffffff)) + (0*64+21 +1); out[0*64+22] = (start += ((w12 >> 2) & 0x7ffffffff)) + (0*64+22 +1); w13 = *(uint64_t *)(in+(0*35+13)*8/sizeof(in[0])); out[0*64+23] = (start += ((w12 >> 37) | (w13 << 27) & 0x7ffffffff)) + (0*64+23 +1); out[0*64+24] = (start += ((w13 >> 8) & 0x7ffffffff)) + (0*64+24 +1); w14 = *(uint64_t *)(in+(0*35+14)*8/sizeof(in[0])); out[0*64+25] = (start += ((w13 >> 43) | (w14 << 21) & 0x7ffffffff)) + (0*64+25 +1); out[0*64+26] = (start += ((w14 >> 14) & 0x7ffffffff)) + (0*64+26 +1); w15 = *(uint64_t *)(in+(0*35+15)*8/sizeof(in[0])); out[0*64+27] = (start += ((w14 >> 49) | (w15 << 15) & 0x7ffffffff)) + (0*64+27 +1); out[0*64+28] = (start += ((w15 >> 20) & 0x7ffffffff)) + (0*64+28 +1); w16 = *(uint64_t *)(in+(0*35+16)*8/sizeof(in[0])); out[0*64+29] = (start += ((w15 >> 55) | (w16 << 9) & 0x7ffffffff)) + (0*64+29 +1); out[0*64+30] = (start += ((w16 >> 26) & 0x7ffffffff)) + (0*64+30 +1); w17 = *(uint32_t *)(in+(0*35+17)*8/sizeof(in[0])); out[0*64+31] = (start += ((w16 >> 61) | (w17 << 3) & 0x7ffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 35*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_36(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*36)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffffffff)) + (0*16+ 0 +1); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*16+ 1] = (start += ((w0 >> 36) | (w1 << 28) & 0xfffffffff)) + (0*16+ 1 +1); out[0*16+ 2] = (start += ((w1 >> 8) & 0xfffffffff)) + (0*16+ 2 +1); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*16+ 3] = (start += ((w1 >> 44) | (w2 << 20) & 0xfffffffff)) + (0*16+ 3 +1); out[0*16+ 4] = (start += ((w2 >> 16) & 0xfffffffff)) + (0*16+ 4 +1); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*16+ 5] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffffffff)) + (0*16+ 5 +1); out[0*16+ 6] = (start += ((w3 >> 24) & 0xfffffffff)) + (0*16+ 6 +1); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*16+ 7] = (start += ((w3 >> 60) | (w4 << 4) & 0xfffffffff)) + (0*16+ 7 +1); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*16+ 8] = (start += ((w4 >> 32) | (w5 << 32) & 0xfffffffff)) + (0*16+ 8 +1); out[0*16+ 9] = (start += ((w5 >> 4) & 0xfffffffff)) + (0*16+ 9 +1); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*16+10] = (start += ((w5 >> 40) | (w6 << 24) & 0xfffffffff)) + (0*16+10 +1); out[0*16+11] = (start += ((w6 >> 12) & 0xfffffffff)) + (0*16+11 +1); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*16+12] = (start += ((w6 >> 48) | (w7 << 16) & 0xfffffffff)) + (0*16+12 +1); out[0*16+13] = (start += ((w7 >> 20) & 0xfffffffff)) + (0*16+13 +1); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*16+14] = (start += ((w7 >> 56) | (w8 << 8) & 0xfffffffff)) + (0*16+14 +1); out[0*16+15] = (start += ((w8 >> 28))) + (0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(1*9+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffffffff)) + (1*16+ 0 +1); w1 = *(uint64_t *)(in+(1*9+1)*8/sizeof(in[0])); out[1*16+ 1] = (start += ((w0 >> 36) | (w1 << 28) & 0xfffffffff)) + (1*16+ 1 +1); out[1*16+ 2] = (start += ((w1 >> 8) & 0xfffffffff)) + (1*16+ 2 +1); w2 = *(uint64_t *)(in+(1*9+2)*8/sizeof(in[0])); out[1*16+ 3] = (start += ((w1 >> 44) | (w2 << 20) & 0xfffffffff)) + (1*16+ 3 +1); out[1*16+ 4] = (start += ((w2 >> 16) & 0xfffffffff)) + (1*16+ 4 +1); w3 = *(uint64_t *)(in+(1*9+3)*8/sizeof(in[0])); out[1*16+ 5] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffffffff)) + (1*16+ 5 +1); out[1*16+ 6] = (start += ((w3 >> 24) & 0xfffffffff)) + (1*16+ 6 +1); w4 = *(uint64_t *)(in+(1*9+4)*8/sizeof(in[0])); out[1*16+ 7] = (start += ((w3 >> 60) | (w4 << 4) & 0xfffffffff)) + (1*16+ 7 +1); w5 = *(uint64_t *)(in+(1*9+5)*8/sizeof(in[0])); out[1*16+ 8] = (start += ((w4 >> 32) | (w5 << 32) & 0xfffffffff)) + (1*16+ 8 +1); out[1*16+ 9] = (start += ((w5 >> 4) & 0xfffffffff)) + (1*16+ 9 +1); w6 = *(uint64_t *)(in+(1*9+6)*8/sizeof(in[0])); out[1*16+10] = (start += ((w5 >> 40) | (w6 << 24) & 0xfffffffff)) + (1*16+10 +1); out[1*16+11] = (start += ((w6 >> 12) & 0xfffffffff)) + (1*16+11 +1); w7 = *(uint64_t *)(in+(1*9+7)*8/sizeof(in[0])); out[1*16+12] = (start += ((w6 >> 48) | (w7 << 16) & 0xfffffffff)) + (1*16+12 +1); out[1*16+13] = (start += ((w7 >> 20) & 0xfffffffff)) + (1*16+13 +1); w8 = *(uint64_t *)(in+(1*9+8)*8/sizeof(in[0])); out[1*16+14] = (start += ((w7 >> 56) | (w8 << 8) & 0xfffffffff)) + (1*16+14 +1); out[1*16+15] = (start += ((w8 >> 28))) + (1*16+15 +1);;}; out += 32; start += 32; in += 36*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_37(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*37)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18; w0 = *(uint64_t *)(in+(0*37+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*37+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 37) | (w1 << 27) & 0x1fffffffff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w1 >> 10) & 0x1fffffffff)) + (0*64+ 2 +1); w2 = *(uint64_t *)(in+(0*37+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w1 >> 47) | (w2 << 17) & 0x1fffffffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w2 >> 20) & 0x1fffffffff)) + (0*64+ 4 +1); w3 = *(uint64_t *)(in+(0*37+3)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w2 >> 57) | (w3 << 7) & 0x1fffffffff)) + (0*64+ 5 +1); w4 = *(uint64_t *)(in+(0*37+4)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w3 >> 30) | (w4 << 34) & 0x1fffffffff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w4 >> 3) & 0x1fffffffff)) + (0*64+ 7 +1); w5 = *(uint64_t *)(in+(0*37+5)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w4 >> 40) | (w5 << 24) & 0x1fffffffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w5 >> 13) & 0x1fffffffff)) + (0*64+ 9 +1); w6 = *(uint64_t *)(in+(0*37+6)*8/sizeof(in[0])); out[0*64+10] = (start += ((w5 >> 50) | (w6 << 14) & 0x1fffffffff)) + (0*64+10 +1); out[0*64+11] = (start += ((w6 >> 23) & 0x1fffffffff)) + (0*64+11 +1); w7 = *(uint64_t *)(in+(0*37+7)*8/sizeof(in[0])); out[0*64+12] = (start += ((w6 >> 60) | (w7 << 4) & 0x1fffffffff)) + (0*64+12 +1); w8 = *(uint64_t *)(in+(0*37+8)*8/sizeof(in[0])); out[0*64+13] = (start += ((w7 >> 33) | (w8 << 31) & 0x1fffffffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w8 >> 6) & 0x1fffffffff)) + (0*64+14 +1); w9 = *(uint64_t *)(in+(0*37+9)*8/sizeof(in[0])); out[0*64+15] = (start += ((w8 >> 43) | (w9 << 21) & 0x1fffffffff)) + (0*64+15 +1); out[0*64+16] = (start += ((w9 >> 16) & 0x1fffffffff)) + (0*64+16 +1); w10 = *(uint64_t *)(in+(0*37+10)*8/sizeof(in[0])); out[0*64+17] = (start += ((w9 >> 53) | (w10 << 11) & 0x1fffffffff)) + (0*64+17 +1); out[0*64+18] = (start += ((w10 >> 26) & 0x1fffffffff)) + (0*64+18 +1); w11 = *(uint64_t *)(in+(0*37+11)*8/sizeof(in[0])); out[0*64+19] = (start += ((w10 >> 63) | (w11 << 1) & 0x1fffffffff)) + (0*64+19 +1); w12 = *(uint64_t *)(in+(0*37+12)*8/sizeof(in[0])); out[0*64+20] = (start += ((w11 >> 36) | (w12 << 28) & 0x1fffffffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w12 >> 9) & 0x1fffffffff)) + (0*64+21 +1); w13 = *(uint64_t *)(in+(0*37+13)*8/sizeof(in[0])); out[0*64+22] = (start += ((w12 >> 46) | (w13 << 18) & 0x1fffffffff)) + (0*64+22 +1); out[0*64+23] = (start += ((w13 >> 19) & 0x1fffffffff)) + (0*64+23 +1); w14 = *(uint64_t *)(in+(0*37+14)*8/sizeof(in[0])); out[0*64+24] = (start += ((w13 >> 56) | (w14 << 8) & 0x1fffffffff)) + (0*64+24 +1); w15 = *(uint64_t *)(in+(0*37+15)*8/sizeof(in[0])); out[0*64+25] = (start += ((w14 >> 29) | (w15 << 35) & 0x1fffffffff)) + (0*64+25 +1); out[0*64+26] = (start += ((w15 >> 2) & 0x1fffffffff)) + (0*64+26 +1); w16 = *(uint64_t *)(in+(0*37+16)*8/sizeof(in[0])); out[0*64+27] = (start += ((w15 >> 39) | (w16 << 25) & 0x1fffffffff)) + (0*64+27 +1); out[0*64+28] = (start += ((w16 >> 12) & 0x1fffffffff)) + (0*64+28 +1); w17 = *(uint64_t *)(in+(0*37+17)*8/sizeof(in[0])); out[0*64+29] = (start += ((w16 >> 49) | (w17 << 15) & 0x1fffffffff)) + (0*64+29 +1); out[0*64+30] = (start += ((w17 >> 22) & 0x1fffffffff)) + (0*64+30 +1); w18 = *(uint32_t *)(in+(0*37+18)*8/sizeof(in[0])); out[0*64+31] = (start += ((w17 >> 59) | (w18 << 5) & 0x1fffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 37*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_38(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*38)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffffffff)) + (0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 38) | (w1 << 26) & 0x3fffffffff)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w1 >> 12) & 0x3fffffffff)) + (0*32+ 2 +1); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w1 >> 50) | (w2 << 14) & 0x3fffffffff)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w2 >> 24) & 0x3fffffffff)) + (0*32+ 4 +1); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w2 >> 62) | (w3 << 2) & 0x3fffffffff)) + (0*32+ 5 +1); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w3 >> 36) | (w4 << 28) & 0x3fffffffff)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w4 >> 10) & 0x3fffffffff)) + (0*32+ 7 +1); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w4 >> 48) | (w5 << 16) & 0x3fffffffff)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w5 >> 22) & 0x3fffffffff)) + (0*32+ 9 +1); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*32+10] = (start += ((w5 >> 60) | (w6 << 4) & 0x3fffffffff)) + (0*32+10 +1); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*32+11] = (start += ((w6 >> 34) | (w7 << 30) & 0x3fffffffff)) + (0*32+11 +1); out[0*32+12] = (start += ((w7 >> 8) & 0x3fffffffff)) + (0*32+12 +1); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*32+13] = (start += ((w7 >> 46) | (w8 << 18) & 0x3fffffffff)) + (0*32+13 +1); out[0*32+14] = (start += ((w8 >> 20) & 0x3fffffffff)) + (0*32+14 +1); w9 = *(uint64_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*32+15] = (start += ((w8 >> 58) | (w9 << 6) & 0x3fffffffff)) + (0*32+15 +1); w10 = *(uint64_t *)(in+(0*19+10)*8/sizeof(in[0])); out[0*32+16] = (start += ((w9 >> 32) | (w10 << 32) & 0x3fffffffff)) + (0*32+16 +1); out[0*32+17] = (start += ((w10 >> 6) & 0x3fffffffff)) + (0*32+17 +1); w11 = *(uint64_t *)(in+(0*19+11)*8/sizeof(in[0])); out[0*32+18] = (start += ((w10 >> 44) | (w11 << 20) & 0x3fffffffff)) + (0*32+18 +1); out[0*32+19] = (start += ((w11 >> 18) & 0x3fffffffff)) + (0*32+19 +1); w12 = *(uint64_t *)(in+(0*19+12)*8/sizeof(in[0])); out[0*32+20] = (start += ((w11 >> 56) | (w12 << 8) & 0x3fffffffff)) + (0*32+20 +1); w13 = *(uint64_t *)(in+(0*19+13)*8/sizeof(in[0])); out[0*32+21] = (start += ((w12 >> 30) | (w13 << 34) & 0x3fffffffff)) + (0*32+21 +1); out[0*32+22] = (start += ((w13 >> 4) & 0x3fffffffff)) + (0*32+22 +1); w14 = *(uint64_t *)(in+(0*19+14)*8/sizeof(in[0])); out[0*32+23] = (start += ((w13 >> 42) | (w14 << 22) & 0x3fffffffff)) + (0*32+23 +1); out[0*32+24] = (start += ((w14 >> 16) & 0x3fffffffff)) + (0*32+24 +1); w15 = *(uint64_t *)(in+(0*19+15)*8/sizeof(in[0])); out[0*32+25] = (start += ((w14 >> 54) | (w15 << 10) & 0x3fffffffff)) + (0*32+25 +1); w16 = *(uint64_t *)(in+(0*19+16)*8/sizeof(in[0])); out[0*32+26] = (start += ((w15 >> 28) | (w16 << 36) & 0x3fffffffff)) + (0*32+26 +1); out[0*32+27] = (start += ((w16 >> 2) & 0x3fffffffff)) + (0*32+27 +1); w17 = *(uint64_t *)(in+(0*19+17)*8/sizeof(in[0])); out[0*32+28] = (start += ((w16 >> 40) | (w17 << 24) & 0x3fffffffff)) + (0*32+28 +1); out[0*32+29] = (start += ((w17 >> 14) & 0x3fffffffff)) + (0*32+29 +1); w18 = *(uint64_t *)(in+(0*19+18)*8/sizeof(in[0])); out[0*32+30] = (start += ((w17 >> 52) | (w18 << 12) & 0x3fffffffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w18 >> 26))) + (0*32+31 +1);;}; out += 32; start += 32; in += 38*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_39(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*39)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(0*39+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*39+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 39) | (w1 << 25) & 0x7fffffffff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w1 >> 14) & 0x7fffffffff)) + (0*64+ 2 +1); w2 = *(uint64_t *)(in+(0*39+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w1 >> 53) | (w2 << 11) & 0x7fffffffff)) + (0*64+ 3 +1); w3 = *(uint64_t *)(in+(0*39+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w2 >> 28) | (w3 << 36) & 0x7fffffffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w3 >> 3) & 0x7fffffffff)) + (0*64+ 5 +1); w4 = *(uint64_t *)(in+(0*39+4)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w3 >> 42) | (w4 << 22) & 0x7fffffffff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w4 >> 17) & 0x7fffffffff)) + (0*64+ 7 +1); w5 = *(uint64_t *)(in+(0*39+5)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w4 >> 56) | (w5 << 8) & 0x7fffffffff)) + (0*64+ 8 +1); w6 = *(uint64_t *)(in+(0*39+6)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w5 >> 31) | (w6 << 33) & 0x7fffffffff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w6 >> 6) & 0x7fffffffff)) + (0*64+10 +1); w7 = *(uint64_t *)(in+(0*39+7)*8/sizeof(in[0])); out[0*64+11] = (start += ((w6 >> 45) | (w7 << 19) & 0x7fffffffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w7 >> 20) & 0x7fffffffff)) + (0*64+12 +1); w8 = *(uint64_t *)(in+(0*39+8)*8/sizeof(in[0])); out[0*64+13] = (start += ((w7 >> 59) | (w8 << 5) & 0x7fffffffff)) + (0*64+13 +1); w9 = *(uint64_t *)(in+(0*39+9)*8/sizeof(in[0])); out[0*64+14] = (start += ((w8 >> 34) | (w9 << 30) & 0x7fffffffff)) + (0*64+14 +1); out[0*64+15] = (start += ((w9 >> 9) & 0x7fffffffff)) + (0*64+15 +1); w10 = *(uint64_t *)(in+(0*39+10)*8/sizeof(in[0])); out[0*64+16] = (start += ((w9 >> 48) | (w10 << 16) & 0x7fffffffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w10 >> 23) & 0x7fffffffff)) + (0*64+17 +1); w11 = *(uint64_t *)(in+(0*39+11)*8/sizeof(in[0])); out[0*64+18] = (start += ((w10 >> 62) | (w11 << 2) & 0x7fffffffff)) + (0*64+18 +1); w12 = *(uint64_t *)(in+(0*39+12)*8/sizeof(in[0])); out[0*64+19] = (start += ((w11 >> 37) | (w12 << 27) & 0x7fffffffff)) + (0*64+19 +1); out[0*64+20] = (start += ((w12 >> 12) & 0x7fffffffff)) + (0*64+20 +1); w13 = *(uint64_t *)(in+(0*39+13)*8/sizeof(in[0])); out[0*64+21] = (start += ((w12 >> 51) | (w13 << 13) & 0x7fffffffff)) + (0*64+21 +1); w14 = *(uint64_t *)(in+(0*39+14)*8/sizeof(in[0])); out[0*64+22] = (start += ((w13 >> 26) | (w14 << 38) & 0x7fffffffff)) + (0*64+22 +1); out[0*64+23] = (start += ((w14 >> 1) & 0x7fffffffff)) + (0*64+23 +1); w15 = *(uint64_t *)(in+(0*39+15)*8/sizeof(in[0])); out[0*64+24] = (start += ((w14 >> 40) | (w15 << 24) & 0x7fffffffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w15 >> 15) & 0x7fffffffff)) + (0*64+25 +1); w16 = *(uint64_t *)(in+(0*39+16)*8/sizeof(in[0])); out[0*64+26] = (start += ((w15 >> 54) | (w16 << 10) & 0x7fffffffff)) + (0*64+26 +1); w17 = *(uint64_t *)(in+(0*39+17)*8/sizeof(in[0])); out[0*64+27] = (start += ((w16 >> 29) | (w17 << 35) & 0x7fffffffff)) + (0*64+27 +1); out[0*64+28] = (start += ((w17 >> 4) & 0x7fffffffff)) + (0*64+28 +1); w18 = *(uint64_t *)(in+(0*39+18)*8/sizeof(in[0])); out[0*64+29] = (start += ((w17 >> 43) | (w18 << 21) & 0x7fffffffff)) + (0*64+29 +1); out[0*64+30] = (start += ((w18 >> 18) & 0x7fffffffff)) + (0*64+30 +1); w19 = *(uint32_t *)(in+(0*39+19)*8/sizeof(in[0])); out[0*64+31] = (start += ((w18 >> 57) | (w19 << 7) & 0x7fffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 39*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_40(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*40)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xffffffffff)) + (0*8+ 0 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*8+ 1] = (start += ((w0 >> 40) | (w1 << 24) & 0xffffffffff)) + (0*8+ 1 +1); out[0*8+ 2] = (start += ((w1 >> 16) & 0xffffffffff)) + (0*8+ 2 +1); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*8+ 3] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffffffff)) + (0*8+ 3 +1); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*8+ 4] = (start += ((w2 >> 32) | (w3 << 32) & 0xffffffffff)) + (0*8+ 4 +1); out[0*8+ 5] = (start += ((w3 >> 8) & 0xffffffffff)) + (0*8+ 5 +1); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*8+ 6] = (start += ((w3 >> 48) | (w4 << 16) & 0xffffffffff)) + (0*8+ 6 +1); out[0*8+ 7] = (start += ((w4 >> 24))) + (0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xffffffffff)) + (1*8+ 0 +1); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*8+ 1] = (start += ((w0 >> 40) | (w1 << 24) & 0xffffffffff)) + (1*8+ 1 +1); out[1*8+ 2] = (start += ((w1 >> 16) & 0xffffffffff)) + (1*8+ 2 +1); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*8+ 3] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffffffff)) + (1*8+ 3 +1); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*8+ 4] = (start += ((w2 >> 32) | (w3 << 32) & 0xffffffffff)) + (1*8+ 4 +1); out[1*8+ 5] = (start += ((w3 >> 8) & 0xffffffffff)) + (1*8+ 5 +1); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*8+ 6] = (start += ((w3 >> 48) | (w4 << 16) & 0xffffffffff)) + (1*8+ 6 +1); out[1*8+ 7] = (start += ((w4 >> 24))) + (1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(2*5+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xffffffffff)) + (2*8+ 0 +1); w1 = *(uint64_t *)(in+(2*5+1)*8/sizeof(in[0])); out[2*8+ 1] = (start += ((w0 >> 40) | (w1 << 24) & 0xffffffffff)) + (2*8+ 1 +1); out[2*8+ 2] = (start += ((w1 >> 16) & 0xffffffffff)) + (2*8+ 2 +1); w2 = *(uint64_t *)(in+(2*5+2)*8/sizeof(in[0])); out[2*8+ 3] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffffffff)) + (2*8+ 3 +1); w3 = *(uint64_t *)(in+(2*5+3)*8/sizeof(in[0])); out[2*8+ 4] = (start += ((w2 >> 32) | (w3 << 32) & 0xffffffffff)) + (2*8+ 4 +1); out[2*8+ 5] = (start += ((w3 >> 8) & 0xffffffffff)) + (2*8+ 5 +1); w4 = *(uint64_t *)(in+(2*5+4)*8/sizeof(in[0])); out[2*8+ 6] = (start += ((w3 >> 48) | (w4 << 16) & 0xffffffffff)) + (2*8+ 6 +1); out[2*8+ 7] = (start += ((w4 >> 24))) + (2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(3*5+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xffffffffff)) + (3*8+ 0 +1); w1 = *(uint64_t *)(in+(3*5+1)*8/sizeof(in[0])); out[3*8+ 1] = (start += ((w0 >> 40) | (w1 << 24) & 0xffffffffff)) + (3*8+ 1 +1); out[3*8+ 2] = (start += ((w1 >> 16) & 0xffffffffff)) + (3*8+ 2 +1); w2 = *(uint64_t *)(in+(3*5+2)*8/sizeof(in[0])); out[3*8+ 3] = (start += ((w1 >> 56) | (w2 << 8) & 0xffffffffff)) + (3*8+ 3 +1); w3 = *(uint64_t *)(in+(3*5+3)*8/sizeof(in[0])); out[3*8+ 4] = (start += ((w2 >> 32) | (w3 << 32) & 0xffffffffff)) + (3*8+ 4 +1); out[3*8+ 5] = (start += ((w3 >> 8) & 0xffffffffff)) + (3*8+ 5 +1); w4 = *(uint64_t *)(in+(3*5+4)*8/sizeof(in[0])); out[3*8+ 6] = (start += ((w3 >> 48) | (w4 << 16) & 0xffffffffff)) + (3*8+ 6 +1); out[3*8+ 7] = (start += ((w4 >> 24))) + (3*8+ 7 +1);;}; out += 32; start += 32; in += 40*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_41(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*41)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20; w0 = *(uint64_t *)(in+(0*41+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*41+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 41) | (w1 << 23) & 0x1ffffffffff)) + (0*64+ 1 +1); out[0*64+ 2] = (start += ((w1 >> 18) & 0x1ffffffffff)) + (0*64+ 2 +1); w2 = *(uint64_t *)(in+(0*41+2)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w1 >> 59) | (w2 << 5) & 0x1ffffffffff)) + (0*64+ 3 +1); w3 = *(uint64_t *)(in+(0*41+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w2 >> 36) | (w3 << 28) & 0x1ffffffffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w3 >> 13) & 0x1ffffffffff)) + (0*64+ 5 +1); w4 = *(uint64_t *)(in+(0*41+4)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w3 >> 54) | (w4 << 10) & 0x1ffffffffff)) + (0*64+ 6 +1); w5 = *(uint64_t *)(in+(0*41+5)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w4 >> 31) | (w5 << 33) & 0x1ffffffffff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w5 >> 8) & 0x1ffffffffff)) + (0*64+ 8 +1); w6 = *(uint64_t *)(in+(0*41+6)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w5 >> 49) | (w6 << 15) & 0x1ffffffffff)) + (0*64+ 9 +1); w7 = *(uint64_t *)(in+(0*41+7)*8/sizeof(in[0])); out[0*64+10] = (start += ((w6 >> 26) | (w7 << 38) & 0x1ffffffffff)) + (0*64+10 +1); out[0*64+11] = (start += ((w7 >> 3) & 0x1ffffffffff)) + (0*64+11 +1); w8 = *(uint64_t *)(in+(0*41+8)*8/sizeof(in[0])); out[0*64+12] = (start += ((w7 >> 44) | (w8 << 20) & 0x1ffffffffff)) + (0*64+12 +1); out[0*64+13] = (start += ((w8 >> 21) & 0x1ffffffffff)) + (0*64+13 +1); w9 = *(uint64_t *)(in+(0*41+9)*8/sizeof(in[0])); out[0*64+14] = (start += ((w8 >> 62) | (w9 << 2) & 0x1ffffffffff)) + (0*64+14 +1); w10 = *(uint64_t *)(in+(0*41+10)*8/sizeof(in[0])); out[0*64+15] = (start += ((w9 >> 39) | (w10 << 25) & 0x1ffffffffff)) + (0*64+15 +1); out[0*64+16] = (start += ((w10 >> 16) & 0x1ffffffffff)) + (0*64+16 +1); w11 = *(uint64_t *)(in+(0*41+11)*8/sizeof(in[0])); out[0*64+17] = (start += ((w10 >> 57) | (w11 << 7) & 0x1ffffffffff)) + (0*64+17 +1); w12 = *(uint64_t *)(in+(0*41+12)*8/sizeof(in[0])); out[0*64+18] = (start += ((w11 >> 34) | (w12 << 30) & 0x1ffffffffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w12 >> 11) & 0x1ffffffffff)) + (0*64+19 +1); w13 = *(uint64_t *)(in+(0*41+13)*8/sizeof(in[0])); out[0*64+20] = (start += ((w12 >> 52) | (w13 << 12) & 0x1ffffffffff)) + (0*64+20 +1); w14 = *(uint64_t *)(in+(0*41+14)*8/sizeof(in[0])); out[0*64+21] = (start += ((w13 >> 29) | (w14 << 35) & 0x1ffffffffff)) + (0*64+21 +1); out[0*64+22] = (start += ((w14 >> 6) & 0x1ffffffffff)) + (0*64+22 +1); w15 = *(uint64_t *)(in+(0*41+15)*8/sizeof(in[0])); out[0*64+23] = (start += ((w14 >> 47) | (w15 << 17) & 0x1ffffffffff)) + (0*64+23 +1); w16 = *(uint64_t *)(in+(0*41+16)*8/sizeof(in[0])); out[0*64+24] = (start += ((w15 >> 24) | (w16 << 40) & 0x1ffffffffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w16 >> 1) & 0x1ffffffffff)) + (0*64+25 +1); w17 = *(uint64_t *)(in+(0*41+17)*8/sizeof(in[0])); out[0*64+26] = (start += ((w16 >> 42) | (w17 << 22) & 0x1ffffffffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w17 >> 19) & 0x1ffffffffff)) + (0*64+27 +1); w18 = *(uint64_t *)(in+(0*41+18)*8/sizeof(in[0])); out[0*64+28] = (start += ((w17 >> 60) | (w18 << 4) & 0x1ffffffffff)) + (0*64+28 +1); w19 = *(uint64_t *)(in+(0*41+19)*8/sizeof(in[0])); out[0*64+29] = (start += ((w18 >> 37) | (w19 << 27) & 0x1ffffffffff)) + (0*64+29 +1); out[0*64+30] = (start += ((w19 >> 14) & 0x1ffffffffff)) + (0*64+30 +1); w20 = *(uint32_t *)(in+(0*41+20)*8/sizeof(in[0])); out[0*64+31] = (start += ((w19 >> 55) | (w20 << 9) & 0x1ffffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 41*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_42(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*42)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffffffffff)) + (0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 42) | (w1 << 22) & 0x3ffffffffff)) + (0*32+ 1 +1); out[0*32+ 2] = (start += ((w1 >> 20) & 0x3ffffffffff)) + (0*32+ 2 +1); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w1 >> 62) | (w2 << 2) & 0x3ffffffffff)) + (0*32+ 3 +1); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w2 >> 40) | (w3 << 24) & 0x3ffffffffff)) + (0*32+ 4 +1); out[0*32+ 5] = (start += ((w3 >> 18) & 0x3ffffffffff)) + (0*32+ 5 +1); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w3 >> 60) | (w4 << 4) & 0x3ffffffffff)) + (0*32+ 6 +1); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w4 >> 38) | (w5 << 26) & 0x3ffffffffff)) + (0*32+ 7 +1); out[0*32+ 8] = (start += ((w5 >> 16) & 0x3ffffffffff)) + (0*32+ 8 +1); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w5 >> 58) | (w6 << 6) & 0x3ffffffffff)) + (0*32+ 9 +1); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*32+10] = (start += ((w6 >> 36) | (w7 << 28) & 0x3ffffffffff)) + (0*32+10 +1); out[0*32+11] = (start += ((w7 >> 14) & 0x3ffffffffff)) + (0*32+11 +1); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*32+12] = (start += ((w7 >> 56) | (w8 << 8) & 0x3ffffffffff)) + (0*32+12 +1); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*32+13] = (start += ((w8 >> 34) | (w9 << 30) & 0x3ffffffffff)) + (0*32+13 +1); out[0*32+14] = (start += ((w9 >> 12) & 0x3ffffffffff)) + (0*32+14 +1); w10 = *(uint64_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*32+15] = (start += ((w9 >> 54) | (w10 << 10) & 0x3ffffffffff)) + (0*32+15 +1); w11 = *(uint64_t *)(in+(0*21+11)*8/sizeof(in[0])); out[0*32+16] = (start += ((w10 >> 32) | (w11 << 32) & 0x3ffffffffff)) + (0*32+16 +1); out[0*32+17] = (start += ((w11 >> 10) & 0x3ffffffffff)) + (0*32+17 +1); w12 = *(uint64_t *)(in+(0*21+12)*8/sizeof(in[0])); out[0*32+18] = (start += ((w11 >> 52) | (w12 << 12) & 0x3ffffffffff)) + (0*32+18 +1); w13 = *(uint64_t *)(in+(0*21+13)*8/sizeof(in[0])); out[0*32+19] = (start += ((w12 >> 30) | (w13 << 34) & 0x3ffffffffff)) + (0*32+19 +1); out[0*32+20] = (start += ((w13 >> 8) & 0x3ffffffffff)) + (0*32+20 +1); w14 = *(uint64_t *)(in+(0*21+14)*8/sizeof(in[0])); out[0*32+21] = (start += ((w13 >> 50) | (w14 << 14) & 0x3ffffffffff)) + (0*32+21 +1); w15 = *(uint64_t *)(in+(0*21+15)*8/sizeof(in[0])); out[0*32+22] = (start += ((w14 >> 28) | (w15 << 36) & 0x3ffffffffff)) + (0*32+22 +1); out[0*32+23] = (start += ((w15 >> 6) & 0x3ffffffffff)) + (0*32+23 +1); w16 = *(uint64_t *)(in+(0*21+16)*8/sizeof(in[0])); out[0*32+24] = (start += ((w15 >> 48) | (w16 << 16) & 0x3ffffffffff)) + (0*32+24 +1); w17 = *(uint64_t *)(in+(0*21+17)*8/sizeof(in[0])); out[0*32+25] = (start += ((w16 >> 26) | (w17 << 38) & 0x3ffffffffff)) + (0*32+25 +1); out[0*32+26] = (start += ((w17 >> 4) & 0x3ffffffffff)) + (0*32+26 +1); w18 = *(uint64_t *)(in+(0*21+18)*8/sizeof(in[0])); out[0*32+27] = (start += ((w17 >> 46) | (w18 << 18) & 0x3ffffffffff)) + (0*32+27 +1); w19 = *(uint64_t *)(in+(0*21+19)*8/sizeof(in[0])); out[0*32+28] = (start += ((w18 >> 24) | (w19 << 40) & 0x3ffffffffff)) + (0*32+28 +1); out[0*32+29] = (start += ((w19 >> 2) & 0x3ffffffffff)) + (0*32+29 +1); w20 = *(uint64_t *)(in+(0*21+20)*8/sizeof(in[0])); out[0*32+30] = (start += ((w19 >> 44) | (w20 << 20) & 0x3ffffffffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w20 >> 22))) + (0*32+31 +1);;}; out += 32; start += 32; in += 42*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_43(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*43)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(0*43+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*43+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 43) | (w1 << 21) & 0x7ffffffffff)) + (0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*43+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 22) | (w2 << 42) & 0x7ffffffffff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w2 >> 1) & 0x7ffffffffff)) + (0*64+ 3 +1); w3 = *(uint64_t *)(in+(0*43+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w2 >> 44) | (w3 << 20) & 0x7ffffffffff)) + (0*64+ 4 +1); w4 = *(uint64_t *)(in+(0*43+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w3 >> 23) | (w4 << 41) & 0x7ffffffffff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w4 >> 2) & 0x7ffffffffff)) + (0*64+ 6 +1); w5 = *(uint64_t *)(in+(0*43+5)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w4 >> 45) | (w5 << 19) & 0x7ffffffffff)) + (0*64+ 7 +1); w6 = *(uint64_t *)(in+(0*43+6)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w5 >> 24) | (w6 << 40) & 0x7ffffffffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w6 >> 3) & 0x7ffffffffff)) + (0*64+ 9 +1); w7 = *(uint64_t *)(in+(0*43+7)*8/sizeof(in[0])); out[0*64+10] = (start += ((w6 >> 46) | (w7 << 18) & 0x7ffffffffff)) + (0*64+10 +1); w8 = *(uint64_t *)(in+(0*43+8)*8/sizeof(in[0])); out[0*64+11] = (start += ((w7 >> 25) | (w8 << 39) & 0x7ffffffffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w8 >> 4) & 0x7ffffffffff)) + (0*64+12 +1); w9 = *(uint64_t *)(in+(0*43+9)*8/sizeof(in[0])); out[0*64+13] = (start += ((w8 >> 47) | (w9 << 17) & 0x7ffffffffff)) + (0*64+13 +1); w10 = *(uint64_t *)(in+(0*43+10)*8/sizeof(in[0])); out[0*64+14] = (start += ((w9 >> 26) | (w10 << 38) & 0x7ffffffffff)) + (0*64+14 +1); out[0*64+15] = (start += ((w10 >> 5) & 0x7ffffffffff)) + (0*64+15 +1); w11 = *(uint64_t *)(in+(0*43+11)*8/sizeof(in[0])); out[0*64+16] = (start += ((w10 >> 48) | (w11 << 16) & 0x7ffffffffff)) + (0*64+16 +1); w12 = *(uint64_t *)(in+(0*43+12)*8/sizeof(in[0])); out[0*64+17] = (start += ((w11 >> 27) | (w12 << 37) & 0x7ffffffffff)) + (0*64+17 +1); out[0*64+18] = (start += ((w12 >> 6) & 0x7ffffffffff)) + (0*64+18 +1); w13 = *(uint64_t *)(in+(0*43+13)*8/sizeof(in[0])); out[0*64+19] = (start += ((w12 >> 49) | (w13 << 15) & 0x7ffffffffff)) + (0*64+19 +1); w14 = *(uint64_t *)(in+(0*43+14)*8/sizeof(in[0])); out[0*64+20] = (start += ((w13 >> 28) | (w14 << 36) & 0x7ffffffffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w14 >> 7) & 0x7ffffffffff)) + (0*64+21 +1); w15 = *(uint64_t *)(in+(0*43+15)*8/sizeof(in[0])); out[0*64+22] = (start += ((w14 >> 50) | (w15 << 14) & 0x7ffffffffff)) + (0*64+22 +1); w16 = *(uint64_t *)(in+(0*43+16)*8/sizeof(in[0])); out[0*64+23] = (start += ((w15 >> 29) | (w16 << 35) & 0x7ffffffffff)) + (0*64+23 +1); out[0*64+24] = (start += ((w16 >> 8) & 0x7ffffffffff)) + (0*64+24 +1); w17 = *(uint64_t *)(in+(0*43+17)*8/sizeof(in[0])); out[0*64+25] = (start += ((w16 >> 51) | (w17 << 13) & 0x7ffffffffff)) + (0*64+25 +1); w18 = *(uint64_t *)(in+(0*43+18)*8/sizeof(in[0])); out[0*64+26] = (start += ((w17 >> 30) | (w18 << 34) & 0x7ffffffffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w18 >> 9) & 0x7ffffffffff)) + (0*64+27 +1); w19 = *(uint64_t *)(in+(0*43+19)*8/sizeof(in[0])); out[0*64+28] = (start += ((w18 >> 52) | (w19 << 12) & 0x7ffffffffff)) + (0*64+28 +1); w20 = *(uint64_t *)(in+(0*43+20)*8/sizeof(in[0])); out[0*64+29] = (start += ((w19 >> 31) | (w20 << 33) & 0x7ffffffffff)) + (0*64+29 +1); out[0*64+30] = (start += ((w20 >> 10) & 0x7ffffffffff)) + (0*64+30 +1); w21 = *(uint32_t *)(in+(0*43+21)*8/sizeof(in[0])); out[0*64+31] = (start += ((w20 >> 53) | (w21 << 11) & 0x7ffffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 43*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_44(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*44)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffffffffff)) + (0*16+ 0 +1); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*16+ 1] = (start += ((w0 >> 44) | (w1 << 20) & 0xfffffffffff)) + (0*16+ 1 +1); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*16+ 2] = (start += ((w1 >> 24) | (w2 << 40) & 0xfffffffffff)) + (0*16+ 2 +1); out[0*16+ 3] = (start += ((w2 >> 4) & 0xfffffffffff)) + (0*16+ 3 +1); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*16+ 4] = (start += ((w2 >> 48) | (w3 << 16) & 0xfffffffffff)) + (0*16+ 4 +1); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*16+ 5] = (start += ((w3 >> 28) | (w4 << 36) & 0xfffffffffff)) + (0*16+ 5 +1); out[0*16+ 6] = (start += ((w4 >> 8) & 0xfffffffffff)) + (0*16+ 6 +1); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*16+ 7] = (start += ((w4 >> 52) | (w5 << 12) & 0xfffffffffff)) + (0*16+ 7 +1); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*16+ 8] = (start += ((w5 >> 32) | (w6 << 32) & 0xfffffffffff)) + (0*16+ 8 +1); out[0*16+ 9] = (start += ((w6 >> 12) & 0xfffffffffff)) + (0*16+ 9 +1); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*16+10] = (start += ((w6 >> 56) | (w7 << 8) & 0xfffffffffff)) + (0*16+10 +1); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*16+11] = (start += ((w7 >> 36) | (w8 << 28) & 0xfffffffffff)) + (0*16+11 +1); out[0*16+12] = (start += ((w8 >> 16) & 0xfffffffffff)) + (0*16+12 +1); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*16+13] = (start += ((w8 >> 60) | (w9 << 4) & 0xfffffffffff)) + (0*16+13 +1); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*16+14] = (start += ((w9 >> 40) | (w10 << 24) & 0xfffffffffff)) + (0*16+14 +1); out[0*16+15] = (start += ((w10 >> 20))) + (0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(1*11+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffffffffff)) + (1*16+ 0 +1); w1 = *(uint64_t *)(in+(1*11+1)*8/sizeof(in[0])); out[1*16+ 1] = (start += ((w0 >> 44) | (w1 << 20) & 0xfffffffffff)) + (1*16+ 1 +1); w2 = *(uint64_t *)(in+(1*11+2)*8/sizeof(in[0])); out[1*16+ 2] = (start += ((w1 >> 24) | (w2 << 40) & 0xfffffffffff)) + (1*16+ 2 +1); out[1*16+ 3] = (start += ((w2 >> 4) & 0xfffffffffff)) + (1*16+ 3 +1); w3 = *(uint64_t *)(in+(1*11+3)*8/sizeof(in[0])); out[1*16+ 4] = (start += ((w2 >> 48) | (w3 << 16) & 0xfffffffffff)) + (1*16+ 4 +1); w4 = *(uint64_t *)(in+(1*11+4)*8/sizeof(in[0])); out[1*16+ 5] = (start += ((w3 >> 28) | (w4 << 36) & 0xfffffffffff)) + (1*16+ 5 +1); out[1*16+ 6] = (start += ((w4 >> 8) & 0xfffffffffff)) + (1*16+ 6 +1); w5 = *(uint64_t *)(in+(1*11+5)*8/sizeof(in[0])); out[1*16+ 7] = (start += ((w4 >> 52) | (w5 << 12) & 0xfffffffffff)) + (1*16+ 7 +1); w6 = *(uint64_t *)(in+(1*11+6)*8/sizeof(in[0])); out[1*16+ 8] = (start += ((w5 >> 32) | (w6 << 32) & 0xfffffffffff)) + (1*16+ 8 +1); out[1*16+ 9] = (start += ((w6 >> 12) & 0xfffffffffff)) + (1*16+ 9 +1); w7 = *(uint64_t *)(in+(1*11+7)*8/sizeof(in[0])); out[1*16+10] = (start += ((w6 >> 56) | (w7 << 8) & 0xfffffffffff)) + (1*16+10 +1); w8 = *(uint64_t *)(in+(1*11+8)*8/sizeof(in[0])); out[1*16+11] = (start += ((w7 >> 36) | (w8 << 28) & 0xfffffffffff)) + (1*16+11 +1); out[1*16+12] = (start += ((w8 >> 16) & 0xfffffffffff)) + (1*16+12 +1); w9 = *(uint64_t *)(in+(1*11+9)*8/sizeof(in[0])); out[1*16+13] = (start += ((w8 >> 60) | (w9 << 4) & 0xfffffffffff)) + (1*16+13 +1); w10 = *(uint64_t *)(in+(1*11+10)*8/sizeof(in[0])); out[1*16+14] = (start += ((w9 >> 40) | (w10 << 24) & 0xfffffffffff)) + (1*16+14 +1); out[1*16+15] = (start += ((w10 >> 20))) + (1*16+15 +1);;}; out += 32; start += 32; in += 44*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_45(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*45)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22; w0 = *(uint64_t *)(in+(0*45+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*45+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 45) | (w1 << 19) & 0x1fffffffffff)) + (0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*45+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 26) | (w2 << 38) & 0x1fffffffffff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w2 >> 7) & 0x1fffffffffff)) + (0*64+ 3 +1); w3 = *(uint64_t *)(in+(0*45+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w2 >> 52) | (w3 << 12) & 0x1fffffffffff)) + (0*64+ 4 +1); w4 = *(uint64_t *)(in+(0*45+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w3 >> 33) | (w4 << 31) & 0x1fffffffffff)) + (0*64+ 5 +1); out[0*64+ 6] = (start += ((w4 >> 14) & 0x1fffffffffff)) + (0*64+ 6 +1); w5 = *(uint64_t *)(in+(0*45+5)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w4 >> 59) | (w5 << 5) & 0x1fffffffffff)) + (0*64+ 7 +1); w6 = *(uint64_t *)(in+(0*45+6)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w5 >> 40) | (w6 << 24) & 0x1fffffffffff)) + (0*64+ 8 +1); w7 = *(uint64_t *)(in+(0*45+7)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w6 >> 21) | (w7 << 43) & 0x1fffffffffff)) + (0*64+ 9 +1); out[0*64+10] = (start += ((w7 >> 2) & 0x1fffffffffff)) + (0*64+10 +1); w8 = *(uint64_t *)(in+(0*45+8)*8/sizeof(in[0])); out[0*64+11] = (start += ((w7 >> 47) | (w8 << 17) & 0x1fffffffffff)) + (0*64+11 +1); w9 = *(uint64_t *)(in+(0*45+9)*8/sizeof(in[0])); out[0*64+12] = (start += ((w8 >> 28) | (w9 << 36) & 0x1fffffffffff)) + (0*64+12 +1); out[0*64+13] = (start += ((w9 >> 9) & 0x1fffffffffff)) + (0*64+13 +1); w10 = *(uint64_t *)(in+(0*45+10)*8/sizeof(in[0])); out[0*64+14] = (start += ((w9 >> 54) | (w10 << 10) & 0x1fffffffffff)) + (0*64+14 +1); w11 = *(uint64_t *)(in+(0*45+11)*8/sizeof(in[0])); out[0*64+15] = (start += ((w10 >> 35) | (w11 << 29) & 0x1fffffffffff)) + (0*64+15 +1); out[0*64+16] = (start += ((w11 >> 16) & 0x1fffffffffff)) + (0*64+16 +1); w12 = *(uint64_t *)(in+(0*45+12)*8/sizeof(in[0])); out[0*64+17] = (start += ((w11 >> 61) | (w12 << 3) & 0x1fffffffffff)) + (0*64+17 +1); w13 = *(uint64_t *)(in+(0*45+13)*8/sizeof(in[0])); out[0*64+18] = (start += ((w12 >> 42) | (w13 << 22) & 0x1fffffffffff)) + (0*64+18 +1); w14 = *(uint64_t *)(in+(0*45+14)*8/sizeof(in[0])); out[0*64+19] = (start += ((w13 >> 23) | (w14 << 41) & 0x1fffffffffff)) + (0*64+19 +1); out[0*64+20] = (start += ((w14 >> 4) & 0x1fffffffffff)) + (0*64+20 +1); w15 = *(uint64_t *)(in+(0*45+15)*8/sizeof(in[0])); out[0*64+21] = (start += ((w14 >> 49) | (w15 << 15) & 0x1fffffffffff)) + (0*64+21 +1); w16 = *(uint64_t *)(in+(0*45+16)*8/sizeof(in[0])); out[0*64+22] = (start += ((w15 >> 30) | (w16 << 34) & 0x1fffffffffff)) + (0*64+22 +1); out[0*64+23] = (start += ((w16 >> 11) & 0x1fffffffffff)) + (0*64+23 +1); w17 = *(uint64_t *)(in+(0*45+17)*8/sizeof(in[0])); out[0*64+24] = (start += ((w16 >> 56) | (w17 << 8) & 0x1fffffffffff)) + (0*64+24 +1); w18 = *(uint64_t *)(in+(0*45+18)*8/sizeof(in[0])); out[0*64+25] = (start += ((w17 >> 37) | (w18 << 27) & 0x1fffffffffff)) + (0*64+25 +1); out[0*64+26] = (start += ((w18 >> 18) & 0x1fffffffffff)) + (0*64+26 +1); w19 = *(uint64_t *)(in+(0*45+19)*8/sizeof(in[0])); out[0*64+27] = (start += ((w18 >> 63) | (w19 << 1) & 0x1fffffffffff)) + (0*64+27 +1); w20 = *(uint64_t *)(in+(0*45+20)*8/sizeof(in[0])); out[0*64+28] = (start += ((w19 >> 44) | (w20 << 20) & 0x1fffffffffff)) + (0*64+28 +1); w21 = *(uint64_t *)(in+(0*45+21)*8/sizeof(in[0])); out[0*64+29] = (start += ((w20 >> 25) | (w21 << 39) & 0x1fffffffffff)) + (0*64+29 +1); out[0*64+30] = (start += ((w21 >> 6) & 0x1fffffffffff)) + (0*64+30 +1); w22 = *(uint32_t *)(in+(0*45+22)*8/sizeof(in[0])); out[0*64+31] = (start += ((w21 >> 51) | (w22 << 13) & 0x1fffffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 45*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_46(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*46)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffffffffff)) + (0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 46) | (w1 << 18) & 0x3fffffffffff)) + (0*32+ 1 +1); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w1 >> 28) | (w2 << 36) & 0x3fffffffffff)) + (0*32+ 2 +1); out[0*32+ 3] = (start += ((w2 >> 10) & 0x3fffffffffff)) + (0*32+ 3 +1); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w2 >> 56) | (w3 << 8) & 0x3fffffffffff)) + (0*32+ 4 +1); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w3 >> 38) | (w4 << 26) & 0x3fffffffffff)) + (0*32+ 5 +1); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w4 >> 20) | (w5 << 44) & 0x3fffffffffff)) + (0*32+ 6 +1); out[0*32+ 7] = (start += ((w5 >> 2) & 0x3fffffffffff)) + (0*32+ 7 +1); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w5 >> 48) | (w6 << 16) & 0x3fffffffffff)) + (0*32+ 8 +1); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w6 >> 30) | (w7 << 34) & 0x3fffffffffff)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w7 >> 12) & 0x3fffffffffff)) + (0*32+10 +1); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*32+11] = (start += ((w7 >> 58) | (w8 << 6) & 0x3fffffffffff)) + (0*32+11 +1); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*32+12] = (start += ((w8 >> 40) | (w9 << 24) & 0x3fffffffffff)) + (0*32+12 +1); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*32+13] = (start += ((w9 >> 22) | (w10 << 42) & 0x3fffffffffff)) + (0*32+13 +1); out[0*32+14] = (start += ((w10 >> 4) & 0x3fffffffffff)) + (0*32+14 +1); w11 = *(uint64_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*32+15] = (start += ((w10 >> 50) | (w11 << 14) & 0x3fffffffffff)) + (0*32+15 +1); w12 = *(uint64_t *)(in+(0*23+12)*8/sizeof(in[0])); out[0*32+16] = (start += ((w11 >> 32) | (w12 << 32) & 0x3fffffffffff)) + (0*32+16 +1); out[0*32+17] = (start += ((w12 >> 14) & 0x3fffffffffff)) + (0*32+17 +1); w13 = *(uint64_t *)(in+(0*23+13)*8/sizeof(in[0])); out[0*32+18] = (start += ((w12 >> 60) | (w13 << 4) & 0x3fffffffffff)) + (0*32+18 +1); w14 = *(uint64_t *)(in+(0*23+14)*8/sizeof(in[0])); out[0*32+19] = (start += ((w13 >> 42) | (w14 << 22) & 0x3fffffffffff)) + (0*32+19 +1); w15 = *(uint64_t *)(in+(0*23+15)*8/sizeof(in[0])); out[0*32+20] = (start += ((w14 >> 24) | (w15 << 40) & 0x3fffffffffff)) + (0*32+20 +1); out[0*32+21] = (start += ((w15 >> 6) & 0x3fffffffffff)) + (0*32+21 +1); w16 = *(uint64_t *)(in+(0*23+16)*8/sizeof(in[0])); out[0*32+22] = (start += ((w15 >> 52) | (w16 << 12) & 0x3fffffffffff)) + (0*32+22 +1); w17 = *(uint64_t *)(in+(0*23+17)*8/sizeof(in[0])); out[0*32+23] = (start += ((w16 >> 34) | (w17 << 30) & 0x3fffffffffff)) + (0*32+23 +1); out[0*32+24] = (start += ((w17 >> 16) & 0x3fffffffffff)) + (0*32+24 +1); w18 = *(uint64_t *)(in+(0*23+18)*8/sizeof(in[0])); out[0*32+25] = (start += ((w17 >> 62) | (w18 << 2) & 0x3fffffffffff)) + (0*32+25 +1); w19 = *(uint64_t *)(in+(0*23+19)*8/sizeof(in[0])); out[0*32+26] = (start += ((w18 >> 44) | (w19 << 20) & 0x3fffffffffff)) + (0*32+26 +1); w20 = *(uint64_t *)(in+(0*23+20)*8/sizeof(in[0])); out[0*32+27] = (start += ((w19 >> 26) | (w20 << 38) & 0x3fffffffffff)) + (0*32+27 +1); out[0*32+28] = (start += ((w20 >> 8) & 0x3fffffffffff)) + (0*32+28 +1); w21 = *(uint64_t *)(in+(0*23+21)*8/sizeof(in[0])); out[0*32+29] = (start += ((w20 >> 54) | (w21 << 10) & 0x3fffffffffff)) + (0*32+29 +1); w22 = *(uint64_t *)(in+(0*23+22)*8/sizeof(in[0])); out[0*32+30] = (start += ((w21 >> 36) | (w22 << 28) & 0x3fffffffffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w22 >> 18))) + (0*32+31 +1);;}; out += 32; start += 32; in += 46*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_47(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*47)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(0*47+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*47+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 47) | (w1 << 17) & 0x7fffffffffff)) + (0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*47+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 30) | (w2 << 34) & 0x7fffffffffff)) + (0*64+ 2 +1); out[0*64+ 3] = (start += ((w2 >> 13) & 0x7fffffffffff)) + (0*64+ 3 +1); w3 = *(uint64_t *)(in+(0*47+3)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w2 >> 60) | (w3 << 4) & 0x7fffffffffff)) + (0*64+ 4 +1); w4 = *(uint64_t *)(in+(0*47+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w3 >> 43) | (w4 << 21) & 0x7fffffffffff)) + (0*64+ 5 +1); w5 = *(uint64_t *)(in+(0*47+5)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w4 >> 26) | (w5 << 38) & 0x7fffffffffff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w5 >> 9) & 0x7fffffffffff)) + (0*64+ 7 +1); w6 = *(uint64_t *)(in+(0*47+6)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w5 >> 56) | (w6 << 8) & 0x7fffffffffff)) + (0*64+ 8 +1); w7 = *(uint64_t *)(in+(0*47+7)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w6 >> 39) | (w7 << 25) & 0x7fffffffffff)) + (0*64+ 9 +1); w8 = *(uint64_t *)(in+(0*47+8)*8/sizeof(in[0])); out[0*64+10] = (start += ((w7 >> 22) | (w8 << 42) & 0x7fffffffffff)) + (0*64+10 +1); out[0*64+11] = (start += ((w8 >> 5) & 0x7fffffffffff)) + (0*64+11 +1); w9 = *(uint64_t *)(in+(0*47+9)*8/sizeof(in[0])); out[0*64+12] = (start += ((w8 >> 52) | (w9 << 12) & 0x7fffffffffff)) + (0*64+12 +1); w10 = *(uint64_t *)(in+(0*47+10)*8/sizeof(in[0])); out[0*64+13] = (start += ((w9 >> 35) | (w10 << 29) & 0x7fffffffffff)) + (0*64+13 +1); w11 = *(uint64_t *)(in+(0*47+11)*8/sizeof(in[0])); out[0*64+14] = (start += ((w10 >> 18) | (w11 << 46) & 0x7fffffffffff)) + (0*64+14 +1); out[0*64+15] = (start += ((w11 >> 1) & 0x7fffffffffff)) + (0*64+15 +1); w12 = *(uint64_t *)(in+(0*47+12)*8/sizeof(in[0])); out[0*64+16] = (start += ((w11 >> 48) | (w12 << 16) & 0x7fffffffffff)) + (0*64+16 +1); w13 = *(uint64_t *)(in+(0*47+13)*8/sizeof(in[0])); out[0*64+17] = (start += ((w12 >> 31) | (w13 << 33) & 0x7fffffffffff)) + (0*64+17 +1); out[0*64+18] = (start += ((w13 >> 14) & 0x7fffffffffff)) + (0*64+18 +1); w14 = *(uint64_t *)(in+(0*47+14)*8/sizeof(in[0])); out[0*64+19] = (start += ((w13 >> 61) | (w14 << 3) & 0x7fffffffffff)) + (0*64+19 +1); w15 = *(uint64_t *)(in+(0*47+15)*8/sizeof(in[0])); out[0*64+20] = (start += ((w14 >> 44) | (w15 << 20) & 0x7fffffffffff)) + (0*64+20 +1); w16 = *(uint64_t *)(in+(0*47+16)*8/sizeof(in[0])); out[0*64+21] = (start += ((w15 >> 27) | (w16 << 37) & 0x7fffffffffff)) + (0*64+21 +1); out[0*64+22] = (start += ((w16 >> 10) & 0x7fffffffffff)) + (0*64+22 +1); w17 = *(uint64_t *)(in+(0*47+17)*8/sizeof(in[0])); out[0*64+23] = (start += ((w16 >> 57) | (w17 << 7) & 0x7fffffffffff)) + (0*64+23 +1); w18 = *(uint64_t *)(in+(0*47+18)*8/sizeof(in[0])); out[0*64+24] = (start += ((w17 >> 40) | (w18 << 24) & 0x7fffffffffff)) + (0*64+24 +1); w19 = *(uint64_t *)(in+(0*47+19)*8/sizeof(in[0])); out[0*64+25] = (start += ((w18 >> 23) | (w19 << 41) & 0x7fffffffffff)) + (0*64+25 +1); out[0*64+26] = (start += ((w19 >> 6) & 0x7fffffffffff)) + (0*64+26 +1); w20 = *(uint64_t *)(in+(0*47+20)*8/sizeof(in[0])); out[0*64+27] = (start += ((w19 >> 53) | (w20 << 11) & 0x7fffffffffff)) + (0*64+27 +1); w21 = *(uint64_t *)(in+(0*47+21)*8/sizeof(in[0])); out[0*64+28] = (start += ((w20 >> 36) | (w21 << 28) & 0x7fffffffffff)) + (0*64+28 +1); w22 = *(uint64_t *)(in+(0*47+22)*8/sizeof(in[0])); out[0*64+29] = (start += ((w21 >> 19) | (w22 << 45) & 0x7fffffffffff)) + (0*64+29 +1); out[0*64+30] = (start += ((w22 >> 2) & 0x7fffffffffff)) + (0*64+30 +1); w23 = *(uint32_t *)(in+(0*47+23)*8/sizeof(in[0])); out[0*64+31] = (start += ((w22 >> 49) | (w23 << 15) & 0x7fffffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 47*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_48(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*48)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*4+ 0] = (start += ((w0 ) & 0xffffffffffff)) + (0*4+ 0 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)) + (0*4+ 1 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)) + (0*4+ 2 +1); out[0*4+ 3] = (start += ((w2 >> 16))) + (0*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*4+ 0] = (start += ((w0 ) & 0xffffffffffff)) + (1*4+ 0 +1); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)) + (1*4+ 1 +1); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)) + (1*4+ 2 +1); out[1*4+ 3] = (start += ((w2 >> 16))) + (1*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*4+ 0] = (start += ((w0 ) & 0xffffffffffff)) + (2*4+ 0 +1); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)) + (2*4+ 1 +1); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)) + (2*4+ 2 +1); out[2*4+ 3] = (start += ((w2 >> 16))) + (2*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*4+ 0] = (start += ((w0 ) & 0xffffffffffff)) + (3*4+ 0 +1); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)) + (3*4+ 1 +1); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)) + (3*4+ 2 +1); out[3*4+ 3] = (start += ((w2 >> 16))) + (3*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(4*3+0)*8/sizeof(in[0])); out[4*4+ 0] = (start += ((w0 ) & 0xffffffffffff)) + (4*4+ 0 +1); w1 = *(uint64_t *)(in+(4*3+1)*8/sizeof(in[0])); out[4*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)) + (4*4+ 1 +1); w2 = *(uint64_t *)(in+(4*3+2)*8/sizeof(in[0])); out[4*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)) + (4*4+ 2 +1); out[4*4+ 3] = (start += ((w2 >> 16))) + (4*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(5*3+0)*8/sizeof(in[0])); out[5*4+ 0] = (start += ((w0 ) & 0xffffffffffff)) + (5*4+ 0 +1); w1 = *(uint64_t *)(in+(5*3+1)*8/sizeof(in[0])); out[5*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)) + (5*4+ 1 +1); w2 = *(uint64_t *)(in+(5*3+2)*8/sizeof(in[0])); out[5*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)) + (5*4+ 2 +1); out[5*4+ 3] = (start += ((w2 >> 16))) + (5*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(6*3+0)*8/sizeof(in[0])); out[6*4+ 0] = (start += ((w0 ) & 0xffffffffffff)) + (6*4+ 0 +1); w1 = *(uint64_t *)(in+(6*3+1)*8/sizeof(in[0])); out[6*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)) + (6*4+ 1 +1); w2 = *(uint64_t *)(in+(6*3+2)*8/sizeof(in[0])); out[6*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)) + (6*4+ 2 +1); out[6*4+ 3] = (start += ((w2 >> 16))) + (6*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(7*3+0)*8/sizeof(in[0])); out[7*4+ 0] = (start += ((w0 ) & 0xffffffffffff)) + (7*4+ 0 +1); w1 = *(uint64_t *)(in+(7*3+1)*8/sizeof(in[0])); out[7*4+ 1] = (start += ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)) + (7*4+ 1 +1); w2 = *(uint64_t *)(in+(7*3+2)*8/sizeof(in[0])); out[7*4+ 2] = (start += ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)) + (7*4+ 2 +1); out[7*4+ 3] = (start += ((w2 >> 16))) + (7*4+ 3 +1);;}; out += 32; start += 32; in += 48*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_49(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*49)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24; w0 = *(uint64_t *)(in+(0*49+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffffffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*49+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 49) | (w1 << 15) & 0x1ffffffffffff)) + (0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*49+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 34) | (w2 << 30) & 0x1ffffffffffff)) + (0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*49+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 19) | (w3 << 45) & 0x1ffffffffffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w3 >> 4) & 0x1ffffffffffff)) + (0*64+ 4 +1); w4 = *(uint64_t *)(in+(0*49+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w3 >> 53) | (w4 << 11) & 0x1ffffffffffff)) + (0*64+ 5 +1); w5 = *(uint64_t *)(in+(0*49+5)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w4 >> 38) | (w5 << 26) & 0x1ffffffffffff)) + (0*64+ 6 +1); w6 = *(uint64_t *)(in+(0*49+6)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w5 >> 23) | (w6 << 41) & 0x1ffffffffffff)) + (0*64+ 7 +1); out[0*64+ 8] = (start += ((w6 >> 8) & 0x1ffffffffffff)) + (0*64+ 8 +1); w7 = *(uint64_t *)(in+(0*49+7)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w6 >> 57) | (w7 << 7) & 0x1ffffffffffff)) + (0*64+ 9 +1); w8 = *(uint64_t *)(in+(0*49+8)*8/sizeof(in[0])); out[0*64+10] = (start += ((w7 >> 42) | (w8 << 22) & 0x1ffffffffffff)) + (0*64+10 +1); w9 = *(uint64_t *)(in+(0*49+9)*8/sizeof(in[0])); out[0*64+11] = (start += ((w8 >> 27) | (w9 << 37) & 0x1ffffffffffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w9 >> 12) & 0x1ffffffffffff)) + (0*64+12 +1); w10 = *(uint64_t *)(in+(0*49+10)*8/sizeof(in[0])); out[0*64+13] = (start += ((w9 >> 61) | (w10 << 3) & 0x1ffffffffffff)) + (0*64+13 +1); w11 = *(uint64_t *)(in+(0*49+11)*8/sizeof(in[0])); out[0*64+14] = (start += ((w10 >> 46) | (w11 << 18) & 0x1ffffffffffff)) + (0*64+14 +1); w12 = *(uint64_t *)(in+(0*49+12)*8/sizeof(in[0])); out[0*64+15] = (start += ((w11 >> 31) | (w12 << 33) & 0x1ffffffffffff)) + (0*64+15 +1); w13 = *(uint64_t *)(in+(0*49+13)*8/sizeof(in[0])); out[0*64+16] = (start += ((w12 >> 16) | (w13 << 48) & 0x1ffffffffffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w13 >> 1) & 0x1ffffffffffff)) + (0*64+17 +1); w14 = *(uint64_t *)(in+(0*49+14)*8/sizeof(in[0])); out[0*64+18] = (start += ((w13 >> 50) | (w14 << 14) & 0x1ffffffffffff)) + (0*64+18 +1); w15 = *(uint64_t *)(in+(0*49+15)*8/sizeof(in[0])); out[0*64+19] = (start += ((w14 >> 35) | (w15 << 29) & 0x1ffffffffffff)) + (0*64+19 +1); w16 = *(uint64_t *)(in+(0*49+16)*8/sizeof(in[0])); out[0*64+20] = (start += ((w15 >> 20) | (w16 << 44) & 0x1ffffffffffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w16 >> 5) & 0x1ffffffffffff)) + (0*64+21 +1); w17 = *(uint64_t *)(in+(0*49+17)*8/sizeof(in[0])); out[0*64+22] = (start += ((w16 >> 54) | (w17 << 10) & 0x1ffffffffffff)) + (0*64+22 +1); w18 = *(uint64_t *)(in+(0*49+18)*8/sizeof(in[0])); out[0*64+23] = (start += ((w17 >> 39) | (w18 << 25) & 0x1ffffffffffff)) + (0*64+23 +1); w19 = *(uint64_t *)(in+(0*49+19)*8/sizeof(in[0])); out[0*64+24] = (start += ((w18 >> 24) | (w19 << 40) & 0x1ffffffffffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w19 >> 9) & 0x1ffffffffffff)) + (0*64+25 +1); w20 = *(uint64_t *)(in+(0*49+20)*8/sizeof(in[0])); out[0*64+26] = (start += ((w19 >> 58) | (w20 << 6) & 0x1ffffffffffff)) + (0*64+26 +1); w21 = *(uint64_t *)(in+(0*49+21)*8/sizeof(in[0])); out[0*64+27] = (start += ((w20 >> 43) | (w21 << 21) & 0x1ffffffffffff)) + (0*64+27 +1); w22 = *(uint64_t *)(in+(0*49+22)*8/sizeof(in[0])); out[0*64+28] = (start += ((w21 >> 28) | (w22 << 36) & 0x1ffffffffffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w22 >> 13) & 0x1ffffffffffff)) + (0*64+29 +1); w23 = *(uint64_t *)(in+(0*49+23)*8/sizeof(in[0])); out[0*64+30] = (start += ((w22 >> 62) | (w23 << 2) & 0x1ffffffffffff)) + (0*64+30 +1); w24 = *(uint32_t *)(in+(0*49+24)*8/sizeof(in[0])); out[0*64+31] = (start += ((w23 >> 47) | (w24 << 17) & 0x1ffffffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 49*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_50(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*50)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffffffffffff)) + (0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 50) | (w1 << 14) & 0x3ffffffffffff)) + (0*32+ 1 +1); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w1 >> 36) | (w2 << 28) & 0x3ffffffffffff)) + (0*32+ 2 +1); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w2 >> 22) | (w3 << 42) & 0x3ffffffffffff)) + (0*32+ 3 +1); out[0*32+ 4] = (start += ((w3 >> 8) & 0x3ffffffffffff)) + (0*32+ 4 +1); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w3 >> 58) | (w4 << 6) & 0x3ffffffffffff)) + (0*32+ 5 +1); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w4 >> 44) | (w5 << 20) & 0x3ffffffffffff)) + (0*32+ 6 +1); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w5 >> 30) | (w6 << 34) & 0x3ffffffffffff)) + (0*32+ 7 +1); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w6 >> 16) | (w7 << 48) & 0x3ffffffffffff)) + (0*32+ 8 +1); out[0*32+ 9] = (start += ((w7 >> 2) & 0x3ffffffffffff)) + (0*32+ 9 +1); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*32+10] = (start += ((w7 >> 52) | (w8 << 12) & 0x3ffffffffffff)) + (0*32+10 +1); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*32+11] = (start += ((w8 >> 38) | (w9 << 26) & 0x3ffffffffffff)) + (0*32+11 +1); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*32+12] = (start += ((w9 >> 24) | (w10 << 40) & 0x3ffffffffffff)) + (0*32+12 +1); out[0*32+13] = (start += ((w10 >> 10) & 0x3ffffffffffff)) + (0*32+13 +1); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*32+14] = (start += ((w10 >> 60) | (w11 << 4) & 0x3ffffffffffff)) + (0*32+14 +1); w12 = *(uint64_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*32+15] = (start += ((w11 >> 46) | (w12 << 18) & 0x3ffffffffffff)) + (0*32+15 +1); w13 = *(uint64_t *)(in+(0*25+13)*8/sizeof(in[0])); out[0*32+16] = (start += ((w12 >> 32) | (w13 << 32) & 0x3ffffffffffff)) + (0*32+16 +1); w14 = *(uint64_t *)(in+(0*25+14)*8/sizeof(in[0])); out[0*32+17] = (start += ((w13 >> 18) | (w14 << 46) & 0x3ffffffffffff)) + (0*32+17 +1); out[0*32+18] = (start += ((w14 >> 4) & 0x3ffffffffffff)) + (0*32+18 +1); w15 = *(uint64_t *)(in+(0*25+15)*8/sizeof(in[0])); out[0*32+19] = (start += ((w14 >> 54) | (w15 << 10) & 0x3ffffffffffff)) + (0*32+19 +1); w16 = *(uint64_t *)(in+(0*25+16)*8/sizeof(in[0])); out[0*32+20] = (start += ((w15 >> 40) | (w16 << 24) & 0x3ffffffffffff)) + (0*32+20 +1); w17 = *(uint64_t *)(in+(0*25+17)*8/sizeof(in[0])); out[0*32+21] = (start += ((w16 >> 26) | (w17 << 38) & 0x3ffffffffffff)) + (0*32+21 +1); out[0*32+22] = (start += ((w17 >> 12) & 0x3ffffffffffff)) + (0*32+22 +1); w18 = *(uint64_t *)(in+(0*25+18)*8/sizeof(in[0])); out[0*32+23] = (start += ((w17 >> 62) | (w18 << 2) & 0x3ffffffffffff)) + (0*32+23 +1); w19 = *(uint64_t *)(in+(0*25+19)*8/sizeof(in[0])); out[0*32+24] = (start += ((w18 >> 48) | (w19 << 16) & 0x3ffffffffffff)) + (0*32+24 +1); w20 = *(uint64_t *)(in+(0*25+20)*8/sizeof(in[0])); out[0*32+25] = (start += ((w19 >> 34) | (w20 << 30) & 0x3ffffffffffff)) + (0*32+25 +1); w21 = *(uint64_t *)(in+(0*25+21)*8/sizeof(in[0])); out[0*32+26] = (start += ((w20 >> 20) | (w21 << 44) & 0x3ffffffffffff)) + (0*32+26 +1); out[0*32+27] = (start += ((w21 >> 6) & 0x3ffffffffffff)) + (0*32+27 +1); w22 = *(uint64_t *)(in+(0*25+22)*8/sizeof(in[0])); out[0*32+28] = (start += ((w21 >> 56) | (w22 << 8) & 0x3ffffffffffff)) + (0*32+28 +1); w23 = *(uint64_t *)(in+(0*25+23)*8/sizeof(in[0])); out[0*32+29] = (start += ((w22 >> 42) | (w23 << 22) & 0x3ffffffffffff)) + (0*32+29 +1); w24 = *(uint64_t *)(in+(0*25+24)*8/sizeof(in[0])); out[0*32+30] = (start += ((w23 >> 28) | (w24 << 36) & 0x3ffffffffffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w24 >> 14))) + (0*32+31 +1);;}; out += 32; start += 32; in += 50*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_51(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*51)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(0*51+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffffffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*51+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 51) | (w1 << 13) & 0x7ffffffffffff)) + (0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*51+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 38) | (w2 << 26) & 0x7ffffffffffff)) + (0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*51+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 25) | (w3 << 39) & 0x7ffffffffffff)) + (0*64+ 3 +1); out[0*64+ 4] = (start += ((w3 >> 12) & 0x7ffffffffffff)) + (0*64+ 4 +1); w4 = *(uint64_t *)(in+(0*51+4)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w3 >> 63) | (w4 << 1) & 0x7ffffffffffff)) + (0*64+ 5 +1); w5 = *(uint64_t *)(in+(0*51+5)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w4 >> 50) | (w5 << 14) & 0x7ffffffffffff)) + (0*64+ 6 +1); w6 = *(uint64_t *)(in+(0*51+6)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w5 >> 37) | (w6 << 27) & 0x7ffffffffffff)) + (0*64+ 7 +1); w7 = *(uint64_t *)(in+(0*51+7)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w6 >> 24) | (w7 << 40) & 0x7ffffffffffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w7 >> 11) & 0x7ffffffffffff)) + (0*64+ 9 +1); w8 = *(uint64_t *)(in+(0*51+8)*8/sizeof(in[0])); out[0*64+10] = (start += ((w7 >> 62) | (w8 << 2) & 0x7ffffffffffff)) + (0*64+10 +1); w9 = *(uint64_t *)(in+(0*51+9)*8/sizeof(in[0])); out[0*64+11] = (start += ((w8 >> 49) | (w9 << 15) & 0x7ffffffffffff)) + (0*64+11 +1); w10 = *(uint64_t *)(in+(0*51+10)*8/sizeof(in[0])); out[0*64+12] = (start += ((w9 >> 36) | (w10 << 28) & 0x7ffffffffffff)) + (0*64+12 +1); w11 = *(uint64_t *)(in+(0*51+11)*8/sizeof(in[0])); out[0*64+13] = (start += ((w10 >> 23) | (w11 << 41) & 0x7ffffffffffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w11 >> 10) & 0x7ffffffffffff)) + (0*64+14 +1); w12 = *(uint64_t *)(in+(0*51+12)*8/sizeof(in[0])); out[0*64+15] = (start += ((w11 >> 61) | (w12 << 3) & 0x7ffffffffffff)) + (0*64+15 +1); w13 = *(uint64_t *)(in+(0*51+13)*8/sizeof(in[0])); out[0*64+16] = (start += ((w12 >> 48) | (w13 << 16) & 0x7ffffffffffff)) + (0*64+16 +1); w14 = *(uint64_t *)(in+(0*51+14)*8/sizeof(in[0])); out[0*64+17] = (start += ((w13 >> 35) | (w14 << 29) & 0x7ffffffffffff)) + (0*64+17 +1); w15 = *(uint64_t *)(in+(0*51+15)*8/sizeof(in[0])); out[0*64+18] = (start += ((w14 >> 22) | (w15 << 42) & 0x7ffffffffffff)) + (0*64+18 +1); out[0*64+19] = (start += ((w15 >> 9) & 0x7ffffffffffff)) + (0*64+19 +1); w16 = *(uint64_t *)(in+(0*51+16)*8/sizeof(in[0])); out[0*64+20] = (start += ((w15 >> 60) | (w16 << 4) & 0x7ffffffffffff)) + (0*64+20 +1); w17 = *(uint64_t *)(in+(0*51+17)*8/sizeof(in[0])); out[0*64+21] = (start += ((w16 >> 47) | (w17 << 17) & 0x7ffffffffffff)) + (0*64+21 +1); w18 = *(uint64_t *)(in+(0*51+18)*8/sizeof(in[0])); out[0*64+22] = (start += ((w17 >> 34) | (w18 << 30) & 0x7ffffffffffff)) + (0*64+22 +1); w19 = *(uint64_t *)(in+(0*51+19)*8/sizeof(in[0])); out[0*64+23] = (start += ((w18 >> 21) | (w19 << 43) & 0x7ffffffffffff)) + (0*64+23 +1); out[0*64+24] = (start += ((w19 >> 8) & 0x7ffffffffffff)) + (0*64+24 +1); w20 = *(uint64_t *)(in+(0*51+20)*8/sizeof(in[0])); out[0*64+25] = (start += ((w19 >> 59) | (w20 << 5) & 0x7ffffffffffff)) + (0*64+25 +1); w21 = *(uint64_t *)(in+(0*51+21)*8/sizeof(in[0])); out[0*64+26] = (start += ((w20 >> 46) | (w21 << 18) & 0x7ffffffffffff)) + (0*64+26 +1); w22 = *(uint64_t *)(in+(0*51+22)*8/sizeof(in[0])); out[0*64+27] = (start += ((w21 >> 33) | (w22 << 31) & 0x7ffffffffffff)) + (0*64+27 +1); w23 = *(uint64_t *)(in+(0*51+23)*8/sizeof(in[0])); out[0*64+28] = (start += ((w22 >> 20) | (w23 << 44) & 0x7ffffffffffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w23 >> 7) & 0x7ffffffffffff)) + (0*64+29 +1); w24 = *(uint64_t *)(in+(0*51+24)*8/sizeof(in[0])); out[0*64+30] = (start += ((w23 >> 58) | (w24 << 6) & 0x7ffffffffffff)) + (0*64+30 +1); w25 = *(uint32_t *)(in+(0*51+25)*8/sizeof(in[0])); out[0*64+31] = (start += ((w24 >> 45) | (w25 << 19) & 0x7ffffffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 51*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_52(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*52)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffffffffffff)) + (0*16+ 0 +1); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*16+ 1] = (start += ((w0 >> 52) | (w1 << 12) & 0xfffffffffffff)) + (0*16+ 1 +1); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*16+ 2] = (start += ((w1 >> 40) | (w2 << 24) & 0xfffffffffffff)) + (0*16+ 2 +1); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*16+ 3] = (start += ((w2 >> 28) | (w3 << 36) & 0xfffffffffffff)) + (0*16+ 3 +1); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*16+ 4] = (start += ((w3 >> 16) | (w4 << 48) & 0xfffffffffffff)) + (0*16+ 4 +1); out[0*16+ 5] = (start += ((w4 >> 4) & 0xfffffffffffff)) + (0*16+ 5 +1); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*16+ 6] = (start += ((w4 >> 56) | (w5 << 8) & 0xfffffffffffff)) + (0*16+ 6 +1); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*16+ 7] = (start += ((w5 >> 44) | (w6 << 20) & 0xfffffffffffff)) + (0*16+ 7 +1); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*16+ 8] = (start += ((w6 >> 32) | (w7 << 32) & 0xfffffffffffff)) + (0*16+ 8 +1); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*16+ 9] = (start += ((w7 >> 20) | (w8 << 44) & 0xfffffffffffff)) + (0*16+ 9 +1); out[0*16+10] = (start += ((w8 >> 8) & 0xfffffffffffff)) + (0*16+10 +1); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*16+11] = (start += ((w8 >> 60) | (w9 << 4) & 0xfffffffffffff)) + (0*16+11 +1); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*16+12] = (start += ((w9 >> 48) | (w10 << 16) & 0xfffffffffffff)) + (0*16+12 +1); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*16+13] = (start += ((w10 >> 36) | (w11 << 28) & 0xfffffffffffff)) + (0*16+13 +1); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*16+14] = (start += ((w11 >> 24) | (w12 << 40) & 0xfffffffffffff)) + (0*16+14 +1); out[0*16+15] = (start += ((w12 >> 12))) + (0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(1*13+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffffffffffff)) + (1*16+ 0 +1); w1 = *(uint64_t *)(in+(1*13+1)*8/sizeof(in[0])); out[1*16+ 1] = (start += ((w0 >> 52) | (w1 << 12) & 0xfffffffffffff)) + (1*16+ 1 +1); w2 = *(uint64_t *)(in+(1*13+2)*8/sizeof(in[0])); out[1*16+ 2] = (start += ((w1 >> 40) | (w2 << 24) & 0xfffffffffffff)) + (1*16+ 2 +1); w3 = *(uint64_t *)(in+(1*13+3)*8/sizeof(in[0])); out[1*16+ 3] = (start += ((w2 >> 28) | (w3 << 36) & 0xfffffffffffff)) + (1*16+ 3 +1); w4 = *(uint64_t *)(in+(1*13+4)*8/sizeof(in[0])); out[1*16+ 4] = (start += ((w3 >> 16) | (w4 << 48) & 0xfffffffffffff)) + (1*16+ 4 +1); out[1*16+ 5] = (start += ((w4 >> 4) & 0xfffffffffffff)) + (1*16+ 5 +1); w5 = *(uint64_t *)(in+(1*13+5)*8/sizeof(in[0])); out[1*16+ 6] = (start += ((w4 >> 56) | (w5 << 8) & 0xfffffffffffff)) + (1*16+ 6 +1); w6 = *(uint64_t *)(in+(1*13+6)*8/sizeof(in[0])); out[1*16+ 7] = (start += ((w5 >> 44) | (w6 << 20) & 0xfffffffffffff)) + (1*16+ 7 +1); w7 = *(uint64_t *)(in+(1*13+7)*8/sizeof(in[0])); out[1*16+ 8] = (start += ((w6 >> 32) | (w7 << 32) & 0xfffffffffffff)) + (1*16+ 8 +1); w8 = *(uint64_t *)(in+(1*13+8)*8/sizeof(in[0])); out[1*16+ 9] = (start += ((w7 >> 20) | (w8 << 44) & 0xfffffffffffff)) + (1*16+ 9 +1); out[1*16+10] = (start += ((w8 >> 8) & 0xfffffffffffff)) + (1*16+10 +1); w9 = *(uint64_t *)(in+(1*13+9)*8/sizeof(in[0])); out[1*16+11] = (start += ((w8 >> 60) | (w9 << 4) & 0xfffffffffffff)) + (1*16+11 +1); w10 = *(uint64_t *)(in+(1*13+10)*8/sizeof(in[0])); out[1*16+12] = (start += ((w9 >> 48) | (w10 << 16) & 0xfffffffffffff)) + (1*16+12 +1); w11 = *(uint64_t *)(in+(1*13+11)*8/sizeof(in[0])); out[1*16+13] = (start += ((w10 >> 36) | (w11 << 28) & 0xfffffffffffff)) + (1*16+13 +1); w12 = *(uint64_t *)(in+(1*13+12)*8/sizeof(in[0])); out[1*16+14] = (start += ((w11 >> 24) | (w12 << 40) & 0xfffffffffffff)) + (1*16+14 +1); out[1*16+15] = (start += ((w12 >> 12))) + (1*16+15 +1);;}; out += 32; start += 32; in += 52*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_53(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*53)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26; w0 = *(uint64_t *)(in+(0*53+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffffffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*53+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 53) | (w1 << 11) & 0x1fffffffffffff)) + (0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*53+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 42) | (w2 << 22) & 0x1fffffffffffff)) + (0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*53+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 31) | (w3 << 33) & 0x1fffffffffffff)) + (0*64+ 3 +1); w4 = *(uint64_t *)(in+(0*53+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w3 >> 20) | (w4 << 44) & 0x1fffffffffffff)) + (0*64+ 4 +1); out[0*64+ 5] = (start += ((w4 >> 9) & 0x1fffffffffffff)) + (0*64+ 5 +1); w5 = *(uint64_t *)(in+(0*53+5)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w4 >> 62) | (w5 << 2) & 0x1fffffffffffff)) + (0*64+ 6 +1); w6 = *(uint64_t *)(in+(0*53+6)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w5 >> 51) | (w6 << 13) & 0x1fffffffffffff)) + (0*64+ 7 +1); w7 = *(uint64_t *)(in+(0*53+7)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w6 >> 40) | (w7 << 24) & 0x1fffffffffffff)) + (0*64+ 8 +1); w8 = *(uint64_t *)(in+(0*53+8)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w7 >> 29) | (w8 << 35) & 0x1fffffffffffff)) + (0*64+ 9 +1); w9 = *(uint64_t *)(in+(0*53+9)*8/sizeof(in[0])); out[0*64+10] = (start += ((w8 >> 18) | (w9 << 46) & 0x1fffffffffffff)) + (0*64+10 +1); out[0*64+11] = (start += ((w9 >> 7) & 0x1fffffffffffff)) + (0*64+11 +1); w10 = *(uint64_t *)(in+(0*53+10)*8/sizeof(in[0])); out[0*64+12] = (start += ((w9 >> 60) | (w10 << 4) & 0x1fffffffffffff)) + (0*64+12 +1); w11 = *(uint64_t *)(in+(0*53+11)*8/sizeof(in[0])); out[0*64+13] = (start += ((w10 >> 49) | (w11 << 15) & 0x1fffffffffffff)) + (0*64+13 +1); w12 = *(uint64_t *)(in+(0*53+12)*8/sizeof(in[0])); out[0*64+14] = (start += ((w11 >> 38) | (w12 << 26) & 0x1fffffffffffff)) + (0*64+14 +1); w13 = *(uint64_t *)(in+(0*53+13)*8/sizeof(in[0])); out[0*64+15] = (start += ((w12 >> 27) | (w13 << 37) & 0x1fffffffffffff)) + (0*64+15 +1); w14 = *(uint64_t *)(in+(0*53+14)*8/sizeof(in[0])); out[0*64+16] = (start += ((w13 >> 16) | (w14 << 48) & 0x1fffffffffffff)) + (0*64+16 +1); out[0*64+17] = (start += ((w14 >> 5) & 0x1fffffffffffff)) + (0*64+17 +1); w15 = *(uint64_t *)(in+(0*53+15)*8/sizeof(in[0])); out[0*64+18] = (start += ((w14 >> 58) | (w15 << 6) & 0x1fffffffffffff)) + (0*64+18 +1); w16 = *(uint64_t *)(in+(0*53+16)*8/sizeof(in[0])); out[0*64+19] = (start += ((w15 >> 47) | (w16 << 17) & 0x1fffffffffffff)) + (0*64+19 +1); w17 = *(uint64_t *)(in+(0*53+17)*8/sizeof(in[0])); out[0*64+20] = (start += ((w16 >> 36) | (w17 << 28) & 0x1fffffffffffff)) + (0*64+20 +1); w18 = *(uint64_t *)(in+(0*53+18)*8/sizeof(in[0])); out[0*64+21] = (start += ((w17 >> 25) | (w18 << 39) & 0x1fffffffffffff)) + (0*64+21 +1); w19 = *(uint64_t *)(in+(0*53+19)*8/sizeof(in[0])); out[0*64+22] = (start += ((w18 >> 14) | (w19 << 50) & 0x1fffffffffffff)) + (0*64+22 +1); out[0*64+23] = (start += ((w19 >> 3) & 0x1fffffffffffff)) + (0*64+23 +1); w20 = *(uint64_t *)(in+(0*53+20)*8/sizeof(in[0])); out[0*64+24] = (start += ((w19 >> 56) | (w20 << 8) & 0x1fffffffffffff)) + (0*64+24 +1); w21 = *(uint64_t *)(in+(0*53+21)*8/sizeof(in[0])); out[0*64+25] = (start += ((w20 >> 45) | (w21 << 19) & 0x1fffffffffffff)) + (0*64+25 +1); w22 = *(uint64_t *)(in+(0*53+22)*8/sizeof(in[0])); out[0*64+26] = (start += ((w21 >> 34) | (w22 << 30) & 0x1fffffffffffff)) + (0*64+26 +1); w23 = *(uint64_t *)(in+(0*53+23)*8/sizeof(in[0])); out[0*64+27] = (start += ((w22 >> 23) | (w23 << 41) & 0x1fffffffffffff)) + (0*64+27 +1); w24 = *(uint64_t *)(in+(0*53+24)*8/sizeof(in[0])); out[0*64+28] = (start += ((w23 >> 12) | (w24 << 52) & 0x1fffffffffffff)) + (0*64+28 +1); out[0*64+29] = (start += ((w24 >> 1) & 0x1fffffffffffff)) + (0*64+29 +1); w25 = *(uint64_t *)(in+(0*53+25)*8/sizeof(in[0])); out[0*64+30] = (start += ((w24 >> 54) | (w25 << 10) & 0x1fffffffffffff)) + (0*64+30 +1); w26 = *(uint32_t *)(in+(0*53+26)*8/sizeof(in[0])); out[0*64+31] = (start += ((w25 >> 43) | (w26 << 21) & 0x1fffffffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 53*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_54(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*54)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffffffffffff)) + (0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 54) | (w1 << 10) & 0x3fffffffffffff)) + (0*32+ 1 +1); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w1 >> 44) | (w2 << 20) & 0x3fffffffffffff)) + (0*32+ 2 +1); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w2 >> 34) | (w3 << 30) & 0x3fffffffffffff)) + (0*32+ 3 +1); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w3 >> 24) | (w4 << 40) & 0x3fffffffffffff)) + (0*32+ 4 +1); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w4 >> 14) | (w5 << 50) & 0x3fffffffffffff)) + (0*32+ 5 +1); out[0*32+ 6] = (start += ((w5 >> 4) & 0x3fffffffffffff)) + (0*32+ 6 +1); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w5 >> 58) | (w6 << 6) & 0x3fffffffffffff)) + (0*32+ 7 +1); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w6 >> 48) | (w7 << 16) & 0x3fffffffffffff)) + (0*32+ 8 +1); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w7 >> 38) | (w8 << 26) & 0x3fffffffffffff)) + (0*32+ 9 +1); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*32+10] = (start += ((w8 >> 28) | (w9 << 36) & 0x3fffffffffffff)) + (0*32+10 +1); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*32+11] = (start += ((w9 >> 18) | (w10 << 46) & 0x3fffffffffffff)) + (0*32+11 +1); out[0*32+12] = (start += ((w10 >> 8) & 0x3fffffffffffff)) + (0*32+12 +1); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*32+13] = (start += ((w10 >> 62) | (w11 << 2) & 0x3fffffffffffff)) + (0*32+13 +1); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*32+14] = (start += ((w11 >> 52) | (w12 << 12) & 0x3fffffffffffff)) + (0*32+14 +1); w13 = *(uint64_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*32+15] = (start += ((w12 >> 42) | (w13 << 22) & 0x3fffffffffffff)) + (0*32+15 +1); w14 = *(uint64_t *)(in+(0*27+14)*8/sizeof(in[0])); out[0*32+16] = (start += ((w13 >> 32) | (w14 << 32) & 0x3fffffffffffff)) + (0*32+16 +1); w15 = *(uint64_t *)(in+(0*27+15)*8/sizeof(in[0])); out[0*32+17] = (start += ((w14 >> 22) | (w15 << 42) & 0x3fffffffffffff)) + (0*32+17 +1); w16 = *(uint64_t *)(in+(0*27+16)*8/sizeof(in[0])); out[0*32+18] = (start += ((w15 >> 12) | (w16 << 52) & 0x3fffffffffffff)) + (0*32+18 +1); out[0*32+19] = (start += ((w16 >> 2) & 0x3fffffffffffff)) + (0*32+19 +1); w17 = *(uint64_t *)(in+(0*27+17)*8/sizeof(in[0])); out[0*32+20] = (start += ((w16 >> 56) | (w17 << 8) & 0x3fffffffffffff)) + (0*32+20 +1); w18 = *(uint64_t *)(in+(0*27+18)*8/sizeof(in[0])); out[0*32+21] = (start += ((w17 >> 46) | (w18 << 18) & 0x3fffffffffffff)) + (0*32+21 +1); w19 = *(uint64_t *)(in+(0*27+19)*8/sizeof(in[0])); out[0*32+22] = (start += ((w18 >> 36) | (w19 << 28) & 0x3fffffffffffff)) + (0*32+22 +1); w20 = *(uint64_t *)(in+(0*27+20)*8/sizeof(in[0])); out[0*32+23] = (start += ((w19 >> 26) | (w20 << 38) & 0x3fffffffffffff)) + (0*32+23 +1); w21 = *(uint64_t *)(in+(0*27+21)*8/sizeof(in[0])); out[0*32+24] = (start += ((w20 >> 16) | (w21 << 48) & 0x3fffffffffffff)) + (0*32+24 +1); out[0*32+25] = (start += ((w21 >> 6) & 0x3fffffffffffff)) + (0*32+25 +1); w22 = *(uint64_t *)(in+(0*27+22)*8/sizeof(in[0])); out[0*32+26] = (start += ((w21 >> 60) | (w22 << 4) & 0x3fffffffffffff)) + (0*32+26 +1); w23 = *(uint64_t *)(in+(0*27+23)*8/sizeof(in[0])); out[0*32+27] = (start += ((w22 >> 50) | (w23 << 14) & 0x3fffffffffffff)) + (0*32+27 +1); w24 = *(uint64_t *)(in+(0*27+24)*8/sizeof(in[0])); out[0*32+28] = (start += ((w23 >> 40) | (w24 << 24) & 0x3fffffffffffff)) + (0*32+28 +1); w25 = *(uint64_t *)(in+(0*27+25)*8/sizeof(in[0])); out[0*32+29] = (start += ((w24 >> 30) | (w25 << 34) & 0x3fffffffffffff)) + (0*32+29 +1); w26 = *(uint64_t *)(in+(0*27+26)*8/sizeof(in[0])); out[0*32+30] = (start += ((w25 >> 20) | (w26 << 44) & 0x3fffffffffffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w26 >> 10))) + (0*32+31 +1);;}; out += 32; start += 32; in += 54*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_55(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*55)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(0*55+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffffffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*55+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 55) | (w1 << 9) & 0x7fffffffffffff)) + (0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*55+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 46) | (w2 << 18) & 0x7fffffffffffff)) + (0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*55+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 37) | (w3 << 27) & 0x7fffffffffffff)) + (0*64+ 3 +1); w4 = *(uint64_t *)(in+(0*55+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w3 >> 28) | (w4 << 36) & 0x7fffffffffffff)) + (0*64+ 4 +1); w5 = *(uint64_t *)(in+(0*55+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w4 >> 19) | (w5 << 45) & 0x7fffffffffffff)) + (0*64+ 5 +1); w6 = *(uint64_t *)(in+(0*55+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w5 >> 10) | (w6 << 54) & 0x7fffffffffffff)) + (0*64+ 6 +1); out[0*64+ 7] = (start += ((w6 >> 1) & 0x7fffffffffffff)) + (0*64+ 7 +1); w7 = *(uint64_t *)(in+(0*55+7)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w6 >> 56) | (w7 << 8) & 0x7fffffffffffff)) + (0*64+ 8 +1); w8 = *(uint64_t *)(in+(0*55+8)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w7 >> 47) | (w8 << 17) & 0x7fffffffffffff)) + (0*64+ 9 +1); w9 = *(uint64_t *)(in+(0*55+9)*8/sizeof(in[0])); out[0*64+10] = (start += ((w8 >> 38) | (w9 << 26) & 0x7fffffffffffff)) + (0*64+10 +1); w10 = *(uint64_t *)(in+(0*55+10)*8/sizeof(in[0])); out[0*64+11] = (start += ((w9 >> 29) | (w10 << 35) & 0x7fffffffffffff)) + (0*64+11 +1); w11 = *(uint64_t *)(in+(0*55+11)*8/sizeof(in[0])); out[0*64+12] = (start += ((w10 >> 20) | (w11 << 44) & 0x7fffffffffffff)) + (0*64+12 +1); w12 = *(uint64_t *)(in+(0*55+12)*8/sizeof(in[0])); out[0*64+13] = (start += ((w11 >> 11) | (w12 << 53) & 0x7fffffffffffff)) + (0*64+13 +1); out[0*64+14] = (start += ((w12 >> 2) & 0x7fffffffffffff)) + (0*64+14 +1); w13 = *(uint64_t *)(in+(0*55+13)*8/sizeof(in[0])); out[0*64+15] = (start += ((w12 >> 57) | (w13 << 7) & 0x7fffffffffffff)) + (0*64+15 +1); w14 = *(uint64_t *)(in+(0*55+14)*8/sizeof(in[0])); out[0*64+16] = (start += ((w13 >> 48) | (w14 << 16) & 0x7fffffffffffff)) + (0*64+16 +1); w15 = *(uint64_t *)(in+(0*55+15)*8/sizeof(in[0])); out[0*64+17] = (start += ((w14 >> 39) | (w15 << 25) & 0x7fffffffffffff)) + (0*64+17 +1); w16 = *(uint64_t *)(in+(0*55+16)*8/sizeof(in[0])); out[0*64+18] = (start += ((w15 >> 30) | (w16 << 34) & 0x7fffffffffffff)) + (0*64+18 +1); w17 = *(uint64_t *)(in+(0*55+17)*8/sizeof(in[0])); out[0*64+19] = (start += ((w16 >> 21) | (w17 << 43) & 0x7fffffffffffff)) + (0*64+19 +1); w18 = *(uint64_t *)(in+(0*55+18)*8/sizeof(in[0])); out[0*64+20] = (start += ((w17 >> 12) | (w18 << 52) & 0x7fffffffffffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w18 >> 3) & 0x7fffffffffffff)) + (0*64+21 +1); w19 = *(uint64_t *)(in+(0*55+19)*8/sizeof(in[0])); out[0*64+22] = (start += ((w18 >> 58) | (w19 << 6) & 0x7fffffffffffff)) + (0*64+22 +1); w20 = *(uint64_t *)(in+(0*55+20)*8/sizeof(in[0])); out[0*64+23] = (start += ((w19 >> 49) | (w20 << 15) & 0x7fffffffffffff)) + (0*64+23 +1); w21 = *(uint64_t *)(in+(0*55+21)*8/sizeof(in[0])); out[0*64+24] = (start += ((w20 >> 40) | (w21 << 24) & 0x7fffffffffffff)) + (0*64+24 +1); w22 = *(uint64_t *)(in+(0*55+22)*8/sizeof(in[0])); out[0*64+25] = (start += ((w21 >> 31) | (w22 << 33) & 0x7fffffffffffff)) + (0*64+25 +1); w23 = *(uint64_t *)(in+(0*55+23)*8/sizeof(in[0])); out[0*64+26] = (start += ((w22 >> 22) | (w23 << 42) & 0x7fffffffffffff)) + (0*64+26 +1); w24 = *(uint64_t *)(in+(0*55+24)*8/sizeof(in[0])); out[0*64+27] = (start += ((w23 >> 13) | (w24 << 51) & 0x7fffffffffffff)) + (0*64+27 +1); out[0*64+28] = (start += ((w24 >> 4) & 0x7fffffffffffff)) + (0*64+28 +1); w25 = *(uint64_t *)(in+(0*55+25)*8/sizeof(in[0])); out[0*64+29] = (start += ((w24 >> 59) | (w25 << 5) & 0x7fffffffffffff)) + (0*64+29 +1); w26 = *(uint64_t *)(in+(0*55+26)*8/sizeof(in[0])); out[0*64+30] = (start += ((w25 >> 50) | (w26 << 14) & 0x7fffffffffffff)) + (0*64+30 +1); w27 = *(uint32_t *)(in+(0*55+27)*8/sizeof(in[0])); out[0*64+31] = (start += ((w26 >> 41) | (w27 << 23) & 0x7fffffffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 55*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_56(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*56)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*8+ 0] = (start += ((w0 ) & 0xffffffffffffff)) + (0*8+ 0 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*8+ 1] = (start += ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)) + (0*8+ 1 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*8+ 2] = (start += ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)) + (0*8+ 2 +1); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*8+ 3] = (start += ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)) + (0*8+ 3 +1); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*8+ 4] = (start += ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)) + (0*8+ 4 +1); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*8+ 5] = (start += ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)) + (0*8+ 5 +1); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*8+ 6] = (start += ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)) + (0*8+ 6 +1); out[0*8+ 7] = (start += ((w6 >> 8))) + (0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*8+ 0] = (start += ((w0 ) & 0xffffffffffffff)) + (1*8+ 0 +1); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*8+ 1] = (start += ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)) + (1*8+ 1 +1); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*8+ 2] = (start += ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)) + (1*8+ 2 +1); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*8+ 3] = (start += ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)) + (1*8+ 3 +1); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*8+ 4] = (start += ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)) + (1*8+ 4 +1); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*8+ 5] = (start += ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)) + (1*8+ 5 +1); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*8+ 6] = (start += ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)) + (1*8+ 6 +1); out[1*8+ 7] = (start += ((w6 >> 8))) + (1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(2*7+0)*8/sizeof(in[0])); out[2*8+ 0] = (start += ((w0 ) & 0xffffffffffffff)) + (2*8+ 0 +1); w1 = *(uint64_t *)(in+(2*7+1)*8/sizeof(in[0])); out[2*8+ 1] = (start += ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)) + (2*8+ 1 +1); w2 = *(uint64_t *)(in+(2*7+2)*8/sizeof(in[0])); out[2*8+ 2] = (start += ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)) + (2*8+ 2 +1); w3 = *(uint64_t *)(in+(2*7+3)*8/sizeof(in[0])); out[2*8+ 3] = (start += ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)) + (2*8+ 3 +1); w4 = *(uint64_t *)(in+(2*7+4)*8/sizeof(in[0])); out[2*8+ 4] = (start += ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)) + (2*8+ 4 +1); w5 = *(uint64_t *)(in+(2*7+5)*8/sizeof(in[0])); out[2*8+ 5] = (start += ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)) + (2*8+ 5 +1); w6 = *(uint64_t *)(in+(2*7+6)*8/sizeof(in[0])); out[2*8+ 6] = (start += ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)) + (2*8+ 6 +1); out[2*8+ 7] = (start += ((w6 >> 8))) + (2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(3*7+0)*8/sizeof(in[0])); out[3*8+ 0] = (start += ((w0 ) & 0xffffffffffffff)) + (3*8+ 0 +1); w1 = *(uint64_t *)(in+(3*7+1)*8/sizeof(in[0])); out[3*8+ 1] = (start += ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)) + (3*8+ 1 +1); w2 = *(uint64_t *)(in+(3*7+2)*8/sizeof(in[0])); out[3*8+ 2] = (start += ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)) + (3*8+ 2 +1); w3 = *(uint64_t *)(in+(3*7+3)*8/sizeof(in[0])); out[3*8+ 3] = (start += ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)) + (3*8+ 3 +1); w4 = *(uint64_t *)(in+(3*7+4)*8/sizeof(in[0])); out[3*8+ 4] = (start += ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)) + (3*8+ 4 +1); w5 = *(uint64_t *)(in+(3*7+5)*8/sizeof(in[0])); out[3*8+ 5] = (start += ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)) + (3*8+ 5 +1); w6 = *(uint64_t *)(in+(3*7+6)*8/sizeof(in[0])); out[3*8+ 6] = (start += ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)) + (3*8+ 6 +1); out[3*8+ 7] = (start += ((w6 >> 8))) + (3*8+ 7 +1);;}; out += 32; start += 32; in += 56*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_57(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*57)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28; w0 = *(uint64_t *)(in+(0*57+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1ffffffffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*57+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 57) | (w1 << 7) & 0x1ffffffffffffff)) + (0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*57+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 50) | (w2 << 14) & 0x1ffffffffffffff)) + (0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*57+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 43) | (w3 << 21) & 0x1ffffffffffffff)) + (0*64+ 3 +1); w4 = *(uint64_t *)(in+(0*57+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w3 >> 36) | (w4 << 28) & 0x1ffffffffffffff)) + (0*64+ 4 +1); w5 = *(uint64_t *)(in+(0*57+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w4 >> 29) | (w5 << 35) & 0x1ffffffffffffff)) + (0*64+ 5 +1); w6 = *(uint64_t *)(in+(0*57+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w5 >> 22) | (w6 << 42) & 0x1ffffffffffffff)) + (0*64+ 6 +1); w7 = *(uint64_t *)(in+(0*57+7)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w6 >> 15) | (w7 << 49) & 0x1ffffffffffffff)) + (0*64+ 7 +1); w8 = *(uint64_t *)(in+(0*57+8)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w7 >> 8) | (w8 << 56) & 0x1ffffffffffffff)) + (0*64+ 8 +1); out[0*64+ 9] = (start += ((w8 >> 1) & 0x1ffffffffffffff)) + (0*64+ 9 +1); w9 = *(uint64_t *)(in+(0*57+9)*8/sizeof(in[0])); out[0*64+10] = (start += ((w8 >> 58) | (w9 << 6) & 0x1ffffffffffffff)) + (0*64+10 +1); w10 = *(uint64_t *)(in+(0*57+10)*8/sizeof(in[0])); out[0*64+11] = (start += ((w9 >> 51) | (w10 << 13) & 0x1ffffffffffffff)) + (0*64+11 +1); w11 = *(uint64_t *)(in+(0*57+11)*8/sizeof(in[0])); out[0*64+12] = (start += ((w10 >> 44) | (w11 << 20) & 0x1ffffffffffffff)) + (0*64+12 +1); w12 = *(uint64_t *)(in+(0*57+12)*8/sizeof(in[0])); out[0*64+13] = (start += ((w11 >> 37) | (w12 << 27) & 0x1ffffffffffffff)) + (0*64+13 +1); w13 = *(uint64_t *)(in+(0*57+13)*8/sizeof(in[0])); out[0*64+14] = (start += ((w12 >> 30) | (w13 << 34) & 0x1ffffffffffffff)) + (0*64+14 +1); w14 = *(uint64_t *)(in+(0*57+14)*8/sizeof(in[0])); out[0*64+15] = (start += ((w13 >> 23) | (w14 << 41) & 0x1ffffffffffffff)) + (0*64+15 +1); w15 = *(uint64_t *)(in+(0*57+15)*8/sizeof(in[0])); out[0*64+16] = (start += ((w14 >> 16) | (w15 << 48) & 0x1ffffffffffffff)) + (0*64+16 +1); w16 = *(uint64_t *)(in+(0*57+16)*8/sizeof(in[0])); out[0*64+17] = (start += ((w15 >> 9) | (w16 << 55) & 0x1ffffffffffffff)) + (0*64+17 +1); out[0*64+18] = (start += ((w16 >> 2) & 0x1ffffffffffffff)) + (0*64+18 +1); w17 = *(uint64_t *)(in+(0*57+17)*8/sizeof(in[0])); out[0*64+19] = (start += ((w16 >> 59) | (w17 << 5) & 0x1ffffffffffffff)) + (0*64+19 +1); w18 = *(uint64_t *)(in+(0*57+18)*8/sizeof(in[0])); out[0*64+20] = (start += ((w17 >> 52) | (w18 << 12) & 0x1ffffffffffffff)) + (0*64+20 +1); w19 = *(uint64_t *)(in+(0*57+19)*8/sizeof(in[0])); out[0*64+21] = (start += ((w18 >> 45) | (w19 << 19) & 0x1ffffffffffffff)) + (0*64+21 +1); w20 = *(uint64_t *)(in+(0*57+20)*8/sizeof(in[0])); out[0*64+22] = (start += ((w19 >> 38) | (w20 << 26) & 0x1ffffffffffffff)) + (0*64+22 +1); w21 = *(uint64_t *)(in+(0*57+21)*8/sizeof(in[0])); out[0*64+23] = (start += ((w20 >> 31) | (w21 << 33) & 0x1ffffffffffffff)) + (0*64+23 +1); w22 = *(uint64_t *)(in+(0*57+22)*8/sizeof(in[0])); out[0*64+24] = (start += ((w21 >> 24) | (w22 << 40) & 0x1ffffffffffffff)) + (0*64+24 +1); w23 = *(uint64_t *)(in+(0*57+23)*8/sizeof(in[0])); out[0*64+25] = (start += ((w22 >> 17) | (w23 << 47) & 0x1ffffffffffffff)) + (0*64+25 +1); w24 = *(uint64_t *)(in+(0*57+24)*8/sizeof(in[0])); out[0*64+26] = (start += ((w23 >> 10) | (w24 << 54) & 0x1ffffffffffffff)) + (0*64+26 +1); out[0*64+27] = (start += ((w24 >> 3) & 0x1ffffffffffffff)) + (0*64+27 +1); w25 = *(uint64_t *)(in+(0*57+25)*8/sizeof(in[0])); out[0*64+28] = (start += ((w24 >> 60) | (w25 << 4) & 0x1ffffffffffffff)) + (0*64+28 +1); w26 = *(uint64_t *)(in+(0*57+26)*8/sizeof(in[0])); out[0*64+29] = (start += ((w25 >> 53) | (w26 << 11) & 0x1ffffffffffffff)) + (0*64+29 +1); w27 = *(uint64_t *)(in+(0*57+27)*8/sizeof(in[0])); out[0*64+30] = (start += ((w26 >> 46) | (w27 << 18) & 0x1ffffffffffffff)) + (0*64+30 +1); w28 = *(uint32_t *)(in+(0*57+28)*8/sizeof(in[0])); out[0*64+31] = (start += ((w27 >> 39) | (w28 << 25) & 0x1ffffffffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 57*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_58(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*58)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3ffffffffffffff)) + (0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 58) | (w1 << 6) & 0x3ffffffffffffff)) + (0*32+ 1 +1); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w1 >> 52) | (w2 << 12) & 0x3ffffffffffffff)) + (0*32+ 2 +1); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w2 >> 46) | (w3 << 18) & 0x3ffffffffffffff)) + (0*32+ 3 +1); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w3 >> 40) | (w4 << 24) & 0x3ffffffffffffff)) + (0*32+ 4 +1); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w4 >> 34) | (w5 << 30) & 0x3ffffffffffffff)) + (0*32+ 5 +1); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w5 >> 28) | (w6 << 36) & 0x3ffffffffffffff)) + (0*32+ 6 +1); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w6 >> 22) | (w7 << 42) & 0x3ffffffffffffff)) + (0*32+ 7 +1); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w7 >> 16) | (w8 << 48) & 0x3ffffffffffffff)) + (0*32+ 8 +1); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w8 >> 10) | (w9 << 54) & 0x3ffffffffffffff)) + (0*32+ 9 +1); out[0*32+10] = (start += ((w9 >> 4) & 0x3ffffffffffffff)) + (0*32+10 +1); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*32+11] = (start += ((w9 >> 62) | (w10 << 2) & 0x3ffffffffffffff)) + (0*32+11 +1); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*32+12] = (start += ((w10 >> 56) | (w11 << 8) & 0x3ffffffffffffff)) + (0*32+12 +1); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*32+13] = (start += ((w11 >> 50) | (w12 << 14) & 0x3ffffffffffffff)) + (0*32+13 +1); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*32+14] = (start += ((w12 >> 44) | (w13 << 20) & 0x3ffffffffffffff)) + (0*32+14 +1); w14 = *(uint64_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*32+15] = (start += ((w13 >> 38) | (w14 << 26) & 0x3ffffffffffffff)) + (0*32+15 +1); w15 = *(uint64_t *)(in+(0*29+15)*8/sizeof(in[0])); out[0*32+16] = (start += ((w14 >> 32) | (w15 << 32) & 0x3ffffffffffffff)) + (0*32+16 +1); w16 = *(uint64_t *)(in+(0*29+16)*8/sizeof(in[0])); out[0*32+17] = (start += ((w15 >> 26) | (w16 << 38) & 0x3ffffffffffffff)) + (0*32+17 +1); w17 = *(uint64_t *)(in+(0*29+17)*8/sizeof(in[0])); out[0*32+18] = (start += ((w16 >> 20) | (w17 << 44) & 0x3ffffffffffffff)) + (0*32+18 +1); w18 = *(uint64_t *)(in+(0*29+18)*8/sizeof(in[0])); out[0*32+19] = (start += ((w17 >> 14) | (w18 << 50) & 0x3ffffffffffffff)) + (0*32+19 +1); w19 = *(uint64_t *)(in+(0*29+19)*8/sizeof(in[0])); out[0*32+20] = (start += ((w18 >> 8) | (w19 << 56) & 0x3ffffffffffffff)) + (0*32+20 +1); out[0*32+21] = (start += ((w19 >> 2) & 0x3ffffffffffffff)) + (0*32+21 +1); w20 = *(uint64_t *)(in+(0*29+20)*8/sizeof(in[0])); out[0*32+22] = (start += ((w19 >> 60) | (w20 << 4) & 0x3ffffffffffffff)) + (0*32+22 +1); w21 = *(uint64_t *)(in+(0*29+21)*8/sizeof(in[0])); out[0*32+23] = (start += ((w20 >> 54) | (w21 << 10) & 0x3ffffffffffffff)) + (0*32+23 +1); w22 = *(uint64_t *)(in+(0*29+22)*8/sizeof(in[0])); out[0*32+24] = (start += ((w21 >> 48) | (w22 << 16) & 0x3ffffffffffffff)) + (0*32+24 +1); w23 = *(uint64_t *)(in+(0*29+23)*8/sizeof(in[0])); out[0*32+25] = (start += ((w22 >> 42) | (w23 << 22) & 0x3ffffffffffffff)) + (0*32+25 +1); w24 = *(uint64_t *)(in+(0*29+24)*8/sizeof(in[0])); out[0*32+26] = (start += ((w23 >> 36) | (w24 << 28) & 0x3ffffffffffffff)) + (0*32+26 +1); w25 = *(uint64_t *)(in+(0*29+25)*8/sizeof(in[0])); out[0*32+27] = (start += ((w24 >> 30) | (w25 << 34) & 0x3ffffffffffffff)) + (0*32+27 +1); w26 = *(uint64_t *)(in+(0*29+26)*8/sizeof(in[0])); out[0*32+28] = (start += ((w25 >> 24) | (w26 << 40) & 0x3ffffffffffffff)) + (0*32+28 +1); w27 = *(uint64_t *)(in+(0*29+27)*8/sizeof(in[0])); out[0*32+29] = (start += ((w26 >> 18) | (w27 << 46) & 0x3ffffffffffffff)) + (0*32+29 +1); w28 = *(uint64_t *)(in+(0*29+28)*8/sizeof(in[0])); out[0*32+30] = (start += ((w27 >> 12) | (w28 << 52) & 0x3ffffffffffffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w28 >> 6))) + (0*32+31 +1);;}; out += 32; start += 32; in += 58*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_59(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*59)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(0*59+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7ffffffffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*59+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 59) | (w1 << 5) & 0x7ffffffffffffff)) + (0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*59+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 54) | (w2 << 10) & 0x7ffffffffffffff)) + (0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*59+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 49) | (w3 << 15) & 0x7ffffffffffffff)) + (0*64+ 3 +1); w4 = *(uint64_t *)(in+(0*59+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w3 >> 44) | (w4 << 20) & 0x7ffffffffffffff)) + (0*64+ 4 +1); w5 = *(uint64_t *)(in+(0*59+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w4 >> 39) | (w5 << 25) & 0x7ffffffffffffff)) + (0*64+ 5 +1); w6 = *(uint64_t *)(in+(0*59+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w5 >> 34) | (w6 << 30) & 0x7ffffffffffffff)) + (0*64+ 6 +1); w7 = *(uint64_t *)(in+(0*59+7)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w6 >> 29) | (w7 << 35) & 0x7ffffffffffffff)) + (0*64+ 7 +1); w8 = *(uint64_t *)(in+(0*59+8)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w7 >> 24) | (w8 << 40) & 0x7ffffffffffffff)) + (0*64+ 8 +1); w9 = *(uint64_t *)(in+(0*59+9)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w8 >> 19) | (w9 << 45) & 0x7ffffffffffffff)) + (0*64+ 9 +1); w10 = *(uint64_t *)(in+(0*59+10)*8/sizeof(in[0])); out[0*64+10] = (start += ((w9 >> 14) | (w10 << 50) & 0x7ffffffffffffff)) + (0*64+10 +1); w11 = *(uint64_t *)(in+(0*59+11)*8/sizeof(in[0])); out[0*64+11] = (start += ((w10 >> 9) | (w11 << 55) & 0x7ffffffffffffff)) + (0*64+11 +1); out[0*64+12] = (start += ((w11 >> 4) & 0x7ffffffffffffff)) + (0*64+12 +1); w12 = *(uint64_t *)(in+(0*59+12)*8/sizeof(in[0])); out[0*64+13] = (start += ((w11 >> 63) | (w12 << 1) & 0x7ffffffffffffff)) + (0*64+13 +1); w13 = *(uint64_t *)(in+(0*59+13)*8/sizeof(in[0])); out[0*64+14] = (start += ((w12 >> 58) | (w13 << 6) & 0x7ffffffffffffff)) + (0*64+14 +1); w14 = *(uint64_t *)(in+(0*59+14)*8/sizeof(in[0])); out[0*64+15] = (start += ((w13 >> 53) | (w14 << 11) & 0x7ffffffffffffff)) + (0*64+15 +1); w15 = *(uint64_t *)(in+(0*59+15)*8/sizeof(in[0])); out[0*64+16] = (start += ((w14 >> 48) | (w15 << 16) & 0x7ffffffffffffff)) + (0*64+16 +1); w16 = *(uint64_t *)(in+(0*59+16)*8/sizeof(in[0])); out[0*64+17] = (start += ((w15 >> 43) | (w16 << 21) & 0x7ffffffffffffff)) + (0*64+17 +1); w17 = *(uint64_t *)(in+(0*59+17)*8/sizeof(in[0])); out[0*64+18] = (start += ((w16 >> 38) | (w17 << 26) & 0x7ffffffffffffff)) + (0*64+18 +1); w18 = *(uint64_t *)(in+(0*59+18)*8/sizeof(in[0])); out[0*64+19] = (start += ((w17 >> 33) | (w18 << 31) & 0x7ffffffffffffff)) + (0*64+19 +1); w19 = *(uint64_t *)(in+(0*59+19)*8/sizeof(in[0])); out[0*64+20] = (start += ((w18 >> 28) | (w19 << 36) & 0x7ffffffffffffff)) + (0*64+20 +1); w20 = *(uint64_t *)(in+(0*59+20)*8/sizeof(in[0])); out[0*64+21] = (start += ((w19 >> 23) | (w20 << 41) & 0x7ffffffffffffff)) + (0*64+21 +1); w21 = *(uint64_t *)(in+(0*59+21)*8/sizeof(in[0])); out[0*64+22] = (start += ((w20 >> 18) | (w21 << 46) & 0x7ffffffffffffff)) + (0*64+22 +1); w22 = *(uint64_t *)(in+(0*59+22)*8/sizeof(in[0])); out[0*64+23] = (start += ((w21 >> 13) | (w22 << 51) & 0x7ffffffffffffff)) + (0*64+23 +1); w23 = *(uint64_t *)(in+(0*59+23)*8/sizeof(in[0])); out[0*64+24] = (start += ((w22 >> 8) | (w23 << 56) & 0x7ffffffffffffff)) + (0*64+24 +1); out[0*64+25] = (start += ((w23 >> 3) & 0x7ffffffffffffff)) + (0*64+25 +1); w24 = *(uint64_t *)(in+(0*59+24)*8/sizeof(in[0])); out[0*64+26] = (start += ((w23 >> 62) | (w24 << 2) & 0x7ffffffffffffff)) + (0*64+26 +1); w25 = *(uint64_t *)(in+(0*59+25)*8/sizeof(in[0])); out[0*64+27] = (start += ((w24 >> 57) | (w25 << 7) & 0x7ffffffffffffff)) + (0*64+27 +1); w26 = *(uint64_t *)(in+(0*59+26)*8/sizeof(in[0])); out[0*64+28] = (start += ((w25 >> 52) | (w26 << 12) & 0x7ffffffffffffff)) + (0*64+28 +1); w27 = *(uint64_t *)(in+(0*59+27)*8/sizeof(in[0])); out[0*64+29] = (start += ((w26 >> 47) | (w27 << 17) & 0x7ffffffffffffff)) + (0*64+29 +1); w28 = *(uint64_t *)(in+(0*59+28)*8/sizeof(in[0])); out[0*64+30] = (start += ((w27 >> 42) | (w28 << 22) & 0x7ffffffffffffff)) + (0*64+30 +1); w29 = *(uint32_t *)(in+(0*59+29)*8/sizeof(in[0])); out[0*64+31] = (start += ((w28 >> 37) | (w29 << 27) & 0x7ffffffffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 59*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_60(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*60)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*16+ 0] = (start += ((w0 ) & 0xfffffffffffffff)) + (0*16+ 0 +1); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*16+ 1] = (start += ((w0 >> 60) | (w1 << 4) & 0xfffffffffffffff)) + (0*16+ 1 +1); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*16+ 2] = (start += ((w1 >> 56) | (w2 << 8) & 0xfffffffffffffff)) + (0*16+ 2 +1); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*16+ 3] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffffffffffffff)) + (0*16+ 3 +1); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*16+ 4] = (start += ((w3 >> 48) | (w4 << 16) & 0xfffffffffffffff)) + (0*16+ 4 +1); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*16+ 5] = (start += ((w4 >> 44) | (w5 << 20) & 0xfffffffffffffff)) + (0*16+ 5 +1); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*16+ 6] = (start += ((w5 >> 40) | (w6 << 24) & 0xfffffffffffffff)) + (0*16+ 6 +1); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*16+ 7] = (start += ((w6 >> 36) | (w7 << 28) & 0xfffffffffffffff)) + (0*16+ 7 +1); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*16+ 8] = (start += ((w7 >> 32) | (w8 << 32) & 0xfffffffffffffff)) + (0*16+ 8 +1); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*16+ 9] = (start += ((w8 >> 28) | (w9 << 36) & 0xfffffffffffffff)) + (0*16+ 9 +1); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*16+10] = (start += ((w9 >> 24) | (w10 << 40) & 0xfffffffffffffff)) + (0*16+10 +1); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*16+11] = (start += ((w10 >> 20) | (w11 << 44) & 0xfffffffffffffff)) + (0*16+11 +1); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*16+12] = (start += ((w11 >> 16) | (w12 << 48) & 0xfffffffffffffff)) + (0*16+12 +1); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*16+13] = (start += ((w12 >> 12) | (w13 << 52) & 0xfffffffffffffff)) + (0*16+13 +1); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*16+14] = (start += ((w13 >> 8) | (w14 << 56) & 0xfffffffffffffff)) + (0*16+14 +1); out[0*16+15] = (start += ((w14 >> 4))) + (0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(1*15+0)*8/sizeof(in[0])); out[1*16+ 0] = (start += ((w0 ) & 0xfffffffffffffff)) + (1*16+ 0 +1); w1 = *(uint64_t *)(in+(1*15+1)*8/sizeof(in[0])); out[1*16+ 1] = (start += ((w0 >> 60) | (w1 << 4) & 0xfffffffffffffff)) + (1*16+ 1 +1); w2 = *(uint64_t *)(in+(1*15+2)*8/sizeof(in[0])); out[1*16+ 2] = (start += ((w1 >> 56) | (w2 << 8) & 0xfffffffffffffff)) + (1*16+ 2 +1); w3 = *(uint64_t *)(in+(1*15+3)*8/sizeof(in[0])); out[1*16+ 3] = (start += ((w2 >> 52) | (w3 << 12) & 0xfffffffffffffff)) + (1*16+ 3 +1); w4 = *(uint64_t *)(in+(1*15+4)*8/sizeof(in[0])); out[1*16+ 4] = (start += ((w3 >> 48) | (w4 << 16) & 0xfffffffffffffff)) + (1*16+ 4 +1); w5 = *(uint64_t *)(in+(1*15+5)*8/sizeof(in[0])); out[1*16+ 5] = (start += ((w4 >> 44) | (w5 << 20) & 0xfffffffffffffff)) + (1*16+ 5 +1); w6 = *(uint64_t *)(in+(1*15+6)*8/sizeof(in[0])); out[1*16+ 6] = (start += ((w5 >> 40) | (w6 << 24) & 0xfffffffffffffff)) + (1*16+ 6 +1); w7 = *(uint64_t *)(in+(1*15+7)*8/sizeof(in[0])); out[1*16+ 7] = (start += ((w6 >> 36) | (w7 << 28) & 0xfffffffffffffff)) + (1*16+ 7 +1); w8 = *(uint64_t *)(in+(1*15+8)*8/sizeof(in[0])); out[1*16+ 8] = (start += ((w7 >> 32) | (w8 << 32) & 0xfffffffffffffff)) + (1*16+ 8 +1); w9 = *(uint64_t *)(in+(1*15+9)*8/sizeof(in[0])); out[1*16+ 9] = (start += ((w8 >> 28) | (w9 << 36) & 0xfffffffffffffff)) + (1*16+ 9 +1); w10 = *(uint64_t *)(in+(1*15+10)*8/sizeof(in[0])); out[1*16+10] = (start += ((w9 >> 24) | (w10 << 40) & 0xfffffffffffffff)) + (1*16+10 +1); w11 = *(uint64_t *)(in+(1*15+11)*8/sizeof(in[0])); out[1*16+11] = (start += ((w10 >> 20) | (w11 << 44) & 0xfffffffffffffff)) + (1*16+11 +1); w12 = *(uint64_t *)(in+(1*15+12)*8/sizeof(in[0])); out[1*16+12] = (start += ((w11 >> 16) | (w12 << 48) & 0xfffffffffffffff)) + (1*16+12 +1); w13 = *(uint64_t *)(in+(1*15+13)*8/sizeof(in[0])); out[1*16+13] = (start += ((w12 >> 12) | (w13 << 52) & 0xfffffffffffffff)) + (1*16+13 +1); w14 = *(uint64_t *)(in+(1*15+14)*8/sizeof(in[0])); out[1*16+14] = (start += ((w13 >> 8) | (w14 << 56) & 0xfffffffffffffff)) + (1*16+14 +1); out[1*16+15] = (start += ((w14 >> 4))) + (1*16+15 +1);;}; out += 32; start += 32; in += 60*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_61(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*61)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30; w0 = *(uint64_t *)(in+(0*61+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x1fffffffffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*61+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 61) | (w1 << 3) & 0x1fffffffffffffff)) + (0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*61+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 58) | (w2 << 6) & 0x1fffffffffffffff)) + (0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*61+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 55) | (w3 << 9) & 0x1fffffffffffffff)) + (0*64+ 3 +1); w4 = *(uint64_t *)(in+(0*61+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w3 >> 52) | (w4 << 12) & 0x1fffffffffffffff)) + (0*64+ 4 +1); w5 = *(uint64_t *)(in+(0*61+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w4 >> 49) | (w5 << 15) & 0x1fffffffffffffff)) + (0*64+ 5 +1); w6 = *(uint64_t *)(in+(0*61+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w5 >> 46) | (w6 << 18) & 0x1fffffffffffffff)) + (0*64+ 6 +1); w7 = *(uint64_t *)(in+(0*61+7)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w6 >> 43) | (w7 << 21) & 0x1fffffffffffffff)) + (0*64+ 7 +1); w8 = *(uint64_t *)(in+(0*61+8)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w7 >> 40) | (w8 << 24) & 0x1fffffffffffffff)) + (0*64+ 8 +1); w9 = *(uint64_t *)(in+(0*61+9)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w8 >> 37) | (w9 << 27) & 0x1fffffffffffffff)) + (0*64+ 9 +1); w10 = *(uint64_t *)(in+(0*61+10)*8/sizeof(in[0])); out[0*64+10] = (start += ((w9 >> 34) | (w10 << 30) & 0x1fffffffffffffff)) + (0*64+10 +1); w11 = *(uint64_t *)(in+(0*61+11)*8/sizeof(in[0])); out[0*64+11] = (start += ((w10 >> 31) | (w11 << 33) & 0x1fffffffffffffff)) + (0*64+11 +1); w12 = *(uint64_t *)(in+(0*61+12)*8/sizeof(in[0])); out[0*64+12] = (start += ((w11 >> 28) | (w12 << 36) & 0x1fffffffffffffff)) + (0*64+12 +1); w13 = *(uint64_t *)(in+(0*61+13)*8/sizeof(in[0])); out[0*64+13] = (start += ((w12 >> 25) | (w13 << 39) & 0x1fffffffffffffff)) + (0*64+13 +1); w14 = *(uint64_t *)(in+(0*61+14)*8/sizeof(in[0])); out[0*64+14] = (start += ((w13 >> 22) | (w14 << 42) & 0x1fffffffffffffff)) + (0*64+14 +1); w15 = *(uint64_t *)(in+(0*61+15)*8/sizeof(in[0])); out[0*64+15] = (start += ((w14 >> 19) | (w15 << 45) & 0x1fffffffffffffff)) + (0*64+15 +1); w16 = *(uint64_t *)(in+(0*61+16)*8/sizeof(in[0])); out[0*64+16] = (start += ((w15 >> 16) | (w16 << 48) & 0x1fffffffffffffff)) + (0*64+16 +1); w17 = *(uint64_t *)(in+(0*61+17)*8/sizeof(in[0])); out[0*64+17] = (start += ((w16 >> 13) | (w17 << 51) & 0x1fffffffffffffff)) + (0*64+17 +1); w18 = *(uint64_t *)(in+(0*61+18)*8/sizeof(in[0])); out[0*64+18] = (start += ((w17 >> 10) | (w18 << 54) & 0x1fffffffffffffff)) + (0*64+18 +1); w19 = *(uint64_t *)(in+(0*61+19)*8/sizeof(in[0])); out[0*64+19] = (start += ((w18 >> 7) | (w19 << 57) & 0x1fffffffffffffff)) + (0*64+19 +1); w20 = *(uint64_t *)(in+(0*61+20)*8/sizeof(in[0])); out[0*64+20] = (start += ((w19 >> 4) | (w20 << 60) & 0x1fffffffffffffff)) + (0*64+20 +1); out[0*64+21] = (start += ((w20 >> 1) & 0x1fffffffffffffff)) + (0*64+21 +1); w21 = *(uint64_t *)(in+(0*61+21)*8/sizeof(in[0])); out[0*64+22] = (start += ((w20 >> 62) | (w21 << 2) & 0x1fffffffffffffff)) + (0*64+22 +1); w22 = *(uint64_t *)(in+(0*61+22)*8/sizeof(in[0])); out[0*64+23] = (start += ((w21 >> 59) | (w22 << 5) & 0x1fffffffffffffff)) + (0*64+23 +1); w23 = *(uint64_t *)(in+(0*61+23)*8/sizeof(in[0])); out[0*64+24] = (start += ((w22 >> 56) | (w23 << 8) & 0x1fffffffffffffff)) + (0*64+24 +1); w24 = *(uint64_t *)(in+(0*61+24)*8/sizeof(in[0])); out[0*64+25] = (start += ((w23 >> 53) | (w24 << 11) & 0x1fffffffffffffff)) + (0*64+25 +1); w25 = *(uint64_t *)(in+(0*61+25)*8/sizeof(in[0])); out[0*64+26] = (start += ((w24 >> 50) | (w25 << 14) & 0x1fffffffffffffff)) + (0*64+26 +1); w26 = *(uint64_t *)(in+(0*61+26)*8/sizeof(in[0])); out[0*64+27] = (start += ((w25 >> 47) | (w26 << 17) & 0x1fffffffffffffff)) + (0*64+27 +1); w27 = *(uint64_t *)(in+(0*61+27)*8/sizeof(in[0])); out[0*64+28] = (start += ((w26 >> 44) | (w27 << 20) & 0x1fffffffffffffff)) + (0*64+28 +1); w28 = *(uint64_t *)(in+(0*61+28)*8/sizeof(in[0])); out[0*64+29] = (start += ((w27 >> 41) | (w28 << 23) & 0x1fffffffffffffff)) + (0*64+29 +1); w29 = *(uint64_t *)(in+(0*61+29)*8/sizeof(in[0])); out[0*64+30] = (start += ((w28 >> 38) | (w29 << 26) & 0x1fffffffffffffff)) + (0*64+30 +1); w30 = *(uint32_t *)(in+(0*61+30)*8/sizeof(in[0])); out[0*64+31] = (start += ((w29 >> 35) | (w30 << 29) & 0x1fffffffffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 61*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_62(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*62)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*32+ 0] = (start += ((w0 ) & 0x3fffffffffffffff)) + (0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*32+ 1] = (start += ((w0 >> 62) | (w1 << 2) & 0x3fffffffffffffff)) + (0*32+ 1 +1); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*32+ 2] = (start += ((w1 >> 60) | (w2 << 4) & 0x3fffffffffffffff)) + (0*32+ 2 +1); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*32+ 3] = (start += ((w2 >> 58) | (w3 << 6) & 0x3fffffffffffffff)) + (0*32+ 3 +1); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*32+ 4] = (start += ((w3 >> 56) | (w4 << 8) & 0x3fffffffffffffff)) + (0*32+ 4 +1); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*32+ 5] = (start += ((w4 >> 54) | (w5 << 10) & 0x3fffffffffffffff)) + (0*32+ 5 +1); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*32+ 6] = (start += ((w5 >> 52) | (w6 << 12) & 0x3fffffffffffffff)) + (0*32+ 6 +1); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*32+ 7] = (start += ((w6 >> 50) | (w7 << 14) & 0x3fffffffffffffff)) + (0*32+ 7 +1); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*32+ 8] = (start += ((w7 >> 48) | (w8 << 16) & 0x3fffffffffffffff)) + (0*32+ 8 +1); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*32+ 9] = (start += ((w8 >> 46) | (w9 << 18) & 0x3fffffffffffffff)) + (0*32+ 9 +1); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*32+10] = (start += ((w9 >> 44) | (w10 << 20) & 0x3fffffffffffffff)) + (0*32+10 +1); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*32+11] = (start += ((w10 >> 42) | (w11 << 22) & 0x3fffffffffffffff)) + (0*32+11 +1); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*32+12] = (start += ((w11 >> 40) | (w12 << 24) & 0x3fffffffffffffff)) + (0*32+12 +1); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*32+13] = (start += ((w12 >> 38) | (w13 << 26) & 0x3fffffffffffffff)) + (0*32+13 +1); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*32+14] = (start += ((w13 >> 36) | (w14 << 28) & 0x3fffffffffffffff)) + (0*32+14 +1); w15 = *(uint64_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*32+15] = (start += ((w14 >> 34) | (w15 << 30) & 0x3fffffffffffffff)) + (0*32+15 +1); w16 = *(uint64_t *)(in+(0*31+16)*8/sizeof(in[0])); out[0*32+16] = (start += ((w15 >> 32) | (w16 << 32) & 0x3fffffffffffffff)) + (0*32+16 +1); w17 = *(uint64_t *)(in+(0*31+17)*8/sizeof(in[0])); out[0*32+17] = (start += ((w16 >> 30) | (w17 << 34) & 0x3fffffffffffffff)) + (0*32+17 +1); w18 = *(uint64_t *)(in+(0*31+18)*8/sizeof(in[0])); out[0*32+18] = (start += ((w17 >> 28) | (w18 << 36) & 0x3fffffffffffffff)) + (0*32+18 +1); w19 = *(uint64_t *)(in+(0*31+19)*8/sizeof(in[0])); out[0*32+19] = (start += ((w18 >> 26) | (w19 << 38) & 0x3fffffffffffffff)) + (0*32+19 +1); w20 = *(uint64_t *)(in+(0*31+20)*8/sizeof(in[0])); out[0*32+20] = (start += ((w19 >> 24) | (w20 << 40) & 0x3fffffffffffffff)) + (0*32+20 +1); w21 = *(uint64_t *)(in+(0*31+21)*8/sizeof(in[0])); out[0*32+21] = (start += ((w20 >> 22) | (w21 << 42) & 0x3fffffffffffffff)) + (0*32+21 +1); w22 = *(uint64_t *)(in+(0*31+22)*8/sizeof(in[0])); out[0*32+22] = (start += ((w21 >> 20) | (w22 << 44) & 0x3fffffffffffffff)) + (0*32+22 +1); w23 = *(uint64_t *)(in+(0*31+23)*8/sizeof(in[0])); out[0*32+23] = (start += ((w22 >> 18) | (w23 << 46) & 0x3fffffffffffffff)) + (0*32+23 +1); w24 = *(uint64_t *)(in+(0*31+24)*8/sizeof(in[0])); out[0*32+24] = (start += ((w23 >> 16) | (w24 << 48) & 0x3fffffffffffffff)) + (0*32+24 +1); w25 = *(uint64_t *)(in+(0*31+25)*8/sizeof(in[0])); out[0*32+25] = (start += ((w24 >> 14) | (w25 << 50) & 0x3fffffffffffffff)) + (0*32+25 +1); w26 = *(uint64_t *)(in+(0*31+26)*8/sizeof(in[0])); out[0*32+26] = (start += ((w25 >> 12) | (w26 << 52) & 0x3fffffffffffffff)) + (0*32+26 +1); w27 = *(uint64_t *)(in+(0*31+27)*8/sizeof(in[0])); out[0*32+27] = (start += ((w26 >> 10) | (w27 << 54) & 0x3fffffffffffffff)) + (0*32+27 +1); w28 = *(uint64_t *)(in+(0*31+28)*8/sizeof(in[0])); out[0*32+28] = (start += ((w27 >> 8) | (w28 << 56) & 0x3fffffffffffffff)) + (0*32+28 +1); w29 = *(uint64_t *)(in+(0*31+29)*8/sizeof(in[0])); out[0*32+29] = (start += ((w28 >> 6) | (w29 << 58) & 0x3fffffffffffffff)) + (0*32+29 +1); w30 = *(uint64_t *)(in+(0*31+30)*8/sizeof(in[0])); out[0*32+30] = (start += ((w29 >> 4) | (w30 << 60) & 0x3fffffffffffffff)) + (0*32+30 +1); out[0*32+31] = (start += ((w30 >> 2))) + (0*32+31 +1);;}; out += 32; start += 32; in += 62*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_63(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*63)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(0*63+0)*8/sizeof(in[0])); out[0*64+ 0] = (start += ((w0 ) & 0x7fffffffffffffff)) + (0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*63+1)*8/sizeof(in[0])); out[0*64+ 1] = (start += ((w0 >> 63) | (w1 << 1) & 0x7fffffffffffffff)) + (0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*63+2)*8/sizeof(in[0])); out[0*64+ 2] = (start += ((w1 >> 62) | (w2 << 2) & 0x7fffffffffffffff)) + (0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*63+3)*8/sizeof(in[0])); out[0*64+ 3] = (start += ((w2 >> 61) | (w3 << 3) & 0x7fffffffffffffff)) + (0*64+ 3 +1); w4 = *(uint64_t *)(in+(0*63+4)*8/sizeof(in[0])); out[0*64+ 4] = (start += ((w3 >> 60) | (w4 << 4) & 0x7fffffffffffffff)) + (0*64+ 4 +1); w5 = *(uint64_t *)(in+(0*63+5)*8/sizeof(in[0])); out[0*64+ 5] = (start += ((w4 >> 59) | (w5 << 5) & 0x7fffffffffffffff)) + (0*64+ 5 +1); w6 = *(uint64_t *)(in+(0*63+6)*8/sizeof(in[0])); out[0*64+ 6] = (start += ((w5 >> 58) | (w6 << 6) & 0x7fffffffffffffff)) + (0*64+ 6 +1); w7 = *(uint64_t *)(in+(0*63+7)*8/sizeof(in[0])); out[0*64+ 7] = (start += ((w6 >> 57) | (w7 << 7) & 0x7fffffffffffffff)) + (0*64+ 7 +1); w8 = *(uint64_t *)(in+(0*63+8)*8/sizeof(in[0])); out[0*64+ 8] = (start += ((w7 >> 56) | (w8 << 8) & 0x7fffffffffffffff)) + (0*64+ 8 +1); w9 = *(uint64_t *)(in+(0*63+9)*8/sizeof(in[0])); out[0*64+ 9] = (start += ((w8 >> 55) | (w9 << 9) & 0x7fffffffffffffff)) + (0*64+ 9 +1); w10 = *(uint64_t *)(in+(0*63+10)*8/sizeof(in[0])); out[0*64+10] = (start += ((w9 >> 54) | (w10 << 10) & 0x7fffffffffffffff)) + (0*64+10 +1); w11 = *(uint64_t *)(in+(0*63+11)*8/sizeof(in[0])); out[0*64+11] = (start += ((w10 >> 53) | (w11 << 11) & 0x7fffffffffffffff)) + (0*64+11 +1); w12 = *(uint64_t *)(in+(0*63+12)*8/sizeof(in[0])); out[0*64+12] = (start += ((w11 >> 52) | (w12 << 12) & 0x7fffffffffffffff)) + (0*64+12 +1); w13 = *(uint64_t *)(in+(0*63+13)*8/sizeof(in[0])); out[0*64+13] = (start += ((w12 >> 51) | (w13 << 13) & 0x7fffffffffffffff)) + (0*64+13 +1); w14 = *(uint64_t *)(in+(0*63+14)*8/sizeof(in[0])); out[0*64+14] = (start += ((w13 >> 50) | (w14 << 14) & 0x7fffffffffffffff)) + (0*64+14 +1); w15 = *(uint64_t *)(in+(0*63+15)*8/sizeof(in[0])); out[0*64+15] = (start += ((w14 >> 49) | (w15 << 15) & 0x7fffffffffffffff)) + (0*64+15 +1); w16 = *(uint64_t *)(in+(0*63+16)*8/sizeof(in[0])); out[0*64+16] = (start += ((w15 >> 48) | (w16 << 16) & 0x7fffffffffffffff)) + (0*64+16 +1); w17 = *(uint64_t *)(in+(0*63+17)*8/sizeof(in[0])); out[0*64+17] = (start += ((w16 >> 47) | (w17 << 17) & 0x7fffffffffffffff)) + (0*64+17 +1); w18 = *(uint64_t *)(in+(0*63+18)*8/sizeof(in[0])); out[0*64+18] = (start += ((w17 >> 46) | (w18 << 18) & 0x7fffffffffffffff)) + (0*64+18 +1); w19 = *(uint64_t *)(in+(0*63+19)*8/sizeof(in[0])); out[0*64+19] = (start += ((w18 >> 45) | (w19 << 19) & 0x7fffffffffffffff)) + (0*64+19 +1); w20 = *(uint64_t *)(in+(0*63+20)*8/sizeof(in[0])); out[0*64+20] = (start += ((w19 >> 44) | (w20 << 20) & 0x7fffffffffffffff)) + (0*64+20 +1); w21 = *(uint64_t *)(in+(0*63+21)*8/sizeof(in[0])); out[0*64+21] = (start += ((w20 >> 43) | (w21 << 21) & 0x7fffffffffffffff)) + (0*64+21 +1); w22 = *(uint64_t *)(in+(0*63+22)*8/sizeof(in[0])); out[0*64+22] = (start += ((w21 >> 42) | (w22 << 22) & 0x7fffffffffffffff)) + (0*64+22 +1); w23 = *(uint64_t *)(in+(0*63+23)*8/sizeof(in[0])); out[0*64+23] = (start += ((w22 >> 41) | (w23 << 23) & 0x7fffffffffffffff)) + (0*64+23 +1); w24 = *(uint64_t *)(in+(0*63+24)*8/sizeof(in[0])); out[0*64+24] = (start += ((w23 >> 40) | (w24 << 24) & 0x7fffffffffffffff)) + (0*64+24 +1); w25 = *(uint64_t *)(in+(0*63+25)*8/sizeof(in[0])); out[0*64+25] = (start += ((w24 >> 39) | (w25 << 25) & 0x7fffffffffffffff)) + (0*64+25 +1); w26 = *(uint64_t *)(in+(0*63+26)*8/sizeof(in[0])); out[0*64+26] = (start += ((w25 >> 38) | (w26 << 26) & 0x7fffffffffffffff)) + (0*64+26 +1); w27 = *(uint64_t *)(in+(0*63+27)*8/sizeof(in[0])); out[0*64+27] = (start += ((w26 >> 37) | (w27 << 27) & 0x7fffffffffffffff)) + (0*64+27 +1); w28 = *(uint64_t *)(in+(0*63+28)*8/sizeof(in[0])); out[0*64+28] = (start += ((w27 >> 36) | (w28 << 28) & 0x7fffffffffffffff)) + (0*64+28 +1); w29 = *(uint64_t *)(in+(0*63+29)*8/sizeof(in[0])); out[0*64+29] = (start += ((w28 >> 35) | (w29 << 29) & 0x7fffffffffffffff)) + (0*64+29 +1); w30 = *(uint64_t *)(in+(0*63+30)*8/sizeof(in[0])); out[0*64+30] = (start += ((w29 >> 34) | (w30 << 30) & 0x7fffffffffffffff)) + (0*64+30 +1); w31 = *(uint32_t *)(in+(0*63+31)*8/sizeof(in[0])); out[0*64+31] = (start += ((w30 >> 33) | (w31 << 31) & 0x7fffffffffffffff)) + (0*64+31 +1);;}; out += 32; start += 32; in += 63*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitd1unpack64_64(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*64)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*1+ 0] = (start += ((w0 ))) + (0*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*1+ 0] = (start += ((w0 ))) + (1*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*1+ 0] = (start += ((w0 ))) + (2*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*1+ 0] = (start += ((w0 ))) + (3*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(4*1+0)*8/sizeof(in[0])); out[4*1+ 0] = (start += ((w0 ))) + (4*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(5*1+0)*8/sizeof(in[0])); out[5*1+ 0] = (start += ((w0 ))) + (5*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(6*1+0)*8/sizeof(in[0])); out[6*1+ 0] = (start += ((w0 ))) + (6*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(7*1+0)*8/sizeof(in[0])); out[7*1+ 0] = (start += ((w0 ))) + (7*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(8*1+0)*8/sizeof(in[0])); out[8*1+ 0] = (start += ((w0 ))) + (8*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(9*1+0)*8/sizeof(in[0])); out[9*1+ 0] = (start += ((w0 ))) + (9*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(10*1+0)*8/sizeof(in[0])); out[10*1+ 0] = (start += ((w0 ))) + (10*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(11*1+0)*8/sizeof(in[0])); out[11*1+ 0] = (start += ((w0 ))) + (11*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(12*1+0)*8/sizeof(in[0])); out[12*1+ 0] = (start += ((w0 ))) + (12*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(13*1+0)*8/sizeof(in[0])); out[13*1+ 0] = (start += ((w0 ))) + (13*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(14*1+0)*8/sizeof(in[0])); out[14*1+ 0] = (start += ((w0 ))) + (14*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(15*1+0)*8/sizeof(in[0])); out[15*1+ 0] = (start += ((w0 ))) + (15*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(16*1+0)*8/sizeof(in[0])); out[16*1+ 0] = (start += ((w0 ))) + (16*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(17*1+0)*8/sizeof(in[0])); out[17*1+ 0] = (start += ((w0 ))) + (17*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(18*1+0)*8/sizeof(in[0])); out[18*1+ 0] = (start += ((w0 ))) + (18*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(19*1+0)*8/sizeof(in[0])); out[19*1+ 0] = (start += ((w0 ))) + (19*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(20*1+0)*8/sizeof(in[0])); out[20*1+ 0] = (start += ((w0 ))) + (20*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(21*1+0)*8/sizeof(in[0])); out[21*1+ 0] = (start += ((w0 ))) + (21*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(22*1+0)*8/sizeof(in[0])); out[22*1+ 0] = (start += ((w0 ))) + (22*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(23*1+0)*8/sizeof(in[0])); out[23*1+ 0] = (start += ((w0 ))) + (23*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(24*1+0)*8/sizeof(in[0])); out[24*1+ 0] = (start += ((w0 ))) + (24*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(25*1+0)*8/sizeof(in[0])); out[25*1+ 0] = (start += ((w0 ))) + (25*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(26*1+0)*8/sizeof(in[0])); out[26*1+ 0] = (start += ((w0 ))) + (26*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(27*1+0)*8/sizeof(in[0])); out[27*1+ 0] = (start += ((w0 ))) + (27*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(28*1+0)*8/sizeof(in[0])); out[28*1+ 0] = (start += ((w0 ))) + (28*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(29*1+0)*8/sizeof(in[0])); out[29*1+ 0] = (start += ((w0 ))) + (29*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(30*1+0)*8/sizeof(in[0])); out[30*1+ 0] = (start += ((w0 ))) + (30*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(31*1+0)*8/sizeof(in[0])); out[31*1+ 0] = (start += ((w0 ))) + (31*1+ 0 +1);;}; out += 32; start += 32; in += 64*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D64 bitd1unpacka64[] = {
  &bitd1unpack64_0,
  &bitd1unpack64_1,
  &bitd1unpack64_2,
  &bitd1unpack64_3,
  &bitd1unpack64_4,
  &bitd1unpack64_5,
  &bitd1unpack64_6,
  &bitd1unpack64_7,
  &bitd1unpack64_8,
  &bitd1unpack64_9,
  &bitd1unpack64_10,
  &bitd1unpack64_11,
  &bitd1unpack64_12,
  &bitd1unpack64_13,
  &bitd1unpack64_14,
  &bitd1unpack64_15,
  &bitd1unpack64_16,
  &bitd1unpack64_17,
  &bitd1unpack64_18,
  &bitd1unpack64_19,
  &bitd1unpack64_20,
  &bitd1unpack64_21,
  &bitd1unpack64_22,
  &bitd1unpack64_23,
  &bitd1unpack64_24,
  &bitd1unpack64_25,
  &bitd1unpack64_26,
  &bitd1unpack64_27,
  &bitd1unpack64_28,
  &bitd1unpack64_29,
  &bitd1unpack64_30,
  &bitd1unpack64_31,
  &bitd1unpack64_32,
  &bitd1unpack64_33,
  &bitd1unpack64_34,
  &bitd1unpack64_35,
  &bitd1unpack64_36,
  &bitd1unpack64_37,
  &bitd1unpack64_38,
  &bitd1unpack64_39,
  &bitd1unpack64_40,
  &bitd1unpack64_41,
  &bitd1unpack64_42,
  &bitd1unpack64_43,
  &bitd1unpack64_44,
  &bitd1unpack64_45,
  &bitd1unpack64_46,
  &bitd1unpack64_47,
  &bitd1unpack64_48,
  &bitd1unpack64_49,
  &bitd1unpack64_50,
  &bitd1unpack64_51,
  &bitd1unpack64_52,
  &bitd1unpack64_53,
  &bitd1unpack64_54,
  &bitd1unpack64_55,
  &bitd1unpack64_56,
  &bitd1unpack64_57,
  &bitd1unpack64_58,
  &bitd1unpack64_59,
  &bitd1unpack64_60,
  &bitd1unpack64_61,
  &bitd1unpack64_62,
  &bitd1unpack64_63,
  &bitd1unpack64_64
};
unsigned char *bitd1unpack64( const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start, unsigned b) { return bitd1unpacka64[ b](in, n, out, start); }
unsigned char *bitf1unpack8_0(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint8_t *out_ = out+n; do { { { out[0*0+ 0] = start + (0)+(0*0+ 0 +1); out[0*0+ 1] = start + (0)+(0*0+ 1 +1); out[0*0+ 2] = start + (0)+(0*0+ 2 +1); out[0*0+ 3] = start + (0)+(0*0+ 3 +1); out[0*0+ 4] = start + (0)+(0*0+ 4 +1); out[0*0+ 5] = start + (0)+(0*0+ 5 +1); out[0*0+ 6] = start + (0)+(0*0+ 6 +1); out[0*0+ 7] = start + (0)+(0*0+ 7 +1); out[0*0+ 8] = start + (0)+(0*0+ 8 +1); out[0*0+ 9] = start + (0)+(0*0+ 9 +1); out[0*0+10] = start + (0)+(0*0+10 +1); out[0*0+11] = start + (0)+(0*0+11 +1); out[0*0+12] = start + (0)+(0*0+12 +1); out[0*0+13] = start + (0)+(0*0+13 +1); out[0*0+14] = start + (0)+(0*0+14 +1); out[0*0+15] = start + (0)+(0*0+15 +1); out[0*0+16] = start + (0)+(0*0+16 +1); out[0*0+17] = start + (0)+(0*0+17 +1); out[0*0+18] = start + (0)+(0*0+18 +1); out[0*0+19] = start + (0)+(0*0+19 +1); out[0*0+20] = start + (0)+(0*0+20 +1); out[0*0+21] = start + (0)+(0*0+21 +1); out[0*0+22] = start + (0)+(0*0+22 +1); out[0*0+23] = start + (0)+(0*0+23 +1); out[0*0+24] = start + (0)+(0*0+24 +1); out[0*0+25] = start + (0)+(0*0+25 +1); out[0*0+26] = start + (0)+(0*0+26 +1); out[0*0+27] = start + (0)+(0*0+27 +1); out[0*0+28] = start + (0)+(0*0+28 +1); out[0*0+29] = start + (0)+(0*0+29 +1); out[0*0+30] = start + (0)+(0*0+30 +1); out[0*0+31] = start + (0)+(0*0+31 +1);;}; out += 32; start += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitf1unpack8_1(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x1)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 1) & 0x1)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 2) & 0x1)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 3) & 0x1)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 4) & 0x1)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 5) & 0x1)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w0 >> 6) & 0x1)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w0 >> 7) & 0x1)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w0 >> 8) & 0x1)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w0 >> 9) & 0x1)+(0*32+ 9 +1); out[0*32+10] = start + ((w0 >> 10) & 0x1)+(0*32+10 +1); out[0*32+11] = start + ((w0 >> 11) & 0x1)+(0*32+11 +1); out[0*32+12] = start + ((w0 >> 12) & 0x1)+(0*32+12 +1); out[0*32+13] = start + ((w0 >> 13) & 0x1)+(0*32+13 +1); out[0*32+14] = start + ((w0 >> 14) & 0x1)+(0*32+14 +1); out[0*32+15] = start + ((w0 >> 15) & 0x1)+(0*32+15 +1); out[0*32+16] = start + ((w0 >> 16) & 0x1)+(0*32+16 +1); out[0*32+17] = start + ((w0 >> 17) & 0x1)+(0*32+17 +1); out[0*32+18] = start + ((w0 >> 18) & 0x1)+(0*32+18 +1); out[0*32+19] = start + ((w0 >> 19) & 0x1)+(0*32+19 +1); out[0*32+20] = start + ((w0 >> 20) & 0x1)+(0*32+20 +1); out[0*32+21] = start + ((w0 >> 21) & 0x1)+(0*32+21 +1); out[0*32+22] = start + ((w0 >> 22) & 0x1)+(0*32+22 +1); out[0*32+23] = start + ((w0 >> 23) & 0x1)+(0*32+23 +1); out[0*32+24] = start + ((w0 >> 24) & 0x1)+(0*32+24 +1); out[0*32+25] = start + ((w0 >> 25) & 0x1)+(0*32+25 +1); out[0*32+26] = start + ((w0 >> 26) & 0x1)+(0*32+26 +1); out[0*32+27] = start + ((w0 >> 27) & 0x1)+(0*32+27 +1); out[0*32+28] = start + ((w0 >> 28) & 0x1)+(0*32+28 +1); out[0*32+29] = start + ((w0 >> 29) & 0x1)+(0*32+29 +1); out[0*32+30] = start + ((w0 >> 30) & 0x1)+(0*32+30 +1); out[0*32+31] = start + ((w0 >> 31))+(0*32+31 +1);;}; out += 32; start += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack8_2(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 2) & 0x3)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 4) & 0x3)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 6) & 0x3)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 8) & 0x3)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 10) & 0x3)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w0 >> 12) & 0x3)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w0 >> 14) & 0x3)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w0 >> 16) & 0x3)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w0 >> 18) & 0x3)+(0*32+ 9 +1); out[0*32+10] = start + ((w0 >> 20) & 0x3)+(0*32+10 +1); out[0*32+11] = start + ((w0 >> 22) & 0x3)+(0*32+11 +1); out[0*32+12] = start + ((w0 >> 24) & 0x3)+(0*32+12 +1); out[0*32+13] = start + ((w0 >> 26) & 0x3)+(0*32+13 +1); out[0*32+14] = start + ((w0 >> 28) & 0x3)+(0*32+14 +1); out[0*32+15] = start + ((w0 >> 30) & 0x3)+(0*32+15 +1); out[0*32+16] = start + ((w0 >> 32) & 0x3)+(0*32+16 +1); out[0*32+17] = start + ((w0 >> 34) & 0x3)+(0*32+17 +1); out[0*32+18] = start + ((w0 >> 36) & 0x3)+(0*32+18 +1); out[0*32+19] = start + ((w0 >> 38) & 0x3)+(0*32+19 +1); out[0*32+20] = start + ((w0 >> 40) & 0x3)+(0*32+20 +1); out[0*32+21] = start + ((w0 >> 42) & 0x3)+(0*32+21 +1); out[0*32+22] = start + ((w0 >> 44) & 0x3)+(0*32+22 +1); out[0*32+23] = start + ((w0 >> 46) & 0x3)+(0*32+23 +1); out[0*32+24] = start + ((w0 >> 48) & 0x3)+(0*32+24 +1); out[0*32+25] = start + ((w0 >> 50) & 0x3)+(0*32+25 +1); out[0*32+26] = start + ((w0 >> 52) & 0x3)+(0*32+26 +1); out[0*32+27] = start + ((w0 >> 54) & 0x3)+(0*32+27 +1); out[0*32+28] = start + ((w0 >> 56) & 0x3)+(0*32+28 +1); out[0*32+29] = start + ((w0 >> 58) & 0x3)+(0*32+29 +1); out[0*32+30] = start + ((w0 >> 60) & 0x3)+(0*32+30 +1); out[0*32+31] = start + ((w0 >> 62))+(0*32+31 +1);;}; out += 32; start += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack8_3(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 3) & 0x7)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 6) & 0x7)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 9) & 0x7)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 12) & 0x7)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 15) & 0x7)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 18) & 0x7)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w0 >> 21) & 0x7)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w0 >> 24) & 0x7)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w0 >> 27) & 0x7)+(0*64+ 9 +1); out[0*64+10] = start + ((w0 >> 30) & 0x7)+(0*64+10 +1); out[0*64+11] = start + ((w0 >> 33) & 0x7)+(0*64+11 +1); out[0*64+12] = start + ((w0 >> 36) & 0x7)+(0*64+12 +1); out[0*64+13] = start + ((w0 >> 39) & 0x7)+(0*64+13 +1); out[0*64+14] = start + ((w0 >> 42) & 0x7)+(0*64+14 +1); out[0*64+15] = start + ((w0 >> 45) & 0x7)+(0*64+15 +1); out[0*64+16] = start + ((w0 >> 48) & 0x7)+(0*64+16 +1); out[0*64+17] = start + ((w0 >> 51) & 0x7)+(0*64+17 +1); out[0*64+18] = start + ((w0 >> 54) & 0x7)+(0*64+18 +1); out[0*64+19] = start + ((w0 >> 57) & 0x7)+(0*64+19 +1); out[0*64+20] = start + ((w0 >> 60) & 0x7)+(0*64+20 +1); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = start + ((w0 >> 63) | (w1 << 1) & 0x7)+(0*64+21 +1); out[0*64+22] = start + ((w1 >> 2) & 0x7)+(0*64+22 +1); out[0*64+23] = start + ((w1 >> 5) & 0x7)+(0*64+23 +1); out[0*64+24] = start + ((w1 >> 8) & 0x7)+(0*64+24 +1); out[0*64+25] = start + ((w1 >> 11) & 0x7)+(0*64+25 +1); out[0*64+26] = start + ((w1 >> 14) & 0x7)+(0*64+26 +1); out[0*64+27] = start + ((w1 >> 17) & 0x7)+(0*64+27 +1); out[0*64+28] = start + ((w1 >> 20) & 0x7)+(0*64+28 +1); out[0*64+29] = start + ((w1 >> 23) & 0x7)+(0*64+29 +1); out[0*64+30] = start + ((w1 >> 26) & 0x7)+(0*64+30 +1); out[0*64+31] = start + ((w1 >> 29) & 0x7)+(0*64+31 +1);;}; out += 32; start += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack8_4(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xf)+(0*16+ 0 +1); out[0*16+ 1] = start + ((w0 >> 4) & 0xf)+(0*16+ 1 +1); out[0*16+ 2] = start + ((w0 >> 8) & 0xf)+(0*16+ 2 +1); out[0*16+ 3] = start + ((w0 >> 12) & 0xf)+(0*16+ 3 +1); out[0*16+ 4] = start + ((w0 >> 16) & 0xf)+(0*16+ 4 +1); out[0*16+ 5] = start + ((w0 >> 20) & 0xf)+(0*16+ 5 +1); out[0*16+ 6] = start + ((w0 >> 24) & 0xf)+(0*16+ 6 +1); out[0*16+ 7] = start + ((w0 >> 28) & 0xf)+(0*16+ 7 +1); out[0*16+ 8] = start + ((w0 >> 32) & 0xf)+(0*16+ 8 +1); out[0*16+ 9] = start + ((w0 >> 36) & 0xf)+(0*16+ 9 +1); out[0*16+10] = start + ((w0 >> 40) & 0xf)+(0*16+10 +1); out[0*16+11] = start + ((w0 >> 44) & 0xf)+(0*16+11 +1); out[0*16+12] = start + ((w0 >> 48) & 0xf)+(0*16+12 +1); out[0*16+13] = start + ((w0 >> 52) & 0xf)+(0*16+13 +1); out[0*16+14] = start + ((w0 >> 56) & 0xf)+(0*16+14 +1); out[0*16+15] = start + ((w0 >> 60))+(0*16+15 +1);;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xf)+(1*16+ 0 +1); out[1*16+ 1] = start + ((w0 >> 4) & 0xf)+(1*16+ 1 +1); out[1*16+ 2] = start + ((w0 >> 8) & 0xf)+(1*16+ 2 +1); out[1*16+ 3] = start + ((w0 >> 12) & 0xf)+(1*16+ 3 +1); out[1*16+ 4] = start + ((w0 >> 16) & 0xf)+(1*16+ 4 +1); out[1*16+ 5] = start + ((w0 >> 20) & 0xf)+(1*16+ 5 +1); out[1*16+ 6] = start + ((w0 >> 24) & 0xf)+(1*16+ 6 +1); out[1*16+ 7] = start + ((w0 >> 28) & 0xf)+(1*16+ 7 +1); out[1*16+ 8] = start + ((w0 >> 32) & 0xf)+(1*16+ 8 +1); out[1*16+ 9] = start + ((w0 >> 36) & 0xf)+(1*16+ 9 +1); out[1*16+10] = start + ((w0 >> 40) & 0xf)+(1*16+10 +1); out[1*16+11] = start + ((w0 >> 44) & 0xf)+(1*16+11 +1); out[1*16+12] = start + ((w0 >> 48) & 0xf)+(1*16+12 +1); out[1*16+13] = start + ((w0 >> 52) & 0xf)+(1*16+13 +1); out[1*16+14] = start + ((w0 >> 56) & 0xf)+(1*16+14 +1); out[1*16+15] = start + ((w0 >> 60))+(1*16+15 +1);;}; out += 32; start += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack8_5(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1f)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 5) & 0x1f)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 10) & 0x1f)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 15) & 0x1f)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 20) & 0x1f)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 25) & 0x1f)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 30) & 0x1f)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w0 >> 35) & 0x1f)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w0 >> 40) & 0x1f)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w0 >> 45) & 0x1f)+(0*64+ 9 +1); out[0*64+10] = start + ((w0 >> 50) & 0x1f)+(0*64+10 +1); out[0*64+11] = start + ((w0 >> 55) & 0x1f)+(0*64+11 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = start + ((w0 >> 60) | (w1 << 4) & 0x1f)+(0*64+12 +1); out[0*64+13] = start + ((w1 >> 1) & 0x1f)+(0*64+13 +1); out[0*64+14] = start + ((w1 >> 6) & 0x1f)+(0*64+14 +1); out[0*64+15] = start + ((w1 >> 11) & 0x1f)+(0*64+15 +1); out[0*64+16] = start + ((w1 >> 16) & 0x1f)+(0*64+16 +1); out[0*64+17] = start + ((w1 >> 21) & 0x1f)+(0*64+17 +1); out[0*64+18] = start + ((w1 >> 26) & 0x1f)+(0*64+18 +1); out[0*64+19] = start + ((w1 >> 31) & 0x1f)+(0*64+19 +1); out[0*64+20] = start + ((w1 >> 36) & 0x1f)+(0*64+20 +1); out[0*64+21] = start + ((w1 >> 41) & 0x1f)+(0*64+21 +1); out[0*64+22] = start + ((w1 >> 46) & 0x1f)+(0*64+22 +1); out[0*64+23] = start + ((w1 >> 51) & 0x1f)+(0*64+23 +1); out[0*64+24] = start + ((w1 >> 56) & 0x1f)+(0*64+24 +1); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = start + ((w1 >> 61) | (w2 << 3) & 0x1f)+(0*64+25 +1); out[0*64+26] = start + ((w2 >> 2) & 0x1f)+(0*64+26 +1); out[0*64+27] = start + ((w2 >> 7) & 0x1f)+(0*64+27 +1); out[0*64+28] = start + ((w2 >> 12) & 0x1f)+(0*64+28 +1); out[0*64+29] = start + ((w2 >> 17) & 0x1f)+(0*64+29 +1); out[0*64+30] = start + ((w2 >> 22) & 0x1f)+(0*64+30 +1); out[0*64+31] = start + ((w2 >> 27) & 0x1f)+(0*64+31 +1);;}; out += 32; start += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack8_6(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3f)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 6) & 0x3f)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 12) & 0x3f)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 18) & 0x3f)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 24) & 0x3f)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 30) & 0x3f)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w0 >> 36) & 0x3f)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w0 >> 42) & 0x3f)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w0 >> 48) & 0x3f)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w0 >> 54) & 0x3f)+(0*32+ 9 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = start + ((w0 >> 60) | (w1 << 4) & 0x3f)+(0*32+10 +1); out[0*32+11] = start + ((w1 >> 2) & 0x3f)+(0*32+11 +1); out[0*32+12] = start + ((w1 >> 8) & 0x3f)+(0*32+12 +1); out[0*32+13] = start + ((w1 >> 14) & 0x3f)+(0*32+13 +1); out[0*32+14] = start + ((w1 >> 20) & 0x3f)+(0*32+14 +1); out[0*32+15] = start + ((w1 >> 26) & 0x3f)+(0*32+15 +1); out[0*32+16] = start + ((w1 >> 32) & 0x3f)+(0*32+16 +1); out[0*32+17] = start + ((w1 >> 38) & 0x3f)+(0*32+17 +1); out[0*32+18] = start + ((w1 >> 44) & 0x3f)+(0*32+18 +1); out[0*32+19] = start + ((w1 >> 50) & 0x3f)+(0*32+19 +1); out[0*32+20] = start + ((w1 >> 56) & 0x3f)+(0*32+20 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = start + ((w1 >> 62) | (w2 << 2) & 0x3f)+(0*32+21 +1); out[0*32+22] = start + ((w2 >> 4) & 0x3f)+(0*32+22 +1); out[0*32+23] = start + ((w2 >> 10) & 0x3f)+(0*32+23 +1); out[0*32+24] = start + ((w2 >> 16) & 0x3f)+(0*32+24 +1); out[0*32+25] = start + ((w2 >> 22) & 0x3f)+(0*32+25 +1); out[0*32+26] = start + ((w2 >> 28) & 0x3f)+(0*32+26 +1); out[0*32+27] = start + ((w2 >> 34) & 0x3f)+(0*32+27 +1); out[0*32+28] = start + ((w2 >> 40) & 0x3f)+(0*32+28 +1); out[0*32+29] = start + ((w2 >> 46) & 0x3f)+(0*32+29 +1); out[0*32+30] = start + ((w2 >> 52) & 0x3f)+(0*32+30 +1); out[0*32+31] = start + ((w2 >> 58))+(0*32+31 +1);;}; out += 32; start += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack8_7(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7f)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 7) & 0x7f)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 14) & 0x7f)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 21) & 0x7f)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 28) & 0x7f)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 35) & 0x7f)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 42) & 0x7f)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w0 >> 49) & 0x7f)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w0 >> 56) & 0x7f)+(0*64+ 8 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w0 >> 63) | (w1 << 1) & 0x7f)+(0*64+ 9 +1); out[0*64+10] = start + ((w1 >> 6) & 0x7f)+(0*64+10 +1); out[0*64+11] = start + ((w1 >> 13) & 0x7f)+(0*64+11 +1); out[0*64+12] = start + ((w1 >> 20) & 0x7f)+(0*64+12 +1); out[0*64+13] = start + ((w1 >> 27) & 0x7f)+(0*64+13 +1); out[0*64+14] = start + ((w1 >> 34) & 0x7f)+(0*64+14 +1); out[0*64+15] = start + ((w1 >> 41) & 0x7f)+(0*64+15 +1); out[0*64+16] = start + ((w1 >> 48) & 0x7f)+(0*64+16 +1); out[0*64+17] = start + ((w1 >> 55) & 0x7f)+(0*64+17 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = start + ((w1 >> 62) | (w2 << 2) & 0x7f)+(0*64+18 +1); out[0*64+19] = start + ((w2 >> 5) & 0x7f)+(0*64+19 +1); out[0*64+20] = start + ((w2 >> 12) & 0x7f)+(0*64+20 +1); out[0*64+21] = start + ((w2 >> 19) & 0x7f)+(0*64+21 +1); out[0*64+22] = start + ((w2 >> 26) & 0x7f)+(0*64+22 +1); out[0*64+23] = start + ((w2 >> 33) & 0x7f)+(0*64+23 +1); out[0*64+24] = start + ((w2 >> 40) & 0x7f)+(0*64+24 +1); out[0*64+25] = start + ((w2 >> 47) & 0x7f)+(0*64+25 +1); out[0*64+26] = start + ((w2 >> 54) & 0x7f)+(0*64+26 +1); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = start + ((w2 >> 61) | (w3 << 3) & 0x7f)+(0*64+27 +1); out[0*64+28] = start + ((w3 >> 4) & 0x7f)+(0*64+28 +1); out[0*64+29] = start + ((w3 >> 11) & 0x7f)+(0*64+29 +1); out[0*64+30] = start + ((w3 >> 18) & 0x7f)+(0*64+30 +1); out[0*64+31] = start + ((w3 >> 25) & 0x7f)+(0*64+31 +1);;}; out += 32; start += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack8_8(const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = start + ((w0 ) & 0xff)+(0*8+ 0 +1); out[0*8+ 1] = start + ((w0 >> 8) & 0xff)+(0*8+ 1 +1); out[0*8+ 2] = start + ((w0 >> 16) & 0xff)+(0*8+ 2 +1); out[0*8+ 3] = start + ((w0 >> 24) & 0xff)+(0*8+ 3 +1); out[0*8+ 4] = start + ((w0 >> 32) & 0xff)+(0*8+ 4 +1); out[0*8+ 5] = start + ((w0 >> 40) & 0xff)+(0*8+ 5 +1); out[0*8+ 6] = start + ((w0 >> 48) & 0xff)+(0*8+ 6 +1); out[0*8+ 7] = start + ((w0 >> 56))+(0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = start + ((w0 ) & 0xff)+(1*8+ 0 +1); out[1*8+ 1] = start + ((w0 >> 8) & 0xff)+(1*8+ 1 +1); out[1*8+ 2] = start + ((w0 >> 16) & 0xff)+(1*8+ 2 +1); out[1*8+ 3] = start + ((w0 >> 24) & 0xff)+(1*8+ 3 +1); out[1*8+ 4] = start + ((w0 >> 32) & 0xff)+(1*8+ 4 +1); out[1*8+ 5] = start + ((w0 >> 40) & 0xff)+(1*8+ 5 +1); out[1*8+ 6] = start + ((w0 >> 48) & 0xff)+(1*8+ 6 +1); out[1*8+ 7] = start + ((w0 >> 56))+(1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = start + ((w0 ) & 0xff)+(2*8+ 0 +1); out[2*8+ 1] = start + ((w0 >> 8) & 0xff)+(2*8+ 1 +1); out[2*8+ 2] = start + ((w0 >> 16) & 0xff)+(2*8+ 2 +1); out[2*8+ 3] = start + ((w0 >> 24) & 0xff)+(2*8+ 3 +1); out[2*8+ 4] = start + ((w0 >> 32) & 0xff)+(2*8+ 4 +1); out[2*8+ 5] = start + ((w0 >> 40) & 0xff)+(2*8+ 5 +1); out[2*8+ 6] = start + ((w0 >> 48) & 0xff)+(2*8+ 6 +1); out[2*8+ 7] = start + ((w0 >> 56))+(2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = start + ((w0 ) & 0xff)+(3*8+ 0 +1); out[3*8+ 1] = start + ((w0 >> 8) & 0xff)+(3*8+ 1 +1); out[3*8+ 2] = start + ((w0 >> 16) & 0xff)+(3*8+ 2 +1); out[3*8+ 3] = start + ((w0 >> 24) & 0xff)+(3*8+ 3 +1); out[3*8+ 4] = start + ((w0 >> 32) & 0xff)+(3*8+ 4 +1); out[3*8+ 5] = start + ((w0 >> 40) & 0xff)+(3*8+ 5 +1); out[3*8+ 6] = start + ((w0 >> 48) & 0xff)+(3*8+ 6 +1); out[3*8+ 7] = start + ((w0 >> 56))+(3*8+ 7 +1);;}; out += 32; start += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D8 bitf1unpacka8[] = {
  &bitf1unpack8_0,
  &bitf1unpack8_1,
  &bitf1unpack8_2,
  &bitf1unpack8_3,
  &bitf1unpack8_4,
  &bitf1unpack8_5,
  &bitf1unpack8_6,
  &bitf1unpack8_7,
  &bitf1unpack8_8
};
unsigned char *bitf1unpack8( const unsigned char *__restrict in, unsigned n, uint8_t *__restrict out , uint8_t start, unsigned b) { return bitf1unpacka8[ b](in, n, out, start); }
unsigned char *bitf1unpack16_0(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint16_t *out_ = out+n; do { { { out[0*0+ 0] = start + (0)+(0*0+ 0 +1); out[0*0+ 1] = start + (0)+(0*0+ 1 +1); out[0*0+ 2] = start + (0)+(0*0+ 2 +1); out[0*0+ 3] = start + (0)+(0*0+ 3 +1); out[0*0+ 4] = start + (0)+(0*0+ 4 +1); out[0*0+ 5] = start + (0)+(0*0+ 5 +1); out[0*0+ 6] = start + (0)+(0*0+ 6 +1); out[0*0+ 7] = start + (0)+(0*0+ 7 +1); out[0*0+ 8] = start + (0)+(0*0+ 8 +1); out[0*0+ 9] = start + (0)+(0*0+ 9 +1); out[0*0+10] = start + (0)+(0*0+10 +1); out[0*0+11] = start + (0)+(0*0+11 +1); out[0*0+12] = start + (0)+(0*0+12 +1); out[0*0+13] = start + (0)+(0*0+13 +1); out[0*0+14] = start + (0)+(0*0+14 +1); out[0*0+15] = start + (0)+(0*0+15 +1); out[0*0+16] = start + (0)+(0*0+16 +1); out[0*0+17] = start + (0)+(0*0+17 +1); out[0*0+18] = start + (0)+(0*0+18 +1); out[0*0+19] = start + (0)+(0*0+19 +1); out[0*0+20] = start + (0)+(0*0+20 +1); out[0*0+21] = start + (0)+(0*0+21 +1); out[0*0+22] = start + (0)+(0*0+22 +1); out[0*0+23] = start + (0)+(0*0+23 +1); out[0*0+24] = start + (0)+(0*0+24 +1); out[0*0+25] = start + (0)+(0*0+25 +1); out[0*0+26] = start + (0)+(0*0+26 +1); out[0*0+27] = start + (0)+(0*0+27 +1); out[0*0+28] = start + (0)+(0*0+28 +1); out[0*0+29] = start + (0)+(0*0+29 +1); out[0*0+30] = start + (0)+(0*0+30 +1); out[0*0+31] = start + (0)+(0*0+31 +1);;}; out += 32; start += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitf1unpack16_1(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x1)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 1) & 0x1)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 2) & 0x1)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 3) & 0x1)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 4) & 0x1)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 5) & 0x1)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w0 >> 6) & 0x1)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w0 >> 7) & 0x1)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w0 >> 8) & 0x1)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w0 >> 9) & 0x1)+(0*32+ 9 +1); out[0*32+10] = start + ((w0 >> 10) & 0x1)+(0*32+10 +1); out[0*32+11] = start + ((w0 >> 11) & 0x1)+(0*32+11 +1); out[0*32+12] = start + ((w0 >> 12) & 0x1)+(0*32+12 +1); out[0*32+13] = start + ((w0 >> 13) & 0x1)+(0*32+13 +1); out[0*32+14] = start + ((w0 >> 14) & 0x1)+(0*32+14 +1); out[0*32+15] = start + ((w0 >> 15) & 0x1)+(0*32+15 +1); out[0*32+16] = start + ((w0 >> 16) & 0x1)+(0*32+16 +1); out[0*32+17] = start + ((w0 >> 17) & 0x1)+(0*32+17 +1); out[0*32+18] = start + ((w0 >> 18) & 0x1)+(0*32+18 +1); out[0*32+19] = start + ((w0 >> 19) & 0x1)+(0*32+19 +1); out[0*32+20] = start + ((w0 >> 20) & 0x1)+(0*32+20 +1); out[0*32+21] = start + ((w0 >> 21) & 0x1)+(0*32+21 +1); out[0*32+22] = start + ((w0 >> 22) & 0x1)+(0*32+22 +1); out[0*32+23] = start + ((w0 >> 23) & 0x1)+(0*32+23 +1); out[0*32+24] = start + ((w0 >> 24) & 0x1)+(0*32+24 +1); out[0*32+25] = start + ((w0 >> 25) & 0x1)+(0*32+25 +1); out[0*32+26] = start + ((w0 >> 26) & 0x1)+(0*32+26 +1); out[0*32+27] = start + ((w0 >> 27) & 0x1)+(0*32+27 +1); out[0*32+28] = start + ((w0 >> 28) & 0x1)+(0*32+28 +1); out[0*32+29] = start + ((w0 >> 29) & 0x1)+(0*32+29 +1); out[0*32+30] = start + ((w0 >> 30) & 0x1)+(0*32+30 +1); out[0*32+31] = start + ((w0 >> 31))+(0*32+31 +1);;}; out += 32; start += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_2(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 2) & 0x3)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 4) & 0x3)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 6) & 0x3)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 8) & 0x3)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 10) & 0x3)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w0 >> 12) & 0x3)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w0 >> 14) & 0x3)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w0 >> 16) & 0x3)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w0 >> 18) & 0x3)+(0*32+ 9 +1); out[0*32+10] = start + ((w0 >> 20) & 0x3)+(0*32+10 +1); out[0*32+11] = start + ((w0 >> 22) & 0x3)+(0*32+11 +1); out[0*32+12] = start + ((w0 >> 24) & 0x3)+(0*32+12 +1); out[0*32+13] = start + ((w0 >> 26) & 0x3)+(0*32+13 +1); out[0*32+14] = start + ((w0 >> 28) & 0x3)+(0*32+14 +1); out[0*32+15] = start + ((w0 >> 30) & 0x3)+(0*32+15 +1); out[0*32+16] = start + ((w0 >> 32) & 0x3)+(0*32+16 +1); out[0*32+17] = start + ((w0 >> 34) & 0x3)+(0*32+17 +1); out[0*32+18] = start + ((w0 >> 36) & 0x3)+(0*32+18 +1); out[0*32+19] = start + ((w0 >> 38) & 0x3)+(0*32+19 +1); out[0*32+20] = start + ((w0 >> 40) & 0x3)+(0*32+20 +1); out[0*32+21] = start + ((w0 >> 42) & 0x3)+(0*32+21 +1); out[0*32+22] = start + ((w0 >> 44) & 0x3)+(0*32+22 +1); out[0*32+23] = start + ((w0 >> 46) & 0x3)+(0*32+23 +1); out[0*32+24] = start + ((w0 >> 48) & 0x3)+(0*32+24 +1); out[0*32+25] = start + ((w0 >> 50) & 0x3)+(0*32+25 +1); out[0*32+26] = start + ((w0 >> 52) & 0x3)+(0*32+26 +1); out[0*32+27] = start + ((w0 >> 54) & 0x3)+(0*32+27 +1); out[0*32+28] = start + ((w0 >> 56) & 0x3)+(0*32+28 +1); out[0*32+29] = start + ((w0 >> 58) & 0x3)+(0*32+29 +1); out[0*32+30] = start + ((w0 >> 60) & 0x3)+(0*32+30 +1); out[0*32+31] = start + ((w0 >> 62))+(0*32+31 +1);;}; out += 32; start += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_3(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 3) & 0x7)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 6) & 0x7)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 9) & 0x7)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 12) & 0x7)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 15) & 0x7)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 18) & 0x7)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w0 >> 21) & 0x7)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w0 >> 24) & 0x7)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w0 >> 27) & 0x7)+(0*64+ 9 +1); out[0*64+10] = start + ((w0 >> 30) & 0x7)+(0*64+10 +1); out[0*64+11] = start + ((w0 >> 33) & 0x7)+(0*64+11 +1); out[0*64+12] = start + ((w0 >> 36) & 0x7)+(0*64+12 +1); out[0*64+13] = start + ((w0 >> 39) & 0x7)+(0*64+13 +1); out[0*64+14] = start + ((w0 >> 42) & 0x7)+(0*64+14 +1); out[0*64+15] = start + ((w0 >> 45) & 0x7)+(0*64+15 +1); out[0*64+16] = start + ((w0 >> 48) & 0x7)+(0*64+16 +1); out[0*64+17] = start + ((w0 >> 51) & 0x7)+(0*64+17 +1); out[0*64+18] = start + ((w0 >> 54) & 0x7)+(0*64+18 +1); out[0*64+19] = start + ((w0 >> 57) & 0x7)+(0*64+19 +1); out[0*64+20] = start + ((w0 >> 60) & 0x7)+(0*64+20 +1); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = start + ((w0 >> 63) | (w1 << 1) & 0x7)+(0*64+21 +1); out[0*64+22] = start + ((w1 >> 2) & 0x7)+(0*64+22 +1); out[0*64+23] = start + ((w1 >> 5) & 0x7)+(0*64+23 +1); out[0*64+24] = start + ((w1 >> 8) & 0x7)+(0*64+24 +1); out[0*64+25] = start + ((w1 >> 11) & 0x7)+(0*64+25 +1); out[0*64+26] = start + ((w1 >> 14) & 0x7)+(0*64+26 +1); out[0*64+27] = start + ((w1 >> 17) & 0x7)+(0*64+27 +1); out[0*64+28] = start + ((w1 >> 20) & 0x7)+(0*64+28 +1); out[0*64+29] = start + ((w1 >> 23) & 0x7)+(0*64+29 +1); out[0*64+30] = start + ((w1 >> 26) & 0x7)+(0*64+30 +1); out[0*64+31] = start + ((w1 >> 29) & 0x7)+(0*64+31 +1);;}; out += 32; start += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_4(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xf)+(0*16+ 0 +1); out[0*16+ 1] = start + ((w0 >> 4) & 0xf)+(0*16+ 1 +1); out[0*16+ 2] = start + ((w0 >> 8) & 0xf)+(0*16+ 2 +1); out[0*16+ 3] = start + ((w0 >> 12) & 0xf)+(0*16+ 3 +1); out[0*16+ 4] = start + ((w0 >> 16) & 0xf)+(0*16+ 4 +1); out[0*16+ 5] = start + ((w0 >> 20) & 0xf)+(0*16+ 5 +1); out[0*16+ 6] = start + ((w0 >> 24) & 0xf)+(0*16+ 6 +1); out[0*16+ 7] = start + ((w0 >> 28) & 0xf)+(0*16+ 7 +1); out[0*16+ 8] = start + ((w0 >> 32) & 0xf)+(0*16+ 8 +1); out[0*16+ 9] = start + ((w0 >> 36) & 0xf)+(0*16+ 9 +1); out[0*16+10] = start + ((w0 >> 40) & 0xf)+(0*16+10 +1); out[0*16+11] = start + ((w0 >> 44) & 0xf)+(0*16+11 +1); out[0*16+12] = start + ((w0 >> 48) & 0xf)+(0*16+12 +1); out[0*16+13] = start + ((w0 >> 52) & 0xf)+(0*16+13 +1); out[0*16+14] = start + ((w0 >> 56) & 0xf)+(0*16+14 +1); out[0*16+15] = start + ((w0 >> 60))+(0*16+15 +1);;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xf)+(1*16+ 0 +1); out[1*16+ 1] = start + ((w0 >> 4) & 0xf)+(1*16+ 1 +1); out[1*16+ 2] = start + ((w0 >> 8) & 0xf)+(1*16+ 2 +1); out[1*16+ 3] = start + ((w0 >> 12) & 0xf)+(1*16+ 3 +1); out[1*16+ 4] = start + ((w0 >> 16) & 0xf)+(1*16+ 4 +1); out[1*16+ 5] = start + ((w0 >> 20) & 0xf)+(1*16+ 5 +1); out[1*16+ 6] = start + ((w0 >> 24) & 0xf)+(1*16+ 6 +1); out[1*16+ 7] = start + ((w0 >> 28) & 0xf)+(1*16+ 7 +1); out[1*16+ 8] = start + ((w0 >> 32) & 0xf)+(1*16+ 8 +1); out[1*16+ 9] = start + ((w0 >> 36) & 0xf)+(1*16+ 9 +1); out[1*16+10] = start + ((w0 >> 40) & 0xf)+(1*16+10 +1); out[1*16+11] = start + ((w0 >> 44) & 0xf)+(1*16+11 +1); out[1*16+12] = start + ((w0 >> 48) & 0xf)+(1*16+12 +1); out[1*16+13] = start + ((w0 >> 52) & 0xf)+(1*16+13 +1); out[1*16+14] = start + ((w0 >> 56) & 0xf)+(1*16+14 +1); out[1*16+15] = start + ((w0 >> 60))+(1*16+15 +1);;}; out += 32; start += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_5(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1f)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 5) & 0x1f)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 10) & 0x1f)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 15) & 0x1f)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 20) & 0x1f)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 25) & 0x1f)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 30) & 0x1f)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w0 >> 35) & 0x1f)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w0 >> 40) & 0x1f)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w0 >> 45) & 0x1f)+(0*64+ 9 +1); out[0*64+10] = start + ((w0 >> 50) & 0x1f)+(0*64+10 +1); out[0*64+11] = start + ((w0 >> 55) & 0x1f)+(0*64+11 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = start + ((w0 >> 60) | (w1 << 4) & 0x1f)+(0*64+12 +1); out[0*64+13] = start + ((w1 >> 1) & 0x1f)+(0*64+13 +1); out[0*64+14] = start + ((w1 >> 6) & 0x1f)+(0*64+14 +1); out[0*64+15] = start + ((w1 >> 11) & 0x1f)+(0*64+15 +1); out[0*64+16] = start + ((w1 >> 16) & 0x1f)+(0*64+16 +1); out[0*64+17] = start + ((w1 >> 21) & 0x1f)+(0*64+17 +1); out[0*64+18] = start + ((w1 >> 26) & 0x1f)+(0*64+18 +1); out[0*64+19] = start + ((w1 >> 31) & 0x1f)+(0*64+19 +1); out[0*64+20] = start + ((w1 >> 36) & 0x1f)+(0*64+20 +1); out[0*64+21] = start + ((w1 >> 41) & 0x1f)+(0*64+21 +1); out[0*64+22] = start + ((w1 >> 46) & 0x1f)+(0*64+22 +1); out[0*64+23] = start + ((w1 >> 51) & 0x1f)+(0*64+23 +1); out[0*64+24] = start + ((w1 >> 56) & 0x1f)+(0*64+24 +1); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = start + ((w1 >> 61) | (w2 << 3) & 0x1f)+(0*64+25 +1); out[0*64+26] = start + ((w2 >> 2) & 0x1f)+(0*64+26 +1); out[0*64+27] = start + ((w2 >> 7) & 0x1f)+(0*64+27 +1); out[0*64+28] = start + ((w2 >> 12) & 0x1f)+(0*64+28 +1); out[0*64+29] = start + ((w2 >> 17) & 0x1f)+(0*64+29 +1); out[0*64+30] = start + ((w2 >> 22) & 0x1f)+(0*64+30 +1); out[0*64+31] = start + ((w2 >> 27) & 0x1f)+(0*64+31 +1);;}; out += 32; start += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_6(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3f)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 6) & 0x3f)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 12) & 0x3f)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 18) & 0x3f)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 24) & 0x3f)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 30) & 0x3f)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w0 >> 36) & 0x3f)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w0 >> 42) & 0x3f)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w0 >> 48) & 0x3f)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w0 >> 54) & 0x3f)+(0*32+ 9 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = start + ((w0 >> 60) | (w1 << 4) & 0x3f)+(0*32+10 +1); out[0*32+11] = start + ((w1 >> 2) & 0x3f)+(0*32+11 +1); out[0*32+12] = start + ((w1 >> 8) & 0x3f)+(0*32+12 +1); out[0*32+13] = start + ((w1 >> 14) & 0x3f)+(0*32+13 +1); out[0*32+14] = start + ((w1 >> 20) & 0x3f)+(0*32+14 +1); out[0*32+15] = start + ((w1 >> 26) & 0x3f)+(0*32+15 +1); out[0*32+16] = start + ((w1 >> 32) & 0x3f)+(0*32+16 +1); out[0*32+17] = start + ((w1 >> 38) & 0x3f)+(0*32+17 +1); out[0*32+18] = start + ((w1 >> 44) & 0x3f)+(0*32+18 +1); out[0*32+19] = start + ((w1 >> 50) & 0x3f)+(0*32+19 +1); out[0*32+20] = start + ((w1 >> 56) & 0x3f)+(0*32+20 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = start + ((w1 >> 62) | (w2 << 2) & 0x3f)+(0*32+21 +1); out[0*32+22] = start + ((w2 >> 4) & 0x3f)+(0*32+22 +1); out[0*32+23] = start + ((w2 >> 10) & 0x3f)+(0*32+23 +1); out[0*32+24] = start + ((w2 >> 16) & 0x3f)+(0*32+24 +1); out[0*32+25] = start + ((w2 >> 22) & 0x3f)+(0*32+25 +1); out[0*32+26] = start + ((w2 >> 28) & 0x3f)+(0*32+26 +1); out[0*32+27] = start + ((w2 >> 34) & 0x3f)+(0*32+27 +1); out[0*32+28] = start + ((w2 >> 40) & 0x3f)+(0*32+28 +1); out[0*32+29] = start + ((w2 >> 46) & 0x3f)+(0*32+29 +1); out[0*32+30] = start + ((w2 >> 52) & 0x3f)+(0*32+30 +1); out[0*32+31] = start + ((w2 >> 58))+(0*32+31 +1);;}; out += 32; start += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_7(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7f)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 7) & 0x7f)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 14) & 0x7f)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 21) & 0x7f)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 28) & 0x7f)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 35) & 0x7f)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 42) & 0x7f)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w0 >> 49) & 0x7f)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w0 >> 56) & 0x7f)+(0*64+ 8 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w0 >> 63) | (w1 << 1) & 0x7f)+(0*64+ 9 +1); out[0*64+10] = start + ((w1 >> 6) & 0x7f)+(0*64+10 +1); out[0*64+11] = start + ((w1 >> 13) & 0x7f)+(0*64+11 +1); out[0*64+12] = start + ((w1 >> 20) & 0x7f)+(0*64+12 +1); out[0*64+13] = start + ((w1 >> 27) & 0x7f)+(0*64+13 +1); out[0*64+14] = start + ((w1 >> 34) & 0x7f)+(0*64+14 +1); out[0*64+15] = start + ((w1 >> 41) & 0x7f)+(0*64+15 +1); out[0*64+16] = start + ((w1 >> 48) & 0x7f)+(0*64+16 +1); out[0*64+17] = start + ((w1 >> 55) & 0x7f)+(0*64+17 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = start + ((w1 >> 62) | (w2 << 2) & 0x7f)+(0*64+18 +1); out[0*64+19] = start + ((w2 >> 5) & 0x7f)+(0*64+19 +1); out[0*64+20] = start + ((w2 >> 12) & 0x7f)+(0*64+20 +1); out[0*64+21] = start + ((w2 >> 19) & 0x7f)+(0*64+21 +1); out[0*64+22] = start + ((w2 >> 26) & 0x7f)+(0*64+22 +1); out[0*64+23] = start + ((w2 >> 33) & 0x7f)+(0*64+23 +1); out[0*64+24] = start + ((w2 >> 40) & 0x7f)+(0*64+24 +1); out[0*64+25] = start + ((w2 >> 47) & 0x7f)+(0*64+25 +1); out[0*64+26] = start + ((w2 >> 54) & 0x7f)+(0*64+26 +1); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = start + ((w2 >> 61) | (w3 << 3) & 0x7f)+(0*64+27 +1); out[0*64+28] = start + ((w3 >> 4) & 0x7f)+(0*64+28 +1); out[0*64+29] = start + ((w3 >> 11) & 0x7f)+(0*64+29 +1); out[0*64+30] = start + ((w3 >> 18) & 0x7f)+(0*64+30 +1); out[0*64+31] = start + ((w3 >> 25) & 0x7f)+(0*64+31 +1);;}; out += 32; start += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_8(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = start + ((w0 ) & 0xff)+(0*8+ 0 +1); out[0*8+ 1] = start + ((w0 >> 8) & 0xff)+(0*8+ 1 +1); out[0*8+ 2] = start + ((w0 >> 16) & 0xff)+(0*8+ 2 +1); out[0*8+ 3] = start + ((w0 >> 24) & 0xff)+(0*8+ 3 +1); out[0*8+ 4] = start + ((w0 >> 32) & 0xff)+(0*8+ 4 +1); out[0*8+ 5] = start + ((w0 >> 40) & 0xff)+(0*8+ 5 +1); out[0*8+ 6] = start + ((w0 >> 48) & 0xff)+(0*8+ 6 +1); out[0*8+ 7] = start + ((w0 >> 56))+(0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = start + ((w0 ) & 0xff)+(1*8+ 0 +1); out[1*8+ 1] = start + ((w0 >> 8) & 0xff)+(1*8+ 1 +1); out[1*8+ 2] = start + ((w0 >> 16) & 0xff)+(1*8+ 2 +1); out[1*8+ 3] = start + ((w0 >> 24) & 0xff)+(1*8+ 3 +1); out[1*8+ 4] = start + ((w0 >> 32) & 0xff)+(1*8+ 4 +1); out[1*8+ 5] = start + ((w0 >> 40) & 0xff)+(1*8+ 5 +1); out[1*8+ 6] = start + ((w0 >> 48) & 0xff)+(1*8+ 6 +1); out[1*8+ 7] = start + ((w0 >> 56))+(1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = start + ((w0 ) & 0xff)+(2*8+ 0 +1); out[2*8+ 1] = start + ((w0 >> 8) & 0xff)+(2*8+ 1 +1); out[2*8+ 2] = start + ((w0 >> 16) & 0xff)+(2*8+ 2 +1); out[2*8+ 3] = start + ((w0 >> 24) & 0xff)+(2*8+ 3 +1); out[2*8+ 4] = start + ((w0 >> 32) & 0xff)+(2*8+ 4 +1); out[2*8+ 5] = start + ((w0 >> 40) & 0xff)+(2*8+ 5 +1); out[2*8+ 6] = start + ((w0 >> 48) & 0xff)+(2*8+ 6 +1); out[2*8+ 7] = start + ((w0 >> 56))+(2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = start + ((w0 ) & 0xff)+(3*8+ 0 +1); out[3*8+ 1] = start + ((w0 >> 8) & 0xff)+(3*8+ 1 +1); out[3*8+ 2] = start + ((w0 >> 16) & 0xff)+(3*8+ 2 +1); out[3*8+ 3] = start + ((w0 >> 24) & 0xff)+(3*8+ 3 +1); out[3*8+ 4] = start + ((w0 >> 32) & 0xff)+(3*8+ 4 +1); out[3*8+ 5] = start + ((w0 >> 40) & 0xff)+(3*8+ 5 +1); out[3*8+ 6] = start + ((w0 >> 48) & 0xff)+(3*8+ 6 +1); out[3*8+ 7] = start + ((w0 >> 56))+(3*8+ 7 +1);;}; out += 32; start += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_9(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1ff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 9) & 0x1ff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 18) & 0x1ff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 27) & 0x1ff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 36) & 0x1ff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 45) & 0x1ff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 54) & 0x1ff)+(0*64+ 6 +1); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w0 >> 63) | (w1 << 1) & 0x1ff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w1 >> 8) & 0x1ff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w1 >> 17) & 0x1ff)+(0*64+ 9 +1); out[0*64+10] = start + ((w1 >> 26) & 0x1ff)+(0*64+10 +1); out[0*64+11] = start + ((w1 >> 35) & 0x1ff)+(0*64+11 +1); out[0*64+12] = start + ((w1 >> 44) & 0x1ff)+(0*64+12 +1); out[0*64+13] = start + ((w1 >> 53) & 0x1ff)+(0*64+13 +1); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = start + ((w1 >> 62) | (w2 << 2) & 0x1ff)+(0*64+14 +1); out[0*64+15] = start + ((w2 >> 7) & 0x1ff)+(0*64+15 +1); out[0*64+16] = start + ((w2 >> 16) & 0x1ff)+(0*64+16 +1); out[0*64+17] = start + ((w2 >> 25) & 0x1ff)+(0*64+17 +1); out[0*64+18] = start + ((w2 >> 34) & 0x1ff)+(0*64+18 +1); out[0*64+19] = start + ((w2 >> 43) & 0x1ff)+(0*64+19 +1); out[0*64+20] = start + ((w2 >> 52) & 0x1ff)+(0*64+20 +1); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = start + ((w2 >> 61) | (w3 << 3) & 0x1ff)+(0*64+21 +1); out[0*64+22] = start + ((w3 >> 6) & 0x1ff)+(0*64+22 +1); out[0*64+23] = start + ((w3 >> 15) & 0x1ff)+(0*64+23 +1); out[0*64+24] = start + ((w3 >> 24) & 0x1ff)+(0*64+24 +1); out[0*64+25] = start + ((w3 >> 33) & 0x1ff)+(0*64+25 +1); out[0*64+26] = start + ((w3 >> 42) & 0x1ff)+(0*64+26 +1); out[0*64+27] = start + ((w3 >> 51) & 0x1ff)+(0*64+27 +1); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = start + ((w3 >> 60) | (w4 << 4) & 0x1ff)+(0*64+28 +1); out[0*64+29] = start + ((w4 >> 5) & 0x1ff)+(0*64+29 +1); out[0*64+30] = start + ((w4 >> 14) & 0x1ff)+(0*64+30 +1); out[0*64+31] = start + ((w4 >> 23) & 0x1ff)+(0*64+31 +1);;}; out += 32; start += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_10(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3ff)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 10) & 0x3ff)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 20) & 0x3ff)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 30) & 0x3ff)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 40) & 0x3ff)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 50) & 0x3ff)+(0*32+ 5 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = start + ((w0 >> 60) | (w1 << 4) & 0x3ff)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w1 >> 6) & 0x3ff)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w1 >> 16) & 0x3ff)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w1 >> 26) & 0x3ff)+(0*32+ 9 +1); out[0*32+10] = start + ((w1 >> 36) & 0x3ff)+(0*32+10 +1); out[0*32+11] = start + ((w1 >> 46) & 0x3ff)+(0*32+11 +1); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = start + ((w1 >> 56) | (w2 << 8) & 0x3ff)+(0*32+12 +1); out[0*32+13] = start + ((w2 >> 2) & 0x3ff)+(0*32+13 +1); out[0*32+14] = start + ((w2 >> 12) & 0x3ff)+(0*32+14 +1); out[0*32+15] = start + ((w2 >> 22) & 0x3ff)+(0*32+15 +1); out[0*32+16] = start + ((w2 >> 32) & 0x3ff)+(0*32+16 +1); out[0*32+17] = start + ((w2 >> 42) & 0x3ff)+(0*32+17 +1); out[0*32+18] = start + ((w2 >> 52) & 0x3ff)+(0*32+18 +1); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = start + ((w2 >> 62) | (w3 << 2) & 0x3ff)+(0*32+19 +1); out[0*32+20] = start + ((w3 >> 8) & 0x3ff)+(0*32+20 +1); out[0*32+21] = start + ((w3 >> 18) & 0x3ff)+(0*32+21 +1); out[0*32+22] = start + ((w3 >> 28) & 0x3ff)+(0*32+22 +1); out[0*32+23] = start + ((w3 >> 38) & 0x3ff)+(0*32+23 +1); out[0*32+24] = start + ((w3 >> 48) & 0x3ff)+(0*32+24 +1); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = start + ((w3 >> 58) | (w4 << 6) & 0x3ff)+(0*32+25 +1); out[0*32+26] = start + ((w4 >> 4) & 0x3ff)+(0*32+26 +1); out[0*32+27] = start + ((w4 >> 14) & 0x3ff)+(0*32+27 +1); out[0*32+28] = start + ((w4 >> 24) & 0x3ff)+(0*32+28 +1); out[0*32+29] = start + ((w4 >> 34) & 0x3ff)+(0*32+29 +1); out[0*32+30] = start + ((w4 >> 44) & 0x3ff)+(0*32+30 +1); out[0*32+31] = start + ((w4 >> 54))+(0*32+31 +1);;}; out += 32; start += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_11(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7ff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 11) & 0x7ff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 22) & 0x7ff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 33) & 0x7ff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 44) & 0x7ff)+(0*64+ 4 +1); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w0 >> 55) | (w1 << 9) & 0x7ff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w1 >> 2) & 0x7ff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w1 >> 13) & 0x7ff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w1 >> 24) & 0x7ff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w1 >> 35) & 0x7ff)+(0*64+ 9 +1); out[0*64+10] = start + ((w1 >> 46) & 0x7ff)+(0*64+10 +1); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = start + ((w1 >> 57) | (w2 << 7) & 0x7ff)+(0*64+11 +1); out[0*64+12] = start + ((w2 >> 4) & 0x7ff)+(0*64+12 +1); out[0*64+13] = start + ((w2 >> 15) & 0x7ff)+(0*64+13 +1); out[0*64+14] = start + ((w2 >> 26) & 0x7ff)+(0*64+14 +1); out[0*64+15] = start + ((w2 >> 37) & 0x7ff)+(0*64+15 +1); out[0*64+16] = start + ((w2 >> 48) & 0x7ff)+(0*64+16 +1); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = start + ((w2 >> 59) | (w3 << 5) & 0x7ff)+(0*64+17 +1); out[0*64+18] = start + ((w3 >> 6) & 0x7ff)+(0*64+18 +1); out[0*64+19] = start + ((w3 >> 17) & 0x7ff)+(0*64+19 +1); out[0*64+20] = start + ((w3 >> 28) & 0x7ff)+(0*64+20 +1); out[0*64+21] = start + ((w3 >> 39) & 0x7ff)+(0*64+21 +1); out[0*64+22] = start + ((w3 >> 50) & 0x7ff)+(0*64+22 +1); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = start + ((w3 >> 61) | (w4 << 3) & 0x7ff)+(0*64+23 +1); out[0*64+24] = start + ((w4 >> 8) & 0x7ff)+(0*64+24 +1); out[0*64+25] = start + ((w4 >> 19) & 0x7ff)+(0*64+25 +1); out[0*64+26] = start + ((w4 >> 30) & 0x7ff)+(0*64+26 +1); out[0*64+27] = start + ((w4 >> 41) & 0x7ff)+(0*64+27 +1); out[0*64+28] = start + ((w4 >> 52) & 0x7ff)+(0*64+28 +1); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = start + ((w4 >> 63) | (w5 << 1) & 0x7ff)+(0*64+29 +1); out[0*64+30] = start + ((w5 >> 10) & 0x7ff)+(0*64+30 +1); out[0*64+31] = start + ((w5 >> 21) & 0x7ff)+(0*64+31 +1);;}; out += 32; start += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_12(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xfff)+(0*16+ 0 +1); out[0*16+ 1] = start + ((w0 >> 12) & 0xfff)+(0*16+ 1 +1); out[0*16+ 2] = start + ((w0 >> 24) & 0xfff)+(0*16+ 2 +1); out[0*16+ 3] = start + ((w0 >> 36) & 0xfff)+(0*16+ 3 +1); out[0*16+ 4] = start + ((w0 >> 48) & 0xfff)+(0*16+ 4 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = start + ((w0 >> 60) | (w1 << 4) & 0xfff)+(0*16+ 5 +1); out[0*16+ 6] = start + ((w1 >> 8) & 0xfff)+(0*16+ 6 +1); out[0*16+ 7] = start + ((w1 >> 20) & 0xfff)+(0*16+ 7 +1); out[0*16+ 8] = start + ((w1 >> 32) & 0xfff)+(0*16+ 8 +1); out[0*16+ 9] = start + ((w1 >> 44) & 0xfff)+(0*16+ 9 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = start + ((w1 >> 56) | (w2 << 8) & 0xfff)+(0*16+10 +1); out[0*16+11] = start + ((w2 >> 4) & 0xfff)+(0*16+11 +1); out[0*16+12] = start + ((w2 >> 16) & 0xfff)+(0*16+12 +1); out[0*16+13] = start + ((w2 >> 28) & 0xfff)+(0*16+13 +1); out[0*16+14] = start + ((w2 >> 40) & 0xfff)+(0*16+14 +1); out[0*16+15] = start + ((w2 >> 52))+(0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xfff)+(1*16+ 0 +1); out[1*16+ 1] = start + ((w0 >> 12) & 0xfff)+(1*16+ 1 +1); out[1*16+ 2] = start + ((w0 >> 24) & 0xfff)+(1*16+ 2 +1); out[1*16+ 3] = start + ((w0 >> 36) & 0xfff)+(1*16+ 3 +1); out[1*16+ 4] = start + ((w0 >> 48) & 0xfff)+(1*16+ 4 +1); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = start + ((w0 >> 60) | (w1 << 4) & 0xfff)+(1*16+ 5 +1); out[1*16+ 6] = start + ((w1 >> 8) & 0xfff)+(1*16+ 6 +1); out[1*16+ 7] = start + ((w1 >> 20) & 0xfff)+(1*16+ 7 +1); out[1*16+ 8] = start + ((w1 >> 32) & 0xfff)+(1*16+ 8 +1); out[1*16+ 9] = start + ((w1 >> 44) & 0xfff)+(1*16+ 9 +1); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = start + ((w1 >> 56) | (w2 << 8) & 0xfff)+(1*16+10 +1); out[1*16+11] = start + ((w2 >> 4) & 0xfff)+(1*16+11 +1); out[1*16+12] = start + ((w2 >> 16) & 0xfff)+(1*16+12 +1); out[1*16+13] = start + ((w2 >> 28) & 0xfff)+(1*16+13 +1); out[1*16+14] = start + ((w2 >> 40) & 0xfff)+(1*16+14 +1); out[1*16+15] = start + ((w2 >> 52))+(1*16+15 +1);;}; out += 32; start += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_13(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1fff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 13) & 0x1fff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 26) & 0x1fff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 39) & 0x1fff)+(0*64+ 3 +1); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w0 >> 52) | (w1 << 12) & 0x1fff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w1 >> 1) & 0x1fff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w1 >> 14) & 0x1fff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w1 >> 27) & 0x1fff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w1 >> 40) & 0x1fff)+(0*64+ 8 +1); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w1 >> 53) | (w2 << 11) & 0x1fff)+(0*64+ 9 +1); out[0*64+10] = start + ((w2 >> 2) & 0x1fff)+(0*64+10 +1); out[0*64+11] = start + ((w2 >> 15) & 0x1fff)+(0*64+11 +1); out[0*64+12] = start + ((w2 >> 28) & 0x1fff)+(0*64+12 +1); out[0*64+13] = start + ((w2 >> 41) & 0x1fff)+(0*64+13 +1); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = start + ((w2 >> 54) | (w3 << 10) & 0x1fff)+(0*64+14 +1); out[0*64+15] = start + ((w3 >> 3) & 0x1fff)+(0*64+15 +1); out[0*64+16] = start + ((w3 >> 16) & 0x1fff)+(0*64+16 +1); out[0*64+17] = start + ((w3 >> 29) & 0x1fff)+(0*64+17 +1); out[0*64+18] = start + ((w3 >> 42) & 0x1fff)+(0*64+18 +1); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = start + ((w3 >> 55) | (w4 << 9) & 0x1fff)+(0*64+19 +1); out[0*64+20] = start + ((w4 >> 4) & 0x1fff)+(0*64+20 +1); out[0*64+21] = start + ((w4 >> 17) & 0x1fff)+(0*64+21 +1); out[0*64+22] = start + ((w4 >> 30) & 0x1fff)+(0*64+22 +1); out[0*64+23] = start + ((w4 >> 43) & 0x1fff)+(0*64+23 +1); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = start + ((w4 >> 56) | (w5 << 8) & 0x1fff)+(0*64+24 +1); out[0*64+25] = start + ((w5 >> 5) & 0x1fff)+(0*64+25 +1); out[0*64+26] = start + ((w5 >> 18) & 0x1fff)+(0*64+26 +1); out[0*64+27] = start + ((w5 >> 31) & 0x1fff)+(0*64+27 +1); out[0*64+28] = start + ((w5 >> 44) & 0x1fff)+(0*64+28 +1); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = start + ((w5 >> 57) | (w6 << 7) & 0x1fff)+(0*64+29 +1); out[0*64+30] = start + ((w6 >> 6) & 0x1fff)+(0*64+30 +1); out[0*64+31] = start + ((w6 >> 19) & 0x1fff)+(0*64+31 +1);;}; out += 32; start += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_14(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3fff)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 14) & 0x3fff)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 28) & 0x3fff)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 42) & 0x3fff)+(0*32+ 3 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = start + ((w0 >> 56) | (w1 << 8) & 0x3fff)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w1 >> 6) & 0x3fff)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w1 >> 20) & 0x3fff)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w1 >> 34) & 0x3fff)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w1 >> 48) & 0x3fff)+(0*32+ 8 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = start + ((w1 >> 62) | (w2 << 2) & 0x3fff)+(0*32+ 9 +1); out[0*32+10] = start + ((w2 >> 12) & 0x3fff)+(0*32+10 +1); out[0*32+11] = start + ((w2 >> 26) & 0x3fff)+(0*32+11 +1); out[0*32+12] = start + ((w2 >> 40) & 0x3fff)+(0*32+12 +1); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = start + ((w2 >> 54) | (w3 << 10) & 0x3fff)+(0*32+13 +1); out[0*32+14] = start + ((w3 >> 4) & 0x3fff)+(0*32+14 +1); out[0*32+15] = start + ((w3 >> 18) & 0x3fff)+(0*32+15 +1); out[0*32+16] = start + ((w3 >> 32) & 0x3fff)+(0*32+16 +1); out[0*32+17] = start + ((w3 >> 46) & 0x3fff)+(0*32+17 +1); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = start + ((w3 >> 60) | (w4 << 4) & 0x3fff)+(0*32+18 +1); out[0*32+19] = start + ((w4 >> 10) & 0x3fff)+(0*32+19 +1); out[0*32+20] = start + ((w4 >> 24) & 0x3fff)+(0*32+20 +1); out[0*32+21] = start + ((w4 >> 38) & 0x3fff)+(0*32+21 +1); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = start + ((w4 >> 52) | (w5 << 12) & 0x3fff)+(0*32+22 +1); out[0*32+23] = start + ((w5 >> 2) & 0x3fff)+(0*32+23 +1); out[0*32+24] = start + ((w5 >> 16) & 0x3fff)+(0*32+24 +1); out[0*32+25] = start + ((w5 >> 30) & 0x3fff)+(0*32+25 +1); out[0*32+26] = start + ((w5 >> 44) & 0x3fff)+(0*32+26 +1); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = start + ((w5 >> 58) | (w6 << 6) & 0x3fff)+(0*32+27 +1); out[0*32+28] = start + ((w6 >> 8) & 0x3fff)+(0*32+28 +1); out[0*32+29] = start + ((w6 >> 22) & 0x3fff)+(0*32+29 +1); out[0*32+30] = start + ((w6 >> 36) & 0x3fff)+(0*32+30 +1); out[0*32+31] = start + ((w6 >> 50))+(0*32+31 +1);;}; out += 32; start += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_15(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7fff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 15) & 0x7fff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 30) & 0x7fff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 45) & 0x7fff)+(0*64+ 3 +1); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w0 >> 60) | (w1 << 4) & 0x7fff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w1 >> 11) & 0x7fff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w1 >> 26) & 0x7fff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w1 >> 41) & 0x7fff)+(0*64+ 7 +1); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w1 >> 56) | (w2 << 8) & 0x7fff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w2 >> 7) & 0x7fff)+(0*64+ 9 +1); out[0*64+10] = start + ((w2 >> 22) & 0x7fff)+(0*64+10 +1); out[0*64+11] = start + ((w2 >> 37) & 0x7fff)+(0*64+11 +1); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = start + ((w2 >> 52) | (w3 << 12) & 0x7fff)+(0*64+12 +1); out[0*64+13] = start + ((w3 >> 3) & 0x7fff)+(0*64+13 +1); out[0*64+14] = start + ((w3 >> 18) & 0x7fff)+(0*64+14 +1); out[0*64+15] = start + ((w3 >> 33) & 0x7fff)+(0*64+15 +1); out[0*64+16] = start + ((w3 >> 48) & 0x7fff)+(0*64+16 +1); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = start + ((w3 >> 63) | (w4 << 1) & 0x7fff)+(0*64+17 +1); out[0*64+18] = start + ((w4 >> 14) & 0x7fff)+(0*64+18 +1); out[0*64+19] = start + ((w4 >> 29) & 0x7fff)+(0*64+19 +1); out[0*64+20] = start + ((w4 >> 44) & 0x7fff)+(0*64+20 +1); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = start + ((w4 >> 59) | (w5 << 5) & 0x7fff)+(0*64+21 +1); out[0*64+22] = start + ((w5 >> 10) & 0x7fff)+(0*64+22 +1); out[0*64+23] = start + ((w5 >> 25) & 0x7fff)+(0*64+23 +1); out[0*64+24] = start + ((w5 >> 40) & 0x7fff)+(0*64+24 +1); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = start + ((w5 >> 55) | (w6 << 9) & 0x7fff)+(0*64+25 +1); out[0*64+26] = start + ((w6 >> 6) & 0x7fff)+(0*64+26 +1); out[0*64+27] = start + ((w6 >> 21) & 0x7fff)+(0*64+27 +1); out[0*64+28] = start + ((w6 >> 36) & 0x7fff)+(0*64+28 +1); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = start + ((w6 >> 51) | (w7 << 13) & 0x7fff)+(0*64+29 +1); out[0*64+30] = start + ((w7 >> 2) & 0x7fff)+(0*64+30 +1); out[0*64+31] = start + ((w7 >> 17) & 0x7fff)+(0*64+31 +1);;}; out += 32; start += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack16_16(const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = start + (*(uint16_t *)(in+0*8+ 0))+(0*4+ 0 +1); out[0*4+ 1] = start + (*(uint16_t *)(in+0*8+ 2))+(0*4+ 1 +1); out[0*4+ 2] = start + (*(uint16_t *)(in+0*8+ 4))+(0*4+ 2 +1); out[0*4+ 3] = start + (*(uint16_t *)(in+0*8+ 6))+(0*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = start + (*(uint16_t *)(in+1*8+ 0))+(1*4+ 0 +1); out[1*4+ 1] = start + (*(uint16_t *)(in+1*8+ 2))+(1*4+ 1 +1); out[1*4+ 2] = start + (*(uint16_t *)(in+1*8+ 4))+(1*4+ 2 +1); out[1*4+ 3] = start + (*(uint16_t *)(in+1*8+ 6))+(1*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = start + (*(uint16_t *)(in+2*8+ 0))+(2*4+ 0 +1); out[2*4+ 1] = start + (*(uint16_t *)(in+2*8+ 2))+(2*4+ 1 +1); out[2*4+ 2] = start + (*(uint16_t *)(in+2*8+ 4))+(2*4+ 2 +1); out[2*4+ 3] = start + (*(uint16_t *)(in+2*8+ 6))+(2*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = start + (*(uint16_t *)(in+3*8+ 0))+(3*4+ 0 +1); out[3*4+ 1] = start + (*(uint16_t *)(in+3*8+ 2))+(3*4+ 1 +1); out[3*4+ 2] = start + (*(uint16_t *)(in+3*8+ 4))+(3*4+ 2 +1); out[3*4+ 3] = start + (*(uint16_t *)(in+3*8+ 6))+(3*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = start + (*(uint16_t *)(in+4*8+ 0))+(4*4+ 0 +1); out[4*4+ 1] = start + (*(uint16_t *)(in+4*8+ 2))+(4*4+ 1 +1); out[4*4+ 2] = start + (*(uint16_t *)(in+4*8+ 4))+(4*4+ 2 +1); out[4*4+ 3] = start + (*(uint16_t *)(in+4*8+ 6))+(4*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = start + (*(uint16_t *)(in+5*8+ 0))+(5*4+ 0 +1); out[5*4+ 1] = start + (*(uint16_t *)(in+5*8+ 2))+(5*4+ 1 +1); out[5*4+ 2] = start + (*(uint16_t *)(in+5*8+ 4))+(5*4+ 2 +1); out[5*4+ 3] = start + (*(uint16_t *)(in+5*8+ 6))+(5*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = start + (*(uint16_t *)(in+6*8+ 0))+(6*4+ 0 +1); out[6*4+ 1] = start + (*(uint16_t *)(in+6*8+ 2))+(6*4+ 1 +1); out[6*4+ 2] = start + (*(uint16_t *)(in+6*8+ 4))+(6*4+ 2 +1); out[6*4+ 3] = start + (*(uint16_t *)(in+6*8+ 6))+(6*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = start + (*(uint16_t *)(in+7*8+ 0))+(7*4+ 0 +1); out[7*4+ 1] = start + (*(uint16_t *)(in+7*8+ 2))+(7*4+ 1 +1); out[7*4+ 2] = start + (*(uint16_t *)(in+7*8+ 4))+(7*4+ 2 +1); out[7*4+ 3] = start + (*(uint16_t *)(in+7*8+ 6))+(7*4+ 3 +1);;}; out += 32; start += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D16 bitf1unpacka16[] = {
  &bitf1unpack16_0,
  &bitf1unpack16_1,
  &bitf1unpack16_2,
  &bitf1unpack16_3,
  &bitf1unpack16_4,
  &bitf1unpack16_5,
  &bitf1unpack16_6,
  &bitf1unpack16_7,
  &bitf1unpack16_8,
  &bitf1unpack16_9,
  &bitf1unpack16_10,
  &bitf1unpack16_11,
  &bitf1unpack16_12,
  &bitf1unpack16_13,
  &bitf1unpack16_14,
  &bitf1unpack16_15,
  &bitf1unpack16_16
};
unsigned char *bitf1unpack16( const unsigned char *__restrict in, unsigned n, uint16_t *__restrict out , uint16_t start, unsigned b) { return bitf1unpacka16[ b](in, n, out, start); }
unsigned char *bitf1unpack32_0(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint32_t *out_ = out+n; do { { { out[0*0+ 0] = start + (0)+(0*0+ 0 +1); out[0*0+ 1] = start + (0)+(0*0+ 1 +1); out[0*0+ 2] = start + (0)+(0*0+ 2 +1); out[0*0+ 3] = start + (0)+(0*0+ 3 +1); out[0*0+ 4] = start + (0)+(0*0+ 4 +1); out[0*0+ 5] = start + (0)+(0*0+ 5 +1); out[0*0+ 6] = start + (0)+(0*0+ 6 +1); out[0*0+ 7] = start + (0)+(0*0+ 7 +1); out[0*0+ 8] = start + (0)+(0*0+ 8 +1); out[0*0+ 9] = start + (0)+(0*0+ 9 +1); out[0*0+10] = start + (0)+(0*0+10 +1); out[0*0+11] = start + (0)+(0*0+11 +1); out[0*0+12] = start + (0)+(0*0+12 +1); out[0*0+13] = start + (0)+(0*0+13 +1); out[0*0+14] = start + (0)+(0*0+14 +1); out[0*0+15] = start + (0)+(0*0+15 +1); out[0*0+16] = start + (0)+(0*0+16 +1); out[0*0+17] = start + (0)+(0*0+17 +1); out[0*0+18] = start + (0)+(0*0+18 +1); out[0*0+19] = start + (0)+(0*0+19 +1); out[0*0+20] = start + (0)+(0*0+20 +1); out[0*0+21] = start + (0)+(0*0+21 +1); out[0*0+22] = start + (0)+(0*0+22 +1); out[0*0+23] = start + (0)+(0*0+23 +1); out[0*0+24] = start + (0)+(0*0+24 +1); out[0*0+25] = start + (0)+(0*0+25 +1); out[0*0+26] = start + (0)+(0*0+26 +1); out[0*0+27] = start + (0)+(0*0+27 +1); out[0*0+28] = start + (0)+(0*0+28 +1); out[0*0+29] = start + (0)+(0*0+29 +1); out[0*0+30] = start + (0)+(0*0+30 +1); out[0*0+31] = start + (0)+(0*0+31 +1);;}; out += 32; start += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitf1unpack32_1(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x1)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 1) & 0x1)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 2) & 0x1)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 3) & 0x1)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 4) & 0x1)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 5) & 0x1)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w0 >> 6) & 0x1)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w0 >> 7) & 0x1)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w0 >> 8) & 0x1)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w0 >> 9) & 0x1)+(0*32+ 9 +1); out[0*32+10] = start + ((w0 >> 10) & 0x1)+(0*32+10 +1); out[0*32+11] = start + ((w0 >> 11) & 0x1)+(0*32+11 +1); out[0*32+12] = start + ((w0 >> 12) & 0x1)+(0*32+12 +1); out[0*32+13] = start + ((w0 >> 13) & 0x1)+(0*32+13 +1); out[0*32+14] = start + ((w0 >> 14) & 0x1)+(0*32+14 +1); out[0*32+15] = start + ((w0 >> 15) & 0x1)+(0*32+15 +1); out[0*32+16] = start + ((w0 >> 16) & 0x1)+(0*32+16 +1); out[0*32+17] = start + ((w0 >> 17) & 0x1)+(0*32+17 +1); out[0*32+18] = start + ((w0 >> 18) & 0x1)+(0*32+18 +1); out[0*32+19] = start + ((w0 >> 19) & 0x1)+(0*32+19 +1); out[0*32+20] = start + ((w0 >> 20) & 0x1)+(0*32+20 +1); out[0*32+21] = start + ((w0 >> 21) & 0x1)+(0*32+21 +1); out[0*32+22] = start + ((w0 >> 22) & 0x1)+(0*32+22 +1); out[0*32+23] = start + ((w0 >> 23) & 0x1)+(0*32+23 +1); out[0*32+24] = start + ((w0 >> 24) & 0x1)+(0*32+24 +1); out[0*32+25] = start + ((w0 >> 25) & 0x1)+(0*32+25 +1); out[0*32+26] = start + ((w0 >> 26) & 0x1)+(0*32+26 +1); out[0*32+27] = start + ((w0 >> 27) & 0x1)+(0*32+27 +1); out[0*32+28] = start + ((w0 >> 28) & 0x1)+(0*32+28 +1); out[0*32+29] = start + ((w0 >> 29) & 0x1)+(0*32+29 +1); out[0*32+30] = start + ((w0 >> 30) & 0x1)+(0*32+30 +1); out[0*32+31] = start + ((w0 >> 31))+(0*32+31 +1);;}; out += 32; start += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_2(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 2) & 0x3)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 4) & 0x3)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 6) & 0x3)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 8) & 0x3)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 10) & 0x3)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w0 >> 12) & 0x3)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w0 >> 14) & 0x3)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w0 >> 16) & 0x3)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w0 >> 18) & 0x3)+(0*32+ 9 +1); out[0*32+10] = start + ((w0 >> 20) & 0x3)+(0*32+10 +1); out[0*32+11] = start + ((w0 >> 22) & 0x3)+(0*32+11 +1); out[0*32+12] = start + ((w0 >> 24) & 0x3)+(0*32+12 +1); out[0*32+13] = start + ((w0 >> 26) & 0x3)+(0*32+13 +1); out[0*32+14] = start + ((w0 >> 28) & 0x3)+(0*32+14 +1); out[0*32+15] = start + ((w0 >> 30) & 0x3)+(0*32+15 +1); out[0*32+16] = start + ((w0 >> 32) & 0x3)+(0*32+16 +1); out[0*32+17] = start + ((w0 >> 34) & 0x3)+(0*32+17 +1); out[0*32+18] = start + ((w0 >> 36) & 0x3)+(0*32+18 +1); out[0*32+19] = start + ((w0 >> 38) & 0x3)+(0*32+19 +1); out[0*32+20] = start + ((w0 >> 40) & 0x3)+(0*32+20 +1); out[0*32+21] = start + ((w0 >> 42) & 0x3)+(0*32+21 +1); out[0*32+22] = start + ((w0 >> 44) & 0x3)+(0*32+22 +1); out[0*32+23] = start + ((w0 >> 46) & 0x3)+(0*32+23 +1); out[0*32+24] = start + ((w0 >> 48) & 0x3)+(0*32+24 +1); out[0*32+25] = start + ((w0 >> 50) & 0x3)+(0*32+25 +1); out[0*32+26] = start + ((w0 >> 52) & 0x3)+(0*32+26 +1); out[0*32+27] = start + ((w0 >> 54) & 0x3)+(0*32+27 +1); out[0*32+28] = start + ((w0 >> 56) & 0x3)+(0*32+28 +1); out[0*32+29] = start + ((w0 >> 58) & 0x3)+(0*32+29 +1); out[0*32+30] = start + ((w0 >> 60) & 0x3)+(0*32+30 +1); out[0*32+31] = start + ((w0 >> 62))+(0*32+31 +1);;}; out += 32; start += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_3(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 3) & 0x7)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 6) & 0x7)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 9) & 0x7)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 12) & 0x7)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 15) & 0x7)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 18) & 0x7)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w0 >> 21) & 0x7)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w0 >> 24) & 0x7)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w0 >> 27) & 0x7)+(0*64+ 9 +1); out[0*64+10] = start + ((w0 >> 30) & 0x7)+(0*64+10 +1); out[0*64+11] = start + ((w0 >> 33) & 0x7)+(0*64+11 +1); out[0*64+12] = start + ((w0 >> 36) & 0x7)+(0*64+12 +1); out[0*64+13] = start + ((w0 >> 39) & 0x7)+(0*64+13 +1); out[0*64+14] = start + ((w0 >> 42) & 0x7)+(0*64+14 +1); out[0*64+15] = start + ((w0 >> 45) & 0x7)+(0*64+15 +1); out[0*64+16] = start + ((w0 >> 48) & 0x7)+(0*64+16 +1); out[0*64+17] = start + ((w0 >> 51) & 0x7)+(0*64+17 +1); out[0*64+18] = start + ((w0 >> 54) & 0x7)+(0*64+18 +1); out[0*64+19] = start + ((w0 >> 57) & 0x7)+(0*64+19 +1); out[0*64+20] = start + ((w0 >> 60) & 0x7)+(0*64+20 +1); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = start + ((w0 >> 63) | (w1 << 1) & 0x7)+(0*64+21 +1); out[0*64+22] = start + ((w1 >> 2) & 0x7)+(0*64+22 +1); out[0*64+23] = start + ((w1 >> 5) & 0x7)+(0*64+23 +1); out[0*64+24] = start + ((w1 >> 8) & 0x7)+(0*64+24 +1); out[0*64+25] = start + ((w1 >> 11) & 0x7)+(0*64+25 +1); out[0*64+26] = start + ((w1 >> 14) & 0x7)+(0*64+26 +1); out[0*64+27] = start + ((w1 >> 17) & 0x7)+(0*64+27 +1); out[0*64+28] = start + ((w1 >> 20) & 0x7)+(0*64+28 +1); out[0*64+29] = start + ((w1 >> 23) & 0x7)+(0*64+29 +1); out[0*64+30] = start + ((w1 >> 26) & 0x7)+(0*64+30 +1); out[0*64+31] = start + ((w1 >> 29) & 0x7)+(0*64+31 +1);;}; out += 32; start += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_4(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xf)+(0*16+ 0 +1); out[0*16+ 1] = start + ((w0 >> 4) & 0xf)+(0*16+ 1 +1); out[0*16+ 2] = start + ((w0 >> 8) & 0xf)+(0*16+ 2 +1); out[0*16+ 3] = start + ((w0 >> 12) & 0xf)+(0*16+ 3 +1); out[0*16+ 4] = start + ((w0 >> 16) & 0xf)+(0*16+ 4 +1); out[0*16+ 5] = start + ((w0 >> 20) & 0xf)+(0*16+ 5 +1); out[0*16+ 6] = start + ((w0 >> 24) & 0xf)+(0*16+ 6 +1); out[0*16+ 7] = start + ((w0 >> 28) & 0xf)+(0*16+ 7 +1); out[0*16+ 8] = start + ((w0 >> 32) & 0xf)+(0*16+ 8 +1); out[0*16+ 9] = start + ((w0 >> 36) & 0xf)+(0*16+ 9 +1); out[0*16+10] = start + ((w0 >> 40) & 0xf)+(0*16+10 +1); out[0*16+11] = start + ((w0 >> 44) & 0xf)+(0*16+11 +1); out[0*16+12] = start + ((w0 >> 48) & 0xf)+(0*16+12 +1); out[0*16+13] = start + ((w0 >> 52) & 0xf)+(0*16+13 +1); out[0*16+14] = start + ((w0 >> 56) & 0xf)+(0*16+14 +1); out[0*16+15] = start + ((w0 >> 60))+(0*16+15 +1);;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xf)+(1*16+ 0 +1); out[1*16+ 1] = start + ((w0 >> 4) & 0xf)+(1*16+ 1 +1); out[1*16+ 2] = start + ((w0 >> 8) & 0xf)+(1*16+ 2 +1); out[1*16+ 3] = start + ((w0 >> 12) & 0xf)+(1*16+ 3 +1); out[1*16+ 4] = start + ((w0 >> 16) & 0xf)+(1*16+ 4 +1); out[1*16+ 5] = start + ((w0 >> 20) & 0xf)+(1*16+ 5 +1); out[1*16+ 6] = start + ((w0 >> 24) & 0xf)+(1*16+ 6 +1); out[1*16+ 7] = start + ((w0 >> 28) & 0xf)+(1*16+ 7 +1); out[1*16+ 8] = start + ((w0 >> 32) & 0xf)+(1*16+ 8 +1); out[1*16+ 9] = start + ((w0 >> 36) & 0xf)+(1*16+ 9 +1); out[1*16+10] = start + ((w0 >> 40) & 0xf)+(1*16+10 +1); out[1*16+11] = start + ((w0 >> 44) & 0xf)+(1*16+11 +1); out[1*16+12] = start + ((w0 >> 48) & 0xf)+(1*16+12 +1); out[1*16+13] = start + ((w0 >> 52) & 0xf)+(1*16+13 +1); out[1*16+14] = start + ((w0 >> 56) & 0xf)+(1*16+14 +1); out[1*16+15] = start + ((w0 >> 60))+(1*16+15 +1);;}; out += 32; start += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_5(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1f)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 5) & 0x1f)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 10) & 0x1f)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 15) & 0x1f)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 20) & 0x1f)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 25) & 0x1f)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 30) & 0x1f)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w0 >> 35) & 0x1f)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w0 >> 40) & 0x1f)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w0 >> 45) & 0x1f)+(0*64+ 9 +1); out[0*64+10] = start + ((w0 >> 50) & 0x1f)+(0*64+10 +1); out[0*64+11] = start + ((w0 >> 55) & 0x1f)+(0*64+11 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = start + ((w0 >> 60) | (w1 << 4) & 0x1f)+(0*64+12 +1); out[0*64+13] = start + ((w1 >> 1) & 0x1f)+(0*64+13 +1); out[0*64+14] = start + ((w1 >> 6) & 0x1f)+(0*64+14 +1); out[0*64+15] = start + ((w1 >> 11) & 0x1f)+(0*64+15 +1); out[0*64+16] = start + ((w1 >> 16) & 0x1f)+(0*64+16 +1); out[0*64+17] = start + ((w1 >> 21) & 0x1f)+(0*64+17 +1); out[0*64+18] = start + ((w1 >> 26) & 0x1f)+(0*64+18 +1); out[0*64+19] = start + ((w1 >> 31) & 0x1f)+(0*64+19 +1); out[0*64+20] = start + ((w1 >> 36) & 0x1f)+(0*64+20 +1); out[0*64+21] = start + ((w1 >> 41) & 0x1f)+(0*64+21 +1); out[0*64+22] = start + ((w1 >> 46) & 0x1f)+(0*64+22 +1); out[0*64+23] = start + ((w1 >> 51) & 0x1f)+(0*64+23 +1); out[0*64+24] = start + ((w1 >> 56) & 0x1f)+(0*64+24 +1); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = start + ((w1 >> 61) | (w2 << 3) & 0x1f)+(0*64+25 +1); out[0*64+26] = start + ((w2 >> 2) & 0x1f)+(0*64+26 +1); out[0*64+27] = start + ((w2 >> 7) & 0x1f)+(0*64+27 +1); out[0*64+28] = start + ((w2 >> 12) & 0x1f)+(0*64+28 +1); out[0*64+29] = start + ((w2 >> 17) & 0x1f)+(0*64+29 +1); out[0*64+30] = start + ((w2 >> 22) & 0x1f)+(0*64+30 +1); out[0*64+31] = start + ((w2 >> 27) & 0x1f)+(0*64+31 +1);;}; out += 32; start += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_6(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3f)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 6) & 0x3f)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 12) & 0x3f)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 18) & 0x3f)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 24) & 0x3f)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 30) & 0x3f)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w0 >> 36) & 0x3f)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w0 >> 42) & 0x3f)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w0 >> 48) & 0x3f)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w0 >> 54) & 0x3f)+(0*32+ 9 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = start + ((w0 >> 60) | (w1 << 4) & 0x3f)+(0*32+10 +1); out[0*32+11] = start + ((w1 >> 2) & 0x3f)+(0*32+11 +1); out[0*32+12] = start + ((w1 >> 8) & 0x3f)+(0*32+12 +1); out[0*32+13] = start + ((w1 >> 14) & 0x3f)+(0*32+13 +1); out[0*32+14] = start + ((w1 >> 20) & 0x3f)+(0*32+14 +1); out[0*32+15] = start + ((w1 >> 26) & 0x3f)+(0*32+15 +1); out[0*32+16] = start + ((w1 >> 32) & 0x3f)+(0*32+16 +1); out[0*32+17] = start + ((w1 >> 38) & 0x3f)+(0*32+17 +1); out[0*32+18] = start + ((w1 >> 44) & 0x3f)+(0*32+18 +1); out[0*32+19] = start + ((w1 >> 50) & 0x3f)+(0*32+19 +1); out[0*32+20] = start + ((w1 >> 56) & 0x3f)+(0*32+20 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = start + ((w1 >> 62) | (w2 << 2) & 0x3f)+(0*32+21 +1); out[0*32+22] = start + ((w2 >> 4) & 0x3f)+(0*32+22 +1); out[0*32+23] = start + ((w2 >> 10) & 0x3f)+(0*32+23 +1); out[0*32+24] = start + ((w2 >> 16) & 0x3f)+(0*32+24 +1); out[0*32+25] = start + ((w2 >> 22) & 0x3f)+(0*32+25 +1); out[0*32+26] = start + ((w2 >> 28) & 0x3f)+(0*32+26 +1); out[0*32+27] = start + ((w2 >> 34) & 0x3f)+(0*32+27 +1); out[0*32+28] = start + ((w2 >> 40) & 0x3f)+(0*32+28 +1); out[0*32+29] = start + ((w2 >> 46) & 0x3f)+(0*32+29 +1); out[0*32+30] = start + ((w2 >> 52) & 0x3f)+(0*32+30 +1); out[0*32+31] = start + ((w2 >> 58))+(0*32+31 +1);;}; out += 32; start += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_7(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7f)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 7) & 0x7f)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 14) & 0x7f)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 21) & 0x7f)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 28) & 0x7f)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 35) & 0x7f)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 42) & 0x7f)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w0 >> 49) & 0x7f)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w0 >> 56) & 0x7f)+(0*64+ 8 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w0 >> 63) | (w1 << 1) & 0x7f)+(0*64+ 9 +1); out[0*64+10] = start + ((w1 >> 6) & 0x7f)+(0*64+10 +1); out[0*64+11] = start + ((w1 >> 13) & 0x7f)+(0*64+11 +1); out[0*64+12] = start + ((w1 >> 20) & 0x7f)+(0*64+12 +1); out[0*64+13] = start + ((w1 >> 27) & 0x7f)+(0*64+13 +1); out[0*64+14] = start + ((w1 >> 34) & 0x7f)+(0*64+14 +1); out[0*64+15] = start + ((w1 >> 41) & 0x7f)+(0*64+15 +1); out[0*64+16] = start + ((w1 >> 48) & 0x7f)+(0*64+16 +1); out[0*64+17] = start + ((w1 >> 55) & 0x7f)+(0*64+17 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = start + ((w1 >> 62) | (w2 << 2) & 0x7f)+(0*64+18 +1); out[0*64+19] = start + ((w2 >> 5) & 0x7f)+(0*64+19 +1); out[0*64+20] = start + ((w2 >> 12) & 0x7f)+(0*64+20 +1); out[0*64+21] = start + ((w2 >> 19) & 0x7f)+(0*64+21 +1); out[0*64+22] = start + ((w2 >> 26) & 0x7f)+(0*64+22 +1); out[0*64+23] = start + ((w2 >> 33) & 0x7f)+(0*64+23 +1); out[0*64+24] = start + ((w2 >> 40) & 0x7f)+(0*64+24 +1); out[0*64+25] = start + ((w2 >> 47) & 0x7f)+(0*64+25 +1); out[0*64+26] = start + ((w2 >> 54) & 0x7f)+(0*64+26 +1); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = start + ((w2 >> 61) | (w3 << 3) & 0x7f)+(0*64+27 +1); out[0*64+28] = start + ((w3 >> 4) & 0x7f)+(0*64+28 +1); out[0*64+29] = start + ((w3 >> 11) & 0x7f)+(0*64+29 +1); out[0*64+30] = start + ((w3 >> 18) & 0x7f)+(0*64+30 +1); out[0*64+31] = start + ((w3 >> 25) & 0x7f)+(0*64+31 +1);;}; out += 32; start += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_8(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = start + ((w0 ) & 0xff)+(0*8+ 0 +1); out[0*8+ 1] = start + ((w0 >> 8) & 0xff)+(0*8+ 1 +1); out[0*8+ 2] = start + ((w0 >> 16) & 0xff)+(0*8+ 2 +1); out[0*8+ 3] = start + ((w0 >> 24) & 0xff)+(0*8+ 3 +1); out[0*8+ 4] = start + ((w0 >> 32) & 0xff)+(0*8+ 4 +1); out[0*8+ 5] = start + ((w0 >> 40) & 0xff)+(0*8+ 5 +1); out[0*8+ 6] = start + ((w0 >> 48) & 0xff)+(0*8+ 6 +1); out[0*8+ 7] = start + ((w0 >> 56))+(0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = start + ((w0 ) & 0xff)+(1*8+ 0 +1); out[1*8+ 1] = start + ((w0 >> 8) & 0xff)+(1*8+ 1 +1); out[1*8+ 2] = start + ((w0 >> 16) & 0xff)+(1*8+ 2 +1); out[1*8+ 3] = start + ((w0 >> 24) & 0xff)+(1*8+ 3 +1); out[1*8+ 4] = start + ((w0 >> 32) & 0xff)+(1*8+ 4 +1); out[1*8+ 5] = start + ((w0 >> 40) & 0xff)+(1*8+ 5 +1); out[1*8+ 6] = start + ((w0 >> 48) & 0xff)+(1*8+ 6 +1); out[1*8+ 7] = start + ((w0 >> 56))+(1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = start + ((w0 ) & 0xff)+(2*8+ 0 +1); out[2*8+ 1] = start + ((w0 >> 8) & 0xff)+(2*8+ 1 +1); out[2*8+ 2] = start + ((w0 >> 16) & 0xff)+(2*8+ 2 +1); out[2*8+ 3] = start + ((w0 >> 24) & 0xff)+(2*8+ 3 +1); out[2*8+ 4] = start + ((w0 >> 32) & 0xff)+(2*8+ 4 +1); out[2*8+ 5] = start + ((w0 >> 40) & 0xff)+(2*8+ 5 +1); out[2*8+ 6] = start + ((w0 >> 48) & 0xff)+(2*8+ 6 +1); out[2*8+ 7] = start + ((w0 >> 56))+(2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = start + ((w0 ) & 0xff)+(3*8+ 0 +1); out[3*8+ 1] = start + ((w0 >> 8) & 0xff)+(3*8+ 1 +1); out[3*8+ 2] = start + ((w0 >> 16) & 0xff)+(3*8+ 2 +1); out[3*8+ 3] = start + ((w0 >> 24) & 0xff)+(3*8+ 3 +1); out[3*8+ 4] = start + ((w0 >> 32) & 0xff)+(3*8+ 4 +1); out[3*8+ 5] = start + ((w0 >> 40) & 0xff)+(3*8+ 5 +1); out[3*8+ 6] = start + ((w0 >> 48) & 0xff)+(3*8+ 6 +1); out[3*8+ 7] = start + ((w0 >> 56))+(3*8+ 7 +1);;}; out += 32; start += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_9(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1ff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 9) & 0x1ff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 18) & 0x1ff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 27) & 0x1ff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 36) & 0x1ff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 45) & 0x1ff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 54) & 0x1ff)+(0*64+ 6 +1); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w0 >> 63) | (w1 << 1) & 0x1ff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w1 >> 8) & 0x1ff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w1 >> 17) & 0x1ff)+(0*64+ 9 +1); out[0*64+10] = start + ((w1 >> 26) & 0x1ff)+(0*64+10 +1); out[0*64+11] = start + ((w1 >> 35) & 0x1ff)+(0*64+11 +1); out[0*64+12] = start + ((w1 >> 44) & 0x1ff)+(0*64+12 +1); out[0*64+13] = start + ((w1 >> 53) & 0x1ff)+(0*64+13 +1); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = start + ((w1 >> 62) | (w2 << 2) & 0x1ff)+(0*64+14 +1); out[0*64+15] = start + ((w2 >> 7) & 0x1ff)+(0*64+15 +1); out[0*64+16] = start + ((w2 >> 16) & 0x1ff)+(0*64+16 +1); out[0*64+17] = start + ((w2 >> 25) & 0x1ff)+(0*64+17 +1); out[0*64+18] = start + ((w2 >> 34) & 0x1ff)+(0*64+18 +1); out[0*64+19] = start + ((w2 >> 43) & 0x1ff)+(0*64+19 +1); out[0*64+20] = start + ((w2 >> 52) & 0x1ff)+(0*64+20 +1); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = start + ((w2 >> 61) | (w3 << 3) & 0x1ff)+(0*64+21 +1); out[0*64+22] = start + ((w3 >> 6) & 0x1ff)+(0*64+22 +1); out[0*64+23] = start + ((w3 >> 15) & 0x1ff)+(0*64+23 +1); out[0*64+24] = start + ((w3 >> 24) & 0x1ff)+(0*64+24 +1); out[0*64+25] = start + ((w3 >> 33) & 0x1ff)+(0*64+25 +1); out[0*64+26] = start + ((w3 >> 42) & 0x1ff)+(0*64+26 +1); out[0*64+27] = start + ((w3 >> 51) & 0x1ff)+(0*64+27 +1); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = start + ((w3 >> 60) | (w4 << 4) & 0x1ff)+(0*64+28 +1); out[0*64+29] = start + ((w4 >> 5) & 0x1ff)+(0*64+29 +1); out[0*64+30] = start + ((w4 >> 14) & 0x1ff)+(0*64+30 +1); out[0*64+31] = start + ((w4 >> 23) & 0x1ff)+(0*64+31 +1);;}; out += 32; start += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_10(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3ff)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 10) & 0x3ff)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 20) & 0x3ff)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 30) & 0x3ff)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 40) & 0x3ff)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 50) & 0x3ff)+(0*32+ 5 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = start + ((w0 >> 60) | (w1 << 4) & 0x3ff)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w1 >> 6) & 0x3ff)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w1 >> 16) & 0x3ff)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w1 >> 26) & 0x3ff)+(0*32+ 9 +1); out[0*32+10] = start + ((w1 >> 36) & 0x3ff)+(0*32+10 +1); out[0*32+11] = start + ((w1 >> 46) & 0x3ff)+(0*32+11 +1); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = start + ((w1 >> 56) | (w2 << 8) & 0x3ff)+(0*32+12 +1); out[0*32+13] = start + ((w2 >> 2) & 0x3ff)+(0*32+13 +1); out[0*32+14] = start + ((w2 >> 12) & 0x3ff)+(0*32+14 +1); out[0*32+15] = start + ((w2 >> 22) & 0x3ff)+(0*32+15 +1); out[0*32+16] = start + ((w2 >> 32) & 0x3ff)+(0*32+16 +1); out[0*32+17] = start + ((w2 >> 42) & 0x3ff)+(0*32+17 +1); out[0*32+18] = start + ((w2 >> 52) & 0x3ff)+(0*32+18 +1); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = start + ((w2 >> 62) | (w3 << 2) & 0x3ff)+(0*32+19 +1); out[0*32+20] = start + ((w3 >> 8) & 0x3ff)+(0*32+20 +1); out[0*32+21] = start + ((w3 >> 18) & 0x3ff)+(0*32+21 +1); out[0*32+22] = start + ((w3 >> 28) & 0x3ff)+(0*32+22 +1); out[0*32+23] = start + ((w3 >> 38) & 0x3ff)+(0*32+23 +1); out[0*32+24] = start + ((w3 >> 48) & 0x3ff)+(0*32+24 +1); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = start + ((w3 >> 58) | (w4 << 6) & 0x3ff)+(0*32+25 +1); out[0*32+26] = start + ((w4 >> 4) & 0x3ff)+(0*32+26 +1); out[0*32+27] = start + ((w4 >> 14) & 0x3ff)+(0*32+27 +1); out[0*32+28] = start + ((w4 >> 24) & 0x3ff)+(0*32+28 +1); out[0*32+29] = start + ((w4 >> 34) & 0x3ff)+(0*32+29 +1); out[0*32+30] = start + ((w4 >> 44) & 0x3ff)+(0*32+30 +1); out[0*32+31] = start + ((w4 >> 54))+(0*32+31 +1);;}; out += 32; start += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_11(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7ff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 11) & 0x7ff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 22) & 0x7ff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 33) & 0x7ff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 44) & 0x7ff)+(0*64+ 4 +1); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w0 >> 55) | (w1 << 9) & 0x7ff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w1 >> 2) & 0x7ff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w1 >> 13) & 0x7ff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w1 >> 24) & 0x7ff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w1 >> 35) & 0x7ff)+(0*64+ 9 +1); out[0*64+10] = start + ((w1 >> 46) & 0x7ff)+(0*64+10 +1); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = start + ((w1 >> 57) | (w2 << 7) & 0x7ff)+(0*64+11 +1); out[0*64+12] = start + ((w2 >> 4) & 0x7ff)+(0*64+12 +1); out[0*64+13] = start + ((w2 >> 15) & 0x7ff)+(0*64+13 +1); out[0*64+14] = start + ((w2 >> 26) & 0x7ff)+(0*64+14 +1); out[0*64+15] = start + ((w2 >> 37) & 0x7ff)+(0*64+15 +1); out[0*64+16] = start + ((w2 >> 48) & 0x7ff)+(0*64+16 +1); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = start + ((w2 >> 59) | (w3 << 5) & 0x7ff)+(0*64+17 +1); out[0*64+18] = start + ((w3 >> 6) & 0x7ff)+(0*64+18 +1); out[0*64+19] = start + ((w3 >> 17) & 0x7ff)+(0*64+19 +1); out[0*64+20] = start + ((w3 >> 28) & 0x7ff)+(0*64+20 +1); out[0*64+21] = start + ((w3 >> 39) & 0x7ff)+(0*64+21 +1); out[0*64+22] = start + ((w3 >> 50) & 0x7ff)+(0*64+22 +1); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = start + ((w3 >> 61) | (w4 << 3) & 0x7ff)+(0*64+23 +1); out[0*64+24] = start + ((w4 >> 8) & 0x7ff)+(0*64+24 +1); out[0*64+25] = start + ((w4 >> 19) & 0x7ff)+(0*64+25 +1); out[0*64+26] = start + ((w4 >> 30) & 0x7ff)+(0*64+26 +1); out[0*64+27] = start + ((w4 >> 41) & 0x7ff)+(0*64+27 +1); out[0*64+28] = start + ((w4 >> 52) & 0x7ff)+(0*64+28 +1); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = start + ((w4 >> 63) | (w5 << 1) & 0x7ff)+(0*64+29 +1); out[0*64+30] = start + ((w5 >> 10) & 0x7ff)+(0*64+30 +1); out[0*64+31] = start + ((w5 >> 21) & 0x7ff)+(0*64+31 +1);;}; out += 32; start += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_12(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xfff)+(0*16+ 0 +1); out[0*16+ 1] = start + ((w0 >> 12) & 0xfff)+(0*16+ 1 +1); out[0*16+ 2] = start + ((w0 >> 24) & 0xfff)+(0*16+ 2 +1); out[0*16+ 3] = start + ((w0 >> 36) & 0xfff)+(0*16+ 3 +1); out[0*16+ 4] = start + ((w0 >> 48) & 0xfff)+(0*16+ 4 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = start + ((w0 >> 60) | (w1 << 4) & 0xfff)+(0*16+ 5 +1); out[0*16+ 6] = start + ((w1 >> 8) & 0xfff)+(0*16+ 6 +1); out[0*16+ 7] = start + ((w1 >> 20) & 0xfff)+(0*16+ 7 +1); out[0*16+ 8] = start + ((w1 >> 32) & 0xfff)+(0*16+ 8 +1); out[0*16+ 9] = start + ((w1 >> 44) & 0xfff)+(0*16+ 9 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = start + ((w1 >> 56) | (w2 << 8) & 0xfff)+(0*16+10 +1); out[0*16+11] = start + ((w2 >> 4) & 0xfff)+(0*16+11 +1); out[0*16+12] = start + ((w2 >> 16) & 0xfff)+(0*16+12 +1); out[0*16+13] = start + ((w2 >> 28) & 0xfff)+(0*16+13 +1); out[0*16+14] = start + ((w2 >> 40) & 0xfff)+(0*16+14 +1); out[0*16+15] = start + ((w2 >> 52))+(0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xfff)+(1*16+ 0 +1); out[1*16+ 1] = start + ((w0 >> 12) & 0xfff)+(1*16+ 1 +1); out[1*16+ 2] = start + ((w0 >> 24) & 0xfff)+(1*16+ 2 +1); out[1*16+ 3] = start + ((w0 >> 36) & 0xfff)+(1*16+ 3 +1); out[1*16+ 4] = start + ((w0 >> 48) & 0xfff)+(1*16+ 4 +1); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = start + ((w0 >> 60) | (w1 << 4) & 0xfff)+(1*16+ 5 +1); out[1*16+ 6] = start + ((w1 >> 8) & 0xfff)+(1*16+ 6 +1); out[1*16+ 7] = start + ((w1 >> 20) & 0xfff)+(1*16+ 7 +1); out[1*16+ 8] = start + ((w1 >> 32) & 0xfff)+(1*16+ 8 +1); out[1*16+ 9] = start + ((w1 >> 44) & 0xfff)+(1*16+ 9 +1); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = start + ((w1 >> 56) | (w2 << 8) & 0xfff)+(1*16+10 +1); out[1*16+11] = start + ((w2 >> 4) & 0xfff)+(1*16+11 +1); out[1*16+12] = start + ((w2 >> 16) & 0xfff)+(1*16+12 +1); out[1*16+13] = start + ((w2 >> 28) & 0xfff)+(1*16+13 +1); out[1*16+14] = start + ((w2 >> 40) & 0xfff)+(1*16+14 +1); out[1*16+15] = start + ((w2 >> 52))+(1*16+15 +1);;}; out += 32; start += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_13(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1fff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 13) & 0x1fff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 26) & 0x1fff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 39) & 0x1fff)+(0*64+ 3 +1); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w0 >> 52) | (w1 << 12) & 0x1fff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w1 >> 1) & 0x1fff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w1 >> 14) & 0x1fff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w1 >> 27) & 0x1fff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w1 >> 40) & 0x1fff)+(0*64+ 8 +1); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w1 >> 53) | (w2 << 11) & 0x1fff)+(0*64+ 9 +1); out[0*64+10] = start + ((w2 >> 2) & 0x1fff)+(0*64+10 +1); out[0*64+11] = start + ((w2 >> 15) & 0x1fff)+(0*64+11 +1); out[0*64+12] = start + ((w2 >> 28) & 0x1fff)+(0*64+12 +1); out[0*64+13] = start + ((w2 >> 41) & 0x1fff)+(0*64+13 +1); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = start + ((w2 >> 54) | (w3 << 10) & 0x1fff)+(0*64+14 +1); out[0*64+15] = start + ((w3 >> 3) & 0x1fff)+(0*64+15 +1); out[0*64+16] = start + ((w3 >> 16) & 0x1fff)+(0*64+16 +1); out[0*64+17] = start + ((w3 >> 29) & 0x1fff)+(0*64+17 +1); out[0*64+18] = start + ((w3 >> 42) & 0x1fff)+(0*64+18 +1); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = start + ((w3 >> 55) | (w4 << 9) & 0x1fff)+(0*64+19 +1); out[0*64+20] = start + ((w4 >> 4) & 0x1fff)+(0*64+20 +1); out[0*64+21] = start + ((w4 >> 17) & 0x1fff)+(0*64+21 +1); out[0*64+22] = start + ((w4 >> 30) & 0x1fff)+(0*64+22 +1); out[0*64+23] = start + ((w4 >> 43) & 0x1fff)+(0*64+23 +1); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = start + ((w4 >> 56) | (w5 << 8) & 0x1fff)+(0*64+24 +1); out[0*64+25] = start + ((w5 >> 5) & 0x1fff)+(0*64+25 +1); out[0*64+26] = start + ((w5 >> 18) & 0x1fff)+(0*64+26 +1); out[0*64+27] = start + ((w5 >> 31) & 0x1fff)+(0*64+27 +1); out[0*64+28] = start + ((w5 >> 44) & 0x1fff)+(0*64+28 +1); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = start + ((w5 >> 57) | (w6 << 7) & 0x1fff)+(0*64+29 +1); out[0*64+30] = start + ((w6 >> 6) & 0x1fff)+(0*64+30 +1); out[0*64+31] = start + ((w6 >> 19) & 0x1fff)+(0*64+31 +1);;}; out += 32; start += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_14(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3fff)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 14) & 0x3fff)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 28) & 0x3fff)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 42) & 0x3fff)+(0*32+ 3 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = start + ((w0 >> 56) | (w1 << 8) & 0x3fff)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w1 >> 6) & 0x3fff)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w1 >> 20) & 0x3fff)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w1 >> 34) & 0x3fff)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w1 >> 48) & 0x3fff)+(0*32+ 8 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = start + ((w1 >> 62) | (w2 << 2) & 0x3fff)+(0*32+ 9 +1); out[0*32+10] = start + ((w2 >> 12) & 0x3fff)+(0*32+10 +1); out[0*32+11] = start + ((w2 >> 26) & 0x3fff)+(0*32+11 +1); out[0*32+12] = start + ((w2 >> 40) & 0x3fff)+(0*32+12 +1); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = start + ((w2 >> 54) | (w3 << 10) & 0x3fff)+(0*32+13 +1); out[0*32+14] = start + ((w3 >> 4) & 0x3fff)+(0*32+14 +1); out[0*32+15] = start + ((w3 >> 18) & 0x3fff)+(0*32+15 +1); out[0*32+16] = start + ((w3 >> 32) & 0x3fff)+(0*32+16 +1); out[0*32+17] = start + ((w3 >> 46) & 0x3fff)+(0*32+17 +1); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = start + ((w3 >> 60) | (w4 << 4) & 0x3fff)+(0*32+18 +1); out[0*32+19] = start + ((w4 >> 10) & 0x3fff)+(0*32+19 +1); out[0*32+20] = start + ((w4 >> 24) & 0x3fff)+(0*32+20 +1); out[0*32+21] = start + ((w4 >> 38) & 0x3fff)+(0*32+21 +1); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = start + ((w4 >> 52) | (w5 << 12) & 0x3fff)+(0*32+22 +1); out[0*32+23] = start + ((w5 >> 2) & 0x3fff)+(0*32+23 +1); out[0*32+24] = start + ((w5 >> 16) & 0x3fff)+(0*32+24 +1); out[0*32+25] = start + ((w5 >> 30) & 0x3fff)+(0*32+25 +1); out[0*32+26] = start + ((w5 >> 44) & 0x3fff)+(0*32+26 +1); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = start + ((w5 >> 58) | (w6 << 6) & 0x3fff)+(0*32+27 +1); out[0*32+28] = start + ((w6 >> 8) & 0x3fff)+(0*32+28 +1); out[0*32+29] = start + ((w6 >> 22) & 0x3fff)+(0*32+29 +1); out[0*32+30] = start + ((w6 >> 36) & 0x3fff)+(0*32+30 +1); out[0*32+31] = start + ((w6 >> 50))+(0*32+31 +1);;}; out += 32; start += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_15(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7fff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 15) & 0x7fff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 30) & 0x7fff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 45) & 0x7fff)+(0*64+ 3 +1); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w0 >> 60) | (w1 << 4) & 0x7fff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w1 >> 11) & 0x7fff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w1 >> 26) & 0x7fff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w1 >> 41) & 0x7fff)+(0*64+ 7 +1); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w1 >> 56) | (w2 << 8) & 0x7fff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w2 >> 7) & 0x7fff)+(0*64+ 9 +1); out[0*64+10] = start + ((w2 >> 22) & 0x7fff)+(0*64+10 +1); out[0*64+11] = start + ((w2 >> 37) & 0x7fff)+(0*64+11 +1); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = start + ((w2 >> 52) | (w3 << 12) & 0x7fff)+(0*64+12 +1); out[0*64+13] = start + ((w3 >> 3) & 0x7fff)+(0*64+13 +1); out[0*64+14] = start + ((w3 >> 18) & 0x7fff)+(0*64+14 +1); out[0*64+15] = start + ((w3 >> 33) & 0x7fff)+(0*64+15 +1); out[0*64+16] = start + ((w3 >> 48) & 0x7fff)+(0*64+16 +1); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = start + ((w3 >> 63) | (w4 << 1) & 0x7fff)+(0*64+17 +1); out[0*64+18] = start + ((w4 >> 14) & 0x7fff)+(0*64+18 +1); out[0*64+19] = start + ((w4 >> 29) & 0x7fff)+(0*64+19 +1); out[0*64+20] = start + ((w4 >> 44) & 0x7fff)+(0*64+20 +1); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = start + ((w4 >> 59) | (w5 << 5) & 0x7fff)+(0*64+21 +1); out[0*64+22] = start + ((w5 >> 10) & 0x7fff)+(0*64+22 +1); out[0*64+23] = start + ((w5 >> 25) & 0x7fff)+(0*64+23 +1); out[0*64+24] = start + ((w5 >> 40) & 0x7fff)+(0*64+24 +1); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = start + ((w5 >> 55) | (w6 << 9) & 0x7fff)+(0*64+25 +1); out[0*64+26] = start + ((w6 >> 6) & 0x7fff)+(0*64+26 +1); out[0*64+27] = start + ((w6 >> 21) & 0x7fff)+(0*64+27 +1); out[0*64+28] = start + ((w6 >> 36) & 0x7fff)+(0*64+28 +1); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = start + ((w6 >> 51) | (w7 << 13) & 0x7fff)+(0*64+29 +1); out[0*64+30] = start + ((w7 >> 2) & 0x7fff)+(0*64+30 +1); out[0*64+31] = start + ((w7 >> 17) & 0x7fff)+(0*64+31 +1);;}; out += 32; start += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_16(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = start + (*(uint16_t *)(in+0*8+ 0))+(0*4+ 0 +1); out[0*4+ 1] = start + (*(uint16_t *)(in+0*8+ 2))+(0*4+ 1 +1); out[0*4+ 2] = start + (*(uint16_t *)(in+0*8+ 4))+(0*4+ 2 +1); out[0*4+ 3] = start + (*(uint16_t *)(in+0*8+ 6))+(0*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = start + (*(uint16_t *)(in+1*8+ 0))+(1*4+ 0 +1); out[1*4+ 1] = start + (*(uint16_t *)(in+1*8+ 2))+(1*4+ 1 +1); out[1*4+ 2] = start + (*(uint16_t *)(in+1*8+ 4))+(1*4+ 2 +1); out[1*4+ 3] = start + (*(uint16_t *)(in+1*8+ 6))+(1*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = start + (*(uint16_t *)(in+2*8+ 0))+(2*4+ 0 +1); out[2*4+ 1] = start + (*(uint16_t *)(in+2*8+ 2))+(2*4+ 1 +1); out[2*4+ 2] = start + (*(uint16_t *)(in+2*8+ 4))+(2*4+ 2 +1); out[2*4+ 3] = start + (*(uint16_t *)(in+2*8+ 6))+(2*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = start + (*(uint16_t *)(in+3*8+ 0))+(3*4+ 0 +1); out[3*4+ 1] = start + (*(uint16_t *)(in+3*8+ 2))+(3*4+ 1 +1); out[3*4+ 2] = start + (*(uint16_t *)(in+3*8+ 4))+(3*4+ 2 +1); out[3*4+ 3] = start + (*(uint16_t *)(in+3*8+ 6))+(3*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = start + (*(uint16_t *)(in+4*8+ 0))+(4*4+ 0 +1); out[4*4+ 1] = start + (*(uint16_t *)(in+4*8+ 2))+(4*4+ 1 +1); out[4*4+ 2] = start + (*(uint16_t *)(in+4*8+ 4))+(4*4+ 2 +1); out[4*4+ 3] = start + (*(uint16_t *)(in+4*8+ 6))+(4*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = start + (*(uint16_t *)(in+5*8+ 0))+(5*4+ 0 +1); out[5*4+ 1] = start + (*(uint16_t *)(in+5*8+ 2))+(5*4+ 1 +1); out[5*4+ 2] = start + (*(uint16_t *)(in+5*8+ 4))+(5*4+ 2 +1); out[5*4+ 3] = start + (*(uint16_t *)(in+5*8+ 6))+(5*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = start + (*(uint16_t *)(in+6*8+ 0))+(6*4+ 0 +1); out[6*4+ 1] = start + (*(uint16_t *)(in+6*8+ 2))+(6*4+ 1 +1); out[6*4+ 2] = start + (*(uint16_t *)(in+6*8+ 4))+(6*4+ 2 +1); out[6*4+ 3] = start + (*(uint16_t *)(in+6*8+ 6))+(6*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = start + (*(uint16_t *)(in+7*8+ 0))+(7*4+ 0 +1); out[7*4+ 1] = start + (*(uint16_t *)(in+7*8+ 2))+(7*4+ 1 +1); out[7*4+ 2] = start + (*(uint16_t *)(in+7*8+ 4))+(7*4+ 2 +1); out[7*4+ 3] = start + (*(uint16_t *)(in+7*8+ 6))+(7*4+ 3 +1);;}; out += 32; start += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_17(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*17)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1ffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 17) & 0x1ffff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 34) & 0x1ffff)+(0*64+ 2 +1); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w0 >> 51) | (w1 << 13) & 0x1ffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w1 >> 4) & 0x1ffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w1 >> 21) & 0x1ffff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w1 >> 38) & 0x1ffff)+(0*64+ 6 +1); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w1 >> 55) | (w2 << 9) & 0x1ffff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w2 >> 8) & 0x1ffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w2 >> 25) & 0x1ffff)+(0*64+ 9 +1); out[0*64+10] = start + ((w2 >> 42) & 0x1ffff)+(0*64+10 +1); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*64+11] = start + ((w2 >> 59) | (w3 << 5) & 0x1ffff)+(0*64+11 +1); out[0*64+12] = start + ((w3 >> 12) & 0x1ffff)+(0*64+12 +1); out[0*64+13] = start + ((w3 >> 29) & 0x1ffff)+(0*64+13 +1); out[0*64+14] = start + ((w3 >> 46) & 0x1ffff)+(0*64+14 +1); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*64+15] = start + ((w3 >> 63) | (w4 << 1) & 0x1ffff)+(0*64+15 +1); out[0*64+16] = start + ((w4 >> 16) & 0x1ffff)+(0*64+16 +1); out[0*64+17] = start + ((w4 >> 33) & 0x1ffff)+(0*64+17 +1); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*64+18] = start + ((w4 >> 50) | (w5 << 14) & 0x1ffff)+(0*64+18 +1); out[0*64+19] = start + ((w5 >> 3) & 0x1ffff)+(0*64+19 +1); out[0*64+20] = start + ((w5 >> 20) & 0x1ffff)+(0*64+20 +1); out[0*64+21] = start + ((w5 >> 37) & 0x1ffff)+(0*64+21 +1); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*64+22] = start + ((w5 >> 54) | (w6 << 10) & 0x1ffff)+(0*64+22 +1); out[0*64+23] = start + ((w6 >> 7) & 0x1ffff)+(0*64+23 +1); out[0*64+24] = start + ((w6 >> 24) & 0x1ffff)+(0*64+24 +1); out[0*64+25] = start + ((w6 >> 41) & 0x1ffff)+(0*64+25 +1); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*64+26] = start + ((w6 >> 58) | (w7 << 6) & 0x1ffff)+(0*64+26 +1); out[0*64+27] = start + ((w7 >> 11) & 0x1ffff)+(0*64+27 +1); out[0*64+28] = start + ((w7 >> 28) & 0x1ffff)+(0*64+28 +1); out[0*64+29] = start + ((w7 >> 45) & 0x1ffff)+(0*64+29 +1); w8 = *(uint32_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*64+30] = start + ((w7 >> 62) | (w8 << 2) & 0x1ffff)+(0*64+30 +1); out[0*64+31] = start + ((w8 >> 15) & 0x1ffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 17*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_18(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*18)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3ffff)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 18) & 0x3ffff)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 36) & 0x3ffff)+(0*32+ 2 +1); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*32+ 3] = start + ((w0 >> 54) | (w1 << 10) & 0x3ffff)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w1 >> 8) & 0x3ffff)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w1 >> 26) & 0x3ffff)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w1 >> 44) & 0x3ffff)+(0*32+ 6 +1); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*32+ 7] = start + ((w1 >> 62) | (w2 << 2) & 0x3ffff)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w2 >> 16) & 0x3ffff)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w2 >> 34) & 0x3ffff)+(0*32+ 9 +1); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*32+10] = start + ((w2 >> 52) | (w3 << 12) & 0x3ffff)+(0*32+10 +1); out[0*32+11] = start + ((w3 >> 6) & 0x3ffff)+(0*32+11 +1); out[0*32+12] = start + ((w3 >> 24) & 0x3ffff)+(0*32+12 +1); out[0*32+13] = start + ((w3 >> 42) & 0x3ffff)+(0*32+13 +1); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*32+14] = start + ((w3 >> 60) | (w4 << 4) & 0x3ffff)+(0*32+14 +1); out[0*32+15] = start + ((w4 >> 14) & 0x3ffff)+(0*32+15 +1); out[0*32+16] = start + ((w4 >> 32) & 0x3ffff)+(0*32+16 +1); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*32+17] = start + ((w4 >> 50) | (w5 << 14) & 0x3ffff)+(0*32+17 +1); out[0*32+18] = start + ((w5 >> 4) & 0x3ffff)+(0*32+18 +1); out[0*32+19] = start + ((w5 >> 22) & 0x3ffff)+(0*32+19 +1); out[0*32+20] = start + ((w5 >> 40) & 0x3ffff)+(0*32+20 +1); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*32+21] = start + ((w5 >> 58) | (w6 << 6) & 0x3ffff)+(0*32+21 +1); out[0*32+22] = start + ((w6 >> 12) & 0x3ffff)+(0*32+22 +1); out[0*32+23] = start + ((w6 >> 30) & 0x3ffff)+(0*32+23 +1); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*32+24] = start + ((w6 >> 48) | (w7 << 16) & 0x3ffff)+(0*32+24 +1); out[0*32+25] = start + ((w7 >> 2) & 0x3ffff)+(0*32+25 +1); out[0*32+26] = start + ((w7 >> 20) & 0x3ffff)+(0*32+26 +1); out[0*32+27] = start + ((w7 >> 38) & 0x3ffff)+(0*32+27 +1); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*32+28] = start + ((w7 >> 56) | (w8 << 8) & 0x3ffff)+(0*32+28 +1); out[0*32+29] = start + ((w8 >> 10) & 0x3ffff)+(0*32+29 +1); out[0*32+30] = start + ((w8 >> 28) & 0x3ffff)+(0*32+30 +1); out[0*32+31] = start + ((w8 >> 46))+(0*32+31 +1);;}; out += 32; start += 32; in += 18*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_19(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*19)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7ffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 19) & 0x7ffff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 38) & 0x7ffff)+(0*64+ 2 +1); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w0 >> 57) | (w1 << 7) & 0x7ffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w1 >> 12) & 0x7ffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w1 >> 31) & 0x7ffff)+(0*64+ 5 +1); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w1 >> 50) | (w2 << 14) & 0x7ffff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w2 >> 5) & 0x7ffff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w2 >> 24) & 0x7ffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w2 >> 43) & 0x7ffff)+(0*64+ 9 +1); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*64+10] = start + ((w2 >> 62) | (w3 << 2) & 0x7ffff)+(0*64+10 +1); out[0*64+11] = start + ((w3 >> 17) & 0x7ffff)+(0*64+11 +1); out[0*64+12] = start + ((w3 >> 36) & 0x7ffff)+(0*64+12 +1); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*64+13] = start + ((w3 >> 55) | (w4 << 9) & 0x7ffff)+(0*64+13 +1); out[0*64+14] = start + ((w4 >> 10) & 0x7ffff)+(0*64+14 +1); out[0*64+15] = start + ((w4 >> 29) & 0x7ffff)+(0*64+15 +1); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*64+16] = start + ((w4 >> 48) | (w5 << 16) & 0x7ffff)+(0*64+16 +1); out[0*64+17] = start + ((w5 >> 3) & 0x7ffff)+(0*64+17 +1); out[0*64+18] = start + ((w5 >> 22) & 0x7ffff)+(0*64+18 +1); out[0*64+19] = start + ((w5 >> 41) & 0x7ffff)+(0*64+19 +1); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*64+20] = start + ((w5 >> 60) | (w6 << 4) & 0x7ffff)+(0*64+20 +1); out[0*64+21] = start + ((w6 >> 15) & 0x7ffff)+(0*64+21 +1); out[0*64+22] = start + ((w6 >> 34) & 0x7ffff)+(0*64+22 +1); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*64+23] = start + ((w6 >> 53) | (w7 << 11) & 0x7ffff)+(0*64+23 +1); out[0*64+24] = start + ((w7 >> 8) & 0x7ffff)+(0*64+24 +1); out[0*64+25] = start + ((w7 >> 27) & 0x7ffff)+(0*64+25 +1); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*64+26] = start + ((w7 >> 46) | (w8 << 18) & 0x7ffff)+(0*64+26 +1); out[0*64+27] = start + ((w8 >> 1) & 0x7ffff)+(0*64+27 +1); out[0*64+28] = start + ((w8 >> 20) & 0x7ffff)+(0*64+28 +1); out[0*64+29] = start + ((w8 >> 39) & 0x7ffff)+(0*64+29 +1); w9 = *(uint32_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*64+30] = start + ((w8 >> 58) | (w9 << 6) & 0x7ffff)+(0*64+30 +1); out[0*64+31] = start + ((w9 >> 13) & 0x7ffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 19*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_20(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*20)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xfffff)+(0*16+ 0 +1); out[0*16+ 1] = start + ((w0 >> 20) & 0xfffff)+(0*16+ 1 +1); out[0*16+ 2] = start + ((w0 >> 40) & 0xfffff)+(0*16+ 2 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*16+ 3] = start + ((w0 >> 60) | (w1 << 4) & 0xfffff)+(0*16+ 3 +1); out[0*16+ 4] = start + ((w1 >> 16) & 0xfffff)+(0*16+ 4 +1); out[0*16+ 5] = start + ((w1 >> 36) & 0xfffff)+(0*16+ 5 +1); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*16+ 6] = start + ((w1 >> 56) | (w2 << 8) & 0xfffff)+(0*16+ 6 +1); out[0*16+ 7] = start + ((w2 >> 12) & 0xfffff)+(0*16+ 7 +1); out[0*16+ 8] = start + ((w2 >> 32) & 0xfffff)+(0*16+ 8 +1); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*16+ 9] = start + ((w2 >> 52) | (w3 << 12) & 0xfffff)+(0*16+ 9 +1); out[0*16+10] = start + ((w3 >> 8) & 0xfffff)+(0*16+10 +1); out[0*16+11] = start + ((w3 >> 28) & 0xfffff)+(0*16+11 +1); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*16+12] = start + ((w3 >> 48) | (w4 << 16) & 0xfffff)+(0*16+12 +1); out[0*16+13] = start + ((w4 >> 4) & 0xfffff)+(0*16+13 +1); out[0*16+14] = start + ((w4 >> 24) & 0xfffff)+(0*16+14 +1); out[0*16+15] = start + ((w4 >> 44))+(0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xfffff)+(1*16+ 0 +1); out[1*16+ 1] = start + ((w0 >> 20) & 0xfffff)+(1*16+ 1 +1); out[1*16+ 2] = start + ((w0 >> 40) & 0xfffff)+(1*16+ 2 +1); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*16+ 3] = start + ((w0 >> 60) | (w1 << 4) & 0xfffff)+(1*16+ 3 +1); out[1*16+ 4] = start + ((w1 >> 16) & 0xfffff)+(1*16+ 4 +1); out[1*16+ 5] = start + ((w1 >> 36) & 0xfffff)+(1*16+ 5 +1); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*16+ 6] = start + ((w1 >> 56) | (w2 << 8) & 0xfffff)+(1*16+ 6 +1); out[1*16+ 7] = start + ((w2 >> 12) & 0xfffff)+(1*16+ 7 +1); out[1*16+ 8] = start + ((w2 >> 32) & 0xfffff)+(1*16+ 8 +1); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*16+ 9] = start + ((w2 >> 52) | (w3 << 12) & 0xfffff)+(1*16+ 9 +1); out[1*16+10] = start + ((w3 >> 8) & 0xfffff)+(1*16+10 +1); out[1*16+11] = start + ((w3 >> 28) & 0xfffff)+(1*16+11 +1); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*16+12] = start + ((w3 >> 48) | (w4 << 16) & 0xfffff)+(1*16+12 +1); out[1*16+13] = start + ((w4 >> 4) & 0xfffff)+(1*16+13 +1); out[1*16+14] = start + ((w4 >> 24) & 0xfffff)+(1*16+14 +1); out[1*16+15] = start + ((w4 >> 44))+(1*16+15 +1);;}; out += 32; start += 32; in += 20*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_21(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*21)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1fffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 21) & 0x1fffff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 42) & 0x1fffff)+(0*64+ 2 +1); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w0 >> 63) | (w1 << 1) & 0x1fffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w1 >> 20) & 0x1fffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w1 >> 41) & 0x1fffff)+(0*64+ 5 +1); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w1 >> 62) | (w2 << 2) & 0x1fffff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w2 >> 19) & 0x1fffff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w2 >> 40) & 0x1fffff)+(0*64+ 8 +1); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w2 >> 61) | (w3 << 3) & 0x1fffff)+(0*64+ 9 +1); out[0*64+10] = start + ((w3 >> 18) & 0x1fffff)+(0*64+10 +1); out[0*64+11] = start + ((w3 >> 39) & 0x1fffff)+(0*64+11 +1); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*64+12] = start + ((w3 >> 60) | (w4 << 4) & 0x1fffff)+(0*64+12 +1); out[0*64+13] = start + ((w4 >> 17) & 0x1fffff)+(0*64+13 +1); out[0*64+14] = start + ((w4 >> 38) & 0x1fffff)+(0*64+14 +1); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*64+15] = start + ((w4 >> 59) | (w5 << 5) & 0x1fffff)+(0*64+15 +1); out[0*64+16] = start + ((w5 >> 16) & 0x1fffff)+(0*64+16 +1); out[0*64+17] = start + ((w5 >> 37) & 0x1fffff)+(0*64+17 +1); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*64+18] = start + ((w5 >> 58) | (w6 << 6) & 0x1fffff)+(0*64+18 +1); out[0*64+19] = start + ((w6 >> 15) & 0x1fffff)+(0*64+19 +1); out[0*64+20] = start + ((w6 >> 36) & 0x1fffff)+(0*64+20 +1); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*64+21] = start + ((w6 >> 57) | (w7 << 7) & 0x1fffff)+(0*64+21 +1); out[0*64+22] = start + ((w7 >> 14) & 0x1fffff)+(0*64+22 +1); out[0*64+23] = start + ((w7 >> 35) & 0x1fffff)+(0*64+23 +1); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*64+24] = start + ((w7 >> 56) | (w8 << 8) & 0x1fffff)+(0*64+24 +1); out[0*64+25] = start + ((w8 >> 13) & 0x1fffff)+(0*64+25 +1); out[0*64+26] = start + ((w8 >> 34) & 0x1fffff)+(0*64+26 +1); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*64+27] = start + ((w8 >> 55) | (w9 << 9) & 0x1fffff)+(0*64+27 +1); out[0*64+28] = start + ((w9 >> 12) & 0x1fffff)+(0*64+28 +1); out[0*64+29] = start + ((w9 >> 33) & 0x1fffff)+(0*64+29 +1); w10 = *(uint32_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*64+30] = start + ((w9 >> 54) | (w10 << 10) & 0x1fffff)+(0*64+30 +1); out[0*64+31] = start + ((w10 >> 11) & 0x1fffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 21*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_22(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*22)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3fffff)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 22) & 0x3fffff)+(0*32+ 1 +1); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*32+ 2] = start + ((w0 >> 44) | (w1 << 20) & 0x3fffff)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w1 >> 2) & 0x3fffff)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w1 >> 24) & 0x3fffff)+(0*32+ 4 +1); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*32+ 5] = start + ((w1 >> 46) | (w2 << 18) & 0x3fffff)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w2 >> 4) & 0x3fffff)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w2 >> 26) & 0x3fffff)+(0*32+ 7 +1); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*32+ 8] = start + ((w2 >> 48) | (w3 << 16) & 0x3fffff)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w3 >> 6) & 0x3fffff)+(0*32+ 9 +1); out[0*32+10] = start + ((w3 >> 28) & 0x3fffff)+(0*32+10 +1); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*32+11] = start + ((w3 >> 50) | (w4 << 14) & 0x3fffff)+(0*32+11 +1); out[0*32+12] = start + ((w4 >> 8) & 0x3fffff)+(0*32+12 +1); out[0*32+13] = start + ((w4 >> 30) & 0x3fffff)+(0*32+13 +1); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*32+14] = start + ((w4 >> 52) | (w5 << 12) & 0x3fffff)+(0*32+14 +1); out[0*32+15] = start + ((w5 >> 10) & 0x3fffff)+(0*32+15 +1); out[0*32+16] = start + ((w5 >> 32) & 0x3fffff)+(0*32+16 +1); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*32+17] = start + ((w5 >> 54) | (w6 << 10) & 0x3fffff)+(0*32+17 +1); out[0*32+18] = start + ((w6 >> 12) & 0x3fffff)+(0*32+18 +1); out[0*32+19] = start + ((w6 >> 34) & 0x3fffff)+(0*32+19 +1); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*32+20] = start + ((w6 >> 56) | (w7 << 8) & 0x3fffff)+(0*32+20 +1); out[0*32+21] = start + ((w7 >> 14) & 0x3fffff)+(0*32+21 +1); out[0*32+22] = start + ((w7 >> 36) & 0x3fffff)+(0*32+22 +1); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*32+23] = start + ((w7 >> 58) | (w8 << 6) & 0x3fffff)+(0*32+23 +1); out[0*32+24] = start + ((w8 >> 16) & 0x3fffff)+(0*32+24 +1); out[0*32+25] = start + ((w8 >> 38) & 0x3fffff)+(0*32+25 +1); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*32+26] = start + ((w8 >> 60) | (w9 << 4) & 0x3fffff)+(0*32+26 +1); out[0*32+27] = start + ((w9 >> 18) & 0x3fffff)+(0*32+27 +1); out[0*32+28] = start + ((w9 >> 40) & 0x3fffff)+(0*32+28 +1); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*32+29] = start + ((w9 >> 62) | (w10 << 2) & 0x3fffff)+(0*32+29 +1); out[0*32+30] = start + ((w10 >> 20) & 0x3fffff)+(0*32+30 +1); out[0*32+31] = start + ((w10 >> 42))+(0*32+31 +1);;}; out += 32; start += 32; in += 22*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_23(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*23)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7fffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 23) & 0x7fffff)+(0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w0 >> 46) | (w1 << 18) & 0x7fffff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w1 >> 5) & 0x7fffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w1 >> 28) & 0x7fffff)+(0*64+ 4 +1); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w1 >> 51) | (w2 << 13) & 0x7fffff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w2 >> 10) & 0x7fffff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w2 >> 33) & 0x7fffff)+(0*64+ 7 +1); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w2 >> 56) | (w3 << 8) & 0x7fffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w3 >> 15) & 0x7fffff)+(0*64+ 9 +1); out[0*64+10] = start + ((w3 >> 38) & 0x7fffff)+(0*64+10 +1); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*64+11] = start + ((w3 >> 61) | (w4 << 3) & 0x7fffff)+(0*64+11 +1); out[0*64+12] = start + ((w4 >> 20) & 0x7fffff)+(0*64+12 +1); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*64+13] = start + ((w4 >> 43) | (w5 << 21) & 0x7fffff)+(0*64+13 +1); out[0*64+14] = start + ((w5 >> 2) & 0x7fffff)+(0*64+14 +1); out[0*64+15] = start + ((w5 >> 25) & 0x7fffff)+(0*64+15 +1); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*64+16] = start + ((w5 >> 48) | (w6 << 16) & 0x7fffff)+(0*64+16 +1); out[0*64+17] = start + ((w6 >> 7) & 0x7fffff)+(0*64+17 +1); out[0*64+18] = start + ((w6 >> 30) & 0x7fffff)+(0*64+18 +1); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*64+19] = start + ((w6 >> 53) | (w7 << 11) & 0x7fffff)+(0*64+19 +1); out[0*64+20] = start + ((w7 >> 12) & 0x7fffff)+(0*64+20 +1); out[0*64+21] = start + ((w7 >> 35) & 0x7fffff)+(0*64+21 +1); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*64+22] = start + ((w7 >> 58) | (w8 << 6) & 0x7fffff)+(0*64+22 +1); out[0*64+23] = start + ((w8 >> 17) & 0x7fffff)+(0*64+23 +1); out[0*64+24] = start + ((w8 >> 40) & 0x7fffff)+(0*64+24 +1); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*64+25] = start + ((w8 >> 63) | (w9 << 1) & 0x7fffff)+(0*64+25 +1); out[0*64+26] = start + ((w9 >> 22) & 0x7fffff)+(0*64+26 +1); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*64+27] = start + ((w9 >> 45) | (w10 << 19) & 0x7fffff)+(0*64+27 +1); out[0*64+28] = start + ((w10 >> 4) & 0x7fffff)+(0*64+28 +1); out[0*64+29] = start + ((w10 >> 27) & 0x7fffff)+(0*64+29 +1); w11 = *(uint32_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*64+30] = start + ((w10 >> 50) | (w11 << 14) & 0x7fffff)+(0*64+30 +1); out[0*64+31] = start + ((w11 >> 9) & 0x7fffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 23*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_24(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*24)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*8+ 0] = start + ((w0 ) & 0xffffff)+(0*8+ 0 +1); out[0*8+ 1] = start + ((w0 >> 24) & 0xffffff)+(0*8+ 1 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*8+ 2] = start + ((w0 >> 48) | (w1 << 16) & 0xffffff)+(0*8+ 2 +1); out[0*8+ 3] = start + ((w1 >> 8) & 0xffffff)+(0*8+ 3 +1); out[0*8+ 4] = start + ((w1 >> 32) & 0xffffff)+(0*8+ 4 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*8+ 5] = start + ((w1 >> 56) | (w2 << 8) & 0xffffff)+(0*8+ 5 +1); out[0*8+ 6] = start + ((w2 >> 16) & 0xffffff)+(0*8+ 6 +1); out[0*8+ 7] = start + ((w2 >> 40))+(0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*8+ 0] = start + ((w0 ) & 0xffffff)+(1*8+ 0 +1); out[1*8+ 1] = start + ((w0 >> 24) & 0xffffff)+(1*8+ 1 +1); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*8+ 2] = start + ((w0 >> 48) | (w1 << 16) & 0xffffff)+(1*8+ 2 +1); out[1*8+ 3] = start + ((w1 >> 8) & 0xffffff)+(1*8+ 3 +1); out[1*8+ 4] = start + ((w1 >> 32) & 0xffffff)+(1*8+ 4 +1); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*8+ 5] = start + ((w1 >> 56) | (w2 << 8) & 0xffffff)+(1*8+ 5 +1); out[1*8+ 6] = start + ((w2 >> 16) & 0xffffff)+(1*8+ 6 +1); out[1*8+ 7] = start + ((w2 >> 40))+(1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*8+ 0] = start + ((w0 ) & 0xffffff)+(2*8+ 0 +1); out[2*8+ 1] = start + ((w0 >> 24) & 0xffffff)+(2*8+ 1 +1); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*8+ 2] = start + ((w0 >> 48) | (w1 << 16) & 0xffffff)+(2*8+ 2 +1); out[2*8+ 3] = start + ((w1 >> 8) & 0xffffff)+(2*8+ 3 +1); out[2*8+ 4] = start + ((w1 >> 32) & 0xffffff)+(2*8+ 4 +1); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*8+ 5] = start + ((w1 >> 56) | (w2 << 8) & 0xffffff)+(2*8+ 5 +1); out[2*8+ 6] = start + ((w2 >> 16) & 0xffffff)+(2*8+ 6 +1); out[2*8+ 7] = start + ((w2 >> 40))+(2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*8+ 0] = start + ((w0 ) & 0xffffff)+(3*8+ 0 +1); out[3*8+ 1] = start + ((w0 >> 24) & 0xffffff)+(3*8+ 1 +1); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*8+ 2] = start + ((w0 >> 48) | (w1 << 16) & 0xffffff)+(3*8+ 2 +1); out[3*8+ 3] = start + ((w1 >> 8) & 0xffffff)+(3*8+ 3 +1); out[3*8+ 4] = start + ((w1 >> 32) & 0xffffff)+(3*8+ 4 +1); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*8+ 5] = start + ((w1 >> 56) | (w2 << 8) & 0xffffff)+(3*8+ 5 +1); out[3*8+ 6] = start + ((w2 >> 16) & 0xffffff)+(3*8+ 6 +1); out[3*8+ 7] = start + ((w2 >> 40))+(3*8+ 7 +1);;}; out += 32; start += 32; in += 24*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_25(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*25)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1ffffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 25) & 0x1ffffff)+(0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w0 >> 50) | (w1 << 14) & 0x1ffffff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w1 >> 11) & 0x1ffffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w1 >> 36) & 0x1ffffff)+(0*64+ 4 +1); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w1 >> 61) | (w2 << 3) & 0x1ffffff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w2 >> 22) & 0x1ffffff)+(0*64+ 6 +1); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w2 >> 47) | (w3 << 17) & 0x1ffffff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w3 >> 8) & 0x1ffffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w3 >> 33) & 0x1ffffff)+(0*64+ 9 +1); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*64+10] = start + ((w3 >> 58) | (w4 << 6) & 0x1ffffff)+(0*64+10 +1); out[0*64+11] = start + ((w4 >> 19) & 0x1ffffff)+(0*64+11 +1); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*64+12] = start + ((w4 >> 44) | (w5 << 20) & 0x1ffffff)+(0*64+12 +1); out[0*64+13] = start + ((w5 >> 5) & 0x1ffffff)+(0*64+13 +1); out[0*64+14] = start + ((w5 >> 30) & 0x1ffffff)+(0*64+14 +1); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*64+15] = start + ((w5 >> 55) | (w6 << 9) & 0x1ffffff)+(0*64+15 +1); out[0*64+16] = start + ((w6 >> 16) & 0x1ffffff)+(0*64+16 +1); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*64+17] = start + ((w6 >> 41) | (w7 << 23) & 0x1ffffff)+(0*64+17 +1); out[0*64+18] = start + ((w7 >> 2) & 0x1ffffff)+(0*64+18 +1); out[0*64+19] = start + ((w7 >> 27) & 0x1ffffff)+(0*64+19 +1); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*64+20] = start + ((w7 >> 52) | (w8 << 12) & 0x1ffffff)+(0*64+20 +1); out[0*64+21] = start + ((w8 >> 13) & 0x1ffffff)+(0*64+21 +1); out[0*64+22] = start + ((w8 >> 38) & 0x1ffffff)+(0*64+22 +1); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*64+23] = start + ((w8 >> 63) | (w9 << 1) & 0x1ffffff)+(0*64+23 +1); out[0*64+24] = start + ((w9 >> 24) & 0x1ffffff)+(0*64+24 +1); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*64+25] = start + ((w9 >> 49) | (w10 << 15) & 0x1ffffff)+(0*64+25 +1); out[0*64+26] = start + ((w10 >> 10) & 0x1ffffff)+(0*64+26 +1); out[0*64+27] = start + ((w10 >> 35) & 0x1ffffff)+(0*64+27 +1); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*64+28] = start + ((w10 >> 60) | (w11 << 4) & 0x1ffffff)+(0*64+28 +1); out[0*64+29] = start + ((w11 >> 21) & 0x1ffffff)+(0*64+29 +1); w12 = *(uint32_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*64+30] = start + ((w11 >> 46) | (w12 << 18) & 0x1ffffff)+(0*64+30 +1); out[0*64+31] = start + ((w12 >> 7) & 0x1ffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 25*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_26(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*26)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3ffffff)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 26) & 0x3ffffff)+(0*32+ 1 +1); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*32+ 2] = start + ((w0 >> 52) | (w1 << 12) & 0x3ffffff)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w1 >> 14) & 0x3ffffff)+(0*32+ 3 +1); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*32+ 4] = start + ((w1 >> 40) | (w2 << 24) & 0x3ffffff)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w2 >> 2) & 0x3ffffff)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w2 >> 28) & 0x3ffffff)+(0*32+ 6 +1); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*32+ 7] = start + ((w2 >> 54) | (w3 << 10) & 0x3ffffff)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w3 >> 16) & 0x3ffffff)+(0*32+ 8 +1); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*32+ 9] = start + ((w3 >> 42) | (w4 << 22) & 0x3ffffff)+(0*32+ 9 +1); out[0*32+10] = start + ((w4 >> 4) & 0x3ffffff)+(0*32+10 +1); out[0*32+11] = start + ((w4 >> 30) & 0x3ffffff)+(0*32+11 +1); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*32+12] = start + ((w4 >> 56) | (w5 << 8) & 0x3ffffff)+(0*32+12 +1); out[0*32+13] = start + ((w5 >> 18) & 0x3ffffff)+(0*32+13 +1); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*32+14] = start + ((w5 >> 44) | (w6 << 20) & 0x3ffffff)+(0*32+14 +1); out[0*32+15] = start + ((w6 >> 6) & 0x3ffffff)+(0*32+15 +1); out[0*32+16] = start + ((w6 >> 32) & 0x3ffffff)+(0*32+16 +1); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*32+17] = start + ((w6 >> 58) | (w7 << 6) & 0x3ffffff)+(0*32+17 +1); out[0*32+18] = start + ((w7 >> 20) & 0x3ffffff)+(0*32+18 +1); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*32+19] = start + ((w7 >> 46) | (w8 << 18) & 0x3ffffff)+(0*32+19 +1); out[0*32+20] = start + ((w8 >> 8) & 0x3ffffff)+(0*32+20 +1); out[0*32+21] = start + ((w8 >> 34) & 0x3ffffff)+(0*32+21 +1); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*32+22] = start + ((w8 >> 60) | (w9 << 4) & 0x3ffffff)+(0*32+22 +1); out[0*32+23] = start + ((w9 >> 22) & 0x3ffffff)+(0*32+23 +1); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*32+24] = start + ((w9 >> 48) | (w10 << 16) & 0x3ffffff)+(0*32+24 +1); out[0*32+25] = start + ((w10 >> 10) & 0x3ffffff)+(0*32+25 +1); out[0*32+26] = start + ((w10 >> 36) & 0x3ffffff)+(0*32+26 +1); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*32+27] = start + ((w10 >> 62) | (w11 << 2) & 0x3ffffff)+(0*32+27 +1); out[0*32+28] = start + ((w11 >> 24) & 0x3ffffff)+(0*32+28 +1); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*32+29] = start + ((w11 >> 50) | (w12 << 14) & 0x3ffffff)+(0*32+29 +1); out[0*32+30] = start + ((w12 >> 12) & 0x3ffffff)+(0*32+30 +1); out[0*32+31] = start + ((w12 >> 38))+(0*32+31 +1);;}; out += 32; start += 32; in += 26*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_27(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*27)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7ffffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 27) & 0x7ffffff)+(0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w0 >> 54) | (w1 << 10) & 0x7ffffff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w1 >> 17) & 0x7ffffff)+(0*64+ 3 +1); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w1 >> 44) | (w2 << 20) & 0x7ffffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w2 >> 7) & 0x7ffffff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w2 >> 34) & 0x7ffffff)+(0*64+ 6 +1); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w2 >> 61) | (w3 << 3) & 0x7ffffff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w3 >> 24) & 0x7ffffff)+(0*64+ 8 +1); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w3 >> 51) | (w4 << 13) & 0x7ffffff)+(0*64+ 9 +1); out[0*64+10] = start + ((w4 >> 14) & 0x7ffffff)+(0*64+10 +1); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*64+11] = start + ((w4 >> 41) | (w5 << 23) & 0x7ffffff)+(0*64+11 +1); out[0*64+12] = start + ((w5 >> 4) & 0x7ffffff)+(0*64+12 +1); out[0*64+13] = start + ((w5 >> 31) & 0x7ffffff)+(0*64+13 +1); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*64+14] = start + ((w5 >> 58) | (w6 << 6) & 0x7ffffff)+(0*64+14 +1); out[0*64+15] = start + ((w6 >> 21) & 0x7ffffff)+(0*64+15 +1); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*64+16] = start + ((w6 >> 48) | (w7 << 16) & 0x7ffffff)+(0*64+16 +1); out[0*64+17] = start + ((w7 >> 11) & 0x7ffffff)+(0*64+17 +1); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*64+18] = start + ((w7 >> 38) | (w8 << 26) & 0x7ffffff)+(0*64+18 +1); out[0*64+19] = start + ((w8 >> 1) & 0x7ffffff)+(0*64+19 +1); out[0*64+20] = start + ((w8 >> 28) & 0x7ffffff)+(0*64+20 +1); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*64+21] = start + ((w8 >> 55) | (w9 << 9) & 0x7ffffff)+(0*64+21 +1); out[0*64+22] = start + ((w9 >> 18) & 0x7ffffff)+(0*64+22 +1); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*64+23] = start + ((w9 >> 45) | (w10 << 19) & 0x7ffffff)+(0*64+23 +1); out[0*64+24] = start + ((w10 >> 8) & 0x7ffffff)+(0*64+24 +1); out[0*64+25] = start + ((w10 >> 35) & 0x7ffffff)+(0*64+25 +1); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*64+26] = start + ((w10 >> 62) | (w11 << 2) & 0x7ffffff)+(0*64+26 +1); out[0*64+27] = start + ((w11 >> 25) & 0x7ffffff)+(0*64+27 +1); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*64+28] = start + ((w11 >> 52) | (w12 << 12) & 0x7ffffff)+(0*64+28 +1); out[0*64+29] = start + ((w12 >> 15) & 0x7ffffff)+(0*64+29 +1); w13 = *(uint32_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*64+30] = start + ((w12 >> 42) | (w13 << 22) & 0x7ffffff)+(0*64+30 +1); out[0*64+31] = start + ((w13 >> 5) & 0x7ffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 27*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_28(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*28)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xfffffff)+(0*16+ 0 +1); out[0*16+ 1] = start + ((w0 >> 28) & 0xfffffff)+(0*16+ 1 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*16+ 2] = start + ((w0 >> 56) | (w1 << 8) & 0xfffffff)+(0*16+ 2 +1); out[0*16+ 3] = start + ((w1 >> 20) & 0xfffffff)+(0*16+ 3 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*16+ 4] = start + ((w1 >> 48) | (w2 << 16) & 0xfffffff)+(0*16+ 4 +1); out[0*16+ 5] = start + ((w2 >> 12) & 0xfffffff)+(0*16+ 5 +1); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*16+ 6] = start + ((w2 >> 40) | (w3 << 24) & 0xfffffff)+(0*16+ 6 +1); out[0*16+ 7] = start + ((w3 >> 4) & 0xfffffff)+(0*16+ 7 +1); out[0*16+ 8] = start + ((w3 >> 32) & 0xfffffff)+(0*16+ 8 +1); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*16+ 9] = start + ((w3 >> 60) | (w4 << 4) & 0xfffffff)+(0*16+ 9 +1); out[0*16+10] = start + ((w4 >> 24) & 0xfffffff)+(0*16+10 +1); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*16+11] = start + ((w4 >> 52) | (w5 << 12) & 0xfffffff)+(0*16+11 +1); out[0*16+12] = start + ((w5 >> 16) & 0xfffffff)+(0*16+12 +1); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*16+13] = start + ((w5 >> 44) | (w6 << 20) & 0xfffffff)+(0*16+13 +1); out[0*16+14] = start + ((w6 >> 8) & 0xfffffff)+(0*16+14 +1); out[0*16+15] = start + ((w6 >> 36))+(0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xfffffff)+(1*16+ 0 +1); out[1*16+ 1] = start + ((w0 >> 28) & 0xfffffff)+(1*16+ 1 +1); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*16+ 2] = start + ((w0 >> 56) | (w1 << 8) & 0xfffffff)+(1*16+ 2 +1); out[1*16+ 3] = start + ((w1 >> 20) & 0xfffffff)+(1*16+ 3 +1); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*16+ 4] = start + ((w1 >> 48) | (w2 << 16) & 0xfffffff)+(1*16+ 4 +1); out[1*16+ 5] = start + ((w2 >> 12) & 0xfffffff)+(1*16+ 5 +1); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*16+ 6] = start + ((w2 >> 40) | (w3 << 24) & 0xfffffff)+(1*16+ 6 +1); out[1*16+ 7] = start + ((w3 >> 4) & 0xfffffff)+(1*16+ 7 +1); out[1*16+ 8] = start + ((w3 >> 32) & 0xfffffff)+(1*16+ 8 +1); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*16+ 9] = start + ((w3 >> 60) | (w4 << 4) & 0xfffffff)+(1*16+ 9 +1); out[1*16+10] = start + ((w4 >> 24) & 0xfffffff)+(1*16+10 +1); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*16+11] = start + ((w4 >> 52) | (w5 << 12) & 0xfffffff)+(1*16+11 +1); out[1*16+12] = start + ((w5 >> 16) & 0xfffffff)+(1*16+12 +1); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*16+13] = start + ((w5 >> 44) | (w6 << 20) & 0xfffffff)+(1*16+13 +1); out[1*16+14] = start + ((w6 >> 8) & 0xfffffff)+(1*16+14 +1); out[1*16+15] = start + ((w6 >> 36))+(1*16+15 +1);;}; out += 32; start += 32; in += 28*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_29(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*29)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1fffffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 29) & 0x1fffffff)+(0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w0 >> 58) | (w1 << 6) & 0x1fffffff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w1 >> 23) & 0x1fffffff)+(0*64+ 3 +1); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w1 >> 52) | (w2 << 12) & 0x1fffffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w2 >> 17) & 0x1fffffff)+(0*64+ 5 +1); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w2 >> 46) | (w3 << 18) & 0x1fffffff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w3 >> 11) & 0x1fffffff)+(0*64+ 7 +1); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w3 >> 40) | (w4 << 24) & 0x1fffffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w4 >> 5) & 0x1fffffff)+(0*64+ 9 +1); out[0*64+10] = start + ((w4 >> 34) & 0x1fffffff)+(0*64+10 +1); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*64+11] = start + ((w4 >> 63) | (w5 << 1) & 0x1fffffff)+(0*64+11 +1); out[0*64+12] = start + ((w5 >> 28) & 0x1fffffff)+(0*64+12 +1); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*64+13] = start + ((w5 >> 57) | (w6 << 7) & 0x1fffffff)+(0*64+13 +1); out[0*64+14] = start + ((w6 >> 22) & 0x1fffffff)+(0*64+14 +1); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*64+15] = start + ((w6 >> 51) | (w7 << 13) & 0x1fffffff)+(0*64+15 +1); out[0*64+16] = start + ((w7 >> 16) & 0x1fffffff)+(0*64+16 +1); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*64+17] = start + ((w7 >> 45) | (w8 << 19) & 0x1fffffff)+(0*64+17 +1); out[0*64+18] = start + ((w8 >> 10) & 0x1fffffff)+(0*64+18 +1); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*64+19] = start + ((w8 >> 39) | (w9 << 25) & 0x1fffffff)+(0*64+19 +1); out[0*64+20] = start + ((w9 >> 4) & 0x1fffffff)+(0*64+20 +1); out[0*64+21] = start + ((w9 >> 33) & 0x1fffffff)+(0*64+21 +1); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*64+22] = start + ((w9 >> 62) | (w10 << 2) & 0x1fffffff)+(0*64+22 +1); out[0*64+23] = start + ((w10 >> 27) & 0x1fffffff)+(0*64+23 +1); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*64+24] = start + ((w10 >> 56) | (w11 << 8) & 0x1fffffff)+(0*64+24 +1); out[0*64+25] = start + ((w11 >> 21) & 0x1fffffff)+(0*64+25 +1); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*64+26] = start + ((w11 >> 50) | (w12 << 14) & 0x1fffffff)+(0*64+26 +1); out[0*64+27] = start + ((w12 >> 15) & 0x1fffffff)+(0*64+27 +1); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*64+28] = start + ((w12 >> 44) | (w13 << 20) & 0x1fffffff)+(0*64+28 +1); out[0*64+29] = start + ((w13 >> 9) & 0x1fffffff)+(0*64+29 +1); w14 = *(uint32_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*64+30] = start + ((w13 >> 38) | (w14 << 26) & 0x1fffffff)+(0*64+30 +1); out[0*64+31] = start + ((w14 >> 3) & 0x1fffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 29*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_30(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*30)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3fffffff)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 30) & 0x3fffffff)+(0*32+ 1 +1); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*32+ 2] = start + ((w0 >> 60) | (w1 << 4) & 0x3fffffff)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w1 >> 26) & 0x3fffffff)+(0*32+ 3 +1); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*32+ 4] = start + ((w1 >> 56) | (w2 << 8) & 0x3fffffff)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w2 >> 22) & 0x3fffffff)+(0*32+ 5 +1); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*32+ 6] = start + ((w2 >> 52) | (w3 << 12) & 0x3fffffff)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w3 >> 18) & 0x3fffffff)+(0*32+ 7 +1); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*32+ 8] = start + ((w3 >> 48) | (w4 << 16) & 0x3fffffff)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w4 >> 14) & 0x3fffffff)+(0*32+ 9 +1); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*32+10] = start + ((w4 >> 44) | (w5 << 20) & 0x3fffffff)+(0*32+10 +1); out[0*32+11] = start + ((w5 >> 10) & 0x3fffffff)+(0*32+11 +1); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*32+12] = start + ((w5 >> 40) | (w6 << 24) & 0x3fffffff)+(0*32+12 +1); out[0*32+13] = start + ((w6 >> 6) & 0x3fffffff)+(0*32+13 +1); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*32+14] = start + ((w6 >> 36) | (w7 << 28) & 0x3fffffff)+(0*32+14 +1); out[0*32+15] = start + ((w7 >> 2) & 0x3fffffff)+(0*32+15 +1); out[0*32+16] = start + ((w7 >> 32) & 0x3fffffff)+(0*32+16 +1); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*32+17] = start + ((w7 >> 62) | (w8 << 2) & 0x3fffffff)+(0*32+17 +1); out[0*32+18] = start + ((w8 >> 28) & 0x3fffffff)+(0*32+18 +1); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*32+19] = start + ((w8 >> 58) | (w9 << 6) & 0x3fffffff)+(0*32+19 +1); out[0*32+20] = start + ((w9 >> 24) & 0x3fffffff)+(0*32+20 +1); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*32+21] = start + ((w9 >> 54) | (w10 << 10) & 0x3fffffff)+(0*32+21 +1); out[0*32+22] = start + ((w10 >> 20) & 0x3fffffff)+(0*32+22 +1); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*32+23] = start + ((w10 >> 50) | (w11 << 14) & 0x3fffffff)+(0*32+23 +1); out[0*32+24] = start + ((w11 >> 16) & 0x3fffffff)+(0*32+24 +1); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*32+25] = start + ((w11 >> 46) | (w12 << 18) & 0x3fffffff)+(0*32+25 +1); out[0*32+26] = start + ((w12 >> 12) & 0x3fffffff)+(0*32+26 +1); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*32+27] = start + ((w12 >> 42) | (w13 << 22) & 0x3fffffff)+(0*32+27 +1); out[0*32+28] = start + ((w13 >> 8) & 0x3fffffff)+(0*32+28 +1); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*32+29] = start + ((w13 >> 38) | (w14 << 26) & 0x3fffffff)+(0*32+29 +1); out[0*32+30] = start + ((w14 >> 4) & 0x3fffffff)+(0*32+30 +1); out[0*32+31] = start + ((w14 >> 34))+(0*32+31 +1);;}; out += 32; start += 32; in += 30*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_31(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*31)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7fffffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 31) & 0x7fffffff)+(0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w0 >> 62) | (w1 << 2) & 0x7fffffff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w1 >> 29) & 0x7fffffff)+(0*64+ 3 +1); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w1 >> 60) | (w2 << 4) & 0x7fffffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w2 >> 27) & 0x7fffffff)+(0*64+ 5 +1); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w2 >> 58) | (w3 << 6) & 0x7fffffff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w3 >> 25) & 0x7fffffff)+(0*64+ 7 +1); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w3 >> 56) | (w4 << 8) & 0x7fffffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w4 >> 23) & 0x7fffffff)+(0*64+ 9 +1); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*64+10] = start + ((w4 >> 54) | (w5 << 10) & 0x7fffffff)+(0*64+10 +1); out[0*64+11] = start + ((w5 >> 21) & 0x7fffffff)+(0*64+11 +1); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*64+12] = start + ((w5 >> 52) | (w6 << 12) & 0x7fffffff)+(0*64+12 +1); out[0*64+13] = start + ((w6 >> 19) & 0x7fffffff)+(0*64+13 +1); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*64+14] = start + ((w6 >> 50) | (w7 << 14) & 0x7fffffff)+(0*64+14 +1); out[0*64+15] = start + ((w7 >> 17) & 0x7fffffff)+(0*64+15 +1); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*64+16] = start + ((w7 >> 48) | (w8 << 16) & 0x7fffffff)+(0*64+16 +1); out[0*64+17] = start + ((w8 >> 15) & 0x7fffffff)+(0*64+17 +1); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*64+18] = start + ((w8 >> 46) | (w9 << 18) & 0x7fffffff)+(0*64+18 +1); out[0*64+19] = start + ((w9 >> 13) & 0x7fffffff)+(0*64+19 +1); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*64+20] = start + ((w9 >> 44) | (w10 << 20) & 0x7fffffff)+(0*64+20 +1); out[0*64+21] = start + ((w10 >> 11) & 0x7fffffff)+(0*64+21 +1); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*64+22] = start + ((w10 >> 42) | (w11 << 22) & 0x7fffffff)+(0*64+22 +1); out[0*64+23] = start + ((w11 >> 9) & 0x7fffffff)+(0*64+23 +1); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*64+24] = start + ((w11 >> 40) | (w12 << 24) & 0x7fffffff)+(0*64+24 +1); out[0*64+25] = start + ((w12 >> 7) & 0x7fffffff)+(0*64+25 +1); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*64+26] = start + ((w12 >> 38) | (w13 << 26) & 0x7fffffff)+(0*64+26 +1); out[0*64+27] = start + ((w13 >> 5) & 0x7fffffff)+(0*64+27 +1); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*64+28] = start + ((w13 >> 36) | (w14 << 28) & 0x7fffffff)+(0*64+28 +1); out[0*64+29] = start + ((w14 >> 3) & 0x7fffffff)+(0*64+29 +1); w15 = *(uint32_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*64+30] = start + ((w14 >> 34) | (w15 << 30) & 0x7fffffff)+(0*64+30 +1); out[0*64+31] = start + ((w15 >> 1) & 0x7fffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 31*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack32_32(const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start ) { unsigned char *in_=in+(((n*32)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[0*2+ 0] = start + (*(uint32_t *)(in+0*8+ 0))+(0*2+ 0 +1); out[0*2+ 1] = start + (*(uint32_t *)(in+0*8+ 4))+(0*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[1*2+ 0] = start + (*(uint32_t *)(in+1*8+ 0))+(1*2+ 0 +1); out[1*2+ 1] = start + (*(uint32_t *)(in+1*8+ 4))+(1*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[2*2+ 0] = start + (*(uint32_t *)(in+2*8+ 0))+(2*2+ 0 +1); out[2*2+ 1] = start + (*(uint32_t *)(in+2*8+ 4))+(2*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[3*2+ 0] = start + (*(uint32_t *)(in+3*8+ 0))+(3*2+ 0 +1); out[3*2+ 1] = start + (*(uint32_t *)(in+3*8+ 4))+(3*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[4*2+ 0] = start + (*(uint32_t *)(in+4*8+ 0))+(4*2+ 0 +1); out[4*2+ 1] = start + (*(uint32_t *)(in+4*8+ 4))+(4*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[5*2+ 0] = start + (*(uint32_t *)(in+5*8+ 0))+(5*2+ 0 +1); out[5*2+ 1] = start + (*(uint32_t *)(in+5*8+ 4))+(5*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[6*2+ 0] = start + (*(uint32_t *)(in+6*8+ 0))+(6*2+ 0 +1); out[6*2+ 1] = start + (*(uint32_t *)(in+6*8+ 4))+(6*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[7*2+ 0] = start + (*(uint32_t *)(in+7*8+ 0))+(7*2+ 0 +1); out[7*2+ 1] = start + (*(uint32_t *)(in+7*8+ 4))+(7*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[8*2+ 0] = start + (*(uint32_t *)(in+8*8+ 0))+(8*2+ 0 +1); out[8*2+ 1] = start + (*(uint32_t *)(in+8*8+ 4))+(8*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[9*2+ 0] = start + (*(uint32_t *)(in+9*8+ 0))+(9*2+ 0 +1); out[9*2+ 1] = start + (*(uint32_t *)(in+9*8+ 4))+(9*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[10*2+ 0] = start + (*(uint32_t *)(in+10*8+ 0))+(10*2+ 0 +1); out[10*2+ 1] = start + (*(uint32_t *)(in+10*8+ 4))+(10*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[11*2+ 0] = start + (*(uint32_t *)(in+11*8+ 0))+(11*2+ 0 +1); out[11*2+ 1] = start + (*(uint32_t *)(in+11*8+ 4))+(11*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[12*2+ 0] = start + (*(uint32_t *)(in+12*8+ 0))+(12*2+ 0 +1); out[12*2+ 1] = start + (*(uint32_t *)(in+12*8+ 4))+(12*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[13*2+ 0] = start + (*(uint32_t *)(in+13*8+ 0))+(13*2+ 0 +1); out[13*2+ 1] = start + (*(uint32_t *)(in+13*8+ 4))+(13*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[14*2+ 0] = start + (*(uint32_t *)(in+14*8+ 0))+(14*2+ 0 +1); out[14*2+ 1] = start + (*(uint32_t *)(in+14*8+ 4))+(14*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[15*2+ 0] = start + (*(uint32_t *)(in+15*8+ 0))+(15*2+ 0 +1); out[15*2+ 1] = start + (*(uint32_t *)(in+15*8+ 4))+(15*2+ 1 +1);;}; out += 32; start += 32; in += 32*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D32 bitf1unpacka32[] = {
  &bitf1unpack32_0,
  &bitf1unpack32_1,
  &bitf1unpack32_2,
  &bitf1unpack32_3,
  &bitf1unpack32_4,
  &bitf1unpack32_5,
  &bitf1unpack32_6,
  &bitf1unpack32_7,
  &bitf1unpack32_8,
  &bitf1unpack32_9,
  &bitf1unpack32_10,
  &bitf1unpack32_11,
  &bitf1unpack32_12,
  &bitf1unpack32_13,
  &bitf1unpack32_14,
  &bitf1unpack32_15,
  &bitf1unpack32_16,
  &bitf1unpack32_17,
  &bitf1unpack32_18,
  &bitf1unpack32_19,
  &bitf1unpack32_20,
  &bitf1unpack32_21,
  &bitf1unpack32_22,
  &bitf1unpack32_23,
  &bitf1unpack32_24,
  &bitf1unpack32_25,
  &bitf1unpack32_26,
  &bitf1unpack32_27,
  &bitf1unpack32_28,
  &bitf1unpack32_29,
  &bitf1unpack32_30,
  &bitf1unpack32_31,
  &bitf1unpack32_32
};
unsigned char *bitf1unpack32( const unsigned char *__restrict in, unsigned n, uint32_t *__restrict out , uint32_t start, unsigned b) { return bitf1unpacka32[ b](in, n, out, start); }
unsigned char *bitf1unpack64_0(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*0)+7)/8),x=0; const uint64_t *out_ = out+n; do { { { out[0*0+ 0] = start + (0)+(0*0+ 0 +1); out[0*0+ 1] = start + (0)+(0*0+ 1 +1); out[0*0+ 2] = start + (0)+(0*0+ 2 +1); out[0*0+ 3] = start + (0)+(0*0+ 3 +1); out[0*0+ 4] = start + (0)+(0*0+ 4 +1); out[0*0+ 5] = start + (0)+(0*0+ 5 +1); out[0*0+ 6] = start + (0)+(0*0+ 6 +1); out[0*0+ 7] = start + (0)+(0*0+ 7 +1); out[0*0+ 8] = start + (0)+(0*0+ 8 +1); out[0*0+ 9] = start + (0)+(0*0+ 9 +1); out[0*0+10] = start + (0)+(0*0+10 +1); out[0*0+11] = start + (0)+(0*0+11 +1); out[0*0+12] = start + (0)+(0*0+12 +1); out[0*0+13] = start + (0)+(0*0+13 +1); out[0*0+14] = start + (0)+(0*0+14 +1); out[0*0+15] = start + (0)+(0*0+15 +1); out[0*0+16] = start + (0)+(0*0+16 +1); out[0*0+17] = start + (0)+(0*0+17 +1); out[0*0+18] = start + (0)+(0*0+18 +1); out[0*0+19] = start + (0)+(0*0+19 +1); out[0*0+20] = start + (0)+(0*0+20 +1); out[0*0+21] = start + (0)+(0*0+21 +1); out[0*0+22] = start + (0)+(0*0+22 +1); out[0*0+23] = start + (0)+(0*0+23 +1); out[0*0+24] = start + (0)+(0*0+24 +1); out[0*0+25] = start + (0)+(0*0+25 +1); out[0*0+26] = start + (0)+(0*0+26 +1); out[0*0+27] = start + (0)+(0*0+27 +1); out[0*0+28] = start + (0)+(0*0+28 +1); out[0*0+29] = start + (0)+(0*0+29 +1); out[0*0+30] = start + (0)+(0*0+30 +1); out[0*0+31] = start + (0)+(0*0+31 +1);;}; out += 32; start += 32;}; __builtin_prefetch(in+512,0); } while(out<out_); return in_; }
unsigned char *bitf1unpack64_1(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*1)+7)/8),x=0; do { { { uint32_t w0; w0 = *(uint32_t *)(in+(0*1+0)*4/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x1)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 1) & 0x1)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 2) & 0x1)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 3) & 0x1)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 4) & 0x1)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 5) & 0x1)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w0 >> 6) & 0x1)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w0 >> 7) & 0x1)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w0 >> 8) & 0x1)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w0 >> 9) & 0x1)+(0*32+ 9 +1); out[0*32+10] = start + ((w0 >> 10) & 0x1)+(0*32+10 +1); out[0*32+11] = start + ((w0 >> 11) & 0x1)+(0*32+11 +1); out[0*32+12] = start + ((w0 >> 12) & 0x1)+(0*32+12 +1); out[0*32+13] = start + ((w0 >> 13) & 0x1)+(0*32+13 +1); out[0*32+14] = start + ((w0 >> 14) & 0x1)+(0*32+14 +1); out[0*32+15] = start + ((w0 >> 15) & 0x1)+(0*32+15 +1); out[0*32+16] = start + ((w0 >> 16) & 0x1)+(0*32+16 +1); out[0*32+17] = start + ((w0 >> 17) & 0x1)+(0*32+17 +1); out[0*32+18] = start + ((w0 >> 18) & 0x1)+(0*32+18 +1); out[0*32+19] = start + ((w0 >> 19) & 0x1)+(0*32+19 +1); out[0*32+20] = start + ((w0 >> 20) & 0x1)+(0*32+20 +1); out[0*32+21] = start + ((w0 >> 21) & 0x1)+(0*32+21 +1); out[0*32+22] = start + ((w0 >> 22) & 0x1)+(0*32+22 +1); out[0*32+23] = start + ((w0 >> 23) & 0x1)+(0*32+23 +1); out[0*32+24] = start + ((w0 >> 24) & 0x1)+(0*32+24 +1); out[0*32+25] = start + ((w0 >> 25) & 0x1)+(0*32+25 +1); out[0*32+26] = start + ((w0 >> 26) & 0x1)+(0*32+26 +1); out[0*32+27] = start + ((w0 >> 27) & 0x1)+(0*32+27 +1); out[0*32+28] = start + ((w0 >> 28) & 0x1)+(0*32+28 +1); out[0*32+29] = start + ((w0 >> 29) & 0x1)+(0*32+29 +1); out[0*32+30] = start + ((w0 >> 30) & 0x1)+(0*32+30 +1); out[0*32+31] = start + ((w0 >> 31))+(0*32+31 +1);;}; out += 32; start += 32; in += 1*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_2(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*2)+7)/8),x=0; do { { { uint64_t w0; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 2) & 0x3)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 4) & 0x3)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 6) & 0x3)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 8) & 0x3)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 10) & 0x3)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w0 >> 12) & 0x3)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w0 >> 14) & 0x3)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w0 >> 16) & 0x3)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w0 >> 18) & 0x3)+(0*32+ 9 +1); out[0*32+10] = start + ((w0 >> 20) & 0x3)+(0*32+10 +1); out[0*32+11] = start + ((w0 >> 22) & 0x3)+(0*32+11 +1); out[0*32+12] = start + ((w0 >> 24) & 0x3)+(0*32+12 +1); out[0*32+13] = start + ((w0 >> 26) & 0x3)+(0*32+13 +1); out[0*32+14] = start + ((w0 >> 28) & 0x3)+(0*32+14 +1); out[0*32+15] = start + ((w0 >> 30) & 0x3)+(0*32+15 +1); out[0*32+16] = start + ((w0 >> 32) & 0x3)+(0*32+16 +1); out[0*32+17] = start + ((w0 >> 34) & 0x3)+(0*32+17 +1); out[0*32+18] = start + ((w0 >> 36) & 0x3)+(0*32+18 +1); out[0*32+19] = start + ((w0 >> 38) & 0x3)+(0*32+19 +1); out[0*32+20] = start + ((w0 >> 40) & 0x3)+(0*32+20 +1); out[0*32+21] = start + ((w0 >> 42) & 0x3)+(0*32+21 +1); out[0*32+22] = start + ((w0 >> 44) & 0x3)+(0*32+22 +1); out[0*32+23] = start + ((w0 >> 46) & 0x3)+(0*32+23 +1); out[0*32+24] = start + ((w0 >> 48) & 0x3)+(0*32+24 +1); out[0*32+25] = start + ((w0 >> 50) & 0x3)+(0*32+25 +1); out[0*32+26] = start + ((w0 >> 52) & 0x3)+(0*32+26 +1); out[0*32+27] = start + ((w0 >> 54) & 0x3)+(0*32+27 +1); out[0*32+28] = start + ((w0 >> 56) & 0x3)+(0*32+28 +1); out[0*32+29] = start + ((w0 >> 58) & 0x3)+(0*32+29 +1); out[0*32+30] = start + ((w0 >> 60) & 0x3)+(0*32+30 +1); out[0*32+31] = start + ((w0 >> 62))+(0*32+31 +1);;}; out += 32; start += 32; in += 2*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_3(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*3)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 3) & 0x7)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 6) & 0x7)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 9) & 0x7)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 12) & 0x7)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 15) & 0x7)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 18) & 0x7)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w0 >> 21) & 0x7)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w0 >> 24) & 0x7)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w0 >> 27) & 0x7)+(0*64+ 9 +1); out[0*64+10] = start + ((w0 >> 30) & 0x7)+(0*64+10 +1); out[0*64+11] = start + ((w0 >> 33) & 0x7)+(0*64+11 +1); out[0*64+12] = start + ((w0 >> 36) & 0x7)+(0*64+12 +1); out[0*64+13] = start + ((w0 >> 39) & 0x7)+(0*64+13 +1); out[0*64+14] = start + ((w0 >> 42) & 0x7)+(0*64+14 +1); out[0*64+15] = start + ((w0 >> 45) & 0x7)+(0*64+15 +1); out[0*64+16] = start + ((w0 >> 48) & 0x7)+(0*64+16 +1); out[0*64+17] = start + ((w0 >> 51) & 0x7)+(0*64+17 +1); out[0*64+18] = start + ((w0 >> 54) & 0x7)+(0*64+18 +1); out[0*64+19] = start + ((w0 >> 57) & 0x7)+(0*64+19 +1); out[0*64+20] = start + ((w0 >> 60) & 0x7)+(0*64+20 +1); w1 = *(uint32_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*64+21] = start + ((w0 >> 63) | (w1 << 1) & 0x7)+(0*64+21 +1); out[0*64+22] = start + ((w1 >> 2) & 0x7)+(0*64+22 +1); out[0*64+23] = start + ((w1 >> 5) & 0x7)+(0*64+23 +1); out[0*64+24] = start + ((w1 >> 8) & 0x7)+(0*64+24 +1); out[0*64+25] = start + ((w1 >> 11) & 0x7)+(0*64+25 +1); out[0*64+26] = start + ((w1 >> 14) & 0x7)+(0*64+26 +1); out[0*64+27] = start + ((w1 >> 17) & 0x7)+(0*64+27 +1); out[0*64+28] = start + ((w1 >> 20) & 0x7)+(0*64+28 +1); out[0*64+29] = start + ((w1 >> 23) & 0x7)+(0*64+29 +1); out[0*64+30] = start + ((w1 >> 26) & 0x7)+(0*64+30 +1); out[0*64+31] = start + ((w1 >> 29) & 0x7)+(0*64+31 +1);;}; out += 32; start += 32; in += 3*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_4(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*4)+7)/8),x=0; do { { { uint64_t w0,w1; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xf)+(0*16+ 0 +1); out[0*16+ 1] = start + ((w0 >> 4) & 0xf)+(0*16+ 1 +1); out[0*16+ 2] = start + ((w0 >> 8) & 0xf)+(0*16+ 2 +1); out[0*16+ 3] = start + ((w0 >> 12) & 0xf)+(0*16+ 3 +1); out[0*16+ 4] = start + ((w0 >> 16) & 0xf)+(0*16+ 4 +1); out[0*16+ 5] = start + ((w0 >> 20) & 0xf)+(0*16+ 5 +1); out[0*16+ 6] = start + ((w0 >> 24) & 0xf)+(0*16+ 6 +1); out[0*16+ 7] = start + ((w0 >> 28) & 0xf)+(0*16+ 7 +1); out[0*16+ 8] = start + ((w0 >> 32) & 0xf)+(0*16+ 8 +1); out[0*16+ 9] = start + ((w0 >> 36) & 0xf)+(0*16+ 9 +1); out[0*16+10] = start + ((w0 >> 40) & 0xf)+(0*16+10 +1); out[0*16+11] = start + ((w0 >> 44) & 0xf)+(0*16+11 +1); out[0*16+12] = start + ((w0 >> 48) & 0xf)+(0*16+12 +1); out[0*16+13] = start + ((w0 >> 52) & 0xf)+(0*16+13 +1); out[0*16+14] = start + ((w0 >> 56) & 0xf)+(0*16+14 +1); out[0*16+15] = start + ((w0 >> 60))+(0*16+15 +1);;}; { uint64_t w0,w1; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xf)+(1*16+ 0 +1); out[1*16+ 1] = start + ((w0 >> 4) & 0xf)+(1*16+ 1 +1); out[1*16+ 2] = start + ((w0 >> 8) & 0xf)+(1*16+ 2 +1); out[1*16+ 3] = start + ((w0 >> 12) & 0xf)+(1*16+ 3 +1); out[1*16+ 4] = start + ((w0 >> 16) & 0xf)+(1*16+ 4 +1); out[1*16+ 5] = start + ((w0 >> 20) & 0xf)+(1*16+ 5 +1); out[1*16+ 6] = start + ((w0 >> 24) & 0xf)+(1*16+ 6 +1); out[1*16+ 7] = start + ((w0 >> 28) & 0xf)+(1*16+ 7 +1); out[1*16+ 8] = start + ((w0 >> 32) & 0xf)+(1*16+ 8 +1); out[1*16+ 9] = start + ((w0 >> 36) & 0xf)+(1*16+ 9 +1); out[1*16+10] = start + ((w0 >> 40) & 0xf)+(1*16+10 +1); out[1*16+11] = start + ((w0 >> 44) & 0xf)+(1*16+11 +1); out[1*16+12] = start + ((w0 >> 48) & 0xf)+(1*16+12 +1); out[1*16+13] = start + ((w0 >> 52) & 0xf)+(1*16+13 +1); out[1*16+14] = start + ((w0 >> 56) & 0xf)+(1*16+14 +1); out[1*16+15] = start + ((w0 >> 60))+(1*16+15 +1);;}; out += 32; start += 32; in += 4*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_5(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*5)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1f)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 5) & 0x1f)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 10) & 0x1f)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 15) & 0x1f)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 20) & 0x1f)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 25) & 0x1f)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 30) & 0x1f)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w0 >> 35) & 0x1f)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w0 >> 40) & 0x1f)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w0 >> 45) & 0x1f)+(0*64+ 9 +1); out[0*64+10] = start + ((w0 >> 50) & 0x1f)+(0*64+10 +1); out[0*64+11] = start + ((w0 >> 55) & 0x1f)+(0*64+11 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*64+12] = start + ((w0 >> 60) | (w1 << 4) & 0x1f)+(0*64+12 +1); out[0*64+13] = start + ((w1 >> 1) & 0x1f)+(0*64+13 +1); out[0*64+14] = start + ((w1 >> 6) & 0x1f)+(0*64+14 +1); out[0*64+15] = start + ((w1 >> 11) & 0x1f)+(0*64+15 +1); out[0*64+16] = start + ((w1 >> 16) & 0x1f)+(0*64+16 +1); out[0*64+17] = start + ((w1 >> 21) & 0x1f)+(0*64+17 +1); out[0*64+18] = start + ((w1 >> 26) & 0x1f)+(0*64+18 +1); out[0*64+19] = start + ((w1 >> 31) & 0x1f)+(0*64+19 +1); out[0*64+20] = start + ((w1 >> 36) & 0x1f)+(0*64+20 +1); out[0*64+21] = start + ((w1 >> 41) & 0x1f)+(0*64+21 +1); out[0*64+22] = start + ((w1 >> 46) & 0x1f)+(0*64+22 +1); out[0*64+23] = start + ((w1 >> 51) & 0x1f)+(0*64+23 +1); out[0*64+24] = start + ((w1 >> 56) & 0x1f)+(0*64+24 +1); w2 = *(uint32_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*64+25] = start + ((w1 >> 61) | (w2 << 3) & 0x1f)+(0*64+25 +1); out[0*64+26] = start + ((w2 >> 2) & 0x1f)+(0*64+26 +1); out[0*64+27] = start + ((w2 >> 7) & 0x1f)+(0*64+27 +1); out[0*64+28] = start + ((w2 >> 12) & 0x1f)+(0*64+28 +1); out[0*64+29] = start + ((w2 >> 17) & 0x1f)+(0*64+29 +1); out[0*64+30] = start + ((w2 >> 22) & 0x1f)+(0*64+30 +1); out[0*64+31] = start + ((w2 >> 27) & 0x1f)+(0*64+31 +1);;}; out += 32; start += 32; in += 5*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_6(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*6)+7)/8),x=0; do { { { uint64_t w0,w1,w2; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3f)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 6) & 0x3f)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 12) & 0x3f)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 18) & 0x3f)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 24) & 0x3f)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 30) & 0x3f)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w0 >> 36) & 0x3f)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w0 >> 42) & 0x3f)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w0 >> 48) & 0x3f)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w0 >> 54) & 0x3f)+(0*32+ 9 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*32+10] = start + ((w0 >> 60) | (w1 << 4) & 0x3f)+(0*32+10 +1); out[0*32+11] = start + ((w1 >> 2) & 0x3f)+(0*32+11 +1); out[0*32+12] = start + ((w1 >> 8) & 0x3f)+(0*32+12 +1); out[0*32+13] = start + ((w1 >> 14) & 0x3f)+(0*32+13 +1); out[0*32+14] = start + ((w1 >> 20) & 0x3f)+(0*32+14 +1); out[0*32+15] = start + ((w1 >> 26) & 0x3f)+(0*32+15 +1); out[0*32+16] = start + ((w1 >> 32) & 0x3f)+(0*32+16 +1); out[0*32+17] = start + ((w1 >> 38) & 0x3f)+(0*32+17 +1); out[0*32+18] = start + ((w1 >> 44) & 0x3f)+(0*32+18 +1); out[0*32+19] = start + ((w1 >> 50) & 0x3f)+(0*32+19 +1); out[0*32+20] = start + ((w1 >> 56) & 0x3f)+(0*32+20 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*32+21] = start + ((w1 >> 62) | (w2 << 2) & 0x3f)+(0*32+21 +1); out[0*32+22] = start + ((w2 >> 4) & 0x3f)+(0*32+22 +1); out[0*32+23] = start + ((w2 >> 10) & 0x3f)+(0*32+23 +1); out[0*32+24] = start + ((w2 >> 16) & 0x3f)+(0*32+24 +1); out[0*32+25] = start + ((w2 >> 22) & 0x3f)+(0*32+25 +1); out[0*32+26] = start + ((w2 >> 28) & 0x3f)+(0*32+26 +1); out[0*32+27] = start + ((w2 >> 34) & 0x3f)+(0*32+27 +1); out[0*32+28] = start + ((w2 >> 40) & 0x3f)+(0*32+28 +1); out[0*32+29] = start + ((w2 >> 46) & 0x3f)+(0*32+29 +1); out[0*32+30] = start + ((w2 >> 52) & 0x3f)+(0*32+30 +1); out[0*32+31] = start + ((w2 >> 58))+(0*32+31 +1);;}; out += 32; start += 32; in += 6*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_7(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*7)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7f)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 7) & 0x7f)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 14) & 0x7f)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 21) & 0x7f)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 28) & 0x7f)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 35) & 0x7f)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 42) & 0x7f)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w0 >> 49) & 0x7f)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w0 >> 56) & 0x7f)+(0*64+ 8 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w0 >> 63) | (w1 << 1) & 0x7f)+(0*64+ 9 +1); out[0*64+10] = start + ((w1 >> 6) & 0x7f)+(0*64+10 +1); out[0*64+11] = start + ((w1 >> 13) & 0x7f)+(0*64+11 +1); out[0*64+12] = start + ((w1 >> 20) & 0x7f)+(0*64+12 +1); out[0*64+13] = start + ((w1 >> 27) & 0x7f)+(0*64+13 +1); out[0*64+14] = start + ((w1 >> 34) & 0x7f)+(0*64+14 +1); out[0*64+15] = start + ((w1 >> 41) & 0x7f)+(0*64+15 +1); out[0*64+16] = start + ((w1 >> 48) & 0x7f)+(0*64+16 +1); out[0*64+17] = start + ((w1 >> 55) & 0x7f)+(0*64+17 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*64+18] = start + ((w1 >> 62) | (w2 << 2) & 0x7f)+(0*64+18 +1); out[0*64+19] = start + ((w2 >> 5) & 0x7f)+(0*64+19 +1); out[0*64+20] = start + ((w2 >> 12) & 0x7f)+(0*64+20 +1); out[0*64+21] = start + ((w2 >> 19) & 0x7f)+(0*64+21 +1); out[0*64+22] = start + ((w2 >> 26) & 0x7f)+(0*64+22 +1); out[0*64+23] = start + ((w2 >> 33) & 0x7f)+(0*64+23 +1); out[0*64+24] = start + ((w2 >> 40) & 0x7f)+(0*64+24 +1); out[0*64+25] = start + ((w2 >> 47) & 0x7f)+(0*64+25 +1); out[0*64+26] = start + ((w2 >> 54) & 0x7f)+(0*64+26 +1); w3 = *(uint32_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*64+27] = start + ((w2 >> 61) | (w3 << 3) & 0x7f)+(0*64+27 +1); out[0*64+28] = start + ((w3 >> 4) & 0x7f)+(0*64+28 +1); out[0*64+29] = start + ((w3 >> 11) & 0x7f)+(0*64+29 +1); out[0*64+30] = start + ((w3 >> 18) & 0x7f)+(0*64+30 +1); out[0*64+31] = start + ((w3 >> 25) & 0x7f)+(0*64+31 +1);;}; out += 32; start += 32; in += 7*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_8(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*8)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*8+ 0] = start + ((w0 ) & 0xff)+(0*8+ 0 +1); out[0*8+ 1] = start + ((w0 >> 8) & 0xff)+(0*8+ 1 +1); out[0*8+ 2] = start + ((w0 >> 16) & 0xff)+(0*8+ 2 +1); out[0*8+ 3] = start + ((w0 >> 24) & 0xff)+(0*8+ 3 +1); out[0*8+ 4] = start + ((w0 >> 32) & 0xff)+(0*8+ 4 +1); out[0*8+ 5] = start + ((w0 >> 40) & 0xff)+(0*8+ 5 +1); out[0*8+ 6] = start + ((w0 >> 48) & 0xff)+(0*8+ 6 +1); out[0*8+ 7] = start + ((w0 >> 56))+(0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*8+ 0] = start + ((w0 ) & 0xff)+(1*8+ 0 +1); out[1*8+ 1] = start + ((w0 >> 8) & 0xff)+(1*8+ 1 +1); out[1*8+ 2] = start + ((w0 >> 16) & 0xff)+(1*8+ 2 +1); out[1*8+ 3] = start + ((w0 >> 24) & 0xff)+(1*8+ 3 +1); out[1*8+ 4] = start + ((w0 >> 32) & 0xff)+(1*8+ 4 +1); out[1*8+ 5] = start + ((w0 >> 40) & 0xff)+(1*8+ 5 +1); out[1*8+ 6] = start + ((w0 >> 48) & 0xff)+(1*8+ 6 +1); out[1*8+ 7] = start + ((w0 >> 56))+(1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*8+ 0] = start + ((w0 ) & 0xff)+(2*8+ 0 +1); out[2*8+ 1] = start + ((w0 >> 8) & 0xff)+(2*8+ 1 +1); out[2*8+ 2] = start + ((w0 >> 16) & 0xff)+(2*8+ 2 +1); out[2*8+ 3] = start + ((w0 >> 24) & 0xff)+(2*8+ 3 +1); out[2*8+ 4] = start + ((w0 >> 32) & 0xff)+(2*8+ 4 +1); out[2*8+ 5] = start + ((w0 >> 40) & 0xff)+(2*8+ 5 +1); out[2*8+ 6] = start + ((w0 >> 48) & 0xff)+(2*8+ 6 +1); out[2*8+ 7] = start + ((w0 >> 56))+(2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*8+ 0] = start + ((w0 ) & 0xff)+(3*8+ 0 +1); out[3*8+ 1] = start + ((w0 >> 8) & 0xff)+(3*8+ 1 +1); out[3*8+ 2] = start + ((w0 >> 16) & 0xff)+(3*8+ 2 +1); out[3*8+ 3] = start + ((w0 >> 24) & 0xff)+(3*8+ 3 +1); out[3*8+ 4] = start + ((w0 >> 32) & 0xff)+(3*8+ 4 +1); out[3*8+ 5] = start + ((w0 >> 40) & 0xff)+(3*8+ 5 +1); out[3*8+ 6] = start + ((w0 >> 48) & 0xff)+(3*8+ 6 +1); out[3*8+ 7] = start + ((w0 >> 56))+(3*8+ 7 +1);;}; out += 32; start += 32; in += 8*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_9(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*9)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1ff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 9) & 0x1ff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 18) & 0x1ff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 27) & 0x1ff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 36) & 0x1ff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w0 >> 45) & 0x1ff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w0 >> 54) & 0x1ff)+(0*64+ 6 +1); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w0 >> 63) | (w1 << 1) & 0x1ff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w1 >> 8) & 0x1ff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w1 >> 17) & 0x1ff)+(0*64+ 9 +1); out[0*64+10] = start + ((w1 >> 26) & 0x1ff)+(0*64+10 +1); out[0*64+11] = start + ((w1 >> 35) & 0x1ff)+(0*64+11 +1); out[0*64+12] = start + ((w1 >> 44) & 0x1ff)+(0*64+12 +1); out[0*64+13] = start + ((w1 >> 53) & 0x1ff)+(0*64+13 +1); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*64+14] = start + ((w1 >> 62) | (w2 << 2) & 0x1ff)+(0*64+14 +1); out[0*64+15] = start + ((w2 >> 7) & 0x1ff)+(0*64+15 +1); out[0*64+16] = start + ((w2 >> 16) & 0x1ff)+(0*64+16 +1); out[0*64+17] = start + ((w2 >> 25) & 0x1ff)+(0*64+17 +1); out[0*64+18] = start + ((w2 >> 34) & 0x1ff)+(0*64+18 +1); out[0*64+19] = start + ((w2 >> 43) & 0x1ff)+(0*64+19 +1); out[0*64+20] = start + ((w2 >> 52) & 0x1ff)+(0*64+20 +1); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*64+21] = start + ((w2 >> 61) | (w3 << 3) & 0x1ff)+(0*64+21 +1); out[0*64+22] = start + ((w3 >> 6) & 0x1ff)+(0*64+22 +1); out[0*64+23] = start + ((w3 >> 15) & 0x1ff)+(0*64+23 +1); out[0*64+24] = start + ((w3 >> 24) & 0x1ff)+(0*64+24 +1); out[0*64+25] = start + ((w3 >> 33) & 0x1ff)+(0*64+25 +1); out[0*64+26] = start + ((w3 >> 42) & 0x1ff)+(0*64+26 +1); out[0*64+27] = start + ((w3 >> 51) & 0x1ff)+(0*64+27 +1); w4 = *(uint32_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*64+28] = start + ((w3 >> 60) | (w4 << 4) & 0x1ff)+(0*64+28 +1); out[0*64+29] = start + ((w4 >> 5) & 0x1ff)+(0*64+29 +1); out[0*64+30] = start + ((w4 >> 14) & 0x1ff)+(0*64+30 +1); out[0*64+31] = start + ((w4 >> 23) & 0x1ff)+(0*64+31 +1);;}; out += 32; start += 32; in += 9*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_10(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*10)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3ff)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 10) & 0x3ff)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 20) & 0x3ff)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 30) & 0x3ff)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w0 >> 40) & 0x3ff)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w0 >> 50) & 0x3ff)+(0*32+ 5 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*32+ 6] = start + ((w0 >> 60) | (w1 << 4) & 0x3ff)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w1 >> 6) & 0x3ff)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w1 >> 16) & 0x3ff)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w1 >> 26) & 0x3ff)+(0*32+ 9 +1); out[0*32+10] = start + ((w1 >> 36) & 0x3ff)+(0*32+10 +1); out[0*32+11] = start + ((w1 >> 46) & 0x3ff)+(0*32+11 +1); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*32+12] = start + ((w1 >> 56) | (w2 << 8) & 0x3ff)+(0*32+12 +1); out[0*32+13] = start + ((w2 >> 2) & 0x3ff)+(0*32+13 +1); out[0*32+14] = start + ((w2 >> 12) & 0x3ff)+(0*32+14 +1); out[0*32+15] = start + ((w2 >> 22) & 0x3ff)+(0*32+15 +1); out[0*32+16] = start + ((w2 >> 32) & 0x3ff)+(0*32+16 +1); out[0*32+17] = start + ((w2 >> 42) & 0x3ff)+(0*32+17 +1); out[0*32+18] = start + ((w2 >> 52) & 0x3ff)+(0*32+18 +1); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*32+19] = start + ((w2 >> 62) | (w3 << 2) & 0x3ff)+(0*32+19 +1); out[0*32+20] = start + ((w3 >> 8) & 0x3ff)+(0*32+20 +1); out[0*32+21] = start + ((w3 >> 18) & 0x3ff)+(0*32+21 +1); out[0*32+22] = start + ((w3 >> 28) & 0x3ff)+(0*32+22 +1); out[0*32+23] = start + ((w3 >> 38) & 0x3ff)+(0*32+23 +1); out[0*32+24] = start + ((w3 >> 48) & 0x3ff)+(0*32+24 +1); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*32+25] = start + ((w3 >> 58) | (w4 << 6) & 0x3ff)+(0*32+25 +1); out[0*32+26] = start + ((w4 >> 4) & 0x3ff)+(0*32+26 +1); out[0*32+27] = start + ((w4 >> 14) & 0x3ff)+(0*32+27 +1); out[0*32+28] = start + ((w4 >> 24) & 0x3ff)+(0*32+28 +1); out[0*32+29] = start + ((w4 >> 34) & 0x3ff)+(0*32+29 +1); out[0*32+30] = start + ((w4 >> 44) & 0x3ff)+(0*32+30 +1); out[0*32+31] = start + ((w4 >> 54))+(0*32+31 +1);;}; out += 32; start += 32; in += 10*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_11(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*11)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7ff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 11) & 0x7ff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 22) & 0x7ff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 33) & 0x7ff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w0 >> 44) & 0x7ff)+(0*64+ 4 +1); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w0 >> 55) | (w1 << 9) & 0x7ff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w1 >> 2) & 0x7ff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w1 >> 13) & 0x7ff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w1 >> 24) & 0x7ff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w1 >> 35) & 0x7ff)+(0*64+ 9 +1); out[0*64+10] = start + ((w1 >> 46) & 0x7ff)+(0*64+10 +1); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*64+11] = start + ((w1 >> 57) | (w2 << 7) & 0x7ff)+(0*64+11 +1); out[0*64+12] = start + ((w2 >> 4) & 0x7ff)+(0*64+12 +1); out[0*64+13] = start + ((w2 >> 15) & 0x7ff)+(0*64+13 +1); out[0*64+14] = start + ((w2 >> 26) & 0x7ff)+(0*64+14 +1); out[0*64+15] = start + ((w2 >> 37) & 0x7ff)+(0*64+15 +1); out[0*64+16] = start + ((w2 >> 48) & 0x7ff)+(0*64+16 +1); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*64+17] = start + ((w2 >> 59) | (w3 << 5) & 0x7ff)+(0*64+17 +1); out[0*64+18] = start + ((w3 >> 6) & 0x7ff)+(0*64+18 +1); out[0*64+19] = start + ((w3 >> 17) & 0x7ff)+(0*64+19 +1); out[0*64+20] = start + ((w3 >> 28) & 0x7ff)+(0*64+20 +1); out[0*64+21] = start + ((w3 >> 39) & 0x7ff)+(0*64+21 +1); out[0*64+22] = start + ((w3 >> 50) & 0x7ff)+(0*64+22 +1); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*64+23] = start + ((w3 >> 61) | (w4 << 3) & 0x7ff)+(0*64+23 +1); out[0*64+24] = start + ((w4 >> 8) & 0x7ff)+(0*64+24 +1); out[0*64+25] = start + ((w4 >> 19) & 0x7ff)+(0*64+25 +1); out[0*64+26] = start + ((w4 >> 30) & 0x7ff)+(0*64+26 +1); out[0*64+27] = start + ((w4 >> 41) & 0x7ff)+(0*64+27 +1); out[0*64+28] = start + ((w4 >> 52) & 0x7ff)+(0*64+28 +1); w5 = *(uint32_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*64+29] = start + ((w4 >> 63) | (w5 << 1) & 0x7ff)+(0*64+29 +1); out[0*64+30] = start + ((w5 >> 10) & 0x7ff)+(0*64+30 +1); out[0*64+31] = start + ((w5 >> 21) & 0x7ff)+(0*64+31 +1);;}; out += 32; start += 32; in += 11*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_12(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*12)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xfff)+(0*16+ 0 +1); out[0*16+ 1] = start + ((w0 >> 12) & 0xfff)+(0*16+ 1 +1); out[0*16+ 2] = start + ((w0 >> 24) & 0xfff)+(0*16+ 2 +1); out[0*16+ 3] = start + ((w0 >> 36) & 0xfff)+(0*16+ 3 +1); out[0*16+ 4] = start + ((w0 >> 48) & 0xfff)+(0*16+ 4 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*16+ 5] = start + ((w0 >> 60) | (w1 << 4) & 0xfff)+(0*16+ 5 +1); out[0*16+ 6] = start + ((w1 >> 8) & 0xfff)+(0*16+ 6 +1); out[0*16+ 7] = start + ((w1 >> 20) & 0xfff)+(0*16+ 7 +1); out[0*16+ 8] = start + ((w1 >> 32) & 0xfff)+(0*16+ 8 +1); out[0*16+ 9] = start + ((w1 >> 44) & 0xfff)+(0*16+ 9 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*16+10] = start + ((w1 >> 56) | (w2 << 8) & 0xfff)+(0*16+10 +1); out[0*16+11] = start + ((w2 >> 4) & 0xfff)+(0*16+11 +1); out[0*16+12] = start + ((w2 >> 16) & 0xfff)+(0*16+12 +1); out[0*16+13] = start + ((w2 >> 28) & 0xfff)+(0*16+13 +1); out[0*16+14] = start + ((w2 >> 40) & 0xfff)+(0*16+14 +1); out[0*16+15] = start + ((w2 >> 52))+(0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xfff)+(1*16+ 0 +1); out[1*16+ 1] = start + ((w0 >> 12) & 0xfff)+(1*16+ 1 +1); out[1*16+ 2] = start + ((w0 >> 24) & 0xfff)+(1*16+ 2 +1); out[1*16+ 3] = start + ((w0 >> 36) & 0xfff)+(1*16+ 3 +1); out[1*16+ 4] = start + ((w0 >> 48) & 0xfff)+(1*16+ 4 +1); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*16+ 5] = start + ((w0 >> 60) | (w1 << 4) & 0xfff)+(1*16+ 5 +1); out[1*16+ 6] = start + ((w1 >> 8) & 0xfff)+(1*16+ 6 +1); out[1*16+ 7] = start + ((w1 >> 20) & 0xfff)+(1*16+ 7 +1); out[1*16+ 8] = start + ((w1 >> 32) & 0xfff)+(1*16+ 8 +1); out[1*16+ 9] = start + ((w1 >> 44) & 0xfff)+(1*16+ 9 +1); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*16+10] = start + ((w1 >> 56) | (w2 << 8) & 0xfff)+(1*16+10 +1); out[1*16+11] = start + ((w2 >> 4) & 0xfff)+(1*16+11 +1); out[1*16+12] = start + ((w2 >> 16) & 0xfff)+(1*16+12 +1); out[1*16+13] = start + ((w2 >> 28) & 0xfff)+(1*16+13 +1); out[1*16+14] = start + ((w2 >> 40) & 0xfff)+(1*16+14 +1); out[1*16+15] = start + ((w2 >> 52))+(1*16+15 +1);;}; out += 32; start += 32; in += 12*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_13(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*13)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1fff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 13) & 0x1fff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 26) & 0x1fff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 39) & 0x1fff)+(0*64+ 3 +1); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w0 >> 52) | (w1 << 12) & 0x1fff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w1 >> 1) & 0x1fff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w1 >> 14) & 0x1fff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w1 >> 27) & 0x1fff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w1 >> 40) & 0x1fff)+(0*64+ 8 +1); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w1 >> 53) | (w2 << 11) & 0x1fff)+(0*64+ 9 +1); out[0*64+10] = start + ((w2 >> 2) & 0x1fff)+(0*64+10 +1); out[0*64+11] = start + ((w2 >> 15) & 0x1fff)+(0*64+11 +1); out[0*64+12] = start + ((w2 >> 28) & 0x1fff)+(0*64+12 +1); out[0*64+13] = start + ((w2 >> 41) & 0x1fff)+(0*64+13 +1); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*64+14] = start + ((w2 >> 54) | (w3 << 10) & 0x1fff)+(0*64+14 +1); out[0*64+15] = start + ((w3 >> 3) & 0x1fff)+(0*64+15 +1); out[0*64+16] = start + ((w3 >> 16) & 0x1fff)+(0*64+16 +1); out[0*64+17] = start + ((w3 >> 29) & 0x1fff)+(0*64+17 +1); out[0*64+18] = start + ((w3 >> 42) & 0x1fff)+(0*64+18 +1); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*64+19] = start + ((w3 >> 55) | (w4 << 9) & 0x1fff)+(0*64+19 +1); out[0*64+20] = start + ((w4 >> 4) & 0x1fff)+(0*64+20 +1); out[0*64+21] = start + ((w4 >> 17) & 0x1fff)+(0*64+21 +1); out[0*64+22] = start + ((w4 >> 30) & 0x1fff)+(0*64+22 +1); out[0*64+23] = start + ((w4 >> 43) & 0x1fff)+(0*64+23 +1); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*64+24] = start + ((w4 >> 56) | (w5 << 8) & 0x1fff)+(0*64+24 +1); out[0*64+25] = start + ((w5 >> 5) & 0x1fff)+(0*64+25 +1); out[0*64+26] = start + ((w5 >> 18) & 0x1fff)+(0*64+26 +1); out[0*64+27] = start + ((w5 >> 31) & 0x1fff)+(0*64+27 +1); out[0*64+28] = start + ((w5 >> 44) & 0x1fff)+(0*64+28 +1); w6 = *(uint32_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*64+29] = start + ((w5 >> 57) | (w6 << 7) & 0x1fff)+(0*64+29 +1); out[0*64+30] = start + ((w6 >> 6) & 0x1fff)+(0*64+30 +1); out[0*64+31] = start + ((w6 >> 19) & 0x1fff)+(0*64+31 +1);;}; out += 32; start += 32; in += 13*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_14(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*14)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3fff)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 14) & 0x3fff)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 28) & 0x3fff)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w0 >> 42) & 0x3fff)+(0*32+ 3 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*32+ 4] = start + ((w0 >> 56) | (w1 << 8) & 0x3fff)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w1 >> 6) & 0x3fff)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w1 >> 20) & 0x3fff)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w1 >> 34) & 0x3fff)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w1 >> 48) & 0x3fff)+(0*32+ 8 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*32+ 9] = start + ((w1 >> 62) | (w2 << 2) & 0x3fff)+(0*32+ 9 +1); out[0*32+10] = start + ((w2 >> 12) & 0x3fff)+(0*32+10 +1); out[0*32+11] = start + ((w2 >> 26) & 0x3fff)+(0*32+11 +1); out[0*32+12] = start + ((w2 >> 40) & 0x3fff)+(0*32+12 +1); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*32+13] = start + ((w2 >> 54) | (w3 << 10) & 0x3fff)+(0*32+13 +1); out[0*32+14] = start + ((w3 >> 4) & 0x3fff)+(0*32+14 +1); out[0*32+15] = start + ((w3 >> 18) & 0x3fff)+(0*32+15 +1); out[0*32+16] = start + ((w3 >> 32) & 0x3fff)+(0*32+16 +1); out[0*32+17] = start + ((w3 >> 46) & 0x3fff)+(0*32+17 +1); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*32+18] = start + ((w3 >> 60) | (w4 << 4) & 0x3fff)+(0*32+18 +1); out[0*32+19] = start + ((w4 >> 10) & 0x3fff)+(0*32+19 +1); out[0*32+20] = start + ((w4 >> 24) & 0x3fff)+(0*32+20 +1); out[0*32+21] = start + ((w4 >> 38) & 0x3fff)+(0*32+21 +1); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*32+22] = start + ((w4 >> 52) | (w5 << 12) & 0x3fff)+(0*32+22 +1); out[0*32+23] = start + ((w5 >> 2) & 0x3fff)+(0*32+23 +1); out[0*32+24] = start + ((w5 >> 16) & 0x3fff)+(0*32+24 +1); out[0*32+25] = start + ((w5 >> 30) & 0x3fff)+(0*32+25 +1); out[0*32+26] = start + ((w5 >> 44) & 0x3fff)+(0*32+26 +1); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*32+27] = start + ((w5 >> 58) | (w6 << 6) & 0x3fff)+(0*32+27 +1); out[0*32+28] = start + ((w6 >> 8) & 0x3fff)+(0*32+28 +1); out[0*32+29] = start + ((w6 >> 22) & 0x3fff)+(0*32+29 +1); out[0*32+30] = start + ((w6 >> 36) & 0x3fff)+(0*32+30 +1); out[0*32+31] = start + ((w6 >> 50))+(0*32+31 +1);;}; out += 32; start += 32; in += 14*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_15(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*15)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7fff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 15) & 0x7fff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 30) & 0x7fff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w0 >> 45) & 0x7fff)+(0*64+ 3 +1); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w0 >> 60) | (w1 << 4) & 0x7fff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w1 >> 11) & 0x7fff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w1 >> 26) & 0x7fff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w1 >> 41) & 0x7fff)+(0*64+ 7 +1); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w1 >> 56) | (w2 << 8) & 0x7fff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w2 >> 7) & 0x7fff)+(0*64+ 9 +1); out[0*64+10] = start + ((w2 >> 22) & 0x7fff)+(0*64+10 +1); out[0*64+11] = start + ((w2 >> 37) & 0x7fff)+(0*64+11 +1); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*64+12] = start + ((w2 >> 52) | (w3 << 12) & 0x7fff)+(0*64+12 +1); out[0*64+13] = start + ((w3 >> 3) & 0x7fff)+(0*64+13 +1); out[0*64+14] = start + ((w3 >> 18) & 0x7fff)+(0*64+14 +1); out[0*64+15] = start + ((w3 >> 33) & 0x7fff)+(0*64+15 +1); out[0*64+16] = start + ((w3 >> 48) & 0x7fff)+(0*64+16 +1); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*64+17] = start + ((w3 >> 63) | (w4 << 1) & 0x7fff)+(0*64+17 +1); out[0*64+18] = start + ((w4 >> 14) & 0x7fff)+(0*64+18 +1); out[0*64+19] = start + ((w4 >> 29) & 0x7fff)+(0*64+19 +1); out[0*64+20] = start + ((w4 >> 44) & 0x7fff)+(0*64+20 +1); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*64+21] = start + ((w4 >> 59) | (w5 << 5) & 0x7fff)+(0*64+21 +1); out[0*64+22] = start + ((w5 >> 10) & 0x7fff)+(0*64+22 +1); out[0*64+23] = start + ((w5 >> 25) & 0x7fff)+(0*64+23 +1); out[0*64+24] = start + ((w5 >> 40) & 0x7fff)+(0*64+24 +1); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*64+25] = start + ((w5 >> 55) | (w6 << 9) & 0x7fff)+(0*64+25 +1); out[0*64+26] = start + ((w6 >> 6) & 0x7fff)+(0*64+26 +1); out[0*64+27] = start + ((w6 >> 21) & 0x7fff)+(0*64+27 +1); out[0*64+28] = start + ((w6 >> 36) & 0x7fff)+(0*64+28 +1); w7 = *(uint32_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*64+29] = start + ((w6 >> 51) | (w7 << 13) & 0x7fff)+(0*64+29 +1); out[0*64+30] = start + ((w7 >> 2) & 0x7fff)+(0*64+30 +1); out[0*64+31] = start + ((w7 >> 17) & 0x7fff)+(0*64+31 +1);;}; out += 32; start += 32; in += 15*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_16(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*16)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[0*4+ 0] = start + (*(uint16_t *)(in+0*8+ 0))+(0*4+ 0 +1); out[0*4+ 1] = start + (*(uint16_t *)(in+0*8+ 2))+(0*4+ 1 +1); out[0*4+ 2] = start + (*(uint16_t *)(in+0*8+ 4))+(0*4+ 2 +1); out[0*4+ 3] = start + (*(uint16_t *)(in+0*8+ 6))+(0*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[1*4+ 0] = start + (*(uint16_t *)(in+1*8+ 0))+(1*4+ 0 +1); out[1*4+ 1] = start + (*(uint16_t *)(in+1*8+ 2))+(1*4+ 1 +1); out[1*4+ 2] = start + (*(uint16_t *)(in+1*8+ 4))+(1*4+ 2 +1); out[1*4+ 3] = start + (*(uint16_t *)(in+1*8+ 6))+(1*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[2*4+ 0] = start + (*(uint16_t *)(in+2*8+ 0))+(2*4+ 0 +1); out[2*4+ 1] = start + (*(uint16_t *)(in+2*8+ 2))+(2*4+ 1 +1); out[2*4+ 2] = start + (*(uint16_t *)(in+2*8+ 4))+(2*4+ 2 +1); out[2*4+ 3] = start + (*(uint16_t *)(in+2*8+ 6))+(2*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[3*4+ 0] = start + (*(uint16_t *)(in+3*8+ 0))+(3*4+ 0 +1); out[3*4+ 1] = start + (*(uint16_t *)(in+3*8+ 2))+(3*4+ 1 +1); out[3*4+ 2] = start + (*(uint16_t *)(in+3*8+ 4))+(3*4+ 2 +1); out[3*4+ 3] = start + (*(uint16_t *)(in+3*8+ 6))+(3*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[4*4+ 0] = start + (*(uint16_t *)(in+4*8+ 0))+(4*4+ 0 +1); out[4*4+ 1] = start + (*(uint16_t *)(in+4*8+ 2))+(4*4+ 1 +1); out[4*4+ 2] = start + (*(uint16_t *)(in+4*8+ 4))+(4*4+ 2 +1); out[4*4+ 3] = start + (*(uint16_t *)(in+4*8+ 6))+(4*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[5*4+ 0] = start + (*(uint16_t *)(in+5*8+ 0))+(5*4+ 0 +1); out[5*4+ 1] = start + (*(uint16_t *)(in+5*8+ 2))+(5*4+ 1 +1); out[5*4+ 2] = start + (*(uint16_t *)(in+5*8+ 4))+(5*4+ 2 +1); out[5*4+ 3] = start + (*(uint16_t *)(in+5*8+ 6))+(5*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[6*4+ 0] = start + (*(uint16_t *)(in+6*8+ 0))+(6*4+ 0 +1); out[6*4+ 1] = start + (*(uint16_t *)(in+6*8+ 2))+(6*4+ 1 +1); out[6*4+ 2] = start + (*(uint16_t *)(in+6*8+ 4))+(6*4+ 2 +1); out[6*4+ 3] = start + (*(uint16_t *)(in+6*8+ 6))+(6*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7; out[7*4+ 0] = start + (*(uint16_t *)(in+7*8+ 0))+(7*4+ 0 +1); out[7*4+ 1] = start + (*(uint16_t *)(in+7*8+ 2))+(7*4+ 1 +1); out[7*4+ 2] = start + (*(uint16_t *)(in+7*8+ 4))+(7*4+ 2 +1); out[7*4+ 3] = start + (*(uint16_t *)(in+7*8+ 6))+(7*4+ 3 +1);;}; out += 32; start += 32; in += 16*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_17(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*17)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1ffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 17) & 0x1ffff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 34) & 0x1ffff)+(0*64+ 2 +1); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w0 >> 51) | (w1 << 13) & 0x1ffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w1 >> 4) & 0x1ffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w1 >> 21) & 0x1ffff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w1 >> 38) & 0x1ffff)+(0*64+ 6 +1); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w1 >> 55) | (w2 << 9) & 0x1ffff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w2 >> 8) & 0x1ffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w2 >> 25) & 0x1ffff)+(0*64+ 9 +1); out[0*64+10] = start + ((w2 >> 42) & 0x1ffff)+(0*64+10 +1); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*64+11] = start + ((w2 >> 59) | (w3 << 5) & 0x1ffff)+(0*64+11 +1); out[0*64+12] = start + ((w3 >> 12) & 0x1ffff)+(0*64+12 +1); out[0*64+13] = start + ((w3 >> 29) & 0x1ffff)+(0*64+13 +1); out[0*64+14] = start + ((w3 >> 46) & 0x1ffff)+(0*64+14 +1); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*64+15] = start + ((w3 >> 63) | (w4 << 1) & 0x1ffff)+(0*64+15 +1); out[0*64+16] = start + ((w4 >> 16) & 0x1ffff)+(0*64+16 +1); out[0*64+17] = start + ((w4 >> 33) & 0x1ffff)+(0*64+17 +1); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*64+18] = start + ((w4 >> 50) | (w5 << 14) & 0x1ffff)+(0*64+18 +1); out[0*64+19] = start + ((w5 >> 3) & 0x1ffff)+(0*64+19 +1); out[0*64+20] = start + ((w5 >> 20) & 0x1ffff)+(0*64+20 +1); out[0*64+21] = start + ((w5 >> 37) & 0x1ffff)+(0*64+21 +1); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*64+22] = start + ((w5 >> 54) | (w6 << 10) & 0x1ffff)+(0*64+22 +1); out[0*64+23] = start + ((w6 >> 7) & 0x1ffff)+(0*64+23 +1); out[0*64+24] = start + ((w6 >> 24) & 0x1ffff)+(0*64+24 +1); out[0*64+25] = start + ((w6 >> 41) & 0x1ffff)+(0*64+25 +1); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*64+26] = start + ((w6 >> 58) | (w7 << 6) & 0x1ffff)+(0*64+26 +1); out[0*64+27] = start + ((w7 >> 11) & 0x1ffff)+(0*64+27 +1); out[0*64+28] = start + ((w7 >> 28) & 0x1ffff)+(0*64+28 +1); out[0*64+29] = start + ((w7 >> 45) & 0x1ffff)+(0*64+29 +1); w8 = *(uint32_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*64+30] = start + ((w7 >> 62) | (w8 << 2) & 0x1ffff)+(0*64+30 +1); out[0*64+31] = start + ((w8 >> 15) & 0x1ffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 17*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_18(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*18)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3ffff)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 18) & 0x3ffff)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w0 >> 36) & 0x3ffff)+(0*32+ 2 +1); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*32+ 3] = start + ((w0 >> 54) | (w1 << 10) & 0x3ffff)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w1 >> 8) & 0x3ffff)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w1 >> 26) & 0x3ffff)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w1 >> 44) & 0x3ffff)+(0*32+ 6 +1); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*32+ 7] = start + ((w1 >> 62) | (w2 << 2) & 0x3ffff)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w2 >> 16) & 0x3ffff)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w2 >> 34) & 0x3ffff)+(0*32+ 9 +1); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*32+10] = start + ((w2 >> 52) | (w3 << 12) & 0x3ffff)+(0*32+10 +1); out[0*32+11] = start + ((w3 >> 6) & 0x3ffff)+(0*32+11 +1); out[0*32+12] = start + ((w3 >> 24) & 0x3ffff)+(0*32+12 +1); out[0*32+13] = start + ((w3 >> 42) & 0x3ffff)+(0*32+13 +1); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*32+14] = start + ((w3 >> 60) | (w4 << 4) & 0x3ffff)+(0*32+14 +1); out[0*32+15] = start + ((w4 >> 14) & 0x3ffff)+(0*32+15 +1); out[0*32+16] = start + ((w4 >> 32) & 0x3ffff)+(0*32+16 +1); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*32+17] = start + ((w4 >> 50) | (w5 << 14) & 0x3ffff)+(0*32+17 +1); out[0*32+18] = start + ((w5 >> 4) & 0x3ffff)+(0*32+18 +1); out[0*32+19] = start + ((w5 >> 22) & 0x3ffff)+(0*32+19 +1); out[0*32+20] = start + ((w5 >> 40) & 0x3ffff)+(0*32+20 +1); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*32+21] = start + ((w5 >> 58) | (w6 << 6) & 0x3ffff)+(0*32+21 +1); out[0*32+22] = start + ((w6 >> 12) & 0x3ffff)+(0*32+22 +1); out[0*32+23] = start + ((w6 >> 30) & 0x3ffff)+(0*32+23 +1); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*32+24] = start + ((w6 >> 48) | (w7 << 16) & 0x3ffff)+(0*32+24 +1); out[0*32+25] = start + ((w7 >> 2) & 0x3ffff)+(0*32+25 +1); out[0*32+26] = start + ((w7 >> 20) & 0x3ffff)+(0*32+26 +1); out[0*32+27] = start + ((w7 >> 38) & 0x3ffff)+(0*32+27 +1); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*32+28] = start + ((w7 >> 56) | (w8 << 8) & 0x3ffff)+(0*32+28 +1); out[0*32+29] = start + ((w8 >> 10) & 0x3ffff)+(0*32+29 +1); out[0*32+30] = start + ((w8 >> 28) & 0x3ffff)+(0*32+30 +1); out[0*32+31] = start + ((w8 >> 46))+(0*32+31 +1);;}; out += 32; start += 32; in += 18*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_19(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*19)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7ffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 19) & 0x7ffff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 38) & 0x7ffff)+(0*64+ 2 +1); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w0 >> 57) | (w1 << 7) & 0x7ffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w1 >> 12) & 0x7ffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w1 >> 31) & 0x7ffff)+(0*64+ 5 +1); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w1 >> 50) | (w2 << 14) & 0x7ffff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w2 >> 5) & 0x7ffff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w2 >> 24) & 0x7ffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w2 >> 43) & 0x7ffff)+(0*64+ 9 +1); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*64+10] = start + ((w2 >> 62) | (w3 << 2) & 0x7ffff)+(0*64+10 +1); out[0*64+11] = start + ((w3 >> 17) & 0x7ffff)+(0*64+11 +1); out[0*64+12] = start + ((w3 >> 36) & 0x7ffff)+(0*64+12 +1); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*64+13] = start + ((w3 >> 55) | (w4 << 9) & 0x7ffff)+(0*64+13 +1); out[0*64+14] = start + ((w4 >> 10) & 0x7ffff)+(0*64+14 +1); out[0*64+15] = start + ((w4 >> 29) & 0x7ffff)+(0*64+15 +1); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*64+16] = start + ((w4 >> 48) | (w5 << 16) & 0x7ffff)+(0*64+16 +1); out[0*64+17] = start + ((w5 >> 3) & 0x7ffff)+(0*64+17 +1); out[0*64+18] = start + ((w5 >> 22) & 0x7ffff)+(0*64+18 +1); out[0*64+19] = start + ((w5 >> 41) & 0x7ffff)+(0*64+19 +1); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*64+20] = start + ((w5 >> 60) | (w6 << 4) & 0x7ffff)+(0*64+20 +1); out[0*64+21] = start + ((w6 >> 15) & 0x7ffff)+(0*64+21 +1); out[0*64+22] = start + ((w6 >> 34) & 0x7ffff)+(0*64+22 +1); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*64+23] = start + ((w6 >> 53) | (w7 << 11) & 0x7ffff)+(0*64+23 +1); out[0*64+24] = start + ((w7 >> 8) & 0x7ffff)+(0*64+24 +1); out[0*64+25] = start + ((w7 >> 27) & 0x7ffff)+(0*64+25 +1); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*64+26] = start + ((w7 >> 46) | (w8 << 18) & 0x7ffff)+(0*64+26 +1); out[0*64+27] = start + ((w8 >> 1) & 0x7ffff)+(0*64+27 +1); out[0*64+28] = start + ((w8 >> 20) & 0x7ffff)+(0*64+28 +1); out[0*64+29] = start + ((w8 >> 39) & 0x7ffff)+(0*64+29 +1); w9 = *(uint32_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*64+30] = start + ((w8 >> 58) | (w9 << 6) & 0x7ffff)+(0*64+30 +1); out[0*64+31] = start + ((w9 >> 13) & 0x7ffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 19*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_20(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*20)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xfffff)+(0*16+ 0 +1); out[0*16+ 1] = start + ((w0 >> 20) & 0xfffff)+(0*16+ 1 +1); out[0*16+ 2] = start + ((w0 >> 40) & 0xfffff)+(0*16+ 2 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*16+ 3] = start + ((w0 >> 60) | (w1 << 4) & 0xfffff)+(0*16+ 3 +1); out[0*16+ 4] = start + ((w1 >> 16) & 0xfffff)+(0*16+ 4 +1); out[0*16+ 5] = start + ((w1 >> 36) & 0xfffff)+(0*16+ 5 +1); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*16+ 6] = start + ((w1 >> 56) | (w2 << 8) & 0xfffff)+(0*16+ 6 +1); out[0*16+ 7] = start + ((w2 >> 12) & 0xfffff)+(0*16+ 7 +1); out[0*16+ 8] = start + ((w2 >> 32) & 0xfffff)+(0*16+ 8 +1); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*16+ 9] = start + ((w2 >> 52) | (w3 << 12) & 0xfffff)+(0*16+ 9 +1); out[0*16+10] = start + ((w3 >> 8) & 0xfffff)+(0*16+10 +1); out[0*16+11] = start + ((w3 >> 28) & 0xfffff)+(0*16+11 +1); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*16+12] = start + ((w3 >> 48) | (w4 << 16) & 0xfffff)+(0*16+12 +1); out[0*16+13] = start + ((w4 >> 4) & 0xfffff)+(0*16+13 +1); out[0*16+14] = start + ((w4 >> 24) & 0xfffff)+(0*16+14 +1); out[0*16+15] = start + ((w4 >> 44))+(0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xfffff)+(1*16+ 0 +1); out[1*16+ 1] = start + ((w0 >> 20) & 0xfffff)+(1*16+ 1 +1); out[1*16+ 2] = start + ((w0 >> 40) & 0xfffff)+(1*16+ 2 +1); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*16+ 3] = start + ((w0 >> 60) | (w1 << 4) & 0xfffff)+(1*16+ 3 +1); out[1*16+ 4] = start + ((w1 >> 16) & 0xfffff)+(1*16+ 4 +1); out[1*16+ 5] = start + ((w1 >> 36) & 0xfffff)+(1*16+ 5 +1); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*16+ 6] = start + ((w1 >> 56) | (w2 << 8) & 0xfffff)+(1*16+ 6 +1); out[1*16+ 7] = start + ((w2 >> 12) & 0xfffff)+(1*16+ 7 +1); out[1*16+ 8] = start + ((w2 >> 32) & 0xfffff)+(1*16+ 8 +1); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*16+ 9] = start + ((w2 >> 52) | (w3 << 12) & 0xfffff)+(1*16+ 9 +1); out[1*16+10] = start + ((w3 >> 8) & 0xfffff)+(1*16+10 +1); out[1*16+11] = start + ((w3 >> 28) & 0xfffff)+(1*16+11 +1); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*16+12] = start + ((w3 >> 48) | (w4 << 16) & 0xfffff)+(1*16+12 +1); out[1*16+13] = start + ((w4 >> 4) & 0xfffff)+(1*16+13 +1); out[1*16+14] = start + ((w4 >> 24) & 0xfffff)+(1*16+14 +1); out[1*16+15] = start + ((w4 >> 44))+(1*16+15 +1);;}; out += 32; start += 32; in += 20*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_21(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*21)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1fffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 21) & 0x1fffff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w0 >> 42) & 0x1fffff)+(0*64+ 2 +1); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w0 >> 63) | (w1 << 1) & 0x1fffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w1 >> 20) & 0x1fffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w1 >> 41) & 0x1fffff)+(0*64+ 5 +1); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w1 >> 62) | (w2 << 2) & 0x1fffff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w2 >> 19) & 0x1fffff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w2 >> 40) & 0x1fffff)+(0*64+ 8 +1); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w2 >> 61) | (w3 << 3) & 0x1fffff)+(0*64+ 9 +1); out[0*64+10] = start + ((w3 >> 18) & 0x1fffff)+(0*64+10 +1); out[0*64+11] = start + ((w3 >> 39) & 0x1fffff)+(0*64+11 +1); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*64+12] = start + ((w3 >> 60) | (w4 << 4) & 0x1fffff)+(0*64+12 +1); out[0*64+13] = start + ((w4 >> 17) & 0x1fffff)+(0*64+13 +1); out[0*64+14] = start + ((w4 >> 38) & 0x1fffff)+(0*64+14 +1); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*64+15] = start + ((w4 >> 59) | (w5 << 5) & 0x1fffff)+(0*64+15 +1); out[0*64+16] = start + ((w5 >> 16) & 0x1fffff)+(0*64+16 +1); out[0*64+17] = start + ((w5 >> 37) & 0x1fffff)+(0*64+17 +1); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*64+18] = start + ((w5 >> 58) | (w6 << 6) & 0x1fffff)+(0*64+18 +1); out[0*64+19] = start + ((w6 >> 15) & 0x1fffff)+(0*64+19 +1); out[0*64+20] = start + ((w6 >> 36) & 0x1fffff)+(0*64+20 +1); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*64+21] = start + ((w6 >> 57) | (w7 << 7) & 0x1fffff)+(0*64+21 +1); out[0*64+22] = start + ((w7 >> 14) & 0x1fffff)+(0*64+22 +1); out[0*64+23] = start + ((w7 >> 35) & 0x1fffff)+(0*64+23 +1); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*64+24] = start + ((w7 >> 56) | (w8 << 8) & 0x1fffff)+(0*64+24 +1); out[0*64+25] = start + ((w8 >> 13) & 0x1fffff)+(0*64+25 +1); out[0*64+26] = start + ((w8 >> 34) & 0x1fffff)+(0*64+26 +1); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*64+27] = start + ((w8 >> 55) | (w9 << 9) & 0x1fffff)+(0*64+27 +1); out[0*64+28] = start + ((w9 >> 12) & 0x1fffff)+(0*64+28 +1); out[0*64+29] = start + ((w9 >> 33) & 0x1fffff)+(0*64+29 +1); w10 = *(uint32_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*64+30] = start + ((w9 >> 54) | (w10 << 10) & 0x1fffff)+(0*64+30 +1); out[0*64+31] = start + ((w10 >> 11) & 0x1fffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 21*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_22(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*22)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3fffff)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 22) & 0x3fffff)+(0*32+ 1 +1); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*32+ 2] = start + ((w0 >> 44) | (w1 << 20) & 0x3fffff)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w1 >> 2) & 0x3fffff)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w1 >> 24) & 0x3fffff)+(0*32+ 4 +1); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*32+ 5] = start + ((w1 >> 46) | (w2 << 18) & 0x3fffff)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w2 >> 4) & 0x3fffff)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w2 >> 26) & 0x3fffff)+(0*32+ 7 +1); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*32+ 8] = start + ((w2 >> 48) | (w3 << 16) & 0x3fffff)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w3 >> 6) & 0x3fffff)+(0*32+ 9 +1); out[0*32+10] = start + ((w3 >> 28) & 0x3fffff)+(0*32+10 +1); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*32+11] = start + ((w3 >> 50) | (w4 << 14) & 0x3fffff)+(0*32+11 +1); out[0*32+12] = start + ((w4 >> 8) & 0x3fffff)+(0*32+12 +1); out[0*32+13] = start + ((w4 >> 30) & 0x3fffff)+(0*32+13 +1); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*32+14] = start + ((w4 >> 52) | (w5 << 12) & 0x3fffff)+(0*32+14 +1); out[0*32+15] = start + ((w5 >> 10) & 0x3fffff)+(0*32+15 +1); out[0*32+16] = start + ((w5 >> 32) & 0x3fffff)+(0*32+16 +1); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*32+17] = start + ((w5 >> 54) | (w6 << 10) & 0x3fffff)+(0*32+17 +1); out[0*32+18] = start + ((w6 >> 12) & 0x3fffff)+(0*32+18 +1); out[0*32+19] = start + ((w6 >> 34) & 0x3fffff)+(0*32+19 +1); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*32+20] = start + ((w6 >> 56) | (w7 << 8) & 0x3fffff)+(0*32+20 +1); out[0*32+21] = start + ((w7 >> 14) & 0x3fffff)+(0*32+21 +1); out[0*32+22] = start + ((w7 >> 36) & 0x3fffff)+(0*32+22 +1); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*32+23] = start + ((w7 >> 58) | (w8 << 6) & 0x3fffff)+(0*32+23 +1); out[0*32+24] = start + ((w8 >> 16) & 0x3fffff)+(0*32+24 +1); out[0*32+25] = start + ((w8 >> 38) & 0x3fffff)+(0*32+25 +1); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*32+26] = start + ((w8 >> 60) | (w9 << 4) & 0x3fffff)+(0*32+26 +1); out[0*32+27] = start + ((w9 >> 18) & 0x3fffff)+(0*32+27 +1); out[0*32+28] = start + ((w9 >> 40) & 0x3fffff)+(0*32+28 +1); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*32+29] = start + ((w9 >> 62) | (w10 << 2) & 0x3fffff)+(0*32+29 +1); out[0*32+30] = start + ((w10 >> 20) & 0x3fffff)+(0*32+30 +1); out[0*32+31] = start + ((w10 >> 42))+(0*32+31 +1);;}; out += 32; start += 32; in += 22*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_23(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*23)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7fffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 23) & 0x7fffff)+(0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w0 >> 46) | (w1 << 18) & 0x7fffff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w1 >> 5) & 0x7fffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w1 >> 28) & 0x7fffff)+(0*64+ 4 +1); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w1 >> 51) | (w2 << 13) & 0x7fffff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w2 >> 10) & 0x7fffff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w2 >> 33) & 0x7fffff)+(0*64+ 7 +1); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w2 >> 56) | (w3 << 8) & 0x7fffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w3 >> 15) & 0x7fffff)+(0*64+ 9 +1); out[0*64+10] = start + ((w3 >> 38) & 0x7fffff)+(0*64+10 +1); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*64+11] = start + ((w3 >> 61) | (w4 << 3) & 0x7fffff)+(0*64+11 +1); out[0*64+12] = start + ((w4 >> 20) & 0x7fffff)+(0*64+12 +1); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*64+13] = start + ((w4 >> 43) | (w5 << 21) & 0x7fffff)+(0*64+13 +1); out[0*64+14] = start + ((w5 >> 2) & 0x7fffff)+(0*64+14 +1); out[0*64+15] = start + ((w5 >> 25) & 0x7fffff)+(0*64+15 +1); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*64+16] = start + ((w5 >> 48) | (w6 << 16) & 0x7fffff)+(0*64+16 +1); out[0*64+17] = start + ((w6 >> 7) & 0x7fffff)+(0*64+17 +1); out[0*64+18] = start + ((w6 >> 30) & 0x7fffff)+(0*64+18 +1); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*64+19] = start + ((w6 >> 53) | (w7 << 11) & 0x7fffff)+(0*64+19 +1); out[0*64+20] = start + ((w7 >> 12) & 0x7fffff)+(0*64+20 +1); out[0*64+21] = start + ((w7 >> 35) & 0x7fffff)+(0*64+21 +1); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*64+22] = start + ((w7 >> 58) | (w8 << 6) & 0x7fffff)+(0*64+22 +1); out[0*64+23] = start + ((w8 >> 17) & 0x7fffff)+(0*64+23 +1); out[0*64+24] = start + ((w8 >> 40) & 0x7fffff)+(0*64+24 +1); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*64+25] = start + ((w8 >> 63) | (w9 << 1) & 0x7fffff)+(0*64+25 +1); out[0*64+26] = start + ((w9 >> 22) & 0x7fffff)+(0*64+26 +1); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*64+27] = start + ((w9 >> 45) | (w10 << 19) & 0x7fffff)+(0*64+27 +1); out[0*64+28] = start + ((w10 >> 4) & 0x7fffff)+(0*64+28 +1); out[0*64+29] = start + ((w10 >> 27) & 0x7fffff)+(0*64+29 +1); w11 = *(uint32_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*64+30] = start + ((w10 >> 50) | (w11 << 14) & 0x7fffff)+(0*64+30 +1); out[0*64+31] = start + ((w11 >> 9) & 0x7fffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 23*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_24(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*24)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*8+ 0] = start + ((w0 ) & 0xffffff)+(0*8+ 0 +1); out[0*8+ 1] = start + ((w0 >> 24) & 0xffffff)+(0*8+ 1 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*8+ 2] = start + ((w0 >> 48) | (w1 << 16) & 0xffffff)+(0*8+ 2 +1); out[0*8+ 3] = start + ((w1 >> 8) & 0xffffff)+(0*8+ 3 +1); out[0*8+ 4] = start + ((w1 >> 32) & 0xffffff)+(0*8+ 4 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*8+ 5] = start + ((w1 >> 56) | (w2 << 8) & 0xffffff)+(0*8+ 5 +1); out[0*8+ 6] = start + ((w2 >> 16) & 0xffffff)+(0*8+ 6 +1); out[0*8+ 7] = start + ((w2 >> 40))+(0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*8+ 0] = start + ((w0 ) & 0xffffff)+(1*8+ 0 +1); out[1*8+ 1] = start + ((w0 >> 24) & 0xffffff)+(1*8+ 1 +1); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*8+ 2] = start + ((w0 >> 48) | (w1 << 16) & 0xffffff)+(1*8+ 2 +1); out[1*8+ 3] = start + ((w1 >> 8) & 0xffffff)+(1*8+ 3 +1); out[1*8+ 4] = start + ((w1 >> 32) & 0xffffff)+(1*8+ 4 +1); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*8+ 5] = start + ((w1 >> 56) | (w2 << 8) & 0xffffff)+(1*8+ 5 +1); out[1*8+ 6] = start + ((w2 >> 16) & 0xffffff)+(1*8+ 6 +1); out[1*8+ 7] = start + ((w2 >> 40))+(1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*8+ 0] = start + ((w0 ) & 0xffffff)+(2*8+ 0 +1); out[2*8+ 1] = start + ((w0 >> 24) & 0xffffff)+(2*8+ 1 +1); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*8+ 2] = start + ((w0 >> 48) | (w1 << 16) & 0xffffff)+(2*8+ 2 +1); out[2*8+ 3] = start + ((w1 >> 8) & 0xffffff)+(2*8+ 3 +1); out[2*8+ 4] = start + ((w1 >> 32) & 0xffffff)+(2*8+ 4 +1); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*8+ 5] = start + ((w1 >> 56) | (w2 << 8) & 0xffffff)+(2*8+ 5 +1); out[2*8+ 6] = start + ((w2 >> 16) & 0xffffff)+(2*8+ 6 +1); out[2*8+ 7] = start + ((w2 >> 40))+(2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*8+ 0] = start + ((w0 ) & 0xffffff)+(3*8+ 0 +1); out[3*8+ 1] = start + ((w0 >> 24) & 0xffffff)+(3*8+ 1 +1); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*8+ 2] = start + ((w0 >> 48) | (w1 << 16) & 0xffffff)+(3*8+ 2 +1); out[3*8+ 3] = start + ((w1 >> 8) & 0xffffff)+(3*8+ 3 +1); out[3*8+ 4] = start + ((w1 >> 32) & 0xffffff)+(3*8+ 4 +1); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*8+ 5] = start + ((w1 >> 56) | (w2 << 8) & 0xffffff)+(3*8+ 5 +1); out[3*8+ 6] = start + ((w2 >> 16) & 0xffffff)+(3*8+ 6 +1); out[3*8+ 7] = start + ((w2 >> 40))+(3*8+ 7 +1);;}; out += 32; start += 32; in += 24*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_25(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*25)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1ffffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 25) & 0x1ffffff)+(0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w0 >> 50) | (w1 << 14) & 0x1ffffff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w1 >> 11) & 0x1ffffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w1 >> 36) & 0x1ffffff)+(0*64+ 4 +1); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w1 >> 61) | (w2 << 3) & 0x1ffffff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w2 >> 22) & 0x1ffffff)+(0*64+ 6 +1); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w2 >> 47) | (w3 << 17) & 0x1ffffff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w3 >> 8) & 0x1ffffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w3 >> 33) & 0x1ffffff)+(0*64+ 9 +1); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*64+10] = start + ((w3 >> 58) | (w4 << 6) & 0x1ffffff)+(0*64+10 +1); out[0*64+11] = start + ((w4 >> 19) & 0x1ffffff)+(0*64+11 +1); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*64+12] = start + ((w4 >> 44) | (w5 << 20) & 0x1ffffff)+(0*64+12 +1); out[0*64+13] = start + ((w5 >> 5) & 0x1ffffff)+(0*64+13 +1); out[0*64+14] = start + ((w5 >> 30) & 0x1ffffff)+(0*64+14 +1); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*64+15] = start + ((w5 >> 55) | (w6 << 9) & 0x1ffffff)+(0*64+15 +1); out[0*64+16] = start + ((w6 >> 16) & 0x1ffffff)+(0*64+16 +1); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*64+17] = start + ((w6 >> 41) | (w7 << 23) & 0x1ffffff)+(0*64+17 +1); out[0*64+18] = start + ((w7 >> 2) & 0x1ffffff)+(0*64+18 +1); out[0*64+19] = start + ((w7 >> 27) & 0x1ffffff)+(0*64+19 +1); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*64+20] = start + ((w7 >> 52) | (w8 << 12) & 0x1ffffff)+(0*64+20 +1); out[0*64+21] = start + ((w8 >> 13) & 0x1ffffff)+(0*64+21 +1); out[0*64+22] = start + ((w8 >> 38) & 0x1ffffff)+(0*64+22 +1); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*64+23] = start + ((w8 >> 63) | (w9 << 1) & 0x1ffffff)+(0*64+23 +1); out[0*64+24] = start + ((w9 >> 24) & 0x1ffffff)+(0*64+24 +1); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*64+25] = start + ((w9 >> 49) | (w10 << 15) & 0x1ffffff)+(0*64+25 +1); out[0*64+26] = start + ((w10 >> 10) & 0x1ffffff)+(0*64+26 +1); out[0*64+27] = start + ((w10 >> 35) & 0x1ffffff)+(0*64+27 +1); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*64+28] = start + ((w10 >> 60) | (w11 << 4) & 0x1ffffff)+(0*64+28 +1); out[0*64+29] = start + ((w11 >> 21) & 0x1ffffff)+(0*64+29 +1); w12 = *(uint32_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*64+30] = start + ((w11 >> 46) | (w12 << 18) & 0x1ffffff)+(0*64+30 +1); out[0*64+31] = start + ((w12 >> 7) & 0x1ffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 25*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_26(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*26)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3ffffff)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 26) & 0x3ffffff)+(0*32+ 1 +1); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*32+ 2] = start + ((w0 >> 52) | (w1 << 12) & 0x3ffffff)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w1 >> 14) & 0x3ffffff)+(0*32+ 3 +1); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*32+ 4] = start + ((w1 >> 40) | (w2 << 24) & 0x3ffffff)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w2 >> 2) & 0x3ffffff)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w2 >> 28) & 0x3ffffff)+(0*32+ 6 +1); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*32+ 7] = start + ((w2 >> 54) | (w3 << 10) & 0x3ffffff)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w3 >> 16) & 0x3ffffff)+(0*32+ 8 +1); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*32+ 9] = start + ((w3 >> 42) | (w4 << 22) & 0x3ffffff)+(0*32+ 9 +1); out[0*32+10] = start + ((w4 >> 4) & 0x3ffffff)+(0*32+10 +1); out[0*32+11] = start + ((w4 >> 30) & 0x3ffffff)+(0*32+11 +1); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*32+12] = start + ((w4 >> 56) | (w5 << 8) & 0x3ffffff)+(0*32+12 +1); out[0*32+13] = start + ((w5 >> 18) & 0x3ffffff)+(0*32+13 +1); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*32+14] = start + ((w5 >> 44) | (w6 << 20) & 0x3ffffff)+(0*32+14 +1); out[0*32+15] = start + ((w6 >> 6) & 0x3ffffff)+(0*32+15 +1); out[0*32+16] = start + ((w6 >> 32) & 0x3ffffff)+(0*32+16 +1); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*32+17] = start + ((w6 >> 58) | (w7 << 6) & 0x3ffffff)+(0*32+17 +1); out[0*32+18] = start + ((w7 >> 20) & 0x3ffffff)+(0*32+18 +1); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*32+19] = start + ((w7 >> 46) | (w8 << 18) & 0x3ffffff)+(0*32+19 +1); out[0*32+20] = start + ((w8 >> 8) & 0x3ffffff)+(0*32+20 +1); out[0*32+21] = start + ((w8 >> 34) & 0x3ffffff)+(0*32+21 +1); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*32+22] = start + ((w8 >> 60) | (w9 << 4) & 0x3ffffff)+(0*32+22 +1); out[0*32+23] = start + ((w9 >> 22) & 0x3ffffff)+(0*32+23 +1); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*32+24] = start + ((w9 >> 48) | (w10 << 16) & 0x3ffffff)+(0*32+24 +1); out[0*32+25] = start + ((w10 >> 10) & 0x3ffffff)+(0*32+25 +1); out[0*32+26] = start + ((w10 >> 36) & 0x3ffffff)+(0*32+26 +1); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*32+27] = start + ((w10 >> 62) | (w11 << 2) & 0x3ffffff)+(0*32+27 +1); out[0*32+28] = start + ((w11 >> 24) & 0x3ffffff)+(0*32+28 +1); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*32+29] = start + ((w11 >> 50) | (w12 << 14) & 0x3ffffff)+(0*32+29 +1); out[0*32+30] = start + ((w12 >> 12) & 0x3ffffff)+(0*32+30 +1); out[0*32+31] = start + ((w12 >> 38))+(0*32+31 +1);;}; out += 32; start += 32; in += 26*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_27(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*27)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7ffffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 27) & 0x7ffffff)+(0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w0 >> 54) | (w1 << 10) & 0x7ffffff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w1 >> 17) & 0x7ffffff)+(0*64+ 3 +1); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w1 >> 44) | (w2 << 20) & 0x7ffffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w2 >> 7) & 0x7ffffff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w2 >> 34) & 0x7ffffff)+(0*64+ 6 +1); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w2 >> 61) | (w3 << 3) & 0x7ffffff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w3 >> 24) & 0x7ffffff)+(0*64+ 8 +1); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w3 >> 51) | (w4 << 13) & 0x7ffffff)+(0*64+ 9 +1); out[0*64+10] = start + ((w4 >> 14) & 0x7ffffff)+(0*64+10 +1); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*64+11] = start + ((w4 >> 41) | (w5 << 23) & 0x7ffffff)+(0*64+11 +1); out[0*64+12] = start + ((w5 >> 4) & 0x7ffffff)+(0*64+12 +1); out[0*64+13] = start + ((w5 >> 31) & 0x7ffffff)+(0*64+13 +1); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*64+14] = start + ((w5 >> 58) | (w6 << 6) & 0x7ffffff)+(0*64+14 +1); out[0*64+15] = start + ((w6 >> 21) & 0x7ffffff)+(0*64+15 +1); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*64+16] = start + ((w6 >> 48) | (w7 << 16) & 0x7ffffff)+(0*64+16 +1); out[0*64+17] = start + ((w7 >> 11) & 0x7ffffff)+(0*64+17 +1); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*64+18] = start + ((w7 >> 38) | (w8 << 26) & 0x7ffffff)+(0*64+18 +1); out[0*64+19] = start + ((w8 >> 1) & 0x7ffffff)+(0*64+19 +1); out[0*64+20] = start + ((w8 >> 28) & 0x7ffffff)+(0*64+20 +1); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*64+21] = start + ((w8 >> 55) | (w9 << 9) & 0x7ffffff)+(0*64+21 +1); out[0*64+22] = start + ((w9 >> 18) & 0x7ffffff)+(0*64+22 +1); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*64+23] = start + ((w9 >> 45) | (w10 << 19) & 0x7ffffff)+(0*64+23 +1); out[0*64+24] = start + ((w10 >> 8) & 0x7ffffff)+(0*64+24 +1); out[0*64+25] = start + ((w10 >> 35) & 0x7ffffff)+(0*64+25 +1); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*64+26] = start + ((w10 >> 62) | (w11 << 2) & 0x7ffffff)+(0*64+26 +1); out[0*64+27] = start + ((w11 >> 25) & 0x7ffffff)+(0*64+27 +1); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*64+28] = start + ((w11 >> 52) | (w12 << 12) & 0x7ffffff)+(0*64+28 +1); out[0*64+29] = start + ((w12 >> 15) & 0x7ffffff)+(0*64+29 +1); w13 = *(uint32_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*64+30] = start + ((w12 >> 42) | (w13 << 22) & 0x7ffffff)+(0*64+30 +1); out[0*64+31] = start + ((w13 >> 5) & 0x7ffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 27*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_28(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*28)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xfffffff)+(0*16+ 0 +1); out[0*16+ 1] = start + ((w0 >> 28) & 0xfffffff)+(0*16+ 1 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*16+ 2] = start + ((w0 >> 56) | (w1 << 8) & 0xfffffff)+(0*16+ 2 +1); out[0*16+ 3] = start + ((w1 >> 20) & 0xfffffff)+(0*16+ 3 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*16+ 4] = start + ((w1 >> 48) | (w2 << 16) & 0xfffffff)+(0*16+ 4 +1); out[0*16+ 5] = start + ((w2 >> 12) & 0xfffffff)+(0*16+ 5 +1); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*16+ 6] = start + ((w2 >> 40) | (w3 << 24) & 0xfffffff)+(0*16+ 6 +1); out[0*16+ 7] = start + ((w3 >> 4) & 0xfffffff)+(0*16+ 7 +1); out[0*16+ 8] = start + ((w3 >> 32) & 0xfffffff)+(0*16+ 8 +1); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*16+ 9] = start + ((w3 >> 60) | (w4 << 4) & 0xfffffff)+(0*16+ 9 +1); out[0*16+10] = start + ((w4 >> 24) & 0xfffffff)+(0*16+10 +1); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*16+11] = start + ((w4 >> 52) | (w5 << 12) & 0xfffffff)+(0*16+11 +1); out[0*16+12] = start + ((w5 >> 16) & 0xfffffff)+(0*16+12 +1); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*16+13] = start + ((w5 >> 44) | (w6 << 20) & 0xfffffff)+(0*16+13 +1); out[0*16+14] = start + ((w6 >> 8) & 0xfffffff)+(0*16+14 +1); out[0*16+15] = start + ((w6 >> 36))+(0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xfffffff)+(1*16+ 0 +1); out[1*16+ 1] = start + ((w0 >> 28) & 0xfffffff)+(1*16+ 1 +1); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*16+ 2] = start + ((w0 >> 56) | (w1 << 8) & 0xfffffff)+(1*16+ 2 +1); out[1*16+ 3] = start + ((w1 >> 20) & 0xfffffff)+(1*16+ 3 +1); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*16+ 4] = start + ((w1 >> 48) | (w2 << 16) & 0xfffffff)+(1*16+ 4 +1); out[1*16+ 5] = start + ((w2 >> 12) & 0xfffffff)+(1*16+ 5 +1); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*16+ 6] = start + ((w2 >> 40) | (w3 << 24) & 0xfffffff)+(1*16+ 6 +1); out[1*16+ 7] = start + ((w3 >> 4) & 0xfffffff)+(1*16+ 7 +1); out[1*16+ 8] = start + ((w3 >> 32) & 0xfffffff)+(1*16+ 8 +1); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*16+ 9] = start + ((w3 >> 60) | (w4 << 4) & 0xfffffff)+(1*16+ 9 +1); out[1*16+10] = start + ((w4 >> 24) & 0xfffffff)+(1*16+10 +1); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*16+11] = start + ((w4 >> 52) | (w5 << 12) & 0xfffffff)+(1*16+11 +1); out[1*16+12] = start + ((w5 >> 16) & 0xfffffff)+(1*16+12 +1); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*16+13] = start + ((w5 >> 44) | (w6 << 20) & 0xfffffff)+(1*16+13 +1); out[1*16+14] = start + ((w6 >> 8) & 0xfffffff)+(1*16+14 +1); out[1*16+15] = start + ((w6 >> 36))+(1*16+15 +1);;}; out += 32; start += 32; in += 28*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_29(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*29)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1fffffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 29) & 0x1fffffff)+(0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w0 >> 58) | (w1 << 6) & 0x1fffffff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w1 >> 23) & 0x1fffffff)+(0*64+ 3 +1); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w1 >> 52) | (w2 << 12) & 0x1fffffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w2 >> 17) & 0x1fffffff)+(0*64+ 5 +1); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w2 >> 46) | (w3 << 18) & 0x1fffffff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w3 >> 11) & 0x1fffffff)+(0*64+ 7 +1); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w3 >> 40) | (w4 << 24) & 0x1fffffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w4 >> 5) & 0x1fffffff)+(0*64+ 9 +1); out[0*64+10] = start + ((w4 >> 34) & 0x1fffffff)+(0*64+10 +1); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*64+11] = start + ((w4 >> 63) | (w5 << 1) & 0x1fffffff)+(0*64+11 +1); out[0*64+12] = start + ((w5 >> 28) & 0x1fffffff)+(0*64+12 +1); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*64+13] = start + ((w5 >> 57) | (w6 << 7) & 0x1fffffff)+(0*64+13 +1); out[0*64+14] = start + ((w6 >> 22) & 0x1fffffff)+(0*64+14 +1); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*64+15] = start + ((w6 >> 51) | (w7 << 13) & 0x1fffffff)+(0*64+15 +1); out[0*64+16] = start + ((w7 >> 16) & 0x1fffffff)+(0*64+16 +1); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*64+17] = start + ((w7 >> 45) | (w8 << 19) & 0x1fffffff)+(0*64+17 +1); out[0*64+18] = start + ((w8 >> 10) & 0x1fffffff)+(0*64+18 +1); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*64+19] = start + ((w8 >> 39) | (w9 << 25) & 0x1fffffff)+(0*64+19 +1); out[0*64+20] = start + ((w9 >> 4) & 0x1fffffff)+(0*64+20 +1); out[0*64+21] = start + ((w9 >> 33) & 0x1fffffff)+(0*64+21 +1); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*64+22] = start + ((w9 >> 62) | (w10 << 2) & 0x1fffffff)+(0*64+22 +1); out[0*64+23] = start + ((w10 >> 27) & 0x1fffffff)+(0*64+23 +1); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*64+24] = start + ((w10 >> 56) | (w11 << 8) & 0x1fffffff)+(0*64+24 +1); out[0*64+25] = start + ((w11 >> 21) & 0x1fffffff)+(0*64+25 +1); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*64+26] = start + ((w11 >> 50) | (w12 << 14) & 0x1fffffff)+(0*64+26 +1); out[0*64+27] = start + ((w12 >> 15) & 0x1fffffff)+(0*64+27 +1); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*64+28] = start + ((w12 >> 44) | (w13 << 20) & 0x1fffffff)+(0*64+28 +1); out[0*64+29] = start + ((w13 >> 9) & 0x1fffffff)+(0*64+29 +1); w14 = *(uint32_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*64+30] = start + ((w13 >> 38) | (w14 << 26) & 0x1fffffff)+(0*64+30 +1); out[0*64+31] = start + ((w14 >> 3) & 0x1fffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 29*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_30(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*30)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3fffffff)+(0*32+ 0 +1); out[0*32+ 1] = start + ((w0 >> 30) & 0x3fffffff)+(0*32+ 1 +1); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*32+ 2] = start + ((w0 >> 60) | (w1 << 4) & 0x3fffffff)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w1 >> 26) & 0x3fffffff)+(0*32+ 3 +1); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*32+ 4] = start + ((w1 >> 56) | (w2 << 8) & 0x3fffffff)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w2 >> 22) & 0x3fffffff)+(0*32+ 5 +1); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*32+ 6] = start + ((w2 >> 52) | (w3 << 12) & 0x3fffffff)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w3 >> 18) & 0x3fffffff)+(0*32+ 7 +1); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*32+ 8] = start + ((w3 >> 48) | (w4 << 16) & 0x3fffffff)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w4 >> 14) & 0x3fffffff)+(0*32+ 9 +1); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*32+10] = start + ((w4 >> 44) | (w5 << 20) & 0x3fffffff)+(0*32+10 +1); out[0*32+11] = start + ((w5 >> 10) & 0x3fffffff)+(0*32+11 +1); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*32+12] = start + ((w5 >> 40) | (w6 << 24) & 0x3fffffff)+(0*32+12 +1); out[0*32+13] = start + ((w6 >> 6) & 0x3fffffff)+(0*32+13 +1); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*32+14] = start + ((w6 >> 36) | (w7 << 28) & 0x3fffffff)+(0*32+14 +1); out[0*32+15] = start + ((w7 >> 2) & 0x3fffffff)+(0*32+15 +1); out[0*32+16] = start + ((w7 >> 32) & 0x3fffffff)+(0*32+16 +1); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*32+17] = start + ((w7 >> 62) | (w8 << 2) & 0x3fffffff)+(0*32+17 +1); out[0*32+18] = start + ((w8 >> 28) & 0x3fffffff)+(0*32+18 +1); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*32+19] = start + ((w8 >> 58) | (w9 << 6) & 0x3fffffff)+(0*32+19 +1); out[0*32+20] = start + ((w9 >> 24) & 0x3fffffff)+(0*32+20 +1); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*32+21] = start + ((w9 >> 54) | (w10 << 10) & 0x3fffffff)+(0*32+21 +1); out[0*32+22] = start + ((w10 >> 20) & 0x3fffffff)+(0*32+22 +1); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*32+23] = start + ((w10 >> 50) | (w11 << 14) & 0x3fffffff)+(0*32+23 +1); out[0*32+24] = start + ((w11 >> 16) & 0x3fffffff)+(0*32+24 +1); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*32+25] = start + ((w11 >> 46) | (w12 << 18) & 0x3fffffff)+(0*32+25 +1); out[0*32+26] = start + ((w12 >> 12) & 0x3fffffff)+(0*32+26 +1); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*32+27] = start + ((w12 >> 42) | (w13 << 22) & 0x3fffffff)+(0*32+27 +1); out[0*32+28] = start + ((w13 >> 8) & 0x3fffffff)+(0*32+28 +1); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*32+29] = start + ((w13 >> 38) | (w14 << 26) & 0x3fffffff)+(0*32+29 +1); out[0*32+30] = start + ((w14 >> 4) & 0x3fffffff)+(0*32+30 +1); out[0*32+31] = start + ((w14 >> 34))+(0*32+31 +1);;}; out += 32; start += 32; in += 30*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_31(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*31)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7fffffff)+(0*64+ 0 +1); out[0*64+ 1] = start + ((w0 >> 31) & 0x7fffffff)+(0*64+ 1 +1); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w0 >> 62) | (w1 << 2) & 0x7fffffff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w1 >> 29) & 0x7fffffff)+(0*64+ 3 +1); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w1 >> 60) | (w2 << 4) & 0x7fffffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w2 >> 27) & 0x7fffffff)+(0*64+ 5 +1); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w2 >> 58) | (w3 << 6) & 0x7fffffff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w3 >> 25) & 0x7fffffff)+(0*64+ 7 +1); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w3 >> 56) | (w4 << 8) & 0x7fffffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w4 >> 23) & 0x7fffffff)+(0*64+ 9 +1); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*64+10] = start + ((w4 >> 54) | (w5 << 10) & 0x7fffffff)+(0*64+10 +1); out[0*64+11] = start + ((w5 >> 21) & 0x7fffffff)+(0*64+11 +1); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*64+12] = start + ((w5 >> 52) | (w6 << 12) & 0x7fffffff)+(0*64+12 +1); out[0*64+13] = start + ((w6 >> 19) & 0x7fffffff)+(0*64+13 +1); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*64+14] = start + ((w6 >> 50) | (w7 << 14) & 0x7fffffff)+(0*64+14 +1); out[0*64+15] = start + ((w7 >> 17) & 0x7fffffff)+(0*64+15 +1); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*64+16] = start + ((w7 >> 48) | (w8 << 16) & 0x7fffffff)+(0*64+16 +1); out[0*64+17] = start + ((w8 >> 15) & 0x7fffffff)+(0*64+17 +1); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*64+18] = start + ((w8 >> 46) | (w9 << 18) & 0x7fffffff)+(0*64+18 +1); out[0*64+19] = start + ((w9 >> 13) & 0x7fffffff)+(0*64+19 +1); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*64+20] = start + ((w9 >> 44) | (w10 << 20) & 0x7fffffff)+(0*64+20 +1); out[0*64+21] = start + ((w10 >> 11) & 0x7fffffff)+(0*64+21 +1); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*64+22] = start + ((w10 >> 42) | (w11 << 22) & 0x7fffffff)+(0*64+22 +1); out[0*64+23] = start + ((w11 >> 9) & 0x7fffffff)+(0*64+23 +1); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*64+24] = start + ((w11 >> 40) | (w12 << 24) & 0x7fffffff)+(0*64+24 +1); out[0*64+25] = start + ((w12 >> 7) & 0x7fffffff)+(0*64+25 +1); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*64+26] = start + ((w12 >> 38) | (w13 << 26) & 0x7fffffff)+(0*64+26 +1); out[0*64+27] = start + ((w13 >> 5) & 0x7fffffff)+(0*64+27 +1); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*64+28] = start + ((w13 >> 36) | (w14 << 28) & 0x7fffffff)+(0*64+28 +1); out[0*64+29] = start + ((w14 >> 3) & 0x7fffffff)+(0*64+29 +1); w15 = *(uint32_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*64+30] = start + ((w14 >> 34) | (w15 << 30) & 0x7fffffff)+(0*64+30 +1); out[0*64+31] = start + ((w15 >> 1) & 0x7fffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 31*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_32(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*32)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[0*2+ 0] = start + (*(uint32_t *)(in+0*8+ 0))+(0*2+ 0 +1); out[0*2+ 1] = start + (*(uint32_t *)(in+0*8+ 4))+(0*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[1*2+ 0] = start + (*(uint32_t *)(in+1*8+ 0))+(1*2+ 0 +1); out[1*2+ 1] = start + (*(uint32_t *)(in+1*8+ 4))+(1*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[2*2+ 0] = start + (*(uint32_t *)(in+2*8+ 0))+(2*2+ 0 +1); out[2*2+ 1] = start + (*(uint32_t *)(in+2*8+ 4))+(2*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[3*2+ 0] = start + (*(uint32_t *)(in+3*8+ 0))+(3*2+ 0 +1); out[3*2+ 1] = start + (*(uint32_t *)(in+3*8+ 4))+(3*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[4*2+ 0] = start + (*(uint32_t *)(in+4*8+ 0))+(4*2+ 0 +1); out[4*2+ 1] = start + (*(uint32_t *)(in+4*8+ 4))+(4*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[5*2+ 0] = start + (*(uint32_t *)(in+5*8+ 0))+(5*2+ 0 +1); out[5*2+ 1] = start + (*(uint32_t *)(in+5*8+ 4))+(5*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[6*2+ 0] = start + (*(uint32_t *)(in+6*8+ 0))+(6*2+ 0 +1); out[6*2+ 1] = start + (*(uint32_t *)(in+6*8+ 4))+(6*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[7*2+ 0] = start + (*(uint32_t *)(in+7*8+ 0))+(7*2+ 0 +1); out[7*2+ 1] = start + (*(uint32_t *)(in+7*8+ 4))+(7*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[8*2+ 0] = start + (*(uint32_t *)(in+8*8+ 0))+(8*2+ 0 +1); out[8*2+ 1] = start + (*(uint32_t *)(in+8*8+ 4))+(8*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[9*2+ 0] = start + (*(uint32_t *)(in+9*8+ 0))+(9*2+ 0 +1); out[9*2+ 1] = start + (*(uint32_t *)(in+9*8+ 4))+(9*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[10*2+ 0] = start + (*(uint32_t *)(in+10*8+ 0))+(10*2+ 0 +1); out[10*2+ 1] = start + (*(uint32_t *)(in+10*8+ 4))+(10*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[11*2+ 0] = start + (*(uint32_t *)(in+11*8+ 0))+(11*2+ 0 +1); out[11*2+ 1] = start + (*(uint32_t *)(in+11*8+ 4))+(11*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[12*2+ 0] = start + (*(uint32_t *)(in+12*8+ 0))+(12*2+ 0 +1); out[12*2+ 1] = start + (*(uint32_t *)(in+12*8+ 4))+(12*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[13*2+ 0] = start + (*(uint32_t *)(in+13*8+ 0))+(13*2+ 0 +1); out[13*2+ 1] = start + (*(uint32_t *)(in+13*8+ 4))+(13*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[14*2+ 0] = start + (*(uint32_t *)(in+14*8+ 0))+(14*2+ 0 +1); out[14*2+ 1] = start + (*(uint32_t *)(in+14*8+ 4))+(14*2+ 1 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15; out[15*2+ 0] = start + (*(uint32_t *)(in+15*8+ 0))+(15*2+ 0 +1); out[15*2+ 1] = start + (*(uint32_t *)(in+15*8+ 4))+(15*2+ 1 +1);;}; out += 32; start += 32; in += 32*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_33(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*33)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16; w0 = *(uint64_t *)(in+(0*33+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1ffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*33+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 33) | (w1 << 31) & 0x1ffffffff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w1 >> 2) & 0x1ffffffff)+(0*64+ 2 +1); w2 = *(uint64_t *)(in+(0*33+2)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w1 >> 35) | (w2 << 29) & 0x1ffffffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w2 >> 4) & 0x1ffffffff)+(0*64+ 4 +1); w3 = *(uint64_t *)(in+(0*33+3)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w2 >> 37) | (w3 << 27) & 0x1ffffffff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w3 >> 6) & 0x1ffffffff)+(0*64+ 6 +1); w4 = *(uint64_t *)(in+(0*33+4)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w3 >> 39) | (w4 << 25) & 0x1ffffffff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w4 >> 8) & 0x1ffffffff)+(0*64+ 8 +1); w5 = *(uint64_t *)(in+(0*33+5)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w4 >> 41) | (w5 << 23) & 0x1ffffffff)+(0*64+ 9 +1); out[0*64+10] = start + ((w5 >> 10) & 0x1ffffffff)+(0*64+10 +1); w6 = *(uint64_t *)(in+(0*33+6)*8/sizeof(in[0])); out[0*64+11] = start + ((w5 >> 43) | (w6 << 21) & 0x1ffffffff)+(0*64+11 +1); out[0*64+12] = start + ((w6 >> 12) & 0x1ffffffff)+(0*64+12 +1); w7 = *(uint64_t *)(in+(0*33+7)*8/sizeof(in[0])); out[0*64+13] = start + ((w6 >> 45) | (w7 << 19) & 0x1ffffffff)+(0*64+13 +1); out[0*64+14] = start + ((w7 >> 14) & 0x1ffffffff)+(0*64+14 +1); w8 = *(uint64_t *)(in+(0*33+8)*8/sizeof(in[0])); out[0*64+15] = start + ((w7 >> 47) | (w8 << 17) & 0x1ffffffff)+(0*64+15 +1); out[0*64+16] = start + ((w8 >> 16) & 0x1ffffffff)+(0*64+16 +1); w9 = *(uint64_t *)(in+(0*33+9)*8/sizeof(in[0])); out[0*64+17] = start + ((w8 >> 49) | (w9 << 15) & 0x1ffffffff)+(0*64+17 +1); out[0*64+18] = start + ((w9 >> 18) & 0x1ffffffff)+(0*64+18 +1); w10 = *(uint64_t *)(in+(0*33+10)*8/sizeof(in[0])); out[0*64+19] = start + ((w9 >> 51) | (w10 << 13) & 0x1ffffffff)+(0*64+19 +1); out[0*64+20] = start + ((w10 >> 20) & 0x1ffffffff)+(0*64+20 +1); w11 = *(uint64_t *)(in+(0*33+11)*8/sizeof(in[0])); out[0*64+21] = start + ((w10 >> 53) | (w11 << 11) & 0x1ffffffff)+(0*64+21 +1); out[0*64+22] = start + ((w11 >> 22) & 0x1ffffffff)+(0*64+22 +1); w12 = *(uint64_t *)(in+(0*33+12)*8/sizeof(in[0])); out[0*64+23] = start + ((w11 >> 55) | (w12 << 9) & 0x1ffffffff)+(0*64+23 +1); out[0*64+24] = start + ((w12 >> 24) & 0x1ffffffff)+(0*64+24 +1); w13 = *(uint64_t *)(in+(0*33+13)*8/sizeof(in[0])); out[0*64+25] = start + ((w12 >> 57) | (w13 << 7) & 0x1ffffffff)+(0*64+25 +1); out[0*64+26] = start + ((w13 >> 26) & 0x1ffffffff)+(0*64+26 +1); w14 = *(uint64_t *)(in+(0*33+14)*8/sizeof(in[0])); out[0*64+27] = start + ((w13 >> 59) | (w14 << 5) & 0x1ffffffff)+(0*64+27 +1); out[0*64+28] = start + ((w14 >> 28) & 0x1ffffffff)+(0*64+28 +1); w15 = *(uint64_t *)(in+(0*33+15)*8/sizeof(in[0])); out[0*64+29] = start + ((w14 >> 61) | (w15 << 3) & 0x1ffffffff)+(0*64+29 +1); out[0*64+30] = start + ((w15 >> 30) & 0x1ffffffff)+(0*64+30 +1); w16 = *(uint32_t *)(in+(0*33+16)*8/sizeof(in[0])); out[0*64+31] = start + ((w15 >> 63) | (w16 << 1) & 0x1ffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 33*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_34(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*34)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16; w0 = *(uint64_t *)(in+(0*17+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3ffffffff)+(0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*17+1)*8/sizeof(in[0])); out[0*32+ 1] = start + ((w0 >> 34) | (w1 << 30) & 0x3ffffffff)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w1 >> 4) & 0x3ffffffff)+(0*32+ 2 +1); w2 = *(uint64_t *)(in+(0*17+2)*8/sizeof(in[0])); out[0*32+ 3] = start + ((w1 >> 38) | (w2 << 26) & 0x3ffffffff)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w2 >> 8) & 0x3ffffffff)+(0*32+ 4 +1); w3 = *(uint64_t *)(in+(0*17+3)*8/sizeof(in[0])); out[0*32+ 5] = start + ((w2 >> 42) | (w3 << 22) & 0x3ffffffff)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w3 >> 12) & 0x3ffffffff)+(0*32+ 6 +1); w4 = *(uint64_t *)(in+(0*17+4)*8/sizeof(in[0])); out[0*32+ 7] = start + ((w3 >> 46) | (w4 << 18) & 0x3ffffffff)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w4 >> 16) & 0x3ffffffff)+(0*32+ 8 +1); w5 = *(uint64_t *)(in+(0*17+5)*8/sizeof(in[0])); out[0*32+ 9] = start + ((w4 >> 50) | (w5 << 14) & 0x3ffffffff)+(0*32+ 9 +1); out[0*32+10] = start + ((w5 >> 20) & 0x3ffffffff)+(0*32+10 +1); w6 = *(uint64_t *)(in+(0*17+6)*8/sizeof(in[0])); out[0*32+11] = start + ((w5 >> 54) | (w6 << 10) & 0x3ffffffff)+(0*32+11 +1); out[0*32+12] = start + ((w6 >> 24) & 0x3ffffffff)+(0*32+12 +1); w7 = *(uint64_t *)(in+(0*17+7)*8/sizeof(in[0])); out[0*32+13] = start + ((w6 >> 58) | (w7 << 6) & 0x3ffffffff)+(0*32+13 +1); out[0*32+14] = start + ((w7 >> 28) & 0x3ffffffff)+(0*32+14 +1); w8 = *(uint64_t *)(in+(0*17+8)*8/sizeof(in[0])); out[0*32+15] = start + ((w7 >> 62) | (w8 << 2) & 0x3ffffffff)+(0*32+15 +1); w9 = *(uint64_t *)(in+(0*17+9)*8/sizeof(in[0])); out[0*32+16] = start + ((w8 >> 32) | (w9 << 32) & 0x3ffffffff)+(0*32+16 +1); out[0*32+17] = start + ((w9 >> 2) & 0x3ffffffff)+(0*32+17 +1); w10 = *(uint64_t *)(in+(0*17+10)*8/sizeof(in[0])); out[0*32+18] = start + ((w9 >> 36) | (w10 << 28) & 0x3ffffffff)+(0*32+18 +1); out[0*32+19] = start + ((w10 >> 6) & 0x3ffffffff)+(0*32+19 +1); w11 = *(uint64_t *)(in+(0*17+11)*8/sizeof(in[0])); out[0*32+20] = start + ((w10 >> 40) | (w11 << 24) & 0x3ffffffff)+(0*32+20 +1); out[0*32+21] = start + ((w11 >> 10) & 0x3ffffffff)+(0*32+21 +1); w12 = *(uint64_t *)(in+(0*17+12)*8/sizeof(in[0])); out[0*32+22] = start + ((w11 >> 44) | (w12 << 20) & 0x3ffffffff)+(0*32+22 +1); out[0*32+23] = start + ((w12 >> 14) & 0x3ffffffff)+(0*32+23 +1); w13 = *(uint64_t *)(in+(0*17+13)*8/sizeof(in[0])); out[0*32+24] = start + ((w12 >> 48) | (w13 << 16) & 0x3ffffffff)+(0*32+24 +1); out[0*32+25] = start + ((w13 >> 18) & 0x3ffffffff)+(0*32+25 +1); w14 = *(uint64_t *)(in+(0*17+14)*8/sizeof(in[0])); out[0*32+26] = start + ((w13 >> 52) | (w14 << 12) & 0x3ffffffff)+(0*32+26 +1); out[0*32+27] = start + ((w14 >> 22) & 0x3ffffffff)+(0*32+27 +1); w15 = *(uint64_t *)(in+(0*17+15)*8/sizeof(in[0])); out[0*32+28] = start + ((w14 >> 56) | (w15 << 8) & 0x3ffffffff)+(0*32+28 +1); out[0*32+29] = start + ((w15 >> 26) & 0x3ffffffff)+(0*32+29 +1); w16 = *(uint64_t *)(in+(0*17+16)*8/sizeof(in[0])); out[0*32+30] = start + ((w15 >> 60) | (w16 << 4) & 0x3ffffffff)+(0*32+30 +1); out[0*32+31] = start + ((w16 >> 30))+(0*32+31 +1);;}; out += 32; start += 32; in += 34*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_35(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*35)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(0*35+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7ffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*35+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 35) | (w1 << 29) & 0x7ffffffff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w1 >> 6) & 0x7ffffffff)+(0*64+ 2 +1); w2 = *(uint64_t *)(in+(0*35+2)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w1 >> 41) | (w2 << 23) & 0x7ffffffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w2 >> 12) & 0x7ffffffff)+(0*64+ 4 +1); w3 = *(uint64_t *)(in+(0*35+3)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w2 >> 47) | (w3 << 17) & 0x7ffffffff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w3 >> 18) & 0x7ffffffff)+(0*64+ 6 +1); w4 = *(uint64_t *)(in+(0*35+4)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w3 >> 53) | (w4 << 11) & 0x7ffffffff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w4 >> 24) & 0x7ffffffff)+(0*64+ 8 +1); w5 = *(uint64_t *)(in+(0*35+5)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w4 >> 59) | (w5 << 5) & 0x7ffffffff)+(0*64+ 9 +1); w6 = *(uint64_t *)(in+(0*35+6)*8/sizeof(in[0])); out[0*64+10] = start + ((w5 >> 30) | (w6 << 34) & 0x7ffffffff)+(0*64+10 +1); out[0*64+11] = start + ((w6 >> 1) & 0x7ffffffff)+(0*64+11 +1); w7 = *(uint64_t *)(in+(0*35+7)*8/sizeof(in[0])); out[0*64+12] = start + ((w6 >> 36) | (w7 << 28) & 0x7ffffffff)+(0*64+12 +1); out[0*64+13] = start + ((w7 >> 7) & 0x7ffffffff)+(0*64+13 +1); w8 = *(uint64_t *)(in+(0*35+8)*8/sizeof(in[0])); out[0*64+14] = start + ((w7 >> 42) | (w8 << 22) & 0x7ffffffff)+(0*64+14 +1); out[0*64+15] = start + ((w8 >> 13) & 0x7ffffffff)+(0*64+15 +1); w9 = *(uint64_t *)(in+(0*35+9)*8/sizeof(in[0])); out[0*64+16] = start + ((w8 >> 48) | (w9 << 16) & 0x7ffffffff)+(0*64+16 +1); out[0*64+17] = start + ((w9 >> 19) & 0x7ffffffff)+(0*64+17 +1); w10 = *(uint64_t *)(in+(0*35+10)*8/sizeof(in[0])); out[0*64+18] = start + ((w9 >> 54) | (w10 << 10) & 0x7ffffffff)+(0*64+18 +1); out[0*64+19] = start + ((w10 >> 25) & 0x7ffffffff)+(0*64+19 +1); w11 = *(uint64_t *)(in+(0*35+11)*8/sizeof(in[0])); out[0*64+20] = start + ((w10 >> 60) | (w11 << 4) & 0x7ffffffff)+(0*64+20 +1); w12 = *(uint64_t *)(in+(0*35+12)*8/sizeof(in[0])); out[0*64+21] = start + ((w11 >> 31) | (w12 << 33) & 0x7ffffffff)+(0*64+21 +1); out[0*64+22] = start + ((w12 >> 2) & 0x7ffffffff)+(0*64+22 +1); w13 = *(uint64_t *)(in+(0*35+13)*8/sizeof(in[0])); out[0*64+23] = start + ((w12 >> 37) | (w13 << 27) & 0x7ffffffff)+(0*64+23 +1); out[0*64+24] = start + ((w13 >> 8) & 0x7ffffffff)+(0*64+24 +1); w14 = *(uint64_t *)(in+(0*35+14)*8/sizeof(in[0])); out[0*64+25] = start + ((w13 >> 43) | (w14 << 21) & 0x7ffffffff)+(0*64+25 +1); out[0*64+26] = start + ((w14 >> 14) & 0x7ffffffff)+(0*64+26 +1); w15 = *(uint64_t *)(in+(0*35+15)*8/sizeof(in[0])); out[0*64+27] = start + ((w14 >> 49) | (w15 << 15) & 0x7ffffffff)+(0*64+27 +1); out[0*64+28] = start + ((w15 >> 20) & 0x7ffffffff)+(0*64+28 +1); w16 = *(uint64_t *)(in+(0*35+16)*8/sizeof(in[0])); out[0*64+29] = start + ((w15 >> 55) | (w16 << 9) & 0x7ffffffff)+(0*64+29 +1); out[0*64+30] = start + ((w16 >> 26) & 0x7ffffffff)+(0*64+30 +1); w17 = *(uint32_t *)(in+(0*35+17)*8/sizeof(in[0])); out[0*64+31] = start + ((w16 >> 61) | (w17 << 3) & 0x7ffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 35*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_36(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*36)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(0*9+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xfffffffff)+(0*16+ 0 +1); w1 = *(uint64_t *)(in+(0*9+1)*8/sizeof(in[0])); out[0*16+ 1] = start + ((w0 >> 36) | (w1 << 28) & 0xfffffffff)+(0*16+ 1 +1); out[0*16+ 2] = start + ((w1 >> 8) & 0xfffffffff)+(0*16+ 2 +1); w2 = *(uint64_t *)(in+(0*9+2)*8/sizeof(in[0])); out[0*16+ 3] = start + ((w1 >> 44) | (w2 << 20) & 0xfffffffff)+(0*16+ 3 +1); out[0*16+ 4] = start + ((w2 >> 16) & 0xfffffffff)+(0*16+ 4 +1); w3 = *(uint64_t *)(in+(0*9+3)*8/sizeof(in[0])); out[0*16+ 5] = start + ((w2 >> 52) | (w3 << 12) & 0xfffffffff)+(0*16+ 5 +1); out[0*16+ 6] = start + ((w3 >> 24) & 0xfffffffff)+(0*16+ 6 +1); w4 = *(uint64_t *)(in+(0*9+4)*8/sizeof(in[0])); out[0*16+ 7] = start + ((w3 >> 60) | (w4 << 4) & 0xfffffffff)+(0*16+ 7 +1); w5 = *(uint64_t *)(in+(0*9+5)*8/sizeof(in[0])); out[0*16+ 8] = start + ((w4 >> 32) | (w5 << 32) & 0xfffffffff)+(0*16+ 8 +1); out[0*16+ 9] = start + ((w5 >> 4) & 0xfffffffff)+(0*16+ 9 +1); w6 = *(uint64_t *)(in+(0*9+6)*8/sizeof(in[0])); out[0*16+10] = start + ((w5 >> 40) | (w6 << 24) & 0xfffffffff)+(0*16+10 +1); out[0*16+11] = start + ((w6 >> 12) & 0xfffffffff)+(0*16+11 +1); w7 = *(uint64_t *)(in+(0*9+7)*8/sizeof(in[0])); out[0*16+12] = start + ((w6 >> 48) | (w7 << 16) & 0xfffffffff)+(0*16+12 +1); out[0*16+13] = start + ((w7 >> 20) & 0xfffffffff)+(0*16+13 +1); w8 = *(uint64_t *)(in+(0*9+8)*8/sizeof(in[0])); out[0*16+14] = start + ((w7 >> 56) | (w8 << 8) & 0xfffffffff)+(0*16+14 +1); out[0*16+15] = start + ((w8 >> 28))+(0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17; w0 = *(uint64_t *)(in+(1*9+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xfffffffff)+(1*16+ 0 +1); w1 = *(uint64_t *)(in+(1*9+1)*8/sizeof(in[0])); out[1*16+ 1] = start + ((w0 >> 36) | (w1 << 28) & 0xfffffffff)+(1*16+ 1 +1); out[1*16+ 2] = start + ((w1 >> 8) & 0xfffffffff)+(1*16+ 2 +1); w2 = *(uint64_t *)(in+(1*9+2)*8/sizeof(in[0])); out[1*16+ 3] = start + ((w1 >> 44) | (w2 << 20) & 0xfffffffff)+(1*16+ 3 +1); out[1*16+ 4] = start + ((w2 >> 16) & 0xfffffffff)+(1*16+ 4 +1); w3 = *(uint64_t *)(in+(1*9+3)*8/sizeof(in[0])); out[1*16+ 5] = start + ((w2 >> 52) | (w3 << 12) & 0xfffffffff)+(1*16+ 5 +1); out[1*16+ 6] = start + ((w3 >> 24) & 0xfffffffff)+(1*16+ 6 +1); w4 = *(uint64_t *)(in+(1*9+4)*8/sizeof(in[0])); out[1*16+ 7] = start + ((w3 >> 60) | (w4 << 4) & 0xfffffffff)+(1*16+ 7 +1); w5 = *(uint64_t *)(in+(1*9+5)*8/sizeof(in[0])); out[1*16+ 8] = start + ((w4 >> 32) | (w5 << 32) & 0xfffffffff)+(1*16+ 8 +1); out[1*16+ 9] = start + ((w5 >> 4) & 0xfffffffff)+(1*16+ 9 +1); w6 = *(uint64_t *)(in+(1*9+6)*8/sizeof(in[0])); out[1*16+10] = start + ((w5 >> 40) | (w6 << 24) & 0xfffffffff)+(1*16+10 +1); out[1*16+11] = start + ((w6 >> 12) & 0xfffffffff)+(1*16+11 +1); w7 = *(uint64_t *)(in+(1*9+7)*8/sizeof(in[0])); out[1*16+12] = start + ((w6 >> 48) | (w7 << 16) & 0xfffffffff)+(1*16+12 +1); out[1*16+13] = start + ((w7 >> 20) & 0xfffffffff)+(1*16+13 +1); w8 = *(uint64_t *)(in+(1*9+8)*8/sizeof(in[0])); out[1*16+14] = start + ((w7 >> 56) | (w8 << 8) & 0xfffffffff)+(1*16+14 +1); out[1*16+15] = start + ((w8 >> 28))+(1*16+15 +1);;}; out += 32; start += 32; in += 36*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_37(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*37)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18; w0 = *(uint64_t *)(in+(0*37+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1fffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*37+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 37) | (w1 << 27) & 0x1fffffffff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w1 >> 10) & 0x1fffffffff)+(0*64+ 2 +1); w2 = *(uint64_t *)(in+(0*37+2)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w1 >> 47) | (w2 << 17) & 0x1fffffffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w2 >> 20) & 0x1fffffffff)+(0*64+ 4 +1); w3 = *(uint64_t *)(in+(0*37+3)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w2 >> 57) | (w3 << 7) & 0x1fffffffff)+(0*64+ 5 +1); w4 = *(uint64_t *)(in+(0*37+4)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w3 >> 30) | (w4 << 34) & 0x1fffffffff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w4 >> 3) & 0x1fffffffff)+(0*64+ 7 +1); w5 = *(uint64_t *)(in+(0*37+5)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w4 >> 40) | (w5 << 24) & 0x1fffffffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w5 >> 13) & 0x1fffffffff)+(0*64+ 9 +1); w6 = *(uint64_t *)(in+(0*37+6)*8/sizeof(in[0])); out[0*64+10] = start + ((w5 >> 50) | (w6 << 14) & 0x1fffffffff)+(0*64+10 +1); out[0*64+11] = start + ((w6 >> 23) & 0x1fffffffff)+(0*64+11 +1); w7 = *(uint64_t *)(in+(0*37+7)*8/sizeof(in[0])); out[0*64+12] = start + ((w6 >> 60) | (w7 << 4) & 0x1fffffffff)+(0*64+12 +1); w8 = *(uint64_t *)(in+(0*37+8)*8/sizeof(in[0])); out[0*64+13] = start + ((w7 >> 33) | (w8 << 31) & 0x1fffffffff)+(0*64+13 +1); out[0*64+14] = start + ((w8 >> 6) & 0x1fffffffff)+(0*64+14 +1); w9 = *(uint64_t *)(in+(0*37+9)*8/sizeof(in[0])); out[0*64+15] = start + ((w8 >> 43) | (w9 << 21) & 0x1fffffffff)+(0*64+15 +1); out[0*64+16] = start + ((w9 >> 16) & 0x1fffffffff)+(0*64+16 +1); w10 = *(uint64_t *)(in+(0*37+10)*8/sizeof(in[0])); out[0*64+17] = start + ((w9 >> 53) | (w10 << 11) & 0x1fffffffff)+(0*64+17 +1); out[0*64+18] = start + ((w10 >> 26) & 0x1fffffffff)+(0*64+18 +1); w11 = *(uint64_t *)(in+(0*37+11)*8/sizeof(in[0])); out[0*64+19] = start + ((w10 >> 63) | (w11 << 1) & 0x1fffffffff)+(0*64+19 +1); w12 = *(uint64_t *)(in+(0*37+12)*8/sizeof(in[0])); out[0*64+20] = start + ((w11 >> 36) | (w12 << 28) & 0x1fffffffff)+(0*64+20 +1); out[0*64+21] = start + ((w12 >> 9) & 0x1fffffffff)+(0*64+21 +1); w13 = *(uint64_t *)(in+(0*37+13)*8/sizeof(in[0])); out[0*64+22] = start + ((w12 >> 46) | (w13 << 18) & 0x1fffffffff)+(0*64+22 +1); out[0*64+23] = start + ((w13 >> 19) & 0x1fffffffff)+(0*64+23 +1); w14 = *(uint64_t *)(in+(0*37+14)*8/sizeof(in[0])); out[0*64+24] = start + ((w13 >> 56) | (w14 << 8) & 0x1fffffffff)+(0*64+24 +1); w15 = *(uint64_t *)(in+(0*37+15)*8/sizeof(in[0])); out[0*64+25] = start + ((w14 >> 29) | (w15 << 35) & 0x1fffffffff)+(0*64+25 +1); out[0*64+26] = start + ((w15 >> 2) & 0x1fffffffff)+(0*64+26 +1); w16 = *(uint64_t *)(in+(0*37+16)*8/sizeof(in[0])); out[0*64+27] = start + ((w15 >> 39) | (w16 << 25) & 0x1fffffffff)+(0*64+27 +1); out[0*64+28] = start + ((w16 >> 12) & 0x1fffffffff)+(0*64+28 +1); w17 = *(uint64_t *)(in+(0*37+17)*8/sizeof(in[0])); out[0*64+29] = start + ((w16 >> 49) | (w17 << 15) & 0x1fffffffff)+(0*64+29 +1); out[0*64+30] = start + ((w17 >> 22) & 0x1fffffffff)+(0*64+30 +1); w18 = *(uint32_t *)(in+(0*37+18)*8/sizeof(in[0])); out[0*64+31] = start + ((w17 >> 59) | (w18 << 5) & 0x1fffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 37*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_38(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*38)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18; w0 = *(uint64_t *)(in+(0*19+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3fffffffff)+(0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*19+1)*8/sizeof(in[0])); out[0*32+ 1] = start + ((w0 >> 38) | (w1 << 26) & 0x3fffffffff)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w1 >> 12) & 0x3fffffffff)+(0*32+ 2 +1); w2 = *(uint64_t *)(in+(0*19+2)*8/sizeof(in[0])); out[0*32+ 3] = start + ((w1 >> 50) | (w2 << 14) & 0x3fffffffff)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w2 >> 24) & 0x3fffffffff)+(0*32+ 4 +1); w3 = *(uint64_t *)(in+(0*19+3)*8/sizeof(in[0])); out[0*32+ 5] = start + ((w2 >> 62) | (w3 << 2) & 0x3fffffffff)+(0*32+ 5 +1); w4 = *(uint64_t *)(in+(0*19+4)*8/sizeof(in[0])); out[0*32+ 6] = start + ((w3 >> 36) | (w4 << 28) & 0x3fffffffff)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w4 >> 10) & 0x3fffffffff)+(0*32+ 7 +1); w5 = *(uint64_t *)(in+(0*19+5)*8/sizeof(in[0])); out[0*32+ 8] = start + ((w4 >> 48) | (w5 << 16) & 0x3fffffffff)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w5 >> 22) & 0x3fffffffff)+(0*32+ 9 +1); w6 = *(uint64_t *)(in+(0*19+6)*8/sizeof(in[0])); out[0*32+10] = start + ((w5 >> 60) | (w6 << 4) & 0x3fffffffff)+(0*32+10 +1); w7 = *(uint64_t *)(in+(0*19+7)*8/sizeof(in[0])); out[0*32+11] = start + ((w6 >> 34) | (w7 << 30) & 0x3fffffffff)+(0*32+11 +1); out[0*32+12] = start + ((w7 >> 8) & 0x3fffffffff)+(0*32+12 +1); w8 = *(uint64_t *)(in+(0*19+8)*8/sizeof(in[0])); out[0*32+13] = start + ((w7 >> 46) | (w8 << 18) & 0x3fffffffff)+(0*32+13 +1); out[0*32+14] = start + ((w8 >> 20) & 0x3fffffffff)+(0*32+14 +1); w9 = *(uint64_t *)(in+(0*19+9)*8/sizeof(in[0])); out[0*32+15] = start + ((w8 >> 58) | (w9 << 6) & 0x3fffffffff)+(0*32+15 +1); w10 = *(uint64_t *)(in+(0*19+10)*8/sizeof(in[0])); out[0*32+16] = start + ((w9 >> 32) | (w10 << 32) & 0x3fffffffff)+(0*32+16 +1); out[0*32+17] = start + ((w10 >> 6) & 0x3fffffffff)+(0*32+17 +1); w11 = *(uint64_t *)(in+(0*19+11)*8/sizeof(in[0])); out[0*32+18] = start + ((w10 >> 44) | (w11 << 20) & 0x3fffffffff)+(0*32+18 +1); out[0*32+19] = start + ((w11 >> 18) & 0x3fffffffff)+(0*32+19 +1); w12 = *(uint64_t *)(in+(0*19+12)*8/sizeof(in[0])); out[0*32+20] = start + ((w11 >> 56) | (w12 << 8) & 0x3fffffffff)+(0*32+20 +1); w13 = *(uint64_t *)(in+(0*19+13)*8/sizeof(in[0])); out[0*32+21] = start + ((w12 >> 30) | (w13 << 34) & 0x3fffffffff)+(0*32+21 +1); out[0*32+22] = start + ((w13 >> 4) & 0x3fffffffff)+(0*32+22 +1); w14 = *(uint64_t *)(in+(0*19+14)*8/sizeof(in[0])); out[0*32+23] = start + ((w13 >> 42) | (w14 << 22) & 0x3fffffffff)+(0*32+23 +1); out[0*32+24] = start + ((w14 >> 16) & 0x3fffffffff)+(0*32+24 +1); w15 = *(uint64_t *)(in+(0*19+15)*8/sizeof(in[0])); out[0*32+25] = start + ((w14 >> 54) | (w15 << 10) & 0x3fffffffff)+(0*32+25 +1); w16 = *(uint64_t *)(in+(0*19+16)*8/sizeof(in[0])); out[0*32+26] = start + ((w15 >> 28) | (w16 << 36) & 0x3fffffffff)+(0*32+26 +1); out[0*32+27] = start + ((w16 >> 2) & 0x3fffffffff)+(0*32+27 +1); w17 = *(uint64_t *)(in+(0*19+17)*8/sizeof(in[0])); out[0*32+28] = start + ((w16 >> 40) | (w17 << 24) & 0x3fffffffff)+(0*32+28 +1); out[0*32+29] = start + ((w17 >> 14) & 0x3fffffffff)+(0*32+29 +1); w18 = *(uint64_t *)(in+(0*19+18)*8/sizeof(in[0])); out[0*32+30] = start + ((w17 >> 52) | (w18 << 12) & 0x3fffffffff)+(0*32+30 +1); out[0*32+31] = start + ((w18 >> 26))+(0*32+31 +1);;}; out += 32; start += 32; in += 38*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_39(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*39)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(0*39+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7fffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*39+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 39) | (w1 << 25) & 0x7fffffffff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w1 >> 14) & 0x7fffffffff)+(0*64+ 2 +1); w2 = *(uint64_t *)(in+(0*39+2)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w1 >> 53) | (w2 << 11) & 0x7fffffffff)+(0*64+ 3 +1); w3 = *(uint64_t *)(in+(0*39+3)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w2 >> 28) | (w3 << 36) & 0x7fffffffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w3 >> 3) & 0x7fffffffff)+(0*64+ 5 +1); w4 = *(uint64_t *)(in+(0*39+4)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w3 >> 42) | (w4 << 22) & 0x7fffffffff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w4 >> 17) & 0x7fffffffff)+(0*64+ 7 +1); w5 = *(uint64_t *)(in+(0*39+5)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w4 >> 56) | (w5 << 8) & 0x7fffffffff)+(0*64+ 8 +1); w6 = *(uint64_t *)(in+(0*39+6)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w5 >> 31) | (w6 << 33) & 0x7fffffffff)+(0*64+ 9 +1); out[0*64+10] = start + ((w6 >> 6) & 0x7fffffffff)+(0*64+10 +1); w7 = *(uint64_t *)(in+(0*39+7)*8/sizeof(in[0])); out[0*64+11] = start + ((w6 >> 45) | (w7 << 19) & 0x7fffffffff)+(0*64+11 +1); out[0*64+12] = start + ((w7 >> 20) & 0x7fffffffff)+(0*64+12 +1); w8 = *(uint64_t *)(in+(0*39+8)*8/sizeof(in[0])); out[0*64+13] = start + ((w7 >> 59) | (w8 << 5) & 0x7fffffffff)+(0*64+13 +1); w9 = *(uint64_t *)(in+(0*39+9)*8/sizeof(in[0])); out[0*64+14] = start + ((w8 >> 34) | (w9 << 30) & 0x7fffffffff)+(0*64+14 +1); out[0*64+15] = start + ((w9 >> 9) & 0x7fffffffff)+(0*64+15 +1); w10 = *(uint64_t *)(in+(0*39+10)*8/sizeof(in[0])); out[0*64+16] = start + ((w9 >> 48) | (w10 << 16) & 0x7fffffffff)+(0*64+16 +1); out[0*64+17] = start + ((w10 >> 23) & 0x7fffffffff)+(0*64+17 +1); w11 = *(uint64_t *)(in+(0*39+11)*8/sizeof(in[0])); out[0*64+18] = start + ((w10 >> 62) | (w11 << 2) & 0x7fffffffff)+(0*64+18 +1); w12 = *(uint64_t *)(in+(0*39+12)*8/sizeof(in[0])); out[0*64+19] = start + ((w11 >> 37) | (w12 << 27) & 0x7fffffffff)+(0*64+19 +1); out[0*64+20] = start + ((w12 >> 12) & 0x7fffffffff)+(0*64+20 +1); w13 = *(uint64_t *)(in+(0*39+13)*8/sizeof(in[0])); out[0*64+21] = start + ((w12 >> 51) | (w13 << 13) & 0x7fffffffff)+(0*64+21 +1); w14 = *(uint64_t *)(in+(0*39+14)*8/sizeof(in[0])); out[0*64+22] = start + ((w13 >> 26) | (w14 << 38) & 0x7fffffffff)+(0*64+22 +1); out[0*64+23] = start + ((w14 >> 1) & 0x7fffffffff)+(0*64+23 +1); w15 = *(uint64_t *)(in+(0*39+15)*8/sizeof(in[0])); out[0*64+24] = start + ((w14 >> 40) | (w15 << 24) & 0x7fffffffff)+(0*64+24 +1); out[0*64+25] = start + ((w15 >> 15) & 0x7fffffffff)+(0*64+25 +1); w16 = *(uint64_t *)(in+(0*39+16)*8/sizeof(in[0])); out[0*64+26] = start + ((w15 >> 54) | (w16 << 10) & 0x7fffffffff)+(0*64+26 +1); w17 = *(uint64_t *)(in+(0*39+17)*8/sizeof(in[0])); out[0*64+27] = start + ((w16 >> 29) | (w17 << 35) & 0x7fffffffff)+(0*64+27 +1); out[0*64+28] = start + ((w17 >> 4) & 0x7fffffffff)+(0*64+28 +1); w18 = *(uint64_t *)(in+(0*39+18)*8/sizeof(in[0])); out[0*64+29] = start + ((w17 >> 43) | (w18 << 21) & 0x7fffffffff)+(0*64+29 +1); out[0*64+30] = start + ((w18 >> 18) & 0x7fffffffff)+(0*64+30 +1); w19 = *(uint32_t *)(in+(0*39+19)*8/sizeof(in[0])); out[0*64+31] = start + ((w18 >> 57) | (w19 << 7) & 0x7fffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 39*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_40(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*40)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(0*5+0)*8/sizeof(in[0])); out[0*8+ 0] = start + ((w0 ) & 0xffffffffff)+(0*8+ 0 +1); w1 = *(uint64_t *)(in+(0*5+1)*8/sizeof(in[0])); out[0*8+ 1] = start + ((w0 >> 40) | (w1 << 24) & 0xffffffffff)+(0*8+ 1 +1); out[0*8+ 2] = start + ((w1 >> 16) & 0xffffffffff)+(0*8+ 2 +1); w2 = *(uint64_t *)(in+(0*5+2)*8/sizeof(in[0])); out[0*8+ 3] = start + ((w1 >> 56) | (w2 << 8) & 0xffffffffff)+(0*8+ 3 +1); w3 = *(uint64_t *)(in+(0*5+3)*8/sizeof(in[0])); out[0*8+ 4] = start + ((w2 >> 32) | (w3 << 32) & 0xffffffffff)+(0*8+ 4 +1); out[0*8+ 5] = start + ((w3 >> 8) & 0xffffffffff)+(0*8+ 5 +1); w4 = *(uint64_t *)(in+(0*5+4)*8/sizeof(in[0])); out[0*8+ 6] = start + ((w3 >> 48) | (w4 << 16) & 0xffffffffff)+(0*8+ 6 +1); out[0*8+ 7] = start + ((w4 >> 24))+(0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(1*5+0)*8/sizeof(in[0])); out[1*8+ 0] = start + ((w0 ) & 0xffffffffff)+(1*8+ 0 +1); w1 = *(uint64_t *)(in+(1*5+1)*8/sizeof(in[0])); out[1*8+ 1] = start + ((w0 >> 40) | (w1 << 24) & 0xffffffffff)+(1*8+ 1 +1); out[1*8+ 2] = start + ((w1 >> 16) & 0xffffffffff)+(1*8+ 2 +1); w2 = *(uint64_t *)(in+(1*5+2)*8/sizeof(in[0])); out[1*8+ 3] = start + ((w1 >> 56) | (w2 << 8) & 0xffffffffff)+(1*8+ 3 +1); w3 = *(uint64_t *)(in+(1*5+3)*8/sizeof(in[0])); out[1*8+ 4] = start + ((w2 >> 32) | (w3 << 32) & 0xffffffffff)+(1*8+ 4 +1); out[1*8+ 5] = start + ((w3 >> 8) & 0xffffffffff)+(1*8+ 5 +1); w4 = *(uint64_t *)(in+(1*5+4)*8/sizeof(in[0])); out[1*8+ 6] = start + ((w3 >> 48) | (w4 << 16) & 0xffffffffff)+(1*8+ 6 +1); out[1*8+ 7] = start + ((w4 >> 24))+(1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(2*5+0)*8/sizeof(in[0])); out[2*8+ 0] = start + ((w0 ) & 0xffffffffff)+(2*8+ 0 +1); w1 = *(uint64_t *)(in+(2*5+1)*8/sizeof(in[0])); out[2*8+ 1] = start + ((w0 >> 40) | (w1 << 24) & 0xffffffffff)+(2*8+ 1 +1); out[2*8+ 2] = start + ((w1 >> 16) & 0xffffffffff)+(2*8+ 2 +1); w2 = *(uint64_t *)(in+(2*5+2)*8/sizeof(in[0])); out[2*8+ 3] = start + ((w1 >> 56) | (w2 << 8) & 0xffffffffff)+(2*8+ 3 +1); w3 = *(uint64_t *)(in+(2*5+3)*8/sizeof(in[0])); out[2*8+ 4] = start + ((w2 >> 32) | (w3 << 32) & 0xffffffffff)+(2*8+ 4 +1); out[2*8+ 5] = start + ((w3 >> 8) & 0xffffffffff)+(2*8+ 5 +1); w4 = *(uint64_t *)(in+(2*5+4)*8/sizeof(in[0])); out[2*8+ 6] = start + ((w3 >> 48) | (w4 << 16) & 0xffffffffff)+(2*8+ 6 +1); out[2*8+ 7] = start + ((w4 >> 24))+(2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19; w0 = *(uint64_t *)(in+(3*5+0)*8/sizeof(in[0])); out[3*8+ 0] = start + ((w0 ) & 0xffffffffff)+(3*8+ 0 +1); w1 = *(uint64_t *)(in+(3*5+1)*8/sizeof(in[0])); out[3*8+ 1] = start + ((w0 >> 40) | (w1 << 24) & 0xffffffffff)+(3*8+ 1 +1); out[3*8+ 2] = start + ((w1 >> 16) & 0xffffffffff)+(3*8+ 2 +1); w2 = *(uint64_t *)(in+(3*5+2)*8/sizeof(in[0])); out[3*8+ 3] = start + ((w1 >> 56) | (w2 << 8) & 0xffffffffff)+(3*8+ 3 +1); w3 = *(uint64_t *)(in+(3*5+3)*8/sizeof(in[0])); out[3*8+ 4] = start + ((w2 >> 32) | (w3 << 32) & 0xffffffffff)+(3*8+ 4 +1); out[3*8+ 5] = start + ((w3 >> 8) & 0xffffffffff)+(3*8+ 5 +1); w4 = *(uint64_t *)(in+(3*5+4)*8/sizeof(in[0])); out[3*8+ 6] = start + ((w3 >> 48) | (w4 << 16) & 0xffffffffff)+(3*8+ 6 +1); out[3*8+ 7] = start + ((w4 >> 24))+(3*8+ 7 +1);;}; out += 32; start += 32; in += 40*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_41(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*41)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20; w0 = *(uint64_t *)(in+(0*41+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1ffffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*41+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 41) | (w1 << 23) & 0x1ffffffffff)+(0*64+ 1 +1); out[0*64+ 2] = start + ((w1 >> 18) & 0x1ffffffffff)+(0*64+ 2 +1); w2 = *(uint64_t *)(in+(0*41+2)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w1 >> 59) | (w2 << 5) & 0x1ffffffffff)+(0*64+ 3 +1); w3 = *(uint64_t *)(in+(0*41+3)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w2 >> 36) | (w3 << 28) & 0x1ffffffffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w3 >> 13) & 0x1ffffffffff)+(0*64+ 5 +1); w4 = *(uint64_t *)(in+(0*41+4)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w3 >> 54) | (w4 << 10) & 0x1ffffffffff)+(0*64+ 6 +1); w5 = *(uint64_t *)(in+(0*41+5)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w4 >> 31) | (w5 << 33) & 0x1ffffffffff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w5 >> 8) & 0x1ffffffffff)+(0*64+ 8 +1); w6 = *(uint64_t *)(in+(0*41+6)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w5 >> 49) | (w6 << 15) & 0x1ffffffffff)+(0*64+ 9 +1); w7 = *(uint64_t *)(in+(0*41+7)*8/sizeof(in[0])); out[0*64+10] = start + ((w6 >> 26) | (w7 << 38) & 0x1ffffffffff)+(0*64+10 +1); out[0*64+11] = start + ((w7 >> 3) & 0x1ffffffffff)+(0*64+11 +1); w8 = *(uint64_t *)(in+(0*41+8)*8/sizeof(in[0])); out[0*64+12] = start + ((w7 >> 44) | (w8 << 20) & 0x1ffffffffff)+(0*64+12 +1); out[0*64+13] = start + ((w8 >> 21) & 0x1ffffffffff)+(0*64+13 +1); w9 = *(uint64_t *)(in+(0*41+9)*8/sizeof(in[0])); out[0*64+14] = start + ((w8 >> 62) | (w9 << 2) & 0x1ffffffffff)+(0*64+14 +1); w10 = *(uint64_t *)(in+(0*41+10)*8/sizeof(in[0])); out[0*64+15] = start + ((w9 >> 39) | (w10 << 25) & 0x1ffffffffff)+(0*64+15 +1); out[0*64+16] = start + ((w10 >> 16) & 0x1ffffffffff)+(0*64+16 +1); w11 = *(uint64_t *)(in+(0*41+11)*8/sizeof(in[0])); out[0*64+17] = start + ((w10 >> 57) | (w11 << 7) & 0x1ffffffffff)+(0*64+17 +1); w12 = *(uint64_t *)(in+(0*41+12)*8/sizeof(in[0])); out[0*64+18] = start + ((w11 >> 34) | (w12 << 30) & 0x1ffffffffff)+(0*64+18 +1); out[0*64+19] = start + ((w12 >> 11) & 0x1ffffffffff)+(0*64+19 +1); w13 = *(uint64_t *)(in+(0*41+13)*8/sizeof(in[0])); out[0*64+20] = start + ((w12 >> 52) | (w13 << 12) & 0x1ffffffffff)+(0*64+20 +1); w14 = *(uint64_t *)(in+(0*41+14)*8/sizeof(in[0])); out[0*64+21] = start + ((w13 >> 29) | (w14 << 35) & 0x1ffffffffff)+(0*64+21 +1); out[0*64+22] = start + ((w14 >> 6) & 0x1ffffffffff)+(0*64+22 +1); w15 = *(uint64_t *)(in+(0*41+15)*8/sizeof(in[0])); out[0*64+23] = start + ((w14 >> 47) | (w15 << 17) & 0x1ffffffffff)+(0*64+23 +1); w16 = *(uint64_t *)(in+(0*41+16)*8/sizeof(in[0])); out[0*64+24] = start + ((w15 >> 24) | (w16 << 40) & 0x1ffffffffff)+(0*64+24 +1); out[0*64+25] = start + ((w16 >> 1) & 0x1ffffffffff)+(0*64+25 +1); w17 = *(uint64_t *)(in+(0*41+17)*8/sizeof(in[0])); out[0*64+26] = start + ((w16 >> 42) | (w17 << 22) & 0x1ffffffffff)+(0*64+26 +1); out[0*64+27] = start + ((w17 >> 19) & 0x1ffffffffff)+(0*64+27 +1); w18 = *(uint64_t *)(in+(0*41+18)*8/sizeof(in[0])); out[0*64+28] = start + ((w17 >> 60) | (w18 << 4) & 0x1ffffffffff)+(0*64+28 +1); w19 = *(uint64_t *)(in+(0*41+19)*8/sizeof(in[0])); out[0*64+29] = start + ((w18 >> 37) | (w19 << 27) & 0x1ffffffffff)+(0*64+29 +1); out[0*64+30] = start + ((w19 >> 14) & 0x1ffffffffff)+(0*64+30 +1); w20 = *(uint32_t *)(in+(0*41+20)*8/sizeof(in[0])); out[0*64+31] = start + ((w19 >> 55) | (w20 << 9) & 0x1ffffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 41*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_42(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*42)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20; w0 = *(uint64_t *)(in+(0*21+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3ffffffffff)+(0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*21+1)*8/sizeof(in[0])); out[0*32+ 1] = start + ((w0 >> 42) | (w1 << 22) & 0x3ffffffffff)+(0*32+ 1 +1); out[0*32+ 2] = start + ((w1 >> 20) & 0x3ffffffffff)+(0*32+ 2 +1); w2 = *(uint64_t *)(in+(0*21+2)*8/sizeof(in[0])); out[0*32+ 3] = start + ((w1 >> 62) | (w2 << 2) & 0x3ffffffffff)+(0*32+ 3 +1); w3 = *(uint64_t *)(in+(0*21+3)*8/sizeof(in[0])); out[0*32+ 4] = start + ((w2 >> 40) | (w3 << 24) & 0x3ffffffffff)+(0*32+ 4 +1); out[0*32+ 5] = start + ((w3 >> 18) & 0x3ffffffffff)+(0*32+ 5 +1); w4 = *(uint64_t *)(in+(0*21+4)*8/sizeof(in[0])); out[0*32+ 6] = start + ((w3 >> 60) | (w4 << 4) & 0x3ffffffffff)+(0*32+ 6 +1); w5 = *(uint64_t *)(in+(0*21+5)*8/sizeof(in[0])); out[0*32+ 7] = start + ((w4 >> 38) | (w5 << 26) & 0x3ffffffffff)+(0*32+ 7 +1); out[0*32+ 8] = start + ((w5 >> 16) & 0x3ffffffffff)+(0*32+ 8 +1); w6 = *(uint64_t *)(in+(0*21+6)*8/sizeof(in[0])); out[0*32+ 9] = start + ((w5 >> 58) | (w6 << 6) & 0x3ffffffffff)+(0*32+ 9 +1); w7 = *(uint64_t *)(in+(0*21+7)*8/sizeof(in[0])); out[0*32+10] = start + ((w6 >> 36) | (w7 << 28) & 0x3ffffffffff)+(0*32+10 +1); out[0*32+11] = start + ((w7 >> 14) & 0x3ffffffffff)+(0*32+11 +1); w8 = *(uint64_t *)(in+(0*21+8)*8/sizeof(in[0])); out[0*32+12] = start + ((w7 >> 56) | (w8 << 8) & 0x3ffffffffff)+(0*32+12 +1); w9 = *(uint64_t *)(in+(0*21+9)*8/sizeof(in[0])); out[0*32+13] = start + ((w8 >> 34) | (w9 << 30) & 0x3ffffffffff)+(0*32+13 +1); out[0*32+14] = start + ((w9 >> 12) & 0x3ffffffffff)+(0*32+14 +1); w10 = *(uint64_t *)(in+(0*21+10)*8/sizeof(in[0])); out[0*32+15] = start + ((w9 >> 54) | (w10 << 10) & 0x3ffffffffff)+(0*32+15 +1); w11 = *(uint64_t *)(in+(0*21+11)*8/sizeof(in[0])); out[0*32+16] = start + ((w10 >> 32) | (w11 << 32) & 0x3ffffffffff)+(0*32+16 +1); out[0*32+17] = start + ((w11 >> 10) & 0x3ffffffffff)+(0*32+17 +1); w12 = *(uint64_t *)(in+(0*21+12)*8/sizeof(in[0])); out[0*32+18] = start + ((w11 >> 52) | (w12 << 12) & 0x3ffffffffff)+(0*32+18 +1); w13 = *(uint64_t *)(in+(0*21+13)*8/sizeof(in[0])); out[0*32+19] = start + ((w12 >> 30) | (w13 << 34) & 0x3ffffffffff)+(0*32+19 +1); out[0*32+20] = start + ((w13 >> 8) & 0x3ffffffffff)+(0*32+20 +1); w14 = *(uint64_t *)(in+(0*21+14)*8/sizeof(in[0])); out[0*32+21] = start + ((w13 >> 50) | (w14 << 14) & 0x3ffffffffff)+(0*32+21 +1); w15 = *(uint64_t *)(in+(0*21+15)*8/sizeof(in[0])); out[0*32+22] = start + ((w14 >> 28) | (w15 << 36) & 0x3ffffffffff)+(0*32+22 +1); out[0*32+23] = start + ((w15 >> 6) & 0x3ffffffffff)+(0*32+23 +1); w16 = *(uint64_t *)(in+(0*21+16)*8/sizeof(in[0])); out[0*32+24] = start + ((w15 >> 48) | (w16 << 16) & 0x3ffffffffff)+(0*32+24 +1); w17 = *(uint64_t *)(in+(0*21+17)*8/sizeof(in[0])); out[0*32+25] = start + ((w16 >> 26) | (w17 << 38) & 0x3ffffffffff)+(0*32+25 +1); out[0*32+26] = start + ((w17 >> 4) & 0x3ffffffffff)+(0*32+26 +1); w18 = *(uint64_t *)(in+(0*21+18)*8/sizeof(in[0])); out[0*32+27] = start + ((w17 >> 46) | (w18 << 18) & 0x3ffffffffff)+(0*32+27 +1); w19 = *(uint64_t *)(in+(0*21+19)*8/sizeof(in[0])); out[0*32+28] = start + ((w18 >> 24) | (w19 << 40) & 0x3ffffffffff)+(0*32+28 +1); out[0*32+29] = start + ((w19 >> 2) & 0x3ffffffffff)+(0*32+29 +1); w20 = *(uint64_t *)(in+(0*21+20)*8/sizeof(in[0])); out[0*32+30] = start + ((w19 >> 44) | (w20 << 20) & 0x3ffffffffff)+(0*32+30 +1); out[0*32+31] = start + ((w20 >> 22))+(0*32+31 +1);;}; out += 32; start += 32; in += 42*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_43(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*43)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(0*43+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7ffffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*43+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 43) | (w1 << 21) & 0x7ffffffffff)+(0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*43+2)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w1 >> 22) | (w2 << 42) & 0x7ffffffffff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w2 >> 1) & 0x7ffffffffff)+(0*64+ 3 +1); w3 = *(uint64_t *)(in+(0*43+3)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w2 >> 44) | (w3 << 20) & 0x7ffffffffff)+(0*64+ 4 +1); w4 = *(uint64_t *)(in+(0*43+4)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w3 >> 23) | (w4 << 41) & 0x7ffffffffff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w4 >> 2) & 0x7ffffffffff)+(0*64+ 6 +1); w5 = *(uint64_t *)(in+(0*43+5)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w4 >> 45) | (w5 << 19) & 0x7ffffffffff)+(0*64+ 7 +1); w6 = *(uint64_t *)(in+(0*43+6)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w5 >> 24) | (w6 << 40) & 0x7ffffffffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w6 >> 3) & 0x7ffffffffff)+(0*64+ 9 +1); w7 = *(uint64_t *)(in+(0*43+7)*8/sizeof(in[0])); out[0*64+10] = start + ((w6 >> 46) | (w7 << 18) & 0x7ffffffffff)+(0*64+10 +1); w8 = *(uint64_t *)(in+(0*43+8)*8/sizeof(in[0])); out[0*64+11] = start + ((w7 >> 25) | (w8 << 39) & 0x7ffffffffff)+(0*64+11 +1); out[0*64+12] = start + ((w8 >> 4) & 0x7ffffffffff)+(0*64+12 +1); w9 = *(uint64_t *)(in+(0*43+9)*8/sizeof(in[0])); out[0*64+13] = start + ((w8 >> 47) | (w9 << 17) & 0x7ffffffffff)+(0*64+13 +1); w10 = *(uint64_t *)(in+(0*43+10)*8/sizeof(in[0])); out[0*64+14] = start + ((w9 >> 26) | (w10 << 38) & 0x7ffffffffff)+(0*64+14 +1); out[0*64+15] = start + ((w10 >> 5) & 0x7ffffffffff)+(0*64+15 +1); w11 = *(uint64_t *)(in+(0*43+11)*8/sizeof(in[0])); out[0*64+16] = start + ((w10 >> 48) | (w11 << 16) & 0x7ffffffffff)+(0*64+16 +1); w12 = *(uint64_t *)(in+(0*43+12)*8/sizeof(in[0])); out[0*64+17] = start + ((w11 >> 27) | (w12 << 37) & 0x7ffffffffff)+(0*64+17 +1); out[0*64+18] = start + ((w12 >> 6) & 0x7ffffffffff)+(0*64+18 +1); w13 = *(uint64_t *)(in+(0*43+13)*8/sizeof(in[0])); out[0*64+19] = start + ((w12 >> 49) | (w13 << 15) & 0x7ffffffffff)+(0*64+19 +1); w14 = *(uint64_t *)(in+(0*43+14)*8/sizeof(in[0])); out[0*64+20] = start + ((w13 >> 28) | (w14 << 36) & 0x7ffffffffff)+(0*64+20 +1); out[0*64+21] = start + ((w14 >> 7) & 0x7ffffffffff)+(0*64+21 +1); w15 = *(uint64_t *)(in+(0*43+15)*8/sizeof(in[0])); out[0*64+22] = start + ((w14 >> 50) | (w15 << 14) & 0x7ffffffffff)+(0*64+22 +1); w16 = *(uint64_t *)(in+(0*43+16)*8/sizeof(in[0])); out[0*64+23] = start + ((w15 >> 29) | (w16 << 35) & 0x7ffffffffff)+(0*64+23 +1); out[0*64+24] = start + ((w16 >> 8) & 0x7ffffffffff)+(0*64+24 +1); w17 = *(uint64_t *)(in+(0*43+17)*8/sizeof(in[0])); out[0*64+25] = start + ((w16 >> 51) | (w17 << 13) & 0x7ffffffffff)+(0*64+25 +1); w18 = *(uint64_t *)(in+(0*43+18)*8/sizeof(in[0])); out[0*64+26] = start + ((w17 >> 30) | (w18 << 34) & 0x7ffffffffff)+(0*64+26 +1); out[0*64+27] = start + ((w18 >> 9) & 0x7ffffffffff)+(0*64+27 +1); w19 = *(uint64_t *)(in+(0*43+19)*8/sizeof(in[0])); out[0*64+28] = start + ((w18 >> 52) | (w19 << 12) & 0x7ffffffffff)+(0*64+28 +1); w20 = *(uint64_t *)(in+(0*43+20)*8/sizeof(in[0])); out[0*64+29] = start + ((w19 >> 31) | (w20 << 33) & 0x7ffffffffff)+(0*64+29 +1); out[0*64+30] = start + ((w20 >> 10) & 0x7ffffffffff)+(0*64+30 +1); w21 = *(uint32_t *)(in+(0*43+21)*8/sizeof(in[0])); out[0*64+31] = start + ((w20 >> 53) | (w21 << 11) & 0x7ffffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 43*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_44(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*44)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(0*11+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xfffffffffff)+(0*16+ 0 +1); w1 = *(uint64_t *)(in+(0*11+1)*8/sizeof(in[0])); out[0*16+ 1] = start + ((w0 >> 44) | (w1 << 20) & 0xfffffffffff)+(0*16+ 1 +1); w2 = *(uint64_t *)(in+(0*11+2)*8/sizeof(in[0])); out[0*16+ 2] = start + ((w1 >> 24) | (w2 << 40) & 0xfffffffffff)+(0*16+ 2 +1); out[0*16+ 3] = start + ((w2 >> 4) & 0xfffffffffff)+(0*16+ 3 +1); w3 = *(uint64_t *)(in+(0*11+3)*8/sizeof(in[0])); out[0*16+ 4] = start + ((w2 >> 48) | (w3 << 16) & 0xfffffffffff)+(0*16+ 4 +1); w4 = *(uint64_t *)(in+(0*11+4)*8/sizeof(in[0])); out[0*16+ 5] = start + ((w3 >> 28) | (w4 << 36) & 0xfffffffffff)+(0*16+ 5 +1); out[0*16+ 6] = start + ((w4 >> 8) & 0xfffffffffff)+(0*16+ 6 +1); w5 = *(uint64_t *)(in+(0*11+5)*8/sizeof(in[0])); out[0*16+ 7] = start + ((w4 >> 52) | (w5 << 12) & 0xfffffffffff)+(0*16+ 7 +1); w6 = *(uint64_t *)(in+(0*11+6)*8/sizeof(in[0])); out[0*16+ 8] = start + ((w5 >> 32) | (w6 << 32) & 0xfffffffffff)+(0*16+ 8 +1); out[0*16+ 9] = start + ((w6 >> 12) & 0xfffffffffff)+(0*16+ 9 +1); w7 = *(uint64_t *)(in+(0*11+7)*8/sizeof(in[0])); out[0*16+10] = start + ((w6 >> 56) | (w7 << 8) & 0xfffffffffff)+(0*16+10 +1); w8 = *(uint64_t *)(in+(0*11+8)*8/sizeof(in[0])); out[0*16+11] = start + ((w7 >> 36) | (w8 << 28) & 0xfffffffffff)+(0*16+11 +1); out[0*16+12] = start + ((w8 >> 16) & 0xfffffffffff)+(0*16+12 +1); w9 = *(uint64_t *)(in+(0*11+9)*8/sizeof(in[0])); out[0*16+13] = start + ((w8 >> 60) | (w9 << 4) & 0xfffffffffff)+(0*16+13 +1); w10 = *(uint64_t *)(in+(0*11+10)*8/sizeof(in[0])); out[0*16+14] = start + ((w9 >> 40) | (w10 << 24) & 0xfffffffffff)+(0*16+14 +1); out[0*16+15] = start + ((w10 >> 20))+(0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21; w0 = *(uint64_t *)(in+(1*11+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xfffffffffff)+(1*16+ 0 +1); w1 = *(uint64_t *)(in+(1*11+1)*8/sizeof(in[0])); out[1*16+ 1] = start + ((w0 >> 44) | (w1 << 20) & 0xfffffffffff)+(1*16+ 1 +1); w2 = *(uint64_t *)(in+(1*11+2)*8/sizeof(in[0])); out[1*16+ 2] = start + ((w1 >> 24) | (w2 << 40) & 0xfffffffffff)+(1*16+ 2 +1); out[1*16+ 3] = start + ((w2 >> 4) & 0xfffffffffff)+(1*16+ 3 +1); w3 = *(uint64_t *)(in+(1*11+3)*8/sizeof(in[0])); out[1*16+ 4] = start + ((w2 >> 48) | (w3 << 16) & 0xfffffffffff)+(1*16+ 4 +1); w4 = *(uint64_t *)(in+(1*11+4)*8/sizeof(in[0])); out[1*16+ 5] = start + ((w3 >> 28) | (w4 << 36) & 0xfffffffffff)+(1*16+ 5 +1); out[1*16+ 6] = start + ((w4 >> 8) & 0xfffffffffff)+(1*16+ 6 +1); w5 = *(uint64_t *)(in+(1*11+5)*8/sizeof(in[0])); out[1*16+ 7] = start + ((w4 >> 52) | (w5 << 12) & 0xfffffffffff)+(1*16+ 7 +1); w6 = *(uint64_t *)(in+(1*11+6)*8/sizeof(in[0])); out[1*16+ 8] = start + ((w5 >> 32) | (w6 << 32) & 0xfffffffffff)+(1*16+ 8 +1); out[1*16+ 9] = start + ((w6 >> 12) & 0xfffffffffff)+(1*16+ 9 +1); w7 = *(uint64_t *)(in+(1*11+7)*8/sizeof(in[0])); out[1*16+10] = start + ((w6 >> 56) | (w7 << 8) & 0xfffffffffff)+(1*16+10 +1); w8 = *(uint64_t *)(in+(1*11+8)*8/sizeof(in[0])); out[1*16+11] = start + ((w7 >> 36) | (w8 << 28) & 0xfffffffffff)+(1*16+11 +1); out[1*16+12] = start + ((w8 >> 16) & 0xfffffffffff)+(1*16+12 +1); w9 = *(uint64_t *)(in+(1*11+9)*8/sizeof(in[0])); out[1*16+13] = start + ((w8 >> 60) | (w9 << 4) & 0xfffffffffff)+(1*16+13 +1); w10 = *(uint64_t *)(in+(1*11+10)*8/sizeof(in[0])); out[1*16+14] = start + ((w9 >> 40) | (w10 << 24) & 0xfffffffffff)+(1*16+14 +1); out[1*16+15] = start + ((w10 >> 20))+(1*16+15 +1);;}; out += 32; start += 32; in += 44*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_45(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*45)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22; w0 = *(uint64_t *)(in+(0*45+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1fffffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*45+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 45) | (w1 << 19) & 0x1fffffffffff)+(0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*45+2)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w1 >> 26) | (w2 << 38) & 0x1fffffffffff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w2 >> 7) & 0x1fffffffffff)+(0*64+ 3 +1); w3 = *(uint64_t *)(in+(0*45+3)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w2 >> 52) | (w3 << 12) & 0x1fffffffffff)+(0*64+ 4 +1); w4 = *(uint64_t *)(in+(0*45+4)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w3 >> 33) | (w4 << 31) & 0x1fffffffffff)+(0*64+ 5 +1); out[0*64+ 6] = start + ((w4 >> 14) & 0x1fffffffffff)+(0*64+ 6 +1); w5 = *(uint64_t *)(in+(0*45+5)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w4 >> 59) | (w5 << 5) & 0x1fffffffffff)+(0*64+ 7 +1); w6 = *(uint64_t *)(in+(0*45+6)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w5 >> 40) | (w6 << 24) & 0x1fffffffffff)+(0*64+ 8 +1); w7 = *(uint64_t *)(in+(0*45+7)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w6 >> 21) | (w7 << 43) & 0x1fffffffffff)+(0*64+ 9 +1); out[0*64+10] = start + ((w7 >> 2) & 0x1fffffffffff)+(0*64+10 +1); w8 = *(uint64_t *)(in+(0*45+8)*8/sizeof(in[0])); out[0*64+11] = start + ((w7 >> 47) | (w8 << 17) & 0x1fffffffffff)+(0*64+11 +1); w9 = *(uint64_t *)(in+(0*45+9)*8/sizeof(in[0])); out[0*64+12] = start + ((w8 >> 28) | (w9 << 36) & 0x1fffffffffff)+(0*64+12 +1); out[0*64+13] = start + ((w9 >> 9) & 0x1fffffffffff)+(0*64+13 +1); w10 = *(uint64_t *)(in+(0*45+10)*8/sizeof(in[0])); out[0*64+14] = start + ((w9 >> 54) | (w10 << 10) & 0x1fffffffffff)+(0*64+14 +1); w11 = *(uint64_t *)(in+(0*45+11)*8/sizeof(in[0])); out[0*64+15] = start + ((w10 >> 35) | (w11 << 29) & 0x1fffffffffff)+(0*64+15 +1); out[0*64+16] = start + ((w11 >> 16) & 0x1fffffffffff)+(0*64+16 +1); w12 = *(uint64_t *)(in+(0*45+12)*8/sizeof(in[0])); out[0*64+17] = start + ((w11 >> 61) | (w12 << 3) & 0x1fffffffffff)+(0*64+17 +1); w13 = *(uint64_t *)(in+(0*45+13)*8/sizeof(in[0])); out[0*64+18] = start + ((w12 >> 42) | (w13 << 22) & 0x1fffffffffff)+(0*64+18 +1); w14 = *(uint64_t *)(in+(0*45+14)*8/sizeof(in[0])); out[0*64+19] = start + ((w13 >> 23) | (w14 << 41) & 0x1fffffffffff)+(0*64+19 +1); out[0*64+20] = start + ((w14 >> 4) & 0x1fffffffffff)+(0*64+20 +1); w15 = *(uint64_t *)(in+(0*45+15)*8/sizeof(in[0])); out[0*64+21] = start + ((w14 >> 49) | (w15 << 15) & 0x1fffffffffff)+(0*64+21 +1); w16 = *(uint64_t *)(in+(0*45+16)*8/sizeof(in[0])); out[0*64+22] = start + ((w15 >> 30) | (w16 << 34) & 0x1fffffffffff)+(0*64+22 +1); out[0*64+23] = start + ((w16 >> 11) & 0x1fffffffffff)+(0*64+23 +1); w17 = *(uint64_t *)(in+(0*45+17)*8/sizeof(in[0])); out[0*64+24] = start + ((w16 >> 56) | (w17 << 8) & 0x1fffffffffff)+(0*64+24 +1); w18 = *(uint64_t *)(in+(0*45+18)*8/sizeof(in[0])); out[0*64+25] = start + ((w17 >> 37) | (w18 << 27) & 0x1fffffffffff)+(0*64+25 +1); out[0*64+26] = start + ((w18 >> 18) & 0x1fffffffffff)+(0*64+26 +1); w19 = *(uint64_t *)(in+(0*45+19)*8/sizeof(in[0])); out[0*64+27] = start + ((w18 >> 63) | (w19 << 1) & 0x1fffffffffff)+(0*64+27 +1); w20 = *(uint64_t *)(in+(0*45+20)*8/sizeof(in[0])); out[0*64+28] = start + ((w19 >> 44) | (w20 << 20) & 0x1fffffffffff)+(0*64+28 +1); w21 = *(uint64_t *)(in+(0*45+21)*8/sizeof(in[0])); out[0*64+29] = start + ((w20 >> 25) | (w21 << 39) & 0x1fffffffffff)+(0*64+29 +1); out[0*64+30] = start + ((w21 >> 6) & 0x1fffffffffff)+(0*64+30 +1); w22 = *(uint32_t *)(in+(0*45+22)*8/sizeof(in[0])); out[0*64+31] = start + ((w21 >> 51) | (w22 << 13) & 0x1fffffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 45*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_46(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*46)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22; w0 = *(uint64_t *)(in+(0*23+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3fffffffffff)+(0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*23+1)*8/sizeof(in[0])); out[0*32+ 1] = start + ((w0 >> 46) | (w1 << 18) & 0x3fffffffffff)+(0*32+ 1 +1); w2 = *(uint64_t *)(in+(0*23+2)*8/sizeof(in[0])); out[0*32+ 2] = start + ((w1 >> 28) | (w2 << 36) & 0x3fffffffffff)+(0*32+ 2 +1); out[0*32+ 3] = start + ((w2 >> 10) & 0x3fffffffffff)+(0*32+ 3 +1); w3 = *(uint64_t *)(in+(0*23+3)*8/sizeof(in[0])); out[0*32+ 4] = start + ((w2 >> 56) | (w3 << 8) & 0x3fffffffffff)+(0*32+ 4 +1); w4 = *(uint64_t *)(in+(0*23+4)*8/sizeof(in[0])); out[0*32+ 5] = start + ((w3 >> 38) | (w4 << 26) & 0x3fffffffffff)+(0*32+ 5 +1); w5 = *(uint64_t *)(in+(0*23+5)*8/sizeof(in[0])); out[0*32+ 6] = start + ((w4 >> 20) | (w5 << 44) & 0x3fffffffffff)+(0*32+ 6 +1); out[0*32+ 7] = start + ((w5 >> 2) & 0x3fffffffffff)+(0*32+ 7 +1); w6 = *(uint64_t *)(in+(0*23+6)*8/sizeof(in[0])); out[0*32+ 8] = start + ((w5 >> 48) | (w6 << 16) & 0x3fffffffffff)+(0*32+ 8 +1); w7 = *(uint64_t *)(in+(0*23+7)*8/sizeof(in[0])); out[0*32+ 9] = start + ((w6 >> 30) | (w7 << 34) & 0x3fffffffffff)+(0*32+ 9 +1); out[0*32+10] = start + ((w7 >> 12) & 0x3fffffffffff)+(0*32+10 +1); w8 = *(uint64_t *)(in+(0*23+8)*8/sizeof(in[0])); out[0*32+11] = start + ((w7 >> 58) | (w8 << 6) & 0x3fffffffffff)+(0*32+11 +1); w9 = *(uint64_t *)(in+(0*23+9)*8/sizeof(in[0])); out[0*32+12] = start + ((w8 >> 40) | (w9 << 24) & 0x3fffffffffff)+(0*32+12 +1); w10 = *(uint64_t *)(in+(0*23+10)*8/sizeof(in[0])); out[0*32+13] = start + ((w9 >> 22) | (w10 << 42) & 0x3fffffffffff)+(0*32+13 +1); out[0*32+14] = start + ((w10 >> 4) & 0x3fffffffffff)+(0*32+14 +1); w11 = *(uint64_t *)(in+(0*23+11)*8/sizeof(in[0])); out[0*32+15] = start + ((w10 >> 50) | (w11 << 14) & 0x3fffffffffff)+(0*32+15 +1); w12 = *(uint64_t *)(in+(0*23+12)*8/sizeof(in[0])); out[0*32+16] = start + ((w11 >> 32) | (w12 << 32) & 0x3fffffffffff)+(0*32+16 +1); out[0*32+17] = start + ((w12 >> 14) & 0x3fffffffffff)+(0*32+17 +1); w13 = *(uint64_t *)(in+(0*23+13)*8/sizeof(in[0])); out[0*32+18] = start + ((w12 >> 60) | (w13 << 4) & 0x3fffffffffff)+(0*32+18 +1); w14 = *(uint64_t *)(in+(0*23+14)*8/sizeof(in[0])); out[0*32+19] = start + ((w13 >> 42) | (w14 << 22) & 0x3fffffffffff)+(0*32+19 +1); w15 = *(uint64_t *)(in+(0*23+15)*8/sizeof(in[0])); out[0*32+20] = start + ((w14 >> 24) | (w15 << 40) & 0x3fffffffffff)+(0*32+20 +1); out[0*32+21] = start + ((w15 >> 6) & 0x3fffffffffff)+(0*32+21 +1); w16 = *(uint64_t *)(in+(0*23+16)*8/sizeof(in[0])); out[0*32+22] = start + ((w15 >> 52) | (w16 << 12) & 0x3fffffffffff)+(0*32+22 +1); w17 = *(uint64_t *)(in+(0*23+17)*8/sizeof(in[0])); out[0*32+23] = start + ((w16 >> 34) | (w17 << 30) & 0x3fffffffffff)+(0*32+23 +1); out[0*32+24] = start + ((w17 >> 16) & 0x3fffffffffff)+(0*32+24 +1); w18 = *(uint64_t *)(in+(0*23+18)*8/sizeof(in[0])); out[0*32+25] = start + ((w17 >> 62) | (w18 << 2) & 0x3fffffffffff)+(0*32+25 +1); w19 = *(uint64_t *)(in+(0*23+19)*8/sizeof(in[0])); out[0*32+26] = start + ((w18 >> 44) | (w19 << 20) & 0x3fffffffffff)+(0*32+26 +1); w20 = *(uint64_t *)(in+(0*23+20)*8/sizeof(in[0])); out[0*32+27] = start + ((w19 >> 26) | (w20 << 38) & 0x3fffffffffff)+(0*32+27 +1); out[0*32+28] = start + ((w20 >> 8) & 0x3fffffffffff)+(0*32+28 +1); w21 = *(uint64_t *)(in+(0*23+21)*8/sizeof(in[0])); out[0*32+29] = start + ((w20 >> 54) | (w21 << 10) & 0x3fffffffffff)+(0*32+29 +1); w22 = *(uint64_t *)(in+(0*23+22)*8/sizeof(in[0])); out[0*32+30] = start + ((w21 >> 36) | (w22 << 28) & 0x3fffffffffff)+(0*32+30 +1); out[0*32+31] = start + ((w22 >> 18))+(0*32+31 +1);;}; out += 32; start += 32; in += 46*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_47(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*47)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(0*47+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7fffffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*47+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 47) | (w1 << 17) & 0x7fffffffffff)+(0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*47+2)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w1 >> 30) | (w2 << 34) & 0x7fffffffffff)+(0*64+ 2 +1); out[0*64+ 3] = start + ((w2 >> 13) & 0x7fffffffffff)+(0*64+ 3 +1); w3 = *(uint64_t *)(in+(0*47+3)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w2 >> 60) | (w3 << 4) & 0x7fffffffffff)+(0*64+ 4 +1); w4 = *(uint64_t *)(in+(0*47+4)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w3 >> 43) | (w4 << 21) & 0x7fffffffffff)+(0*64+ 5 +1); w5 = *(uint64_t *)(in+(0*47+5)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w4 >> 26) | (w5 << 38) & 0x7fffffffffff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w5 >> 9) & 0x7fffffffffff)+(0*64+ 7 +1); w6 = *(uint64_t *)(in+(0*47+6)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w5 >> 56) | (w6 << 8) & 0x7fffffffffff)+(0*64+ 8 +1); w7 = *(uint64_t *)(in+(0*47+7)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w6 >> 39) | (w7 << 25) & 0x7fffffffffff)+(0*64+ 9 +1); w8 = *(uint64_t *)(in+(0*47+8)*8/sizeof(in[0])); out[0*64+10] = start + ((w7 >> 22) | (w8 << 42) & 0x7fffffffffff)+(0*64+10 +1); out[0*64+11] = start + ((w8 >> 5) & 0x7fffffffffff)+(0*64+11 +1); w9 = *(uint64_t *)(in+(0*47+9)*8/sizeof(in[0])); out[0*64+12] = start + ((w8 >> 52) | (w9 << 12) & 0x7fffffffffff)+(0*64+12 +1); w10 = *(uint64_t *)(in+(0*47+10)*8/sizeof(in[0])); out[0*64+13] = start + ((w9 >> 35) | (w10 << 29) & 0x7fffffffffff)+(0*64+13 +1); w11 = *(uint64_t *)(in+(0*47+11)*8/sizeof(in[0])); out[0*64+14] = start + ((w10 >> 18) | (w11 << 46) & 0x7fffffffffff)+(0*64+14 +1); out[0*64+15] = start + ((w11 >> 1) & 0x7fffffffffff)+(0*64+15 +1); w12 = *(uint64_t *)(in+(0*47+12)*8/sizeof(in[0])); out[0*64+16] = start + ((w11 >> 48) | (w12 << 16) & 0x7fffffffffff)+(0*64+16 +1); w13 = *(uint64_t *)(in+(0*47+13)*8/sizeof(in[0])); out[0*64+17] = start + ((w12 >> 31) | (w13 << 33) & 0x7fffffffffff)+(0*64+17 +1); out[0*64+18] = start + ((w13 >> 14) & 0x7fffffffffff)+(0*64+18 +1); w14 = *(uint64_t *)(in+(0*47+14)*8/sizeof(in[0])); out[0*64+19] = start + ((w13 >> 61) | (w14 << 3) & 0x7fffffffffff)+(0*64+19 +1); w15 = *(uint64_t *)(in+(0*47+15)*8/sizeof(in[0])); out[0*64+20] = start + ((w14 >> 44) | (w15 << 20) & 0x7fffffffffff)+(0*64+20 +1); w16 = *(uint64_t *)(in+(0*47+16)*8/sizeof(in[0])); out[0*64+21] = start + ((w15 >> 27) | (w16 << 37) & 0x7fffffffffff)+(0*64+21 +1); out[0*64+22] = start + ((w16 >> 10) & 0x7fffffffffff)+(0*64+22 +1); w17 = *(uint64_t *)(in+(0*47+17)*8/sizeof(in[0])); out[0*64+23] = start + ((w16 >> 57) | (w17 << 7) & 0x7fffffffffff)+(0*64+23 +1); w18 = *(uint64_t *)(in+(0*47+18)*8/sizeof(in[0])); out[0*64+24] = start + ((w17 >> 40) | (w18 << 24) & 0x7fffffffffff)+(0*64+24 +1); w19 = *(uint64_t *)(in+(0*47+19)*8/sizeof(in[0])); out[0*64+25] = start + ((w18 >> 23) | (w19 << 41) & 0x7fffffffffff)+(0*64+25 +1); out[0*64+26] = start + ((w19 >> 6) & 0x7fffffffffff)+(0*64+26 +1); w20 = *(uint64_t *)(in+(0*47+20)*8/sizeof(in[0])); out[0*64+27] = start + ((w19 >> 53) | (w20 << 11) & 0x7fffffffffff)+(0*64+27 +1); w21 = *(uint64_t *)(in+(0*47+21)*8/sizeof(in[0])); out[0*64+28] = start + ((w20 >> 36) | (w21 << 28) & 0x7fffffffffff)+(0*64+28 +1); w22 = *(uint64_t *)(in+(0*47+22)*8/sizeof(in[0])); out[0*64+29] = start + ((w21 >> 19) | (w22 << 45) & 0x7fffffffffff)+(0*64+29 +1); out[0*64+30] = start + ((w22 >> 2) & 0x7fffffffffff)+(0*64+30 +1); w23 = *(uint32_t *)(in+(0*47+23)*8/sizeof(in[0])); out[0*64+31] = start + ((w22 >> 49) | (w23 << 15) & 0x7fffffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 47*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_48(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*48)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(0*3+0)*8/sizeof(in[0])); out[0*4+ 0] = start + ((w0 ) & 0xffffffffffff)+(0*4+ 0 +1); w1 = *(uint64_t *)(in+(0*3+1)*8/sizeof(in[0])); out[0*4+ 1] = start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)+(0*4+ 1 +1); w2 = *(uint64_t *)(in+(0*3+2)*8/sizeof(in[0])); out[0*4+ 2] = start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)+(0*4+ 2 +1); out[0*4+ 3] = start + ((w2 >> 16))+(0*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(1*3+0)*8/sizeof(in[0])); out[1*4+ 0] = start + ((w0 ) & 0xffffffffffff)+(1*4+ 0 +1); w1 = *(uint64_t *)(in+(1*3+1)*8/sizeof(in[0])); out[1*4+ 1] = start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)+(1*4+ 1 +1); w2 = *(uint64_t *)(in+(1*3+2)*8/sizeof(in[0])); out[1*4+ 2] = start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)+(1*4+ 2 +1); out[1*4+ 3] = start + ((w2 >> 16))+(1*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(2*3+0)*8/sizeof(in[0])); out[2*4+ 0] = start + ((w0 ) & 0xffffffffffff)+(2*4+ 0 +1); w1 = *(uint64_t *)(in+(2*3+1)*8/sizeof(in[0])); out[2*4+ 1] = start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)+(2*4+ 1 +1); w2 = *(uint64_t *)(in+(2*3+2)*8/sizeof(in[0])); out[2*4+ 2] = start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)+(2*4+ 2 +1); out[2*4+ 3] = start + ((w2 >> 16))+(2*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(3*3+0)*8/sizeof(in[0])); out[3*4+ 0] = start + ((w0 ) & 0xffffffffffff)+(3*4+ 0 +1); w1 = *(uint64_t *)(in+(3*3+1)*8/sizeof(in[0])); out[3*4+ 1] = start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)+(3*4+ 1 +1); w2 = *(uint64_t *)(in+(3*3+2)*8/sizeof(in[0])); out[3*4+ 2] = start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)+(3*4+ 2 +1); out[3*4+ 3] = start + ((w2 >> 16))+(3*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(4*3+0)*8/sizeof(in[0])); out[4*4+ 0] = start + ((w0 ) & 0xffffffffffff)+(4*4+ 0 +1); w1 = *(uint64_t *)(in+(4*3+1)*8/sizeof(in[0])); out[4*4+ 1] = start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)+(4*4+ 1 +1); w2 = *(uint64_t *)(in+(4*3+2)*8/sizeof(in[0])); out[4*4+ 2] = start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)+(4*4+ 2 +1); out[4*4+ 3] = start + ((w2 >> 16))+(4*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(5*3+0)*8/sizeof(in[0])); out[5*4+ 0] = start + ((w0 ) & 0xffffffffffff)+(5*4+ 0 +1); w1 = *(uint64_t *)(in+(5*3+1)*8/sizeof(in[0])); out[5*4+ 1] = start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)+(5*4+ 1 +1); w2 = *(uint64_t *)(in+(5*3+2)*8/sizeof(in[0])); out[5*4+ 2] = start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)+(5*4+ 2 +1); out[5*4+ 3] = start + ((w2 >> 16))+(5*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(6*3+0)*8/sizeof(in[0])); out[6*4+ 0] = start + ((w0 ) & 0xffffffffffff)+(6*4+ 0 +1); w1 = *(uint64_t *)(in+(6*3+1)*8/sizeof(in[0])); out[6*4+ 1] = start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)+(6*4+ 1 +1); w2 = *(uint64_t *)(in+(6*3+2)*8/sizeof(in[0])); out[6*4+ 2] = start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)+(6*4+ 2 +1); out[6*4+ 3] = start + ((w2 >> 16))+(6*4+ 3 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23; w0 = *(uint64_t *)(in+(7*3+0)*8/sizeof(in[0])); out[7*4+ 0] = start + ((w0 ) & 0xffffffffffff)+(7*4+ 0 +1); w1 = *(uint64_t *)(in+(7*3+1)*8/sizeof(in[0])); out[7*4+ 1] = start + ((w0 >> 48) | (w1 << 16) & 0xffffffffffff)+(7*4+ 1 +1); w2 = *(uint64_t *)(in+(7*3+2)*8/sizeof(in[0])); out[7*4+ 2] = start + ((w1 >> 32) | (w2 << 32) & 0xffffffffffff)+(7*4+ 2 +1); out[7*4+ 3] = start + ((w2 >> 16))+(7*4+ 3 +1);;}; out += 32; start += 32; in += 48*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_49(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*49)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24; w0 = *(uint64_t *)(in+(0*49+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1ffffffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*49+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 49) | (w1 << 15) & 0x1ffffffffffff)+(0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*49+2)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w1 >> 34) | (w2 << 30) & 0x1ffffffffffff)+(0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*49+3)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w2 >> 19) | (w3 << 45) & 0x1ffffffffffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w3 >> 4) & 0x1ffffffffffff)+(0*64+ 4 +1); w4 = *(uint64_t *)(in+(0*49+4)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w3 >> 53) | (w4 << 11) & 0x1ffffffffffff)+(0*64+ 5 +1); w5 = *(uint64_t *)(in+(0*49+5)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w4 >> 38) | (w5 << 26) & 0x1ffffffffffff)+(0*64+ 6 +1); w6 = *(uint64_t *)(in+(0*49+6)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w5 >> 23) | (w6 << 41) & 0x1ffffffffffff)+(0*64+ 7 +1); out[0*64+ 8] = start + ((w6 >> 8) & 0x1ffffffffffff)+(0*64+ 8 +1); w7 = *(uint64_t *)(in+(0*49+7)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w6 >> 57) | (w7 << 7) & 0x1ffffffffffff)+(0*64+ 9 +1); w8 = *(uint64_t *)(in+(0*49+8)*8/sizeof(in[0])); out[0*64+10] = start + ((w7 >> 42) | (w8 << 22) & 0x1ffffffffffff)+(0*64+10 +1); w9 = *(uint64_t *)(in+(0*49+9)*8/sizeof(in[0])); out[0*64+11] = start + ((w8 >> 27) | (w9 << 37) & 0x1ffffffffffff)+(0*64+11 +1); out[0*64+12] = start + ((w9 >> 12) & 0x1ffffffffffff)+(0*64+12 +1); w10 = *(uint64_t *)(in+(0*49+10)*8/sizeof(in[0])); out[0*64+13] = start + ((w9 >> 61) | (w10 << 3) & 0x1ffffffffffff)+(0*64+13 +1); w11 = *(uint64_t *)(in+(0*49+11)*8/sizeof(in[0])); out[0*64+14] = start + ((w10 >> 46) | (w11 << 18) & 0x1ffffffffffff)+(0*64+14 +1); w12 = *(uint64_t *)(in+(0*49+12)*8/sizeof(in[0])); out[0*64+15] = start + ((w11 >> 31) | (w12 << 33) & 0x1ffffffffffff)+(0*64+15 +1); w13 = *(uint64_t *)(in+(0*49+13)*8/sizeof(in[0])); out[0*64+16] = start + ((w12 >> 16) | (w13 << 48) & 0x1ffffffffffff)+(0*64+16 +1); out[0*64+17] = start + ((w13 >> 1) & 0x1ffffffffffff)+(0*64+17 +1); w14 = *(uint64_t *)(in+(0*49+14)*8/sizeof(in[0])); out[0*64+18] = start + ((w13 >> 50) | (w14 << 14) & 0x1ffffffffffff)+(0*64+18 +1); w15 = *(uint64_t *)(in+(0*49+15)*8/sizeof(in[0])); out[0*64+19] = start + ((w14 >> 35) | (w15 << 29) & 0x1ffffffffffff)+(0*64+19 +1); w16 = *(uint64_t *)(in+(0*49+16)*8/sizeof(in[0])); out[0*64+20] = start + ((w15 >> 20) | (w16 << 44) & 0x1ffffffffffff)+(0*64+20 +1); out[0*64+21] = start + ((w16 >> 5) & 0x1ffffffffffff)+(0*64+21 +1); w17 = *(uint64_t *)(in+(0*49+17)*8/sizeof(in[0])); out[0*64+22] = start + ((w16 >> 54) | (w17 << 10) & 0x1ffffffffffff)+(0*64+22 +1); w18 = *(uint64_t *)(in+(0*49+18)*8/sizeof(in[0])); out[0*64+23] = start + ((w17 >> 39) | (w18 << 25) & 0x1ffffffffffff)+(0*64+23 +1); w19 = *(uint64_t *)(in+(0*49+19)*8/sizeof(in[0])); out[0*64+24] = start + ((w18 >> 24) | (w19 << 40) & 0x1ffffffffffff)+(0*64+24 +1); out[0*64+25] = start + ((w19 >> 9) & 0x1ffffffffffff)+(0*64+25 +1); w20 = *(uint64_t *)(in+(0*49+20)*8/sizeof(in[0])); out[0*64+26] = start + ((w19 >> 58) | (w20 << 6) & 0x1ffffffffffff)+(0*64+26 +1); w21 = *(uint64_t *)(in+(0*49+21)*8/sizeof(in[0])); out[0*64+27] = start + ((w20 >> 43) | (w21 << 21) & 0x1ffffffffffff)+(0*64+27 +1); w22 = *(uint64_t *)(in+(0*49+22)*8/sizeof(in[0])); out[0*64+28] = start + ((w21 >> 28) | (w22 << 36) & 0x1ffffffffffff)+(0*64+28 +1); out[0*64+29] = start + ((w22 >> 13) & 0x1ffffffffffff)+(0*64+29 +1); w23 = *(uint64_t *)(in+(0*49+23)*8/sizeof(in[0])); out[0*64+30] = start + ((w22 >> 62) | (w23 << 2) & 0x1ffffffffffff)+(0*64+30 +1); w24 = *(uint32_t *)(in+(0*49+24)*8/sizeof(in[0])); out[0*64+31] = start + ((w23 >> 47) | (w24 << 17) & 0x1ffffffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 49*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_50(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*50)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24; w0 = *(uint64_t *)(in+(0*25+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3ffffffffffff)+(0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*25+1)*8/sizeof(in[0])); out[0*32+ 1] = start + ((w0 >> 50) | (w1 << 14) & 0x3ffffffffffff)+(0*32+ 1 +1); w2 = *(uint64_t *)(in+(0*25+2)*8/sizeof(in[0])); out[0*32+ 2] = start + ((w1 >> 36) | (w2 << 28) & 0x3ffffffffffff)+(0*32+ 2 +1); w3 = *(uint64_t *)(in+(0*25+3)*8/sizeof(in[0])); out[0*32+ 3] = start + ((w2 >> 22) | (w3 << 42) & 0x3ffffffffffff)+(0*32+ 3 +1); out[0*32+ 4] = start + ((w3 >> 8) & 0x3ffffffffffff)+(0*32+ 4 +1); w4 = *(uint64_t *)(in+(0*25+4)*8/sizeof(in[0])); out[0*32+ 5] = start + ((w3 >> 58) | (w4 << 6) & 0x3ffffffffffff)+(0*32+ 5 +1); w5 = *(uint64_t *)(in+(0*25+5)*8/sizeof(in[0])); out[0*32+ 6] = start + ((w4 >> 44) | (w5 << 20) & 0x3ffffffffffff)+(0*32+ 6 +1); w6 = *(uint64_t *)(in+(0*25+6)*8/sizeof(in[0])); out[0*32+ 7] = start + ((w5 >> 30) | (w6 << 34) & 0x3ffffffffffff)+(0*32+ 7 +1); w7 = *(uint64_t *)(in+(0*25+7)*8/sizeof(in[0])); out[0*32+ 8] = start + ((w6 >> 16) | (w7 << 48) & 0x3ffffffffffff)+(0*32+ 8 +1); out[0*32+ 9] = start + ((w7 >> 2) & 0x3ffffffffffff)+(0*32+ 9 +1); w8 = *(uint64_t *)(in+(0*25+8)*8/sizeof(in[0])); out[0*32+10] = start + ((w7 >> 52) | (w8 << 12) & 0x3ffffffffffff)+(0*32+10 +1); w9 = *(uint64_t *)(in+(0*25+9)*8/sizeof(in[0])); out[0*32+11] = start + ((w8 >> 38) | (w9 << 26) & 0x3ffffffffffff)+(0*32+11 +1); w10 = *(uint64_t *)(in+(0*25+10)*8/sizeof(in[0])); out[0*32+12] = start + ((w9 >> 24) | (w10 << 40) & 0x3ffffffffffff)+(0*32+12 +1); out[0*32+13] = start + ((w10 >> 10) & 0x3ffffffffffff)+(0*32+13 +1); w11 = *(uint64_t *)(in+(0*25+11)*8/sizeof(in[0])); out[0*32+14] = start + ((w10 >> 60) | (w11 << 4) & 0x3ffffffffffff)+(0*32+14 +1); w12 = *(uint64_t *)(in+(0*25+12)*8/sizeof(in[0])); out[0*32+15] = start + ((w11 >> 46) | (w12 << 18) & 0x3ffffffffffff)+(0*32+15 +1); w13 = *(uint64_t *)(in+(0*25+13)*8/sizeof(in[0])); out[0*32+16] = start + ((w12 >> 32) | (w13 << 32) & 0x3ffffffffffff)+(0*32+16 +1); w14 = *(uint64_t *)(in+(0*25+14)*8/sizeof(in[0])); out[0*32+17] = start + ((w13 >> 18) | (w14 << 46) & 0x3ffffffffffff)+(0*32+17 +1); out[0*32+18] = start + ((w14 >> 4) & 0x3ffffffffffff)+(0*32+18 +1); w15 = *(uint64_t *)(in+(0*25+15)*8/sizeof(in[0])); out[0*32+19] = start + ((w14 >> 54) | (w15 << 10) & 0x3ffffffffffff)+(0*32+19 +1); w16 = *(uint64_t *)(in+(0*25+16)*8/sizeof(in[0])); out[0*32+20] = start + ((w15 >> 40) | (w16 << 24) & 0x3ffffffffffff)+(0*32+20 +1); w17 = *(uint64_t *)(in+(0*25+17)*8/sizeof(in[0])); out[0*32+21] = start + ((w16 >> 26) | (w17 << 38) & 0x3ffffffffffff)+(0*32+21 +1); out[0*32+22] = start + ((w17 >> 12) & 0x3ffffffffffff)+(0*32+22 +1); w18 = *(uint64_t *)(in+(0*25+18)*8/sizeof(in[0])); out[0*32+23] = start + ((w17 >> 62) | (w18 << 2) & 0x3ffffffffffff)+(0*32+23 +1); w19 = *(uint64_t *)(in+(0*25+19)*8/sizeof(in[0])); out[0*32+24] = start + ((w18 >> 48) | (w19 << 16) & 0x3ffffffffffff)+(0*32+24 +1); w20 = *(uint64_t *)(in+(0*25+20)*8/sizeof(in[0])); out[0*32+25] = start + ((w19 >> 34) | (w20 << 30) & 0x3ffffffffffff)+(0*32+25 +1); w21 = *(uint64_t *)(in+(0*25+21)*8/sizeof(in[0])); out[0*32+26] = start + ((w20 >> 20) | (w21 << 44) & 0x3ffffffffffff)+(0*32+26 +1); out[0*32+27] = start + ((w21 >> 6) & 0x3ffffffffffff)+(0*32+27 +1); w22 = *(uint64_t *)(in+(0*25+22)*8/sizeof(in[0])); out[0*32+28] = start + ((w21 >> 56) | (w22 << 8) & 0x3ffffffffffff)+(0*32+28 +1); w23 = *(uint64_t *)(in+(0*25+23)*8/sizeof(in[0])); out[0*32+29] = start + ((w22 >> 42) | (w23 << 22) & 0x3ffffffffffff)+(0*32+29 +1); w24 = *(uint64_t *)(in+(0*25+24)*8/sizeof(in[0])); out[0*32+30] = start + ((w23 >> 28) | (w24 << 36) & 0x3ffffffffffff)+(0*32+30 +1); out[0*32+31] = start + ((w24 >> 14))+(0*32+31 +1);;}; out += 32; start += 32; in += 50*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_51(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*51)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(0*51+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7ffffffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*51+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 51) | (w1 << 13) & 0x7ffffffffffff)+(0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*51+2)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w1 >> 38) | (w2 << 26) & 0x7ffffffffffff)+(0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*51+3)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w2 >> 25) | (w3 << 39) & 0x7ffffffffffff)+(0*64+ 3 +1); out[0*64+ 4] = start + ((w3 >> 12) & 0x7ffffffffffff)+(0*64+ 4 +1); w4 = *(uint64_t *)(in+(0*51+4)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w3 >> 63) | (w4 << 1) & 0x7ffffffffffff)+(0*64+ 5 +1); w5 = *(uint64_t *)(in+(0*51+5)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w4 >> 50) | (w5 << 14) & 0x7ffffffffffff)+(0*64+ 6 +1); w6 = *(uint64_t *)(in+(0*51+6)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w5 >> 37) | (w6 << 27) & 0x7ffffffffffff)+(0*64+ 7 +1); w7 = *(uint64_t *)(in+(0*51+7)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w6 >> 24) | (w7 << 40) & 0x7ffffffffffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w7 >> 11) & 0x7ffffffffffff)+(0*64+ 9 +1); w8 = *(uint64_t *)(in+(0*51+8)*8/sizeof(in[0])); out[0*64+10] = start + ((w7 >> 62) | (w8 << 2) & 0x7ffffffffffff)+(0*64+10 +1); w9 = *(uint64_t *)(in+(0*51+9)*8/sizeof(in[0])); out[0*64+11] = start + ((w8 >> 49) | (w9 << 15) & 0x7ffffffffffff)+(0*64+11 +1); w10 = *(uint64_t *)(in+(0*51+10)*8/sizeof(in[0])); out[0*64+12] = start + ((w9 >> 36) | (w10 << 28) & 0x7ffffffffffff)+(0*64+12 +1); w11 = *(uint64_t *)(in+(0*51+11)*8/sizeof(in[0])); out[0*64+13] = start + ((w10 >> 23) | (w11 << 41) & 0x7ffffffffffff)+(0*64+13 +1); out[0*64+14] = start + ((w11 >> 10) & 0x7ffffffffffff)+(0*64+14 +1); w12 = *(uint64_t *)(in+(0*51+12)*8/sizeof(in[0])); out[0*64+15] = start + ((w11 >> 61) | (w12 << 3) & 0x7ffffffffffff)+(0*64+15 +1); w13 = *(uint64_t *)(in+(0*51+13)*8/sizeof(in[0])); out[0*64+16] = start + ((w12 >> 48) | (w13 << 16) & 0x7ffffffffffff)+(0*64+16 +1); w14 = *(uint64_t *)(in+(0*51+14)*8/sizeof(in[0])); out[0*64+17] = start + ((w13 >> 35) | (w14 << 29) & 0x7ffffffffffff)+(0*64+17 +1); w15 = *(uint64_t *)(in+(0*51+15)*8/sizeof(in[0])); out[0*64+18] = start + ((w14 >> 22) | (w15 << 42) & 0x7ffffffffffff)+(0*64+18 +1); out[0*64+19] = start + ((w15 >> 9) & 0x7ffffffffffff)+(0*64+19 +1); w16 = *(uint64_t *)(in+(0*51+16)*8/sizeof(in[0])); out[0*64+20] = start + ((w15 >> 60) | (w16 << 4) & 0x7ffffffffffff)+(0*64+20 +1); w17 = *(uint64_t *)(in+(0*51+17)*8/sizeof(in[0])); out[0*64+21] = start + ((w16 >> 47) | (w17 << 17) & 0x7ffffffffffff)+(0*64+21 +1); w18 = *(uint64_t *)(in+(0*51+18)*8/sizeof(in[0])); out[0*64+22] = start + ((w17 >> 34) | (w18 << 30) & 0x7ffffffffffff)+(0*64+22 +1); w19 = *(uint64_t *)(in+(0*51+19)*8/sizeof(in[0])); out[0*64+23] = start + ((w18 >> 21) | (w19 << 43) & 0x7ffffffffffff)+(0*64+23 +1); out[0*64+24] = start + ((w19 >> 8) & 0x7ffffffffffff)+(0*64+24 +1); w20 = *(uint64_t *)(in+(0*51+20)*8/sizeof(in[0])); out[0*64+25] = start + ((w19 >> 59) | (w20 << 5) & 0x7ffffffffffff)+(0*64+25 +1); w21 = *(uint64_t *)(in+(0*51+21)*8/sizeof(in[0])); out[0*64+26] = start + ((w20 >> 46) | (w21 << 18) & 0x7ffffffffffff)+(0*64+26 +1); w22 = *(uint64_t *)(in+(0*51+22)*8/sizeof(in[0])); out[0*64+27] = start + ((w21 >> 33) | (w22 << 31) & 0x7ffffffffffff)+(0*64+27 +1); w23 = *(uint64_t *)(in+(0*51+23)*8/sizeof(in[0])); out[0*64+28] = start + ((w22 >> 20) | (w23 << 44) & 0x7ffffffffffff)+(0*64+28 +1); out[0*64+29] = start + ((w23 >> 7) & 0x7ffffffffffff)+(0*64+29 +1); w24 = *(uint64_t *)(in+(0*51+24)*8/sizeof(in[0])); out[0*64+30] = start + ((w23 >> 58) | (w24 << 6) & 0x7ffffffffffff)+(0*64+30 +1); w25 = *(uint32_t *)(in+(0*51+25)*8/sizeof(in[0])); out[0*64+31] = start + ((w24 >> 45) | (w25 << 19) & 0x7ffffffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 51*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_52(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*52)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(0*13+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xfffffffffffff)+(0*16+ 0 +1); w1 = *(uint64_t *)(in+(0*13+1)*8/sizeof(in[0])); out[0*16+ 1] = start + ((w0 >> 52) | (w1 << 12) & 0xfffffffffffff)+(0*16+ 1 +1); w2 = *(uint64_t *)(in+(0*13+2)*8/sizeof(in[0])); out[0*16+ 2] = start + ((w1 >> 40) | (w2 << 24) & 0xfffffffffffff)+(0*16+ 2 +1); w3 = *(uint64_t *)(in+(0*13+3)*8/sizeof(in[0])); out[0*16+ 3] = start + ((w2 >> 28) | (w3 << 36) & 0xfffffffffffff)+(0*16+ 3 +1); w4 = *(uint64_t *)(in+(0*13+4)*8/sizeof(in[0])); out[0*16+ 4] = start + ((w3 >> 16) | (w4 << 48) & 0xfffffffffffff)+(0*16+ 4 +1); out[0*16+ 5] = start + ((w4 >> 4) & 0xfffffffffffff)+(0*16+ 5 +1); w5 = *(uint64_t *)(in+(0*13+5)*8/sizeof(in[0])); out[0*16+ 6] = start + ((w4 >> 56) | (w5 << 8) & 0xfffffffffffff)+(0*16+ 6 +1); w6 = *(uint64_t *)(in+(0*13+6)*8/sizeof(in[0])); out[0*16+ 7] = start + ((w5 >> 44) | (w6 << 20) & 0xfffffffffffff)+(0*16+ 7 +1); w7 = *(uint64_t *)(in+(0*13+7)*8/sizeof(in[0])); out[0*16+ 8] = start + ((w6 >> 32) | (w7 << 32) & 0xfffffffffffff)+(0*16+ 8 +1); w8 = *(uint64_t *)(in+(0*13+8)*8/sizeof(in[0])); out[0*16+ 9] = start + ((w7 >> 20) | (w8 << 44) & 0xfffffffffffff)+(0*16+ 9 +1); out[0*16+10] = start + ((w8 >> 8) & 0xfffffffffffff)+(0*16+10 +1); w9 = *(uint64_t *)(in+(0*13+9)*8/sizeof(in[0])); out[0*16+11] = start + ((w8 >> 60) | (w9 << 4) & 0xfffffffffffff)+(0*16+11 +1); w10 = *(uint64_t *)(in+(0*13+10)*8/sizeof(in[0])); out[0*16+12] = start + ((w9 >> 48) | (w10 << 16) & 0xfffffffffffff)+(0*16+12 +1); w11 = *(uint64_t *)(in+(0*13+11)*8/sizeof(in[0])); out[0*16+13] = start + ((w10 >> 36) | (w11 << 28) & 0xfffffffffffff)+(0*16+13 +1); w12 = *(uint64_t *)(in+(0*13+12)*8/sizeof(in[0])); out[0*16+14] = start + ((w11 >> 24) | (w12 << 40) & 0xfffffffffffff)+(0*16+14 +1); out[0*16+15] = start + ((w12 >> 12))+(0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25; w0 = *(uint64_t *)(in+(1*13+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xfffffffffffff)+(1*16+ 0 +1); w1 = *(uint64_t *)(in+(1*13+1)*8/sizeof(in[0])); out[1*16+ 1] = start + ((w0 >> 52) | (w1 << 12) & 0xfffffffffffff)+(1*16+ 1 +1); w2 = *(uint64_t *)(in+(1*13+2)*8/sizeof(in[0])); out[1*16+ 2] = start + ((w1 >> 40) | (w2 << 24) & 0xfffffffffffff)+(1*16+ 2 +1); w3 = *(uint64_t *)(in+(1*13+3)*8/sizeof(in[0])); out[1*16+ 3] = start + ((w2 >> 28) | (w3 << 36) & 0xfffffffffffff)+(1*16+ 3 +1); w4 = *(uint64_t *)(in+(1*13+4)*8/sizeof(in[0])); out[1*16+ 4] = start + ((w3 >> 16) | (w4 << 48) & 0xfffffffffffff)+(1*16+ 4 +1); out[1*16+ 5] = start + ((w4 >> 4) & 0xfffffffffffff)+(1*16+ 5 +1); w5 = *(uint64_t *)(in+(1*13+5)*8/sizeof(in[0])); out[1*16+ 6] = start + ((w4 >> 56) | (w5 << 8) & 0xfffffffffffff)+(1*16+ 6 +1); w6 = *(uint64_t *)(in+(1*13+6)*8/sizeof(in[0])); out[1*16+ 7] = start + ((w5 >> 44) | (w6 << 20) & 0xfffffffffffff)+(1*16+ 7 +1); w7 = *(uint64_t *)(in+(1*13+7)*8/sizeof(in[0])); out[1*16+ 8] = start + ((w6 >> 32) | (w7 << 32) & 0xfffffffffffff)+(1*16+ 8 +1); w8 = *(uint64_t *)(in+(1*13+8)*8/sizeof(in[0])); out[1*16+ 9] = start + ((w7 >> 20) | (w8 << 44) & 0xfffffffffffff)+(1*16+ 9 +1); out[1*16+10] = start + ((w8 >> 8) & 0xfffffffffffff)+(1*16+10 +1); w9 = *(uint64_t *)(in+(1*13+9)*8/sizeof(in[0])); out[1*16+11] = start + ((w8 >> 60) | (w9 << 4) & 0xfffffffffffff)+(1*16+11 +1); w10 = *(uint64_t *)(in+(1*13+10)*8/sizeof(in[0])); out[1*16+12] = start + ((w9 >> 48) | (w10 << 16) & 0xfffffffffffff)+(1*16+12 +1); w11 = *(uint64_t *)(in+(1*13+11)*8/sizeof(in[0])); out[1*16+13] = start + ((w10 >> 36) | (w11 << 28) & 0xfffffffffffff)+(1*16+13 +1); w12 = *(uint64_t *)(in+(1*13+12)*8/sizeof(in[0])); out[1*16+14] = start + ((w11 >> 24) | (w12 << 40) & 0xfffffffffffff)+(1*16+14 +1); out[1*16+15] = start + ((w12 >> 12))+(1*16+15 +1);;}; out += 32; start += 32; in += 52*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_53(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*53)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26; w0 = *(uint64_t *)(in+(0*53+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1fffffffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*53+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 53) | (w1 << 11) & 0x1fffffffffffff)+(0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*53+2)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w1 >> 42) | (w2 << 22) & 0x1fffffffffffff)+(0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*53+3)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w2 >> 31) | (w3 << 33) & 0x1fffffffffffff)+(0*64+ 3 +1); w4 = *(uint64_t *)(in+(0*53+4)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w3 >> 20) | (w4 << 44) & 0x1fffffffffffff)+(0*64+ 4 +1); out[0*64+ 5] = start + ((w4 >> 9) & 0x1fffffffffffff)+(0*64+ 5 +1); w5 = *(uint64_t *)(in+(0*53+5)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w4 >> 62) | (w5 << 2) & 0x1fffffffffffff)+(0*64+ 6 +1); w6 = *(uint64_t *)(in+(0*53+6)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w5 >> 51) | (w6 << 13) & 0x1fffffffffffff)+(0*64+ 7 +1); w7 = *(uint64_t *)(in+(0*53+7)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w6 >> 40) | (w7 << 24) & 0x1fffffffffffff)+(0*64+ 8 +1); w8 = *(uint64_t *)(in+(0*53+8)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w7 >> 29) | (w8 << 35) & 0x1fffffffffffff)+(0*64+ 9 +1); w9 = *(uint64_t *)(in+(0*53+9)*8/sizeof(in[0])); out[0*64+10] = start + ((w8 >> 18) | (w9 << 46) & 0x1fffffffffffff)+(0*64+10 +1); out[0*64+11] = start + ((w9 >> 7) & 0x1fffffffffffff)+(0*64+11 +1); w10 = *(uint64_t *)(in+(0*53+10)*8/sizeof(in[0])); out[0*64+12] = start + ((w9 >> 60) | (w10 << 4) & 0x1fffffffffffff)+(0*64+12 +1); w11 = *(uint64_t *)(in+(0*53+11)*8/sizeof(in[0])); out[0*64+13] = start + ((w10 >> 49) | (w11 << 15) & 0x1fffffffffffff)+(0*64+13 +1); w12 = *(uint64_t *)(in+(0*53+12)*8/sizeof(in[0])); out[0*64+14] = start + ((w11 >> 38) | (w12 << 26) & 0x1fffffffffffff)+(0*64+14 +1); w13 = *(uint64_t *)(in+(0*53+13)*8/sizeof(in[0])); out[0*64+15] = start + ((w12 >> 27) | (w13 << 37) & 0x1fffffffffffff)+(0*64+15 +1); w14 = *(uint64_t *)(in+(0*53+14)*8/sizeof(in[0])); out[0*64+16] = start + ((w13 >> 16) | (w14 << 48) & 0x1fffffffffffff)+(0*64+16 +1); out[0*64+17] = start + ((w14 >> 5) & 0x1fffffffffffff)+(0*64+17 +1); w15 = *(uint64_t *)(in+(0*53+15)*8/sizeof(in[0])); out[0*64+18] = start + ((w14 >> 58) | (w15 << 6) & 0x1fffffffffffff)+(0*64+18 +1); w16 = *(uint64_t *)(in+(0*53+16)*8/sizeof(in[0])); out[0*64+19] = start + ((w15 >> 47) | (w16 << 17) & 0x1fffffffffffff)+(0*64+19 +1); w17 = *(uint64_t *)(in+(0*53+17)*8/sizeof(in[0])); out[0*64+20] = start + ((w16 >> 36) | (w17 << 28) & 0x1fffffffffffff)+(0*64+20 +1); w18 = *(uint64_t *)(in+(0*53+18)*8/sizeof(in[0])); out[0*64+21] = start + ((w17 >> 25) | (w18 << 39) & 0x1fffffffffffff)+(0*64+21 +1); w19 = *(uint64_t *)(in+(0*53+19)*8/sizeof(in[0])); out[0*64+22] = start + ((w18 >> 14) | (w19 << 50) & 0x1fffffffffffff)+(0*64+22 +1); out[0*64+23] = start + ((w19 >> 3) & 0x1fffffffffffff)+(0*64+23 +1); w20 = *(uint64_t *)(in+(0*53+20)*8/sizeof(in[0])); out[0*64+24] = start + ((w19 >> 56) | (w20 << 8) & 0x1fffffffffffff)+(0*64+24 +1); w21 = *(uint64_t *)(in+(0*53+21)*8/sizeof(in[0])); out[0*64+25] = start + ((w20 >> 45) | (w21 << 19) & 0x1fffffffffffff)+(0*64+25 +1); w22 = *(uint64_t *)(in+(0*53+22)*8/sizeof(in[0])); out[0*64+26] = start + ((w21 >> 34) | (w22 << 30) & 0x1fffffffffffff)+(0*64+26 +1); w23 = *(uint64_t *)(in+(0*53+23)*8/sizeof(in[0])); out[0*64+27] = start + ((w22 >> 23) | (w23 << 41) & 0x1fffffffffffff)+(0*64+27 +1); w24 = *(uint64_t *)(in+(0*53+24)*8/sizeof(in[0])); out[0*64+28] = start + ((w23 >> 12) | (w24 << 52) & 0x1fffffffffffff)+(0*64+28 +1); out[0*64+29] = start + ((w24 >> 1) & 0x1fffffffffffff)+(0*64+29 +1); w25 = *(uint64_t *)(in+(0*53+25)*8/sizeof(in[0])); out[0*64+30] = start + ((w24 >> 54) | (w25 << 10) & 0x1fffffffffffff)+(0*64+30 +1); w26 = *(uint32_t *)(in+(0*53+26)*8/sizeof(in[0])); out[0*64+31] = start + ((w25 >> 43) | (w26 << 21) & 0x1fffffffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 53*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_54(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*54)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26; w0 = *(uint64_t *)(in+(0*27+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3fffffffffffff)+(0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*27+1)*8/sizeof(in[0])); out[0*32+ 1] = start + ((w0 >> 54) | (w1 << 10) & 0x3fffffffffffff)+(0*32+ 1 +1); w2 = *(uint64_t *)(in+(0*27+2)*8/sizeof(in[0])); out[0*32+ 2] = start + ((w1 >> 44) | (w2 << 20) & 0x3fffffffffffff)+(0*32+ 2 +1); w3 = *(uint64_t *)(in+(0*27+3)*8/sizeof(in[0])); out[0*32+ 3] = start + ((w2 >> 34) | (w3 << 30) & 0x3fffffffffffff)+(0*32+ 3 +1); w4 = *(uint64_t *)(in+(0*27+4)*8/sizeof(in[0])); out[0*32+ 4] = start + ((w3 >> 24) | (w4 << 40) & 0x3fffffffffffff)+(0*32+ 4 +1); w5 = *(uint64_t *)(in+(0*27+5)*8/sizeof(in[0])); out[0*32+ 5] = start + ((w4 >> 14) | (w5 << 50) & 0x3fffffffffffff)+(0*32+ 5 +1); out[0*32+ 6] = start + ((w5 >> 4) & 0x3fffffffffffff)+(0*32+ 6 +1); w6 = *(uint64_t *)(in+(0*27+6)*8/sizeof(in[0])); out[0*32+ 7] = start + ((w5 >> 58) | (w6 << 6) & 0x3fffffffffffff)+(0*32+ 7 +1); w7 = *(uint64_t *)(in+(0*27+7)*8/sizeof(in[0])); out[0*32+ 8] = start + ((w6 >> 48) | (w7 << 16) & 0x3fffffffffffff)+(0*32+ 8 +1); w8 = *(uint64_t *)(in+(0*27+8)*8/sizeof(in[0])); out[0*32+ 9] = start + ((w7 >> 38) | (w8 << 26) & 0x3fffffffffffff)+(0*32+ 9 +1); w9 = *(uint64_t *)(in+(0*27+9)*8/sizeof(in[0])); out[0*32+10] = start + ((w8 >> 28) | (w9 << 36) & 0x3fffffffffffff)+(0*32+10 +1); w10 = *(uint64_t *)(in+(0*27+10)*8/sizeof(in[0])); out[0*32+11] = start + ((w9 >> 18) | (w10 << 46) & 0x3fffffffffffff)+(0*32+11 +1); out[0*32+12] = start + ((w10 >> 8) & 0x3fffffffffffff)+(0*32+12 +1); w11 = *(uint64_t *)(in+(0*27+11)*8/sizeof(in[0])); out[0*32+13] = start + ((w10 >> 62) | (w11 << 2) & 0x3fffffffffffff)+(0*32+13 +1); w12 = *(uint64_t *)(in+(0*27+12)*8/sizeof(in[0])); out[0*32+14] = start + ((w11 >> 52) | (w12 << 12) & 0x3fffffffffffff)+(0*32+14 +1); w13 = *(uint64_t *)(in+(0*27+13)*8/sizeof(in[0])); out[0*32+15] = start + ((w12 >> 42) | (w13 << 22) & 0x3fffffffffffff)+(0*32+15 +1); w14 = *(uint64_t *)(in+(0*27+14)*8/sizeof(in[0])); out[0*32+16] = start + ((w13 >> 32) | (w14 << 32) & 0x3fffffffffffff)+(0*32+16 +1); w15 = *(uint64_t *)(in+(0*27+15)*8/sizeof(in[0])); out[0*32+17] = start + ((w14 >> 22) | (w15 << 42) & 0x3fffffffffffff)+(0*32+17 +1); w16 = *(uint64_t *)(in+(0*27+16)*8/sizeof(in[0])); out[0*32+18] = start + ((w15 >> 12) | (w16 << 52) & 0x3fffffffffffff)+(0*32+18 +1); out[0*32+19] = start + ((w16 >> 2) & 0x3fffffffffffff)+(0*32+19 +1); w17 = *(uint64_t *)(in+(0*27+17)*8/sizeof(in[0])); out[0*32+20] = start + ((w16 >> 56) | (w17 << 8) & 0x3fffffffffffff)+(0*32+20 +1); w18 = *(uint64_t *)(in+(0*27+18)*8/sizeof(in[0])); out[0*32+21] = start + ((w17 >> 46) | (w18 << 18) & 0x3fffffffffffff)+(0*32+21 +1); w19 = *(uint64_t *)(in+(0*27+19)*8/sizeof(in[0])); out[0*32+22] = start + ((w18 >> 36) | (w19 << 28) & 0x3fffffffffffff)+(0*32+22 +1); w20 = *(uint64_t *)(in+(0*27+20)*8/sizeof(in[0])); out[0*32+23] = start + ((w19 >> 26) | (w20 << 38) & 0x3fffffffffffff)+(0*32+23 +1); w21 = *(uint64_t *)(in+(0*27+21)*8/sizeof(in[0])); out[0*32+24] = start + ((w20 >> 16) | (w21 << 48) & 0x3fffffffffffff)+(0*32+24 +1); out[0*32+25] = start + ((w21 >> 6) & 0x3fffffffffffff)+(0*32+25 +1); w22 = *(uint64_t *)(in+(0*27+22)*8/sizeof(in[0])); out[0*32+26] = start + ((w21 >> 60) | (w22 << 4) & 0x3fffffffffffff)+(0*32+26 +1); w23 = *(uint64_t *)(in+(0*27+23)*8/sizeof(in[0])); out[0*32+27] = start + ((w22 >> 50) | (w23 << 14) & 0x3fffffffffffff)+(0*32+27 +1); w24 = *(uint64_t *)(in+(0*27+24)*8/sizeof(in[0])); out[0*32+28] = start + ((w23 >> 40) | (w24 << 24) & 0x3fffffffffffff)+(0*32+28 +1); w25 = *(uint64_t *)(in+(0*27+25)*8/sizeof(in[0])); out[0*32+29] = start + ((w24 >> 30) | (w25 << 34) & 0x3fffffffffffff)+(0*32+29 +1); w26 = *(uint64_t *)(in+(0*27+26)*8/sizeof(in[0])); out[0*32+30] = start + ((w25 >> 20) | (w26 << 44) & 0x3fffffffffffff)+(0*32+30 +1); out[0*32+31] = start + ((w26 >> 10))+(0*32+31 +1);;}; out += 32; start += 32; in += 54*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_55(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*55)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(0*55+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7fffffffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*55+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 55) | (w1 << 9) & 0x7fffffffffffff)+(0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*55+2)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w1 >> 46) | (w2 << 18) & 0x7fffffffffffff)+(0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*55+3)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w2 >> 37) | (w3 << 27) & 0x7fffffffffffff)+(0*64+ 3 +1); w4 = *(uint64_t *)(in+(0*55+4)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w3 >> 28) | (w4 << 36) & 0x7fffffffffffff)+(0*64+ 4 +1); w5 = *(uint64_t *)(in+(0*55+5)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w4 >> 19) | (w5 << 45) & 0x7fffffffffffff)+(0*64+ 5 +1); w6 = *(uint64_t *)(in+(0*55+6)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w5 >> 10) | (w6 << 54) & 0x7fffffffffffff)+(0*64+ 6 +1); out[0*64+ 7] = start + ((w6 >> 1) & 0x7fffffffffffff)+(0*64+ 7 +1); w7 = *(uint64_t *)(in+(0*55+7)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w6 >> 56) | (w7 << 8) & 0x7fffffffffffff)+(0*64+ 8 +1); w8 = *(uint64_t *)(in+(0*55+8)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w7 >> 47) | (w8 << 17) & 0x7fffffffffffff)+(0*64+ 9 +1); w9 = *(uint64_t *)(in+(0*55+9)*8/sizeof(in[0])); out[0*64+10] = start + ((w8 >> 38) | (w9 << 26) & 0x7fffffffffffff)+(0*64+10 +1); w10 = *(uint64_t *)(in+(0*55+10)*8/sizeof(in[0])); out[0*64+11] = start + ((w9 >> 29) | (w10 << 35) & 0x7fffffffffffff)+(0*64+11 +1); w11 = *(uint64_t *)(in+(0*55+11)*8/sizeof(in[0])); out[0*64+12] = start + ((w10 >> 20) | (w11 << 44) & 0x7fffffffffffff)+(0*64+12 +1); w12 = *(uint64_t *)(in+(0*55+12)*8/sizeof(in[0])); out[0*64+13] = start + ((w11 >> 11) | (w12 << 53) & 0x7fffffffffffff)+(0*64+13 +1); out[0*64+14] = start + ((w12 >> 2) & 0x7fffffffffffff)+(0*64+14 +1); w13 = *(uint64_t *)(in+(0*55+13)*8/sizeof(in[0])); out[0*64+15] = start + ((w12 >> 57) | (w13 << 7) & 0x7fffffffffffff)+(0*64+15 +1); w14 = *(uint64_t *)(in+(0*55+14)*8/sizeof(in[0])); out[0*64+16] = start + ((w13 >> 48) | (w14 << 16) & 0x7fffffffffffff)+(0*64+16 +1); w15 = *(uint64_t *)(in+(0*55+15)*8/sizeof(in[0])); out[0*64+17] = start + ((w14 >> 39) | (w15 << 25) & 0x7fffffffffffff)+(0*64+17 +1); w16 = *(uint64_t *)(in+(0*55+16)*8/sizeof(in[0])); out[0*64+18] = start + ((w15 >> 30) | (w16 << 34) & 0x7fffffffffffff)+(0*64+18 +1); w17 = *(uint64_t *)(in+(0*55+17)*8/sizeof(in[0])); out[0*64+19] = start + ((w16 >> 21) | (w17 << 43) & 0x7fffffffffffff)+(0*64+19 +1); w18 = *(uint64_t *)(in+(0*55+18)*8/sizeof(in[0])); out[0*64+20] = start + ((w17 >> 12) | (w18 << 52) & 0x7fffffffffffff)+(0*64+20 +1); out[0*64+21] = start + ((w18 >> 3) & 0x7fffffffffffff)+(0*64+21 +1); w19 = *(uint64_t *)(in+(0*55+19)*8/sizeof(in[0])); out[0*64+22] = start + ((w18 >> 58) | (w19 << 6) & 0x7fffffffffffff)+(0*64+22 +1); w20 = *(uint64_t *)(in+(0*55+20)*8/sizeof(in[0])); out[0*64+23] = start + ((w19 >> 49) | (w20 << 15) & 0x7fffffffffffff)+(0*64+23 +1); w21 = *(uint64_t *)(in+(0*55+21)*8/sizeof(in[0])); out[0*64+24] = start + ((w20 >> 40) | (w21 << 24) & 0x7fffffffffffff)+(0*64+24 +1); w22 = *(uint64_t *)(in+(0*55+22)*8/sizeof(in[0])); out[0*64+25] = start + ((w21 >> 31) | (w22 << 33) & 0x7fffffffffffff)+(0*64+25 +1); w23 = *(uint64_t *)(in+(0*55+23)*8/sizeof(in[0])); out[0*64+26] = start + ((w22 >> 22) | (w23 << 42) & 0x7fffffffffffff)+(0*64+26 +1); w24 = *(uint64_t *)(in+(0*55+24)*8/sizeof(in[0])); out[0*64+27] = start + ((w23 >> 13) | (w24 << 51) & 0x7fffffffffffff)+(0*64+27 +1); out[0*64+28] = start + ((w24 >> 4) & 0x7fffffffffffff)+(0*64+28 +1); w25 = *(uint64_t *)(in+(0*55+25)*8/sizeof(in[0])); out[0*64+29] = start + ((w24 >> 59) | (w25 << 5) & 0x7fffffffffffff)+(0*64+29 +1); w26 = *(uint64_t *)(in+(0*55+26)*8/sizeof(in[0])); out[0*64+30] = start + ((w25 >> 50) | (w26 << 14) & 0x7fffffffffffff)+(0*64+30 +1); w27 = *(uint32_t *)(in+(0*55+27)*8/sizeof(in[0])); out[0*64+31] = start + ((w26 >> 41) | (w27 << 23) & 0x7fffffffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 55*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_56(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*56)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(0*7+0)*8/sizeof(in[0])); out[0*8+ 0] = start + ((w0 ) & 0xffffffffffffff)+(0*8+ 0 +1); w1 = *(uint64_t *)(in+(0*7+1)*8/sizeof(in[0])); out[0*8+ 1] = start + ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)+(0*8+ 1 +1); w2 = *(uint64_t *)(in+(0*7+2)*8/sizeof(in[0])); out[0*8+ 2] = start + ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)+(0*8+ 2 +1); w3 = *(uint64_t *)(in+(0*7+3)*8/sizeof(in[0])); out[0*8+ 3] = start + ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)+(0*8+ 3 +1); w4 = *(uint64_t *)(in+(0*7+4)*8/sizeof(in[0])); out[0*8+ 4] = start + ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)+(0*8+ 4 +1); w5 = *(uint64_t *)(in+(0*7+5)*8/sizeof(in[0])); out[0*8+ 5] = start + ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)+(0*8+ 5 +1); w6 = *(uint64_t *)(in+(0*7+6)*8/sizeof(in[0])); out[0*8+ 6] = start + ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)+(0*8+ 6 +1); out[0*8+ 7] = start + ((w6 >> 8))+(0*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(1*7+0)*8/sizeof(in[0])); out[1*8+ 0] = start + ((w0 ) & 0xffffffffffffff)+(1*8+ 0 +1); w1 = *(uint64_t *)(in+(1*7+1)*8/sizeof(in[0])); out[1*8+ 1] = start + ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)+(1*8+ 1 +1); w2 = *(uint64_t *)(in+(1*7+2)*8/sizeof(in[0])); out[1*8+ 2] = start + ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)+(1*8+ 2 +1); w3 = *(uint64_t *)(in+(1*7+3)*8/sizeof(in[0])); out[1*8+ 3] = start + ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)+(1*8+ 3 +1); w4 = *(uint64_t *)(in+(1*7+4)*8/sizeof(in[0])); out[1*8+ 4] = start + ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)+(1*8+ 4 +1); w5 = *(uint64_t *)(in+(1*7+5)*8/sizeof(in[0])); out[1*8+ 5] = start + ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)+(1*8+ 5 +1); w6 = *(uint64_t *)(in+(1*7+6)*8/sizeof(in[0])); out[1*8+ 6] = start + ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)+(1*8+ 6 +1); out[1*8+ 7] = start + ((w6 >> 8))+(1*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(2*7+0)*8/sizeof(in[0])); out[2*8+ 0] = start + ((w0 ) & 0xffffffffffffff)+(2*8+ 0 +1); w1 = *(uint64_t *)(in+(2*7+1)*8/sizeof(in[0])); out[2*8+ 1] = start + ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)+(2*8+ 1 +1); w2 = *(uint64_t *)(in+(2*7+2)*8/sizeof(in[0])); out[2*8+ 2] = start + ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)+(2*8+ 2 +1); w3 = *(uint64_t *)(in+(2*7+3)*8/sizeof(in[0])); out[2*8+ 3] = start + ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)+(2*8+ 3 +1); w4 = *(uint64_t *)(in+(2*7+4)*8/sizeof(in[0])); out[2*8+ 4] = start + ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)+(2*8+ 4 +1); w5 = *(uint64_t *)(in+(2*7+5)*8/sizeof(in[0])); out[2*8+ 5] = start + ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)+(2*8+ 5 +1); w6 = *(uint64_t *)(in+(2*7+6)*8/sizeof(in[0])); out[2*8+ 6] = start + ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)+(2*8+ 6 +1); out[2*8+ 7] = start + ((w6 >> 8))+(2*8+ 7 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27; w0 = *(uint64_t *)(in+(3*7+0)*8/sizeof(in[0])); out[3*8+ 0] = start + ((w0 ) & 0xffffffffffffff)+(3*8+ 0 +1); w1 = *(uint64_t *)(in+(3*7+1)*8/sizeof(in[0])); out[3*8+ 1] = start + ((w0 >> 56) | (w1 << 8) & 0xffffffffffffff)+(3*8+ 1 +1); w2 = *(uint64_t *)(in+(3*7+2)*8/sizeof(in[0])); out[3*8+ 2] = start + ((w1 >> 48) | (w2 << 16) & 0xffffffffffffff)+(3*8+ 2 +1); w3 = *(uint64_t *)(in+(3*7+3)*8/sizeof(in[0])); out[3*8+ 3] = start + ((w2 >> 40) | (w3 << 24) & 0xffffffffffffff)+(3*8+ 3 +1); w4 = *(uint64_t *)(in+(3*7+4)*8/sizeof(in[0])); out[3*8+ 4] = start + ((w3 >> 32) | (w4 << 32) & 0xffffffffffffff)+(3*8+ 4 +1); w5 = *(uint64_t *)(in+(3*7+5)*8/sizeof(in[0])); out[3*8+ 5] = start + ((w4 >> 24) | (w5 << 40) & 0xffffffffffffff)+(3*8+ 5 +1); w6 = *(uint64_t *)(in+(3*7+6)*8/sizeof(in[0])); out[3*8+ 6] = start + ((w5 >> 16) | (w6 << 48) & 0xffffffffffffff)+(3*8+ 6 +1); out[3*8+ 7] = start + ((w6 >> 8))+(3*8+ 7 +1);;}; out += 32; start += 32; in += 56*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_57(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*57)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28; w0 = *(uint64_t *)(in+(0*57+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1ffffffffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*57+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 57) | (w1 << 7) & 0x1ffffffffffffff)+(0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*57+2)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w1 >> 50) | (w2 << 14) & 0x1ffffffffffffff)+(0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*57+3)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w2 >> 43) | (w3 << 21) & 0x1ffffffffffffff)+(0*64+ 3 +1); w4 = *(uint64_t *)(in+(0*57+4)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w3 >> 36) | (w4 << 28) & 0x1ffffffffffffff)+(0*64+ 4 +1); w5 = *(uint64_t *)(in+(0*57+5)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w4 >> 29) | (w5 << 35) & 0x1ffffffffffffff)+(0*64+ 5 +1); w6 = *(uint64_t *)(in+(0*57+6)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w5 >> 22) | (w6 << 42) & 0x1ffffffffffffff)+(0*64+ 6 +1); w7 = *(uint64_t *)(in+(0*57+7)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w6 >> 15) | (w7 << 49) & 0x1ffffffffffffff)+(0*64+ 7 +1); w8 = *(uint64_t *)(in+(0*57+8)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w7 >> 8) | (w8 << 56) & 0x1ffffffffffffff)+(0*64+ 8 +1); out[0*64+ 9] = start + ((w8 >> 1) & 0x1ffffffffffffff)+(0*64+ 9 +1); w9 = *(uint64_t *)(in+(0*57+9)*8/sizeof(in[0])); out[0*64+10] = start + ((w8 >> 58) | (w9 << 6) & 0x1ffffffffffffff)+(0*64+10 +1); w10 = *(uint64_t *)(in+(0*57+10)*8/sizeof(in[0])); out[0*64+11] = start + ((w9 >> 51) | (w10 << 13) & 0x1ffffffffffffff)+(0*64+11 +1); w11 = *(uint64_t *)(in+(0*57+11)*8/sizeof(in[0])); out[0*64+12] = start + ((w10 >> 44) | (w11 << 20) & 0x1ffffffffffffff)+(0*64+12 +1); w12 = *(uint64_t *)(in+(0*57+12)*8/sizeof(in[0])); out[0*64+13] = start + ((w11 >> 37) | (w12 << 27) & 0x1ffffffffffffff)+(0*64+13 +1); w13 = *(uint64_t *)(in+(0*57+13)*8/sizeof(in[0])); out[0*64+14] = start + ((w12 >> 30) | (w13 << 34) & 0x1ffffffffffffff)+(0*64+14 +1); w14 = *(uint64_t *)(in+(0*57+14)*8/sizeof(in[0])); out[0*64+15] = start + ((w13 >> 23) | (w14 << 41) & 0x1ffffffffffffff)+(0*64+15 +1); w15 = *(uint64_t *)(in+(0*57+15)*8/sizeof(in[0])); out[0*64+16] = start + ((w14 >> 16) | (w15 << 48) & 0x1ffffffffffffff)+(0*64+16 +1); w16 = *(uint64_t *)(in+(0*57+16)*8/sizeof(in[0])); out[0*64+17] = start + ((w15 >> 9) | (w16 << 55) & 0x1ffffffffffffff)+(0*64+17 +1); out[0*64+18] = start + ((w16 >> 2) & 0x1ffffffffffffff)+(0*64+18 +1); w17 = *(uint64_t *)(in+(0*57+17)*8/sizeof(in[0])); out[0*64+19] = start + ((w16 >> 59) | (w17 << 5) & 0x1ffffffffffffff)+(0*64+19 +1); w18 = *(uint64_t *)(in+(0*57+18)*8/sizeof(in[0])); out[0*64+20] = start + ((w17 >> 52) | (w18 << 12) & 0x1ffffffffffffff)+(0*64+20 +1); w19 = *(uint64_t *)(in+(0*57+19)*8/sizeof(in[0])); out[0*64+21] = start + ((w18 >> 45) | (w19 << 19) & 0x1ffffffffffffff)+(0*64+21 +1); w20 = *(uint64_t *)(in+(0*57+20)*8/sizeof(in[0])); out[0*64+22] = start + ((w19 >> 38) | (w20 << 26) & 0x1ffffffffffffff)+(0*64+22 +1); w21 = *(uint64_t *)(in+(0*57+21)*8/sizeof(in[0])); out[0*64+23] = start + ((w20 >> 31) | (w21 << 33) & 0x1ffffffffffffff)+(0*64+23 +1); w22 = *(uint64_t *)(in+(0*57+22)*8/sizeof(in[0])); out[0*64+24] = start + ((w21 >> 24) | (w22 << 40) & 0x1ffffffffffffff)+(0*64+24 +1); w23 = *(uint64_t *)(in+(0*57+23)*8/sizeof(in[0])); out[0*64+25] = start + ((w22 >> 17) | (w23 << 47) & 0x1ffffffffffffff)+(0*64+25 +1); w24 = *(uint64_t *)(in+(0*57+24)*8/sizeof(in[0])); out[0*64+26] = start + ((w23 >> 10) | (w24 << 54) & 0x1ffffffffffffff)+(0*64+26 +1); out[0*64+27] = start + ((w24 >> 3) & 0x1ffffffffffffff)+(0*64+27 +1); w25 = *(uint64_t *)(in+(0*57+25)*8/sizeof(in[0])); out[0*64+28] = start + ((w24 >> 60) | (w25 << 4) & 0x1ffffffffffffff)+(0*64+28 +1); w26 = *(uint64_t *)(in+(0*57+26)*8/sizeof(in[0])); out[0*64+29] = start + ((w25 >> 53) | (w26 << 11) & 0x1ffffffffffffff)+(0*64+29 +1); w27 = *(uint64_t *)(in+(0*57+27)*8/sizeof(in[0])); out[0*64+30] = start + ((w26 >> 46) | (w27 << 18) & 0x1ffffffffffffff)+(0*64+30 +1); w28 = *(uint32_t *)(in+(0*57+28)*8/sizeof(in[0])); out[0*64+31] = start + ((w27 >> 39) | (w28 << 25) & 0x1ffffffffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 57*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_58(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*58)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28; w0 = *(uint64_t *)(in+(0*29+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3ffffffffffffff)+(0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*29+1)*8/sizeof(in[0])); out[0*32+ 1] = start + ((w0 >> 58) | (w1 << 6) & 0x3ffffffffffffff)+(0*32+ 1 +1); w2 = *(uint64_t *)(in+(0*29+2)*8/sizeof(in[0])); out[0*32+ 2] = start + ((w1 >> 52) | (w2 << 12) & 0x3ffffffffffffff)+(0*32+ 2 +1); w3 = *(uint64_t *)(in+(0*29+3)*8/sizeof(in[0])); out[0*32+ 3] = start + ((w2 >> 46) | (w3 << 18) & 0x3ffffffffffffff)+(0*32+ 3 +1); w4 = *(uint64_t *)(in+(0*29+4)*8/sizeof(in[0])); out[0*32+ 4] = start + ((w3 >> 40) | (w4 << 24) & 0x3ffffffffffffff)+(0*32+ 4 +1); w5 = *(uint64_t *)(in+(0*29+5)*8/sizeof(in[0])); out[0*32+ 5] = start + ((w4 >> 34) | (w5 << 30) & 0x3ffffffffffffff)+(0*32+ 5 +1); w6 = *(uint64_t *)(in+(0*29+6)*8/sizeof(in[0])); out[0*32+ 6] = start + ((w5 >> 28) | (w6 << 36) & 0x3ffffffffffffff)+(0*32+ 6 +1); w7 = *(uint64_t *)(in+(0*29+7)*8/sizeof(in[0])); out[0*32+ 7] = start + ((w6 >> 22) | (w7 << 42) & 0x3ffffffffffffff)+(0*32+ 7 +1); w8 = *(uint64_t *)(in+(0*29+8)*8/sizeof(in[0])); out[0*32+ 8] = start + ((w7 >> 16) | (w8 << 48) & 0x3ffffffffffffff)+(0*32+ 8 +1); w9 = *(uint64_t *)(in+(0*29+9)*8/sizeof(in[0])); out[0*32+ 9] = start + ((w8 >> 10) | (w9 << 54) & 0x3ffffffffffffff)+(0*32+ 9 +1); out[0*32+10] = start + ((w9 >> 4) & 0x3ffffffffffffff)+(0*32+10 +1); w10 = *(uint64_t *)(in+(0*29+10)*8/sizeof(in[0])); out[0*32+11] = start + ((w9 >> 62) | (w10 << 2) & 0x3ffffffffffffff)+(0*32+11 +1); w11 = *(uint64_t *)(in+(0*29+11)*8/sizeof(in[0])); out[0*32+12] = start + ((w10 >> 56) | (w11 << 8) & 0x3ffffffffffffff)+(0*32+12 +1); w12 = *(uint64_t *)(in+(0*29+12)*8/sizeof(in[0])); out[0*32+13] = start + ((w11 >> 50) | (w12 << 14) & 0x3ffffffffffffff)+(0*32+13 +1); w13 = *(uint64_t *)(in+(0*29+13)*8/sizeof(in[0])); out[0*32+14] = start + ((w12 >> 44) | (w13 << 20) & 0x3ffffffffffffff)+(0*32+14 +1); w14 = *(uint64_t *)(in+(0*29+14)*8/sizeof(in[0])); out[0*32+15] = start + ((w13 >> 38) | (w14 << 26) & 0x3ffffffffffffff)+(0*32+15 +1); w15 = *(uint64_t *)(in+(0*29+15)*8/sizeof(in[0])); out[0*32+16] = start + ((w14 >> 32) | (w15 << 32) & 0x3ffffffffffffff)+(0*32+16 +1); w16 = *(uint64_t *)(in+(0*29+16)*8/sizeof(in[0])); out[0*32+17] = start + ((w15 >> 26) | (w16 << 38) & 0x3ffffffffffffff)+(0*32+17 +1); w17 = *(uint64_t *)(in+(0*29+17)*8/sizeof(in[0])); out[0*32+18] = start + ((w16 >> 20) | (w17 << 44) & 0x3ffffffffffffff)+(0*32+18 +1); w18 = *(uint64_t *)(in+(0*29+18)*8/sizeof(in[0])); out[0*32+19] = start + ((w17 >> 14) | (w18 << 50) & 0x3ffffffffffffff)+(0*32+19 +1); w19 = *(uint64_t *)(in+(0*29+19)*8/sizeof(in[0])); out[0*32+20] = start + ((w18 >> 8) | (w19 << 56) & 0x3ffffffffffffff)+(0*32+20 +1); out[0*32+21] = start + ((w19 >> 2) & 0x3ffffffffffffff)+(0*32+21 +1); w20 = *(uint64_t *)(in+(0*29+20)*8/sizeof(in[0])); out[0*32+22] = start + ((w19 >> 60) | (w20 << 4) & 0x3ffffffffffffff)+(0*32+22 +1); w21 = *(uint64_t *)(in+(0*29+21)*8/sizeof(in[0])); out[0*32+23] = start + ((w20 >> 54) | (w21 << 10) & 0x3ffffffffffffff)+(0*32+23 +1); w22 = *(uint64_t *)(in+(0*29+22)*8/sizeof(in[0])); out[0*32+24] = start + ((w21 >> 48) | (w22 << 16) & 0x3ffffffffffffff)+(0*32+24 +1); w23 = *(uint64_t *)(in+(0*29+23)*8/sizeof(in[0])); out[0*32+25] = start + ((w22 >> 42) | (w23 << 22) & 0x3ffffffffffffff)+(0*32+25 +1); w24 = *(uint64_t *)(in+(0*29+24)*8/sizeof(in[0])); out[0*32+26] = start + ((w23 >> 36) | (w24 << 28) & 0x3ffffffffffffff)+(0*32+26 +1); w25 = *(uint64_t *)(in+(0*29+25)*8/sizeof(in[0])); out[0*32+27] = start + ((w24 >> 30) | (w25 << 34) & 0x3ffffffffffffff)+(0*32+27 +1); w26 = *(uint64_t *)(in+(0*29+26)*8/sizeof(in[0])); out[0*32+28] = start + ((w25 >> 24) | (w26 << 40) & 0x3ffffffffffffff)+(0*32+28 +1); w27 = *(uint64_t *)(in+(0*29+27)*8/sizeof(in[0])); out[0*32+29] = start + ((w26 >> 18) | (w27 << 46) & 0x3ffffffffffffff)+(0*32+29 +1); w28 = *(uint64_t *)(in+(0*29+28)*8/sizeof(in[0])); out[0*32+30] = start + ((w27 >> 12) | (w28 << 52) & 0x3ffffffffffffff)+(0*32+30 +1); out[0*32+31] = start + ((w28 >> 6))+(0*32+31 +1);;}; out += 32; start += 32; in += 58*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_59(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*59)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(0*59+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7ffffffffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*59+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 59) | (w1 << 5) & 0x7ffffffffffffff)+(0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*59+2)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w1 >> 54) | (w2 << 10) & 0x7ffffffffffffff)+(0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*59+3)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w2 >> 49) | (w3 << 15) & 0x7ffffffffffffff)+(0*64+ 3 +1); w4 = *(uint64_t *)(in+(0*59+4)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w3 >> 44) | (w4 << 20) & 0x7ffffffffffffff)+(0*64+ 4 +1); w5 = *(uint64_t *)(in+(0*59+5)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w4 >> 39) | (w5 << 25) & 0x7ffffffffffffff)+(0*64+ 5 +1); w6 = *(uint64_t *)(in+(0*59+6)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w5 >> 34) | (w6 << 30) & 0x7ffffffffffffff)+(0*64+ 6 +1); w7 = *(uint64_t *)(in+(0*59+7)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w6 >> 29) | (w7 << 35) & 0x7ffffffffffffff)+(0*64+ 7 +1); w8 = *(uint64_t *)(in+(0*59+8)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w7 >> 24) | (w8 << 40) & 0x7ffffffffffffff)+(0*64+ 8 +1); w9 = *(uint64_t *)(in+(0*59+9)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w8 >> 19) | (w9 << 45) & 0x7ffffffffffffff)+(0*64+ 9 +1); w10 = *(uint64_t *)(in+(0*59+10)*8/sizeof(in[0])); out[0*64+10] = start + ((w9 >> 14) | (w10 << 50) & 0x7ffffffffffffff)+(0*64+10 +1); w11 = *(uint64_t *)(in+(0*59+11)*8/sizeof(in[0])); out[0*64+11] = start + ((w10 >> 9) | (w11 << 55) & 0x7ffffffffffffff)+(0*64+11 +1); out[0*64+12] = start + ((w11 >> 4) & 0x7ffffffffffffff)+(0*64+12 +1); w12 = *(uint64_t *)(in+(0*59+12)*8/sizeof(in[0])); out[0*64+13] = start + ((w11 >> 63) | (w12 << 1) & 0x7ffffffffffffff)+(0*64+13 +1); w13 = *(uint64_t *)(in+(0*59+13)*8/sizeof(in[0])); out[0*64+14] = start + ((w12 >> 58) | (w13 << 6) & 0x7ffffffffffffff)+(0*64+14 +1); w14 = *(uint64_t *)(in+(0*59+14)*8/sizeof(in[0])); out[0*64+15] = start + ((w13 >> 53) | (w14 << 11) & 0x7ffffffffffffff)+(0*64+15 +1); w15 = *(uint64_t *)(in+(0*59+15)*8/sizeof(in[0])); out[0*64+16] = start + ((w14 >> 48) | (w15 << 16) & 0x7ffffffffffffff)+(0*64+16 +1); w16 = *(uint64_t *)(in+(0*59+16)*8/sizeof(in[0])); out[0*64+17] = start + ((w15 >> 43) | (w16 << 21) & 0x7ffffffffffffff)+(0*64+17 +1); w17 = *(uint64_t *)(in+(0*59+17)*8/sizeof(in[0])); out[0*64+18] = start + ((w16 >> 38) | (w17 << 26) & 0x7ffffffffffffff)+(0*64+18 +1); w18 = *(uint64_t *)(in+(0*59+18)*8/sizeof(in[0])); out[0*64+19] = start + ((w17 >> 33) | (w18 << 31) & 0x7ffffffffffffff)+(0*64+19 +1); w19 = *(uint64_t *)(in+(0*59+19)*8/sizeof(in[0])); out[0*64+20] = start + ((w18 >> 28) | (w19 << 36) & 0x7ffffffffffffff)+(0*64+20 +1); w20 = *(uint64_t *)(in+(0*59+20)*8/sizeof(in[0])); out[0*64+21] = start + ((w19 >> 23) | (w20 << 41) & 0x7ffffffffffffff)+(0*64+21 +1); w21 = *(uint64_t *)(in+(0*59+21)*8/sizeof(in[0])); out[0*64+22] = start + ((w20 >> 18) | (w21 << 46) & 0x7ffffffffffffff)+(0*64+22 +1); w22 = *(uint64_t *)(in+(0*59+22)*8/sizeof(in[0])); out[0*64+23] = start + ((w21 >> 13) | (w22 << 51) & 0x7ffffffffffffff)+(0*64+23 +1); w23 = *(uint64_t *)(in+(0*59+23)*8/sizeof(in[0])); out[0*64+24] = start + ((w22 >> 8) | (w23 << 56) & 0x7ffffffffffffff)+(0*64+24 +1); out[0*64+25] = start + ((w23 >> 3) & 0x7ffffffffffffff)+(0*64+25 +1); w24 = *(uint64_t *)(in+(0*59+24)*8/sizeof(in[0])); out[0*64+26] = start + ((w23 >> 62) | (w24 << 2) & 0x7ffffffffffffff)+(0*64+26 +1); w25 = *(uint64_t *)(in+(0*59+25)*8/sizeof(in[0])); out[0*64+27] = start + ((w24 >> 57) | (w25 << 7) & 0x7ffffffffffffff)+(0*64+27 +1); w26 = *(uint64_t *)(in+(0*59+26)*8/sizeof(in[0])); out[0*64+28] = start + ((w25 >> 52) | (w26 << 12) & 0x7ffffffffffffff)+(0*64+28 +1); w27 = *(uint64_t *)(in+(0*59+27)*8/sizeof(in[0])); out[0*64+29] = start + ((w26 >> 47) | (w27 << 17) & 0x7ffffffffffffff)+(0*64+29 +1); w28 = *(uint64_t *)(in+(0*59+28)*8/sizeof(in[0])); out[0*64+30] = start + ((w27 >> 42) | (w28 << 22) & 0x7ffffffffffffff)+(0*64+30 +1); w29 = *(uint32_t *)(in+(0*59+29)*8/sizeof(in[0])); out[0*64+31] = start + ((w28 >> 37) | (w29 << 27) & 0x7ffffffffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 59*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_60(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*60)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(0*15+0)*8/sizeof(in[0])); out[0*16+ 0] = start + ((w0 ) & 0xfffffffffffffff)+(0*16+ 0 +1); w1 = *(uint64_t *)(in+(0*15+1)*8/sizeof(in[0])); out[0*16+ 1] = start + ((w0 >> 60) | (w1 << 4) & 0xfffffffffffffff)+(0*16+ 1 +1); w2 = *(uint64_t *)(in+(0*15+2)*8/sizeof(in[0])); out[0*16+ 2] = start + ((w1 >> 56) | (w2 << 8) & 0xfffffffffffffff)+(0*16+ 2 +1); w3 = *(uint64_t *)(in+(0*15+3)*8/sizeof(in[0])); out[0*16+ 3] = start + ((w2 >> 52) | (w3 << 12) & 0xfffffffffffffff)+(0*16+ 3 +1); w4 = *(uint64_t *)(in+(0*15+4)*8/sizeof(in[0])); out[0*16+ 4] = start + ((w3 >> 48) | (w4 << 16) & 0xfffffffffffffff)+(0*16+ 4 +1); w5 = *(uint64_t *)(in+(0*15+5)*8/sizeof(in[0])); out[0*16+ 5] = start + ((w4 >> 44) | (w5 << 20) & 0xfffffffffffffff)+(0*16+ 5 +1); w6 = *(uint64_t *)(in+(0*15+6)*8/sizeof(in[0])); out[0*16+ 6] = start + ((w5 >> 40) | (w6 << 24) & 0xfffffffffffffff)+(0*16+ 6 +1); w7 = *(uint64_t *)(in+(0*15+7)*8/sizeof(in[0])); out[0*16+ 7] = start + ((w6 >> 36) | (w7 << 28) & 0xfffffffffffffff)+(0*16+ 7 +1); w8 = *(uint64_t *)(in+(0*15+8)*8/sizeof(in[0])); out[0*16+ 8] = start + ((w7 >> 32) | (w8 << 32) & 0xfffffffffffffff)+(0*16+ 8 +1); w9 = *(uint64_t *)(in+(0*15+9)*8/sizeof(in[0])); out[0*16+ 9] = start + ((w8 >> 28) | (w9 << 36) & 0xfffffffffffffff)+(0*16+ 9 +1); w10 = *(uint64_t *)(in+(0*15+10)*8/sizeof(in[0])); out[0*16+10] = start + ((w9 >> 24) | (w10 << 40) & 0xfffffffffffffff)+(0*16+10 +1); w11 = *(uint64_t *)(in+(0*15+11)*8/sizeof(in[0])); out[0*16+11] = start + ((w10 >> 20) | (w11 << 44) & 0xfffffffffffffff)+(0*16+11 +1); w12 = *(uint64_t *)(in+(0*15+12)*8/sizeof(in[0])); out[0*16+12] = start + ((w11 >> 16) | (w12 << 48) & 0xfffffffffffffff)+(0*16+12 +1); w13 = *(uint64_t *)(in+(0*15+13)*8/sizeof(in[0])); out[0*16+13] = start + ((w12 >> 12) | (w13 << 52) & 0xfffffffffffffff)+(0*16+13 +1); w14 = *(uint64_t *)(in+(0*15+14)*8/sizeof(in[0])); out[0*16+14] = start + ((w13 >> 8) | (w14 << 56) & 0xfffffffffffffff)+(0*16+14 +1); out[0*16+15] = start + ((w14 >> 4))+(0*16+15 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29; w0 = *(uint64_t *)(in+(1*15+0)*8/sizeof(in[0])); out[1*16+ 0] = start + ((w0 ) & 0xfffffffffffffff)+(1*16+ 0 +1); w1 = *(uint64_t *)(in+(1*15+1)*8/sizeof(in[0])); out[1*16+ 1] = start + ((w0 >> 60) | (w1 << 4) & 0xfffffffffffffff)+(1*16+ 1 +1); w2 = *(uint64_t *)(in+(1*15+2)*8/sizeof(in[0])); out[1*16+ 2] = start + ((w1 >> 56) | (w2 << 8) & 0xfffffffffffffff)+(1*16+ 2 +1); w3 = *(uint64_t *)(in+(1*15+3)*8/sizeof(in[0])); out[1*16+ 3] = start + ((w2 >> 52) | (w3 << 12) & 0xfffffffffffffff)+(1*16+ 3 +1); w4 = *(uint64_t *)(in+(1*15+4)*8/sizeof(in[0])); out[1*16+ 4] = start + ((w3 >> 48) | (w4 << 16) & 0xfffffffffffffff)+(1*16+ 4 +1); w5 = *(uint64_t *)(in+(1*15+5)*8/sizeof(in[0])); out[1*16+ 5] = start + ((w4 >> 44) | (w5 << 20) & 0xfffffffffffffff)+(1*16+ 5 +1); w6 = *(uint64_t *)(in+(1*15+6)*8/sizeof(in[0])); out[1*16+ 6] = start + ((w5 >> 40) | (w6 << 24) & 0xfffffffffffffff)+(1*16+ 6 +1); w7 = *(uint64_t *)(in+(1*15+7)*8/sizeof(in[0])); out[1*16+ 7] = start + ((w6 >> 36) | (w7 << 28) & 0xfffffffffffffff)+(1*16+ 7 +1); w8 = *(uint64_t *)(in+(1*15+8)*8/sizeof(in[0])); out[1*16+ 8] = start + ((w7 >> 32) | (w8 << 32) & 0xfffffffffffffff)+(1*16+ 8 +1); w9 = *(uint64_t *)(in+(1*15+9)*8/sizeof(in[0])); out[1*16+ 9] = start + ((w8 >> 28) | (w9 << 36) & 0xfffffffffffffff)+(1*16+ 9 +1); w10 = *(uint64_t *)(in+(1*15+10)*8/sizeof(in[0])); out[1*16+10] = start + ((w9 >> 24) | (w10 << 40) & 0xfffffffffffffff)+(1*16+10 +1); w11 = *(uint64_t *)(in+(1*15+11)*8/sizeof(in[0])); out[1*16+11] = start + ((w10 >> 20) | (w11 << 44) & 0xfffffffffffffff)+(1*16+11 +1); w12 = *(uint64_t *)(in+(1*15+12)*8/sizeof(in[0])); out[1*16+12] = start + ((w11 >> 16) | (w12 << 48) & 0xfffffffffffffff)+(1*16+12 +1); w13 = *(uint64_t *)(in+(1*15+13)*8/sizeof(in[0])); out[1*16+13] = start + ((w12 >> 12) | (w13 << 52) & 0xfffffffffffffff)+(1*16+13 +1); w14 = *(uint64_t *)(in+(1*15+14)*8/sizeof(in[0])); out[1*16+14] = start + ((w13 >> 8) | (w14 << 56) & 0xfffffffffffffff)+(1*16+14 +1); out[1*16+15] = start + ((w14 >> 4))+(1*16+15 +1);;}; out += 32; start += 32; in += 60*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_61(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*61)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30; w0 = *(uint64_t *)(in+(0*61+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x1fffffffffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*61+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 61) | (w1 << 3) & 0x1fffffffffffffff)+(0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*61+2)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w1 >> 58) | (w2 << 6) & 0x1fffffffffffffff)+(0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*61+3)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w2 >> 55) | (w3 << 9) & 0x1fffffffffffffff)+(0*64+ 3 +1); w4 = *(uint64_t *)(in+(0*61+4)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w3 >> 52) | (w4 << 12) & 0x1fffffffffffffff)+(0*64+ 4 +1); w5 = *(uint64_t *)(in+(0*61+5)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w4 >> 49) | (w5 << 15) & 0x1fffffffffffffff)+(0*64+ 5 +1); w6 = *(uint64_t *)(in+(0*61+6)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w5 >> 46) | (w6 << 18) & 0x1fffffffffffffff)+(0*64+ 6 +1); w7 = *(uint64_t *)(in+(0*61+7)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w6 >> 43) | (w7 << 21) & 0x1fffffffffffffff)+(0*64+ 7 +1); w8 = *(uint64_t *)(in+(0*61+8)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w7 >> 40) | (w8 << 24) & 0x1fffffffffffffff)+(0*64+ 8 +1); w9 = *(uint64_t *)(in+(0*61+9)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w8 >> 37) | (w9 << 27) & 0x1fffffffffffffff)+(0*64+ 9 +1); w10 = *(uint64_t *)(in+(0*61+10)*8/sizeof(in[0])); out[0*64+10] = start + ((w9 >> 34) | (w10 << 30) & 0x1fffffffffffffff)+(0*64+10 +1); w11 = *(uint64_t *)(in+(0*61+11)*8/sizeof(in[0])); out[0*64+11] = start + ((w10 >> 31) | (w11 << 33) & 0x1fffffffffffffff)+(0*64+11 +1); w12 = *(uint64_t *)(in+(0*61+12)*8/sizeof(in[0])); out[0*64+12] = start + ((w11 >> 28) | (w12 << 36) & 0x1fffffffffffffff)+(0*64+12 +1); w13 = *(uint64_t *)(in+(0*61+13)*8/sizeof(in[0])); out[0*64+13] = start + ((w12 >> 25) | (w13 << 39) & 0x1fffffffffffffff)+(0*64+13 +1); w14 = *(uint64_t *)(in+(0*61+14)*8/sizeof(in[0])); out[0*64+14] = start + ((w13 >> 22) | (w14 << 42) & 0x1fffffffffffffff)+(0*64+14 +1); w15 = *(uint64_t *)(in+(0*61+15)*8/sizeof(in[0])); out[0*64+15] = start + ((w14 >> 19) | (w15 << 45) & 0x1fffffffffffffff)+(0*64+15 +1); w16 = *(uint64_t *)(in+(0*61+16)*8/sizeof(in[0])); out[0*64+16] = start + ((w15 >> 16) | (w16 << 48) & 0x1fffffffffffffff)+(0*64+16 +1); w17 = *(uint64_t *)(in+(0*61+17)*8/sizeof(in[0])); out[0*64+17] = start + ((w16 >> 13) | (w17 << 51) & 0x1fffffffffffffff)+(0*64+17 +1); w18 = *(uint64_t *)(in+(0*61+18)*8/sizeof(in[0])); out[0*64+18] = start + ((w17 >> 10) | (w18 << 54) & 0x1fffffffffffffff)+(0*64+18 +1); w19 = *(uint64_t *)(in+(0*61+19)*8/sizeof(in[0])); out[0*64+19] = start + ((w18 >> 7) | (w19 << 57) & 0x1fffffffffffffff)+(0*64+19 +1); w20 = *(uint64_t *)(in+(0*61+20)*8/sizeof(in[0])); out[0*64+20] = start + ((w19 >> 4) | (w20 << 60) & 0x1fffffffffffffff)+(0*64+20 +1); out[0*64+21] = start + ((w20 >> 1) & 0x1fffffffffffffff)+(0*64+21 +1); w21 = *(uint64_t *)(in+(0*61+21)*8/sizeof(in[0])); out[0*64+22] = start + ((w20 >> 62) | (w21 << 2) & 0x1fffffffffffffff)+(0*64+22 +1); w22 = *(uint64_t *)(in+(0*61+22)*8/sizeof(in[0])); out[0*64+23] = start + ((w21 >> 59) | (w22 << 5) & 0x1fffffffffffffff)+(0*64+23 +1); w23 = *(uint64_t *)(in+(0*61+23)*8/sizeof(in[0])); out[0*64+24] = start + ((w22 >> 56) | (w23 << 8) & 0x1fffffffffffffff)+(0*64+24 +1); w24 = *(uint64_t *)(in+(0*61+24)*8/sizeof(in[0])); out[0*64+25] = start + ((w23 >> 53) | (w24 << 11) & 0x1fffffffffffffff)+(0*64+25 +1); w25 = *(uint64_t *)(in+(0*61+25)*8/sizeof(in[0])); out[0*64+26] = start + ((w24 >> 50) | (w25 << 14) & 0x1fffffffffffffff)+(0*64+26 +1); w26 = *(uint64_t *)(in+(0*61+26)*8/sizeof(in[0])); out[0*64+27] = start + ((w25 >> 47) | (w26 << 17) & 0x1fffffffffffffff)+(0*64+27 +1); w27 = *(uint64_t *)(in+(0*61+27)*8/sizeof(in[0])); out[0*64+28] = start + ((w26 >> 44) | (w27 << 20) & 0x1fffffffffffffff)+(0*64+28 +1); w28 = *(uint64_t *)(in+(0*61+28)*8/sizeof(in[0])); out[0*64+29] = start + ((w27 >> 41) | (w28 << 23) & 0x1fffffffffffffff)+(0*64+29 +1); w29 = *(uint64_t *)(in+(0*61+29)*8/sizeof(in[0])); out[0*64+30] = start + ((w28 >> 38) | (w29 << 26) & 0x1fffffffffffffff)+(0*64+30 +1); w30 = *(uint32_t *)(in+(0*61+30)*8/sizeof(in[0])); out[0*64+31] = start + ((w29 >> 35) | (w30 << 29) & 0x1fffffffffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 61*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_62(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*62)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30; w0 = *(uint64_t *)(in+(0*31+0)*8/sizeof(in[0])); out[0*32+ 0] = start + ((w0 ) & 0x3fffffffffffffff)+(0*32+ 0 +1); w1 = *(uint64_t *)(in+(0*31+1)*8/sizeof(in[0])); out[0*32+ 1] = start + ((w0 >> 62) | (w1 << 2) & 0x3fffffffffffffff)+(0*32+ 1 +1); w2 = *(uint64_t *)(in+(0*31+2)*8/sizeof(in[0])); out[0*32+ 2] = start + ((w1 >> 60) | (w2 << 4) & 0x3fffffffffffffff)+(0*32+ 2 +1); w3 = *(uint64_t *)(in+(0*31+3)*8/sizeof(in[0])); out[0*32+ 3] = start + ((w2 >> 58) | (w3 << 6) & 0x3fffffffffffffff)+(0*32+ 3 +1); w4 = *(uint64_t *)(in+(0*31+4)*8/sizeof(in[0])); out[0*32+ 4] = start + ((w3 >> 56) | (w4 << 8) & 0x3fffffffffffffff)+(0*32+ 4 +1); w5 = *(uint64_t *)(in+(0*31+5)*8/sizeof(in[0])); out[0*32+ 5] = start + ((w4 >> 54) | (w5 << 10) & 0x3fffffffffffffff)+(0*32+ 5 +1); w6 = *(uint64_t *)(in+(0*31+6)*8/sizeof(in[0])); out[0*32+ 6] = start + ((w5 >> 52) | (w6 << 12) & 0x3fffffffffffffff)+(0*32+ 6 +1); w7 = *(uint64_t *)(in+(0*31+7)*8/sizeof(in[0])); out[0*32+ 7] = start + ((w6 >> 50) | (w7 << 14) & 0x3fffffffffffffff)+(0*32+ 7 +1); w8 = *(uint64_t *)(in+(0*31+8)*8/sizeof(in[0])); out[0*32+ 8] = start + ((w7 >> 48) | (w8 << 16) & 0x3fffffffffffffff)+(0*32+ 8 +1); w9 = *(uint64_t *)(in+(0*31+9)*8/sizeof(in[0])); out[0*32+ 9] = start + ((w8 >> 46) | (w9 << 18) & 0x3fffffffffffffff)+(0*32+ 9 +1); w10 = *(uint64_t *)(in+(0*31+10)*8/sizeof(in[0])); out[0*32+10] = start + ((w9 >> 44) | (w10 << 20) & 0x3fffffffffffffff)+(0*32+10 +1); w11 = *(uint64_t *)(in+(0*31+11)*8/sizeof(in[0])); out[0*32+11] = start + ((w10 >> 42) | (w11 << 22) & 0x3fffffffffffffff)+(0*32+11 +1); w12 = *(uint64_t *)(in+(0*31+12)*8/sizeof(in[0])); out[0*32+12] = start + ((w11 >> 40) | (w12 << 24) & 0x3fffffffffffffff)+(0*32+12 +1); w13 = *(uint64_t *)(in+(0*31+13)*8/sizeof(in[0])); out[0*32+13] = start + ((w12 >> 38) | (w13 << 26) & 0x3fffffffffffffff)+(0*32+13 +1); w14 = *(uint64_t *)(in+(0*31+14)*8/sizeof(in[0])); out[0*32+14] = start + ((w13 >> 36) | (w14 << 28) & 0x3fffffffffffffff)+(0*32+14 +1); w15 = *(uint64_t *)(in+(0*31+15)*8/sizeof(in[0])); out[0*32+15] = start + ((w14 >> 34) | (w15 << 30) & 0x3fffffffffffffff)+(0*32+15 +1); w16 = *(uint64_t *)(in+(0*31+16)*8/sizeof(in[0])); out[0*32+16] = start + ((w15 >> 32) | (w16 << 32) & 0x3fffffffffffffff)+(0*32+16 +1); w17 = *(uint64_t *)(in+(0*31+17)*8/sizeof(in[0])); out[0*32+17] = start + ((w16 >> 30) | (w17 << 34) & 0x3fffffffffffffff)+(0*32+17 +1); w18 = *(uint64_t *)(in+(0*31+18)*8/sizeof(in[0])); out[0*32+18] = start + ((w17 >> 28) | (w18 << 36) & 0x3fffffffffffffff)+(0*32+18 +1); w19 = *(uint64_t *)(in+(0*31+19)*8/sizeof(in[0])); out[0*32+19] = start + ((w18 >> 26) | (w19 << 38) & 0x3fffffffffffffff)+(0*32+19 +1); w20 = *(uint64_t *)(in+(0*31+20)*8/sizeof(in[0])); out[0*32+20] = start + ((w19 >> 24) | (w20 << 40) & 0x3fffffffffffffff)+(0*32+20 +1); w21 = *(uint64_t *)(in+(0*31+21)*8/sizeof(in[0])); out[0*32+21] = start + ((w20 >> 22) | (w21 << 42) & 0x3fffffffffffffff)+(0*32+21 +1); w22 = *(uint64_t *)(in+(0*31+22)*8/sizeof(in[0])); out[0*32+22] = start + ((w21 >> 20) | (w22 << 44) & 0x3fffffffffffffff)+(0*32+22 +1); w23 = *(uint64_t *)(in+(0*31+23)*8/sizeof(in[0])); out[0*32+23] = start + ((w22 >> 18) | (w23 << 46) & 0x3fffffffffffffff)+(0*32+23 +1); w24 = *(uint64_t *)(in+(0*31+24)*8/sizeof(in[0])); out[0*32+24] = start + ((w23 >> 16) | (w24 << 48) & 0x3fffffffffffffff)+(0*32+24 +1); w25 = *(uint64_t *)(in+(0*31+25)*8/sizeof(in[0])); out[0*32+25] = start + ((w24 >> 14) | (w25 << 50) & 0x3fffffffffffffff)+(0*32+25 +1); w26 = *(uint64_t *)(in+(0*31+26)*8/sizeof(in[0])); out[0*32+26] = start + ((w25 >> 12) | (w26 << 52) & 0x3fffffffffffffff)+(0*32+26 +1); w27 = *(uint64_t *)(in+(0*31+27)*8/sizeof(in[0])); out[0*32+27] = start + ((w26 >> 10) | (w27 << 54) & 0x3fffffffffffffff)+(0*32+27 +1); w28 = *(uint64_t *)(in+(0*31+28)*8/sizeof(in[0])); out[0*32+28] = start + ((w27 >> 8) | (w28 << 56) & 0x3fffffffffffffff)+(0*32+28 +1); w29 = *(uint64_t *)(in+(0*31+29)*8/sizeof(in[0])); out[0*32+29] = start + ((w28 >> 6) | (w29 << 58) & 0x3fffffffffffffff)+(0*32+29 +1); w30 = *(uint64_t *)(in+(0*31+30)*8/sizeof(in[0])); out[0*32+30] = start + ((w29 >> 4) | (w30 << 60) & 0x3fffffffffffffff)+(0*32+30 +1); out[0*32+31] = start + ((w30 >> 2))+(0*32+31 +1);;}; out += 32; start += 32; in += 62*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_63(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*63)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(0*63+0)*8/sizeof(in[0])); out[0*64+ 0] = start + ((w0 ) & 0x7fffffffffffffff)+(0*64+ 0 +1); w1 = *(uint64_t *)(in+(0*63+1)*8/sizeof(in[0])); out[0*64+ 1] = start + ((w0 >> 63) | (w1 << 1) & 0x7fffffffffffffff)+(0*64+ 1 +1); w2 = *(uint64_t *)(in+(0*63+2)*8/sizeof(in[0])); out[0*64+ 2] = start + ((w1 >> 62) | (w2 << 2) & 0x7fffffffffffffff)+(0*64+ 2 +1); w3 = *(uint64_t *)(in+(0*63+3)*8/sizeof(in[0])); out[0*64+ 3] = start + ((w2 >> 61) | (w3 << 3) & 0x7fffffffffffffff)+(0*64+ 3 +1); w4 = *(uint64_t *)(in+(0*63+4)*8/sizeof(in[0])); out[0*64+ 4] = start + ((w3 >> 60) | (w4 << 4) & 0x7fffffffffffffff)+(0*64+ 4 +1); w5 = *(uint64_t *)(in+(0*63+5)*8/sizeof(in[0])); out[0*64+ 5] = start + ((w4 >> 59) | (w5 << 5) & 0x7fffffffffffffff)+(0*64+ 5 +1); w6 = *(uint64_t *)(in+(0*63+6)*8/sizeof(in[0])); out[0*64+ 6] = start + ((w5 >> 58) | (w6 << 6) & 0x7fffffffffffffff)+(0*64+ 6 +1); w7 = *(uint64_t *)(in+(0*63+7)*8/sizeof(in[0])); out[0*64+ 7] = start + ((w6 >> 57) | (w7 << 7) & 0x7fffffffffffffff)+(0*64+ 7 +1); w8 = *(uint64_t *)(in+(0*63+8)*8/sizeof(in[0])); out[0*64+ 8] = start + ((w7 >> 56) | (w8 << 8) & 0x7fffffffffffffff)+(0*64+ 8 +1); w9 = *(uint64_t *)(in+(0*63+9)*8/sizeof(in[0])); out[0*64+ 9] = start + ((w8 >> 55) | (w9 << 9) & 0x7fffffffffffffff)+(0*64+ 9 +1); w10 = *(uint64_t *)(in+(0*63+10)*8/sizeof(in[0])); out[0*64+10] = start + ((w9 >> 54) | (w10 << 10) & 0x7fffffffffffffff)+(0*64+10 +1); w11 = *(uint64_t *)(in+(0*63+11)*8/sizeof(in[0])); out[0*64+11] = start + ((w10 >> 53) | (w11 << 11) & 0x7fffffffffffffff)+(0*64+11 +1); w12 = *(uint64_t *)(in+(0*63+12)*8/sizeof(in[0])); out[0*64+12] = start + ((w11 >> 52) | (w12 << 12) & 0x7fffffffffffffff)+(0*64+12 +1); w13 = *(uint64_t *)(in+(0*63+13)*8/sizeof(in[0])); out[0*64+13] = start + ((w12 >> 51) | (w13 << 13) & 0x7fffffffffffffff)+(0*64+13 +1); w14 = *(uint64_t *)(in+(0*63+14)*8/sizeof(in[0])); out[0*64+14] = start + ((w13 >> 50) | (w14 << 14) & 0x7fffffffffffffff)+(0*64+14 +1); w15 = *(uint64_t *)(in+(0*63+15)*8/sizeof(in[0])); out[0*64+15] = start + ((w14 >> 49) | (w15 << 15) & 0x7fffffffffffffff)+(0*64+15 +1); w16 = *(uint64_t *)(in+(0*63+16)*8/sizeof(in[0])); out[0*64+16] = start + ((w15 >> 48) | (w16 << 16) & 0x7fffffffffffffff)+(0*64+16 +1); w17 = *(uint64_t *)(in+(0*63+17)*8/sizeof(in[0])); out[0*64+17] = start + ((w16 >> 47) | (w17 << 17) & 0x7fffffffffffffff)+(0*64+17 +1); w18 = *(uint64_t *)(in+(0*63+18)*8/sizeof(in[0])); out[0*64+18] = start + ((w17 >> 46) | (w18 << 18) & 0x7fffffffffffffff)+(0*64+18 +1); w19 = *(uint64_t *)(in+(0*63+19)*8/sizeof(in[0])); out[0*64+19] = start + ((w18 >> 45) | (w19 << 19) & 0x7fffffffffffffff)+(0*64+19 +1); w20 = *(uint64_t *)(in+(0*63+20)*8/sizeof(in[0])); out[0*64+20] = start + ((w19 >> 44) | (w20 << 20) & 0x7fffffffffffffff)+(0*64+20 +1); w21 = *(uint64_t *)(in+(0*63+21)*8/sizeof(in[0])); out[0*64+21] = start + ((w20 >> 43) | (w21 << 21) & 0x7fffffffffffffff)+(0*64+21 +1); w22 = *(uint64_t *)(in+(0*63+22)*8/sizeof(in[0])); out[0*64+22] = start + ((w21 >> 42) | (w22 << 22) & 0x7fffffffffffffff)+(0*64+22 +1); w23 = *(uint64_t *)(in+(0*63+23)*8/sizeof(in[0])); out[0*64+23] = start + ((w22 >> 41) | (w23 << 23) & 0x7fffffffffffffff)+(0*64+23 +1); w24 = *(uint64_t *)(in+(0*63+24)*8/sizeof(in[0])); out[0*64+24] = start + ((w23 >> 40) | (w24 << 24) & 0x7fffffffffffffff)+(0*64+24 +1); w25 = *(uint64_t *)(in+(0*63+25)*8/sizeof(in[0])); out[0*64+25] = start + ((w24 >> 39) | (w25 << 25) & 0x7fffffffffffffff)+(0*64+25 +1); w26 = *(uint64_t *)(in+(0*63+26)*8/sizeof(in[0])); out[0*64+26] = start + ((w25 >> 38) | (w26 << 26) & 0x7fffffffffffffff)+(0*64+26 +1); w27 = *(uint64_t *)(in+(0*63+27)*8/sizeof(in[0])); out[0*64+27] = start + ((w26 >> 37) | (w27 << 27) & 0x7fffffffffffffff)+(0*64+27 +1); w28 = *(uint64_t *)(in+(0*63+28)*8/sizeof(in[0])); out[0*64+28] = start + ((w27 >> 36) | (w28 << 28) & 0x7fffffffffffffff)+(0*64+28 +1); w29 = *(uint64_t *)(in+(0*63+29)*8/sizeof(in[0])); out[0*64+29] = start + ((w28 >> 35) | (w29 << 29) & 0x7fffffffffffffff)+(0*64+29 +1); w30 = *(uint64_t *)(in+(0*63+30)*8/sizeof(in[0])); out[0*64+30] = start + ((w29 >> 34) | (w30 << 30) & 0x7fffffffffffffff)+(0*64+30 +1); w31 = *(uint32_t *)(in+(0*63+31)*8/sizeof(in[0])); out[0*64+31] = start + ((w30 >> 33) | (w31 << 31) & 0x7fffffffffffffff)+(0*64+31 +1);;}; out += 32; start += 32; in += 63*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
unsigned char *bitf1unpack64_64(const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start ) { unsigned char *in_=in+(((n*64)+7)/8),x=0; do { { { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(0*1+0)*8/sizeof(in[0])); out[0*1+ 0] = start + ((w0 ))+(0*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(1*1+0)*8/sizeof(in[0])); out[1*1+ 0] = start + ((w0 ))+(1*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(2*1+0)*8/sizeof(in[0])); out[2*1+ 0] = start + ((w0 ))+(2*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(3*1+0)*8/sizeof(in[0])); out[3*1+ 0] = start + ((w0 ))+(3*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(4*1+0)*8/sizeof(in[0])); out[4*1+ 0] = start + ((w0 ))+(4*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(5*1+0)*8/sizeof(in[0])); out[5*1+ 0] = start + ((w0 ))+(5*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(6*1+0)*8/sizeof(in[0])); out[6*1+ 0] = start + ((w0 ))+(6*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(7*1+0)*8/sizeof(in[0])); out[7*1+ 0] = start + ((w0 ))+(7*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(8*1+0)*8/sizeof(in[0])); out[8*1+ 0] = start + ((w0 ))+(8*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(9*1+0)*8/sizeof(in[0])); out[9*1+ 0] = start + ((w0 ))+(9*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(10*1+0)*8/sizeof(in[0])); out[10*1+ 0] = start + ((w0 ))+(10*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(11*1+0)*8/sizeof(in[0])); out[11*1+ 0] = start + ((w0 ))+(11*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(12*1+0)*8/sizeof(in[0])); out[12*1+ 0] = start + ((w0 ))+(12*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(13*1+0)*8/sizeof(in[0])); out[13*1+ 0] = start + ((w0 ))+(13*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(14*1+0)*8/sizeof(in[0])); out[14*1+ 0] = start + ((w0 ))+(14*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(15*1+0)*8/sizeof(in[0])); out[15*1+ 0] = start + ((w0 ))+(15*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(16*1+0)*8/sizeof(in[0])); out[16*1+ 0] = start + ((w0 ))+(16*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(17*1+0)*8/sizeof(in[0])); out[17*1+ 0] = start + ((w0 ))+(17*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(18*1+0)*8/sizeof(in[0])); out[18*1+ 0] = start + ((w0 ))+(18*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(19*1+0)*8/sizeof(in[0])); out[19*1+ 0] = start + ((w0 ))+(19*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(20*1+0)*8/sizeof(in[0])); out[20*1+ 0] = start + ((w0 ))+(20*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(21*1+0)*8/sizeof(in[0])); out[21*1+ 0] = start + ((w0 ))+(21*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(22*1+0)*8/sizeof(in[0])); out[22*1+ 0] = start + ((w0 ))+(22*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(23*1+0)*8/sizeof(in[0])); out[23*1+ 0] = start + ((w0 ))+(23*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(24*1+0)*8/sizeof(in[0])); out[24*1+ 0] = start + ((w0 ))+(24*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(25*1+0)*8/sizeof(in[0])); out[25*1+ 0] = start + ((w0 ))+(25*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(26*1+0)*8/sizeof(in[0])); out[26*1+ 0] = start + ((w0 ))+(26*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(27*1+0)*8/sizeof(in[0])); out[27*1+ 0] = start + ((w0 ))+(27*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(28*1+0)*8/sizeof(in[0])); out[28*1+ 0] = start + ((w0 ))+(28*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(29*1+0)*8/sizeof(in[0])); out[29*1+ 0] = start + ((w0 ))+(29*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(30*1+0)*8/sizeof(in[0])); out[30*1+ 0] = start + ((w0 ))+(30*1+ 0 +1);;}; { uint64_t w0,w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15,w16,w17,w18,w19,w20,w21,w22,w23,w24,w25,w26,w27,w28,w29,w30,w31; w0 = *(uint64_t *)(in+(31*1+0)*8/sizeof(in[0])); out[31*1+ 0] = start + ((w0 ))+(31*1+ 0 +1);;}; out += 32; start += 32; in += 64*4/sizeof(in[0]);}; __builtin_prefetch(in+512,0); } while(in<in_); return in_; }
BITUNPACK_D64 bitf1unpacka64[] = {
  &bitf1unpack64_0,
  &bitf1unpack64_1,
  &bitf1unpack64_2,
  &bitf1unpack64_3,
  &bitf1unpack64_4,
  &bitf1unpack64_5,
  &bitf1unpack64_6,
  &bitf1unpack64_7,
  &bitf1unpack64_8,
  &bitf1unpack64_9,
  &bitf1unpack64_10,
  &bitf1unpack64_11,
  &bitf1unpack64_12,
  &bitf1unpack64_13,
  &bitf1unpack64_14,
  &bitf1unpack64_15,
  &bitf1unpack64_16,
  &bitf1unpack64_17,
  &bitf1unpack64_18,
  &bitf1unpack64_19,
  &bitf1unpack64_20,
  &bitf1unpack64_21,
  &bitf1unpack64_22,
  &bitf1unpack64_23,
  &bitf1unpack64_24,
  &bitf1unpack64_25,
  &bitf1unpack64_26,
  &bitf1unpack64_27,
  &bitf1unpack64_28,
  &bitf1unpack64_29,
  &bitf1unpack64_30,
  &bitf1unpack64_31,
  &bitf1unpack64_32,
  &bitf1unpack64_33,
  &bitf1unpack64_34,
  &bitf1unpack64_35,
  &bitf1unpack64_36,
  &bitf1unpack64_37,
  &bitf1unpack64_38,
  &bitf1unpack64_39,
  &bitf1unpack64_40,
  &bitf1unpack64_41,
  &bitf1unpack64_42,
  &bitf1unpack64_43,
  &bitf1unpack64_44,
  &bitf1unpack64_45,
  &bitf1unpack64_46,
  &bitf1unpack64_47,
  &bitf1unpack64_48,
  &bitf1unpack64_49,
  &bitf1unpack64_50,
  &bitf1unpack64_51,
  &bitf1unpack64_52,
  &bitf1unpack64_53,
  &bitf1unpack64_54,
  &bitf1unpack64_55,
  &bitf1unpack64_56,
  &bitf1unpack64_57,
  &bitf1unpack64_58,
  &bitf1unpack64_59,
  &bitf1unpack64_60,
  &bitf1unpack64_61,
  &bitf1unpack64_62,
  &bitf1unpack64_63,
  &bitf1unpack64_64
};
unsigned char *bitf1unpack64( const unsigned char *__restrict in, unsigned n, uint64_t *__restrict out , uint64_t start, unsigned b) { return bitf1unpacka64[ b](in, n, out, start); }
size_t bitnunpack8( unsigned char *__restrict in, size_t n, uint8_t *__restrict out) { uint8_t *op; { unsigned char *ip = in; for(op = out,out+=n; op < out;) { unsigned oplen = out - op,b; if(oplen > 128) oplen = 128; __builtin_prefetch(in+512 +512,0); b = *ip++; ip = bitunpacka8[b](ip, oplen, op); op += oplen; } return ip - in;}; }
size_t bitnunpack16( unsigned char *__restrict in, size_t n, uint16_t *__restrict out) { uint16_t *op; { unsigned char *ip = in; for(op = out,out+=n; op < out;) { unsigned oplen = out - op,b; if(oplen > 128) oplen = 128; __builtin_prefetch(in+512 +512,0); b = *ip++; ip = bitunpacka16[b](ip, oplen, op); op += oplen; } return ip - in;}; }
size_t bitnunpack32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out) { uint32_t *op; { unsigned char *ip = in; for(op = out,out+=n; op < out;) { unsigned oplen = out - op,b; if(oplen > 128) oplen = 128; __builtin_prefetch(in+512 +512,0); b = *ip++; ip = bitunpacka32[b](ip, oplen, op); op += oplen; } return ip - in;}; }
size_t bitnunpack64( unsigned char *__restrict in, size_t n, uint64_t *__restrict out) { uint64_t *op; { unsigned char *ip = in; for(op = out,out+=n; op < out;) { unsigned oplen = out - op,b; if(oplen > 128) oplen = 128; __builtin_prefetch(in+512 +512,0); b = *ip++; ip = bitunpacka64[b](ip, oplen, op); op += oplen; } return ip - in;}; }
size_t bitndunpack8( unsigned char *__restrict in, size_t n, uint8_t *__restrict out) { uint8_t *op,start; { if(!n) return 0; unsigned char *ip = in; (start = *ip++); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitdunpacka8[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitdunpacka8[b](ip, n, op, start); } return ip - in;}; }
size_t bitndunpack16( unsigned char *__restrict in, size_t n, uint16_t *__restrict out) { uint16_t *op,start; { if(!n) return 0; unsigned char *ip = in; do { start = (unsigned)(*ip++); if(!(start & 0x80u)) { ;;} else if(!(start & 0x40u)) { start = __builtin_bswap16((*(unsigned short *)(ip - 1)) & 0xff3fu); ip++; ;;} else if(!(start & 0x20u)) { start = (start & 0x1f)<<16 | (*(unsigned short *)(ip)); ip += 2; ;;} else if(!(start & 0x10u)) { start = __builtin_bswap32((*(unsigned *)(ip-1)) & 0xffffff0fu); ip += 3; ;;} else { start = (unsigned long long)((start) & 0x07)<<32 | (*(unsigned *)(ip)); ip += 4; ;;}} while(0); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitdunpacka16[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitdunpacka16[b](ip, n, op, start); } return ip - in;}; }
size_t bitndunpack32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out) { uint32_t *op,start; { if(!n) return 0; unsigned char *ip = in; do { start = (unsigned)(*ip++); if(!(start & 0x80u)) { ;;} else if(!(start & 0x40u)) { start = __builtin_bswap16((*(unsigned short *)(ip - 1)) & 0xff3fu); ip++; ;;} else if(!(start & 0x20u)) { start = (start & 0x1f)<<16 | (*(unsigned short *)(ip)); ip += 2; ;;} else if(!(start & 0x10u)) { start = __builtin_bswap32((*(unsigned *)(ip-1)) & 0xffffff0fu); ip += 3; ;;} else { start = (unsigned long long)((start) & 0x07)<<32 | (*(unsigned *)(ip)); ip += 4; ;;}} while(0); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitdunpacka32[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitdunpacka32[b](ip, n, op, start); } return ip - in;}; }
size_t bitndunpack64( unsigned char *__restrict in, size_t n, uint64_t *__restrict out) { uint64_t *op,start; { if(!n) return 0; unsigned char *ip = in; do { start = *ip++; if(!(start & 0x80)) { ;;} else if(!(start & 0x40)) { start = __builtin_bswap16((*(unsigned short *)(ip++-1)) & 0xff3f); ;;} else if(!(start & 0x20)) { start = (start & 0x1f)<<16 | (*(unsigned short *)(ip)); ip += 2; ;;} else if(!(start & 0x10)) { start = __builtin_bswap32((*(unsigned *)(ip-1)) & 0xffffff0f); ip += 3; ;;} else if(!(start & 0x08)) { start = (start & 0x07)<<32 | (*(unsigned *)(ip)); ip += 4; ;;} else if(!(start & 0x04)) { start = (unsigned long long)(__builtin_bswap16((*(unsigned short *)(ip-1))) & 0x7ff) << 32 | (*(unsigned *)(ip+1)); ip += 5; ;;} else if(!(start & 0x02)) { start = (start & 0x03)<<48 | (unsigned long long)(*(unsigned short *)(ip)) << 32 | (*(unsigned *)(ip+2)); ip += 6; ;;} else if(!(start & 0x01)) { start = __builtin_bswap64((*(uint64_t *)(ip-1))) & 0x01ffffffffffffffull; ip += 7; ;;} else { start = (*(uint64_t *)(ip)); ip += 8; ;;}} while(0); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitdunpacka64[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitdunpacka64[b](ip, n, op, start); } return ip - in;}; }
size_t bitnd1unpack8( unsigned char *__restrict in, size_t n, uint8_t *__restrict out) { uint8_t *op,start; { if(!n) return 0; unsigned char *ip = in; (start = *ip++); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitd1unpacka8[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitd1unpacka8[b](ip, n, op, start); } return ip - in;}; }
size_t bitnd1unpack16(unsigned char *__restrict in, size_t n, uint16_t *__restrict out) { uint16_t *op,start; { if(!n) return 0; unsigned char *ip = in; do { start = (unsigned)(*ip++); if(!(start & 0x80u)) { ;;} else if(!(start & 0x40u)) { start = __builtin_bswap16((*(unsigned short *)(ip - 1)) & 0xff3fu); ip++; ;;} else if(!(start & 0x20u)) { start = (start & 0x1f)<<16 | (*(unsigned short *)(ip)); ip += 2; ;;} else if(!(start & 0x10u)) { start = __builtin_bswap32((*(unsigned *)(ip-1)) & 0xffffff0fu); ip += 3; ;;} else { start = (unsigned long long)((start) & 0x07)<<32 | (*(unsigned *)(ip)); ip += 4; ;;}} while(0); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitd1unpacka16[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitd1unpacka16[b](ip, n, op, start); } return ip - in;}; }
size_t bitnd1unpack32(unsigned char *__restrict in, size_t n, uint32_t *__restrict out) { uint32_t *op,start; { if(!n) return 0; unsigned char *ip = in; do { start = (unsigned)(*ip++); if(!(start & 0x80u)) { ;;} else if(!(start & 0x40u)) { start = __builtin_bswap16((*(unsigned short *)(ip - 1)) & 0xff3fu); ip++; ;;} else if(!(start & 0x20u)) { start = (start & 0x1f)<<16 | (*(unsigned short *)(ip)); ip += 2; ;;} else if(!(start & 0x10u)) { start = __builtin_bswap32((*(unsigned *)(ip-1)) & 0xffffff0fu); ip += 3; ;;} else { start = (unsigned long long)((start) & 0x07)<<32 | (*(unsigned *)(ip)); ip += 4; ;;}} while(0); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitd1unpacka32[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitd1unpacka32[b](ip, n, op, start); } return ip - in;}; }
size_t bitnd1unpack64(unsigned char *__restrict in, size_t n, uint64_t *__restrict out) { uint64_t *op,start; { if(!n) return 0; unsigned char *ip = in; do { start = *ip++; if(!(start & 0x80)) { ;;} else if(!(start & 0x40)) { start = __builtin_bswap16((*(unsigned short *)(ip++-1)) & 0xff3f); ;;} else if(!(start & 0x20)) { start = (start & 0x1f)<<16 | (*(unsigned short *)(ip)); ip += 2; ;;} else if(!(start & 0x10)) { start = __builtin_bswap32((*(unsigned *)(ip-1)) & 0xffffff0f); ip += 3; ;;} else if(!(start & 0x08)) { start = (start & 0x07)<<32 | (*(unsigned *)(ip)); ip += 4; ;;} else if(!(start & 0x04)) { start = (unsigned long long)(__builtin_bswap16((*(unsigned short *)(ip-1))) & 0x7ff) << 32 | (*(unsigned *)(ip+1)); ip += 5; ;;} else if(!(start & 0x02)) { start = (start & 0x03)<<48 | (unsigned long long)(*(unsigned short *)(ip)) << 32 | (*(unsigned *)(ip+2)); ip += 6; ;;} else if(!(start & 0x01)) { start = __builtin_bswap64((*(uint64_t *)(ip-1))) & 0x01ffffffffffffffull; ip += 7; ;;} else { start = (*(uint64_t *)(ip)); ip += 8; ;;}} while(0); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitd1unpacka64[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitd1unpacka64[b](ip, n, op, start); } return ip - in;}; }
size_t bitnzunpack8( unsigned char *__restrict in, size_t n, uint8_t *__restrict out) { uint8_t *op,start; { if(!n) return 0; unsigned char *ip = in; (start = *ip++); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitzunpacka8[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitzunpacka8[b](ip, n, op, start); } return ip - in;}; }
size_t bitnzunpack16( unsigned char *__restrict in, size_t n, uint16_t *__restrict out) { uint16_t *op,start; { if(!n) return 0; unsigned char *ip = in; do { start = (unsigned)(*ip++); if(!(start & 0x80u)) { ;;} else if(!(start & 0x40u)) { start = __builtin_bswap16((*(unsigned short *)(ip - 1)) & 0xff3fu); ip++; ;;} else if(!(start & 0x20u)) { start = (start & 0x1f)<<16 | (*(unsigned short *)(ip)); ip += 2; ;;} else if(!(start & 0x10u)) { start = __builtin_bswap32((*(unsigned *)(ip-1)) & 0xffffff0fu); ip += 3; ;;} else { start = (unsigned long long)((start) & 0x07)<<32 | (*(unsigned *)(ip)); ip += 4; ;;}} while(0); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitzunpacka16[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitzunpacka16[b](ip, n, op, start); } return ip - in;}; }
size_t bitnzunpack32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out) { uint32_t *op,start; { if(!n) return 0; unsigned char *ip = in; do { start = (unsigned)(*ip++); if(!(start & 0x80u)) { ;;} else if(!(start & 0x40u)) { start = __builtin_bswap16((*(unsigned short *)(ip - 1)) & 0xff3fu); ip++; ;;} else if(!(start & 0x20u)) { start = (start & 0x1f)<<16 | (*(unsigned short *)(ip)); ip += 2; ;;} else if(!(start & 0x10u)) { start = __builtin_bswap32((*(unsigned *)(ip-1)) & 0xffffff0fu); ip += 3; ;;} else { start = (unsigned long long)((start) & 0x07)<<32 | (*(unsigned *)(ip)); ip += 4; ;;}} while(0); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitzunpacka32[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitzunpacka32[b](ip, n, op, start); } return ip - in;}; }
size_t bitnzunpack64( unsigned char *__restrict in, size_t n, uint64_t *__restrict out) { uint64_t *op,start; { if(!n) return 0; unsigned char *ip = in; do { start = *ip++; if(!(start & 0x80)) { ;;} else if(!(start & 0x40)) { start = __builtin_bswap16((*(unsigned short *)(ip++-1)) & 0xff3f); ;;} else if(!(start & 0x20)) { start = (start & 0x1f)<<16 | (*(unsigned short *)(ip)); ip += 2; ;;} else if(!(start & 0x10)) { start = __builtin_bswap32((*(unsigned *)(ip-1)) & 0xffffff0f); ip += 3; ;;} else if(!(start & 0x08)) { start = (start & 0x07)<<32 | (*(unsigned *)(ip)); ip += 4; ;;} else if(!(start & 0x04)) { start = (unsigned long long)(__builtin_bswap16((*(unsigned short *)(ip-1))) & 0x7ff) << 32 | (*(unsigned *)(ip+1)); ip += 5; ;;} else if(!(start & 0x02)) { start = (start & 0x03)<<48 | (unsigned long long)(*(unsigned short *)(ip)) << 32 | (*(unsigned *)(ip+2)); ip += 6; ;;} else if(!(start & 0x01)) { start = __builtin_bswap64((*(uint64_t *)(ip-1))) & 0x01ffffffffffffffull; ip += 7; ;;} else { start = (*(uint64_t *)(ip)); ip += 8; ;;}} while(0); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitzunpacka64[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitzunpacka64[b](ip, n, op, start); } return ip - in;}; }
size_t bitnfunpack8( unsigned char *__restrict in, size_t n, uint8_t *__restrict out) { uint8_t *op,start; { if(!n) return 0; unsigned char *ip = in; (start = *ip++); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitfunpacka8[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitfunpacka8[b](ip, n, op, start); } return ip - in;}; }
size_t bitnfunpack16( unsigned char *__restrict in, size_t n, uint16_t *__restrict out) { uint16_t *op,start; { if(!n) return 0; unsigned char *ip = in; do { start = (unsigned)(*ip++); if(!(start & 0x80u)) { ;;} else if(!(start & 0x40u)) { start = __builtin_bswap16((*(unsigned short *)(ip - 1)) & 0xff3fu); ip++; ;;} else if(!(start & 0x20u)) { start = (start & 0x1f)<<16 | (*(unsigned short *)(ip)); ip += 2; ;;} else if(!(start & 0x10u)) { start = __builtin_bswap32((*(unsigned *)(ip-1)) & 0xffffff0fu); ip += 3; ;;} else { start = (unsigned long long)((start) & 0x07)<<32 | (*(unsigned *)(ip)); ip += 4; ;;}} while(0); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitfunpacka16[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitfunpacka16[b](ip, n, op, start); } return ip - in;}; }
size_t bitnfunpack32( unsigned char *__restrict in, size_t n, uint32_t *__restrict out) { uint32_t *op,start; { if(!n) return 0; unsigned char *ip = in; do { start = (unsigned)(*ip++); if(!(start & 0x80u)) { ;;} else if(!(start & 0x40u)) { start = __builtin_bswap16((*(unsigned short *)(ip - 1)) & 0xff3fu); ip++; ;;} else if(!(start & 0x20u)) { start = (start & 0x1f)<<16 | (*(unsigned short *)(ip)); ip += 2; ;;} else if(!(start & 0x10u)) { start = __builtin_bswap32((*(unsigned *)(ip-1)) & 0xffffff0fu); ip += 3; ;;} else { start = (unsigned long long)((start) & 0x07)<<32 | (*(unsigned *)(ip)); ip += 4; ;;}} while(0); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitfunpacka32[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitfunpacka32[b](ip, n, op, start); } return ip - in;}; }
size_t bitnfunpack64( unsigned char *__restrict in, size_t n, uint64_t *__restrict out) { uint64_t *op,start; { if(!n) return 0; unsigned char *ip = in; do { start = *ip++; if(!(start & 0x80)) { ;;} else if(!(start & 0x40)) { start = __builtin_bswap16((*(unsigned short *)(ip++-1)) & 0xff3f); ;;} else if(!(start & 0x20)) { start = (start & 0x1f)<<16 | (*(unsigned short *)(ip)); ip += 2; ;;} else if(!(start & 0x10)) { start = __builtin_bswap32((*(unsigned *)(ip-1)) & 0xffffff0f); ip += 3; ;;} else if(!(start & 0x08)) { start = (start & 0x07)<<32 | (*(unsigned *)(ip)); ip += 4; ;;} else if(!(start & 0x04)) { start = (unsigned long long)(__builtin_bswap16((*(unsigned short *)(ip-1))) & 0x7ff) << 32 | (*(unsigned *)(ip+1)); ip += 5; ;;} else if(!(start & 0x02)) { start = (start & 0x03)<<48 | (unsigned long long)(*(unsigned short *)(ip)) << 32 | (*(unsigned *)(ip+2)); ip += 6; ;;} else if(!(start & 0x01)) { start = __builtin_bswap64((*(uint64_t *)(ip-1))) & 0x01ffffffffffffffull; ip += 7; ;;} else { start = (*(uint64_t *)(ip)); ip += 8; ;;}} while(0); for(*out++ = start,--n,op = out; op != out+(n&~(128 -1)); ) { __builtin_prefetch(ip+512 +512,0); unsigned b = *ip++; ip = bitfunpacka64[b](ip, 128, op, start); op += 128; start = op[-1]; } if(n&=(128 -1)) { unsigned b = *ip++; ip = bitfunpacka64[b](ip, n, op, start); } return ip - in;}; }
#pragma clang diagnostic pop
#pragma GCC pop_options
